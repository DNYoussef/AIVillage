# Phase 8: Neural Network Compression

**Advanced compression pipeline for deployment-ready neural network optimization**

## Overview

Phase 8 Compression represents the final optimization stage in the AIVillage agent forge pipeline. It receives models from Phase 7 ADAS (Advanced Driver Assistance Systems) and applies comprehensive compression techniques to create deployment-ready models optimized for various target platforms.

### Key Features

- **9 Specialized Compression Agents**: Each agent handles specific aspects of the compression pipeline
- **Multi-Technique Compression**: Supports pruning, quantization, knowledge distillation, and architecture optimization
- **Advanced Optimization**: Multi-objective hyperparameter optimization with Pareto front analysis
- **Comprehensive Validation**: Quality assurance with accuracy, performance, and deployment readiness checks
- **Deployment Packaging**: Creates deployment-ready packages for various runtime environments
- **Performance Profiling**: Detailed performance analysis and benchmarking

## Architecture

```
phase8_compression/
â”œâ”€â”€ agents/                     # 9 compression agents
â”‚   â”œâ”€â”€ model_analyzer.py           # Model structure analysis
â”‚   â”œâ”€â”€ pruning_agent.py            # Neural network pruning
â”‚   â”œâ”€â”€ quantization_agent.py       # Weight/activation quantization
â”‚   â”œâ”€â”€ knowledge_distiller.py      # Knowledge distillation
â”‚   â”œâ”€â”€ architecture_optimizer.py   # Neural architecture search
â”‚   â”œâ”€â”€ compression_validator.py    # Quality validation
â”‚   â”œâ”€â”€ deployment_packager.py      # Deployment packaging
â”‚   â”œâ”€â”€ performance_profiler.py     # Performance profiling
â”‚   â””â”€â”€ compression_orchestrator.py # Pipeline coordination
â”œâ”€â”€ core/                       # Core algorithms
â”‚   â””â”€â”€ compression_algorithms.py   # Fundamental compression algorithms
â”œâ”€â”€ optimization/               # Advanced optimization
â”‚   â””â”€â”€ compression_optimizer.py    # Multi-objective optimization
â”œâ”€â”€ validation/                 # Quality validation
â”‚   â””â”€â”€ model_validator.py         # Comprehensive validation framework
â”œâ”€â”€ deployment/                 # Deployment support files
â”œâ”€â”€ tests/                      # Comprehensive test suite
â””â”€â”€ docs/                       # Documentation
```

## Compression Agents

### 1. ModelAnalyzer Agent
Analyzes model structure and characteristics to determine optimal compression strategies.

**Key Capabilities:**
- Parameter count and model size analysis
- Layer-wise redundancy detection
- Compression potential estimation
- Strategy recommendation based on analysis

**Usage:**
```python
from phase8_compression.agents import ModelAnalyzerAgent

analyzer = ModelAnalyzerAgent()
analysis = analyzer.analyze_model(model, "model_name")

print(f"Compression potential: {analysis.compression_potential:.2%}")
print(f"Recommended strategies: {analysis.recommended_strategies}")
```

### 2. PruningAgent
Implements neural network pruning algorithms including magnitude-based, structured, and gradient-based pruning.

**Supported Techniques:**
- Magnitude-based pruning (unstructured/structured)
- Gradient-based pruning with Taylor expansion
- Progressive pruning schedules
- N:M structured pruning

**Usage:**
```python
from phase8_compression.agents import PruningAgent, PruningConfig

agent = PruningAgent()
config = PruningConfig(
    strategy='magnitude',
    sparsity_ratio=0.5,
    granularity='unstructured'
)

results = agent.prune_model(model, config)
print(f"Achieved {results.actual_sparsity:.2%} sparsity")
```

### 3. QuantizationAgent
Implements weight and activation quantization strategies for model compression.

**Supported Techniques:**
- Dynamic quantization (weights only)
- Static quantization (weights + activations)
- Quantization-Aware Training (QAT)
- Custom bit-width quantization

**Usage:**
```python
from phase8_compression.agents import QuantizationAgent, QuantizationConfig

agent = QuantizationAgent()
config = QuantizationConfig(
    strategy='dynamic',
    bit_width=8,
    target_dtype='int8'
)

quantized_model, results = agent.quantize_model(model, config)
print(f"Compression ratio: {results.compression_ratio:.2f}x")
```

### 4. KnowledgeDistiller
Implements knowledge distillation techniques to compress large teacher models into smaller student models.

**Supported Techniques:**
- Response-based distillation
- Feature-based distillation
- Attention-based distillation
- Progressive distillation

**Usage:**
```python
from phase8_compression.agents import KnowledgeDistillationAgent, DistillationConfig

agent = KnowledgeDistillationAgent()
config = DistillationConfig(
    temperature=4.0,
    alpha=0.7,
    distillation_type='response'
)

student_model, results = agent.distill_knowledge(
    teacher_model, student_model, train_data, val_data, config
)
```

### 5. ArchitectureOptimizer
Implements neural architecture search and optimization for efficient model architectures.

**Key Features:**
- Evolutionary architecture search
- Multi-objective optimization (accuracy vs. efficiency)
- Progressive architecture shrinking
- Pareto front analysis

**Usage:**
```python
from phase8_compression.agents import ArchitectureOptimizerAgent, ArchitectureConfig

agent = ArchitectureOptimizerAgent()
config = ArchitectureConfig(
    search_strategy='evolutionary',
    target_params=500000,
    max_generations=50
)

results = agent.optimize_architecture('cnn', config, input_shape, num_classes)
```

### 6. CompressionValidator
Validates quality and performance of compressed models against deployment requirements.

**Validation Areas:**
- Accuracy retention analysis
- Performance impact assessment
- Numerical stability verification
- Deployment readiness checks

**Usage:**
```python
from phase8_compression.agents import CompressionValidatorAgent, ValidationConfig

agent = CompressionValidatorAgent()
config = ValidationConfig(
    accuracy_threshold=0.95,
    latency_threshold=1.5
)

results = agent.validate_compression(
    original_model, compressed_model, validation_data, config
)
```

### 7. DeploymentPackager
Creates deployment-ready packages from compressed models for various runtime environments.

**Supported Targets:**
- PyTorch (CPU/CUDA)
- ONNX cross-platform
- Mobile deployment (iOS/Android)
- Edge device optimization

**Usage:**
```python
from phase8_compression.agents import DeploymentPackagerAgent, DeploymentConfig

agent = DeploymentPackagerAgent()
config = DeploymentConfig(
    target_platform='cpu',
    runtime_environment='pytorch',
    include_preprocessing=True
)

results = agent.create_deployment_package(model, config, output_dir)
```

### 8. PerformanceProfiler
Profiles performance characteristics of compressed models including latency, throughput, and memory usage.

**Profiling Metrics:**
- Inference latency (mean, percentiles)
- Throughput (samples/second)
- Memory usage (allocated, reserved)
- Layer-wise performance analysis

**Usage:**
```python
from phase8_compression.agents import PerformanceProfilerAgent, ProfilingConfig

agent = PerformanceProfilerAgent()
config = ProfilingConfig(
    device='cpu',
    batch_sizes=[1, 4, 8],
    measurement_iterations=100
)

results = agent.profile_model(model, input_tensors, config)
```

### 9. CompressionOrchestrator
Orchestrates the entire compression pipeline, coordinating all agents for end-to-end optimization.

**Pipeline Strategies:**
- Pruning-only pipeline
- Quantization-only pipeline
- Knowledge distillation pipeline
- Hybrid compression (multiple techniques)
- Progressive compression (gradual optimization)

## Compression Strategies

### Hybrid Compression Pipeline

The most comprehensive strategy combining multiple techniques:

1. **Analysis Phase**: Model structure analysis and strategy planning
2. **Compression Phase**: Sequential application of pruning â†’ quantization
3. **Validation Phase**: Quality and performance validation
4. **Optimization Phase**: Hyperparameter tuning and refinement
5. **Packaging Phase**: Deployment package creation

### Progressive Compression Pipeline

Gradual compression with performance monitoring:

1. **Stage 1**: Light pruning (20% sparsity)
2. **Stage 2**: Moderate pruning (40% sparsity)
3. **Stage 3**: Aggressive pruning (60% sparsity)
4. **Stage 4**: Quantization of pruned model
5. **Stage 5**: Fine-tuning for accuracy recovery

## Quick Start

### Basic Compression Pipeline

```python
from phase8_compression import create_compression_pipeline

# Create compression pipeline
pipeline = create_compression_pipeline(
    strategy="hybrid",
    target_platform="cpu",
    target_accuracy_retention=0.95,
    target_model_size_mb=50.0
)

# Compress model from Phase 7 ADAS
results = pipeline.compress_model(
    adas_model,
    validation_data,
    training_data,
    model_name="adas_compressed"
)

# Access results
compressed_model = results.best_model
print(f"Achieved {results.compression_ratio:.2f}x compression")
print(f"Retained {results.accuracy_retention:.1%} accuracy")
```

### Custom Compression Configuration

```python
from phase8_compression.agents.compression_orchestrator import (
    CompressionOrchestrator,
    CompressionPipelineConfig,
    CompressionStrategy,
    CompressionTarget
)

# Define compression target
target = CompressionTarget(
    max_model_size_mb=25.0,
    max_latency_ms=100.0,
    min_accuracy_retention=0.95,
    target_platform='cpu'
)

# Configure pipeline
config = CompressionPipelineConfig(
    strategy=CompressionStrategy.PROGRESSIVE_COMPRESSION,
    target=target,
    parallel_execution=True,
    max_workers=4,
    save_intermediate_results=True
)

# Create orchestrator
orchestrator = CompressionOrchestrator(config)

# Run compression
results = orchestrator.compress_model(
    model, validation_data, training_data, "custom_model"
)
```

## Advanced Usage

### Multi-Objective Optimization

```python
from phase8_compression.optimization.compression_optimizer import (
    HyperparameterOptimizer,
    OptimizationConfig,
    OptimizationObjective
)

# Define objectives
objectives = [
    OptimizationObjective('compression_ratio', weight=0.4, minimize=False),
    OptimizationObjective('accuracy_retention', weight=0.6, minimize=False)
]

# Define search space
search_space = {
    'sparsity_ratio': {'type': 'float', 'low': 0.1, 'high': 0.9},
    'quantization_bits': {'type': 'int', 'low': 4, 'high': 16}
}

# Configure optimization
config = OptimizationConfig(
    objectives=objectives,
    search_space=search_space,
    n_trials=100
)

# Run optimization
optimizer = HyperparameterOptimizer(config)
results = optimizer.optimize(compression_function, model, validation_data)
```

### Comprehensive Model Validation

```python
from phase8_compression.validation.model_validator import (
    ModelValidationFramework,
    ValidationThresholds
)

# Set validation thresholds
thresholds = ValidationThresholds(
    min_accuracy_retention=0.95,
    max_latency_increase=1.2,
    max_memory_increase=1.5,
    min_numerical_stability=0.99
)

# Create validation framework
validator = ModelValidationFramework(thresholds)

# Run validation
report = validator.validate_model(
    original_model,
    compressed_model,
    validation_data,
    model_name="production_model"
)

print(f"Validation: {'PASSED' if report.metrics.validation_passed else 'FAILED'}")
print(f"Overall score: {report.metrics.overall_score:.3f}")
```

## Performance Benchmarks

Typical compression results achieved by Phase 8:

| Model Type | Original Size | Compressed Size | Compression Ratio | Accuracy Retention |
|------------|---------------|-----------------|-------------------|-------------------|
| ResNet-50  | 98MB         | 12MB           | 8.2x             | 97.2%            |
| MobileNet  | 17MB         | 4MB            | 4.3x             | 98.1%            |
| BERT-Base  | 440MB        | 55MB           | 8.0x             | 96.8%            |
| ADAS Model | 125MB        | 18MB           | 6.9x             | 97.5%            |

## Integration with Phase 7 ADAS

Phase 8 seamlessly integrates with Phase 7 ADAS outputs:

```python
# Phase 7 ADAS produces trained models
adas_model = phase7_adas.get_trained_model("perception_model")
validation_data = phase7_adas.get_validation_data()

# Phase 8 compresses for deployment
compressed_model = phase8_compression.compress_model(
    adas_model,
    validation_data,
    target_platform="edge_device"
)

# Deploy compressed model
deployment_package = compressed_model.create_deployment_package()
```

## Testing

Run the comprehensive test suite:

```bash
# Run all tests
pytest tests/ -v

# Run specific test categories
pytest tests/test_compression_pipeline.py::TestModelAnalyzer -v
pytest tests/test_compression_pipeline.py::TestPruningAgent -v
pytest tests/test_compression_pipeline.py::TestQuantizationAgent -v

# Run integration tests
pytest tests/test_compression_pipeline.py::TestIntegration -v --slow

# Generate coverage report
pytest tests/ --cov=phase8_compression --cov-report=html
```

## Configuration Options

### Compression Strategies

- `PRUNING_ONLY`: Applies only neural network pruning
- `QUANTIZATION_ONLY`: Applies only weight/activation quantization
- `DISTILLATION_ONLY`: Uses knowledge distillation approach
- `ARCHITECTURE_SEARCH`: Optimizes model architecture
- `HYBRID_COMPRESSION`: Combines multiple techniques
- `PROGRESSIVE_COMPRESSION`: Gradual optimization approach

### Target Platforms

- `cpu`: CPU-optimized deployment
- `cuda`: NVIDIA GPU deployment
- `mobile`: Mobile device deployment
- `edge`: Edge device deployment
- `web`: Web browser deployment

### Runtime Environments

- `pytorch`: PyTorch native runtime
- `onnx`: ONNX cross-platform runtime
- `tensorrt`: NVIDIA TensorRT optimization
- `openvino`: Intel OpenVINO optimization
- `tflite`: TensorFlow Lite for mobile

## Troubleshooting

### Common Issues

**1. Accuracy Drop Too High**
```python
# Solution: Adjust compression parameters
config.target.min_accuracy_retention = 0.90  # Relax threshold
config.pruning_config['sparsity_ratio'] = 0.3  # Reduce sparsity
```

**2. Compression Ratio Too Low**
```python
# Solution: Use more aggressive compression
config = CompressionPipelineConfig(
    strategy=CompressionStrategy.PROGRESSIVE_COMPRESSION,
    target=CompressionTarget(max_model_size_mb=10.0)
)
```

**3. Deployment Package Issues**
```python
# Solution: Check runtime environment compatibility
config.deployment_config['runtime_environment'] = 'onnx'
config.deployment_config['target_platform'] = 'cpu'
```

## Contributing

1. Follow the established architecture patterns
2. Add comprehensive tests for new features
3. Update documentation for any API changes
4. Ensure compatibility with Phase 7 ADAS integration
5. Validate against deployment target requirements

## License

Part of the AIVillage agent forge framework. See main project license.

## Support

For issues and questions:
- Check the troubleshooting section above
- Review test cases for usage examples
- Consult agent-specific documentation in `agents/` directory
- Refer to core algorithm documentation in `core/` directory

---

**Phase 8 Compression - Optimizing AI for Real-World Deployment** ðŸš€