[
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\aivillage-module\\__init__.py",
    "line_number": 10,
    "column": 4,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "      7: \n      8: _src = Path(__file__).resolve().parent.parent / \"src\"\n      9: if str(_src) not in sys.path:\n>>>  10:     sys.path.insert(0, str(_src))\n     11: \n     12: # Expose submodules under src through this package\n     13: __path__ = [str(_src)]",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_cli.py",
    "line_number": 80,
    "column": 32,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     77:                     },\n     78:                 )\n     79:             else:\n>>>  80:                 self._success(f\"Backup created successfully: {backup_id}\")\n     81:                 self._info(f\"Type: {backup_info.backup_type.value}\")\n     82:                 self._info(f\"Size: {backup_info.size_bytes / 1024 / 1024:.2f} MB\")\n     83:                 self._info(f\"Files: {backup_info.file_count}\")",
    "context": {
      "query_preview": "Backup created successfully: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_cli.py",
    "line_number": 492,
    "column": 13,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    489:         \"backup_type\",\n    490:         default=\"full\",\n    491:         type=click.Choice([\"full\", \"incremental\", \"tenant\"]),\n>>> 492:         help=\"Type of backup to create\",\n    493:     )\n    494:     @click.option(\"--tenant\", multiple=True, help=\"Tenant IDs to include (for tenant backup)\")\n    495:     @click.option(\"--exclude\", multiple=True, help=\"Components to exclude\")",
    "context": {
      "query_preview": "Type of backup to create"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_cli.py",
    "line_number": 552,
    "column": 4,
    "description": "Function 'restore' has 7 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    549:     @click.option(\"--component\", help=\"Component name (for component restore)\")\n    550:     @click.option(\"--no-rollback\", is_flag=True, help=\"Skip creating rollback point\")\n    551:     @click.option(\"--dry-run\", is_flag=True, help=\"Show what would be restored without doing it\")\n>>> 552:     def restore(backup_id, restore_type, strategy, tenant, component, no_rollback, dry_run):\n    553:         \"\"\"Restore from backup\"\"\"\n    554:         cli = BackupCLI()\n    555:         asyncio.run(",
    "context": {
      "parameter_count": 7,
      "function_name": "restore"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_cli.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (74 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 74,
      "methods": [
        "_success",
        "_initialize_managers",
        "_error",
        "_info",
        "_output_json",
        "_warning"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_cli.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'asyncio' methods (14 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "asyncio",
      "method_count": 14,
      "methods": [
        "sleep",
        "run",
        "wait_for"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_cli.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'click' methods (29 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "click",
      "method_count": 29,
      "methods": [
        "group",
        "Choice",
        "argument",
        "option"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_cli.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'cli' methods (12 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "cli",
      "method_count": 12,
      "methods": [
        "restore_backup",
        "list_restores",
        "stop_scheduler",
        "emergency_backup",
        "list_backups",
        "backup_info",
        "create_backup",
        "start_scheduler",
        "scheduler_status"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_cli.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'backup_cli' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "backup_cli",
      "method_count": 9,
      "methods": [
        "command"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_cli.py",
    "line_number": 74,
    "column": 60,
    "description": "Excessive magic literals detected (23 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     71:                         \"backup_id\": backup_id,\n     72:                         \"backup_type\": backup_info.backup_type.value,\n     73:                         \"status\": backup_info.status.value,\n>>>  74:                         \"size_mb\": backup_info.size_bytes / 1024 / 1024,\n     75:                         \"file_count\": backup_info.file_count,\n     76:                         \"created_at\": backup_info.created_at.isoformat(),\n     77:                     },",
    "context": {
      "total_magic_literals": 23,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_cli.py",
    "line_number": 74,
    "column": 67,
    "description": "Excessive magic literals detected (23 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     71:                         \"backup_id\": backup_id,\n     72:                         \"backup_type\": backup_info.backup_type.value,\n     73:                         \"status\": backup_info.status.value,\n>>>  74:                         \"size_mb\": backup_info.size_bytes / 1024 / 1024,\n     75:                         \"file_count\": backup_info.file_count,\n     76:                         \"created_at\": backup_info.created_at.isoformat(),\n     77:                     },",
    "context": {
      "total_magic_literals": 23,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_cli.py",
    "line_number": 82,
    "column": 61,
    "description": "Excessive magic literals detected (23 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     79:             else:\n     80:                 self._success(f\"Backup created successfully: {backup_id}\")\n     81:                 self._info(f\"Type: {backup_info.backup_type.value}\")\n>>>  82:                 self._info(f\"Size: {backup_info.size_bytes / 1024 / 1024:.2f} MB\")\n     83:                 self._info(f\"Files: {backup_info.file_count}\")\n     84:                 self._info(f\"Status: {backup_info.status.value}\")\n     85: ",
    "context": {
      "total_magic_literals": 23,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_cli.py",
    "line_number": 82,
    "column": 68,
    "description": "Excessive magic literals detected (23 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     79:             else:\n     80:                 self._success(f\"Backup created successfully: {backup_id}\")\n     81:                 self._info(f\"Type: {backup_info.backup_type.value}\")\n>>>  82:                 self._info(f\"Size: {backup_info.size_bytes / 1024 / 1024:.2f} MB\")\n     83:                 self._info(f\"Files: {backup_info.file_count}\")\n     84:                 self._info(f\"Status: {backup_info.status.value}\")\n     85: ",
    "context": {
      "total_magic_literals": 23,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_cli.py",
    "line_number": 90,
    "column": 86,
    "description": "Excessive magic literals detected (23 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     87:             self._error(f\"Backup failed: {e}\")\n     88: \n     89:     async def list_backups(\n>>>  90:         self, backup_type: str | None = None, status: str | None = None, limit: int = 20, output_format: str = \"table\",\n     91:     ):\n     92:         \"\"\"List available backups.\"\"\"\n     93:         await self._initialize_managers()",
    "context": {
      "total_magic_literals": 23,
      "current_value": 20
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 81,
    "column": 0,
    "description": "Class 'BackupManager' is a God Object: 5 methods, ~1129 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "     78:     warnings: list[str] = field(default_factory=list)\n     79: \n     80: \n>>>  81: class BackupManager:\n     82:     \"\"\"Main backup and restore management system.\"\"\"\n     83: \n     84:     def __init__(",
    "context": {
      "method_count": 5,
      "estimated_lines": 1129,
      "class_name": "BackupManager",
      "data_methods": 0,
      "business_methods": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 130,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    127:         logger.info(f\"Backup manager initialized at {self.backup_root}\")\n    128: \n    129:     def _load_or_create_encryption_key(self) -> bytes:\n>>> 130:         \"\"\"Load or create encryption key for backup security.\"\"\"\n    131:         key_file = self.backup_root / \".backup_key\"\n    132: \n    133:         if key_file.exists():",
    "context": {
      "query_preview": "Load or create encryption key for backup security."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 172,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    169:             with open(self.config_path) as f:\n    170:                 user_config = json.load(f)\n    171:                 # Merge with defaults\n>>> 172:                 default_config.update(user_config)\n    173:         else:\n    174:             # Create default config\n    175:             self.config_path.parent.mkdir(parents=True, exist_ok=True)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 181,
    "column": 4,
    "description": "Method '_init_metadata_db' is too complex: 1 complexity, 59 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    178: \n    179:         return default_config\n    180: \n>>> 181:     def _init_metadata_db(self):\n    182:         \"\"\"Initialize backup metadata database.\"\"\"\n    183:         conn = sqlite3.connect(self.metadata_db)\n    184:         cursor = conn.cursor()",
    "context": {
      "complexity": 1,
      "lines": 59,
      "max_nesting": 0,
      "method_name": "_init_metadata_db"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 186,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    183:         conn = sqlite3.connect(self.metadata_db)\n    184:         cursor = conn.cursor()\n    185: \n>>> 186:         cursor.execute(\n    187:             \"\"\"\n    188:             CREATE TABLE IF NOT EXISTS backups (\n    189:                 backup_id TEXT PRIMARY KEY,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 187,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    184:         cursor = conn.cursor()\n    185: \n    186:         cursor.execute(\n>>> 187:             \"\"\"\n    188:             CREATE TABLE IF NOT EXISTS backups (\n    189:                 backup_id TEXT PRIMARY KEY,\n    190:                 backup_type TEXT NOT NULL,",
    "context": {
      "query_preview": "\n            CREATE TABLE IF NOT EXISTS backups (\n                backup_id TEXT PRIMARY KEY,\n      ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 210,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    207:         \"\"\",\n    208:         )\n    209: \n>>> 210:         cursor.execute(\n    211:             \"\"\"\n    212:             CREATE TABLE IF NOT EXISTS restore_history (\n    213:                 id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 211,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    208:         )\n    209: \n    210:         cursor.execute(\n>>> 211:             \"\"\"\n    212:             CREATE TABLE IF NOT EXISTS restore_history (\n    213:                 id INTEGER PRIMARY KEY AUTOINCREMENT,\n    214:                 backup_id TEXT NOT NULL,",
    "context": {
      "query_preview": "\n            CREATE TABLE IF NOT EXISTS restore_history (\n                id INTEGER PRIMARY KEY AUT..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 225,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    222:         \"\"\",\n    223:         )\n    224: \n>>> 225:         cursor.execute(\n    226:             \"\"\"\n    227:             CREATE INDEX IF NOT EXISTS idx_backup_created\n    228:             ON backups(created_at)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 226,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    223:         )\n    224: \n    225:         cursor.execute(\n>>> 226:             \"\"\"\n    227:             CREATE INDEX IF NOT EXISTS idx_backup_created\n    228:             ON backups(created_at)\n    229:         \"\"\",",
    "context": {
      "query_preview": "\n            CREATE INDEX IF NOT EXISTS idx_backup_created\n            ON backups(created_at)\n      ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 232,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    229:         \"\"\",\n    230:         )\n    231: \n>>> 232:         cursor.execute(\n    233:             \"\"\"\n    234:             CREATE INDEX IF NOT EXISTS idx_backup_type\n    235:             ON backups(backup_type, status)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 233,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    230:         )\n    231: \n    232:         cursor.execute(\n>>> 233:             \"\"\"\n    234:             CREATE INDEX IF NOT EXISTS idx_backup_type\n    235:             ON backups(backup_type, status)\n    236:         \"\"\",",
    "context": {
      "query_preview": "\n            CREATE INDEX IF NOT EXISTS idx_backup_type\n            ON backups(backup_type, status)\n..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 239,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    236:         \"\"\",\n    237:         )\n    238: \n>>> 239:         conn.commit()\n    240:         conn.close()\n    241: \n    242:     def _load_backup_metadata(self):",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 243,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    240:         conn.close()\n    241: \n    242:     def _load_backup_metadata(self):\n>>> 243:         \"\"\"Load existing backup metadata from database.\"\"\"\n    244:         conn = sqlite3.connect(self.metadata_db)\n    245:         cursor = conn.cursor()\n    246: ",
    "context": {
      "query_preview": "Load existing backup metadata from database."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 247,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    244:         conn = sqlite3.connect(self.metadata_db)\n    245:         cursor = conn.cursor()\n    246: \n>>> 247:         cursor.execute(\"SELECT * FROM backups ORDER BY created_at DESC\")\n    248:         rows = cursor.fetchall()\n    249: \n    250:         for row in rows:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 247,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    244:         conn = sqlite3.connect(self.metadata_db)\n    245:         cursor = conn.cursor()\n    246: \n>>> 247:         cursor.execute(\"SELECT * FROM backups ORDER BY created_at DESC\")\n    248:         rows = cursor.fetchall()\n    249: \n    250:         for row in rows:",
    "context": {
      "query_preview": "SELECT * FROM backups ORDER BY created_at DESC"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 282,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    279:     async def create_full_backup(\n    280:         self, include_tenants: list[str] | None = None, exclude_components: list[str] | None = None,\n    281:     ) -> str:\n>>> 282:         \"\"\"Create comprehensive full system backup.\"\"\"\n    283:         backup_id = f\"full_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n    284: \n    285:         metadata = BackupMetadata(",
    "context": {
      "query_preview": "Create comprehensive full system backup."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 409,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    406:             raise\n    407: \n    408:     async def create_incremental_backup(self, base_backup_id: str | None = None) -> str:\n>>> 409:         \"\"\"Create incremental backup (changes since last backup).\"\"\"\n    410:         backup_id = f\"inc_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n    411: \n    412:         # Find base backup",
    "context": {
      "query_preview": "Create incremental backup (changes since last backup)."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 513,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    510:             raise\n    511: \n    512:     async def create_tenant_backup(self, tenant_id: str, include_models: bool = True) -> str:\n>>> 513:         \"\"\"Create backup for specific tenant.\"\"\"\n    514:         backup_id = f\"tenant_{tenant_id}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n    515: \n    516:         metadata = BackupMetadata(",
    "context": {
      "query_preview": "Create backup for specific tenant."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 949,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    946:     # Utility methods\n    947: \n    948:     async def _create_compressed_archive(self, source_dir: Path, archive_path: Path):\n>>> 949:         \"\"\"Create compressed tar archive.\"\"\"\n    950:         with tarfile.open(archive_path, \"w:gz\", compresslevel=self.config[\"compression\"][\"level\"]) as tar:\n    951:             tar.add(source_dir, arcname=source_dir.name)\n    952: ",
    "context": {
      "query_preview": "Create compressed tar archive."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 958,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    955:         hash_sha256 = hashlib.sha256()\n    956:         with open(file_path, \"rb\") as f:\n    957:             for chunk in iter(lambda: f.read(4096), b\"\"):\n>>> 958:                 hash_sha256.update(chunk)\n    959:         return hash_sha256.hexdigest()\n    960: \n    961:     async def _encrypt_file(self, source_path: Path, dest_path: Path):",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1012,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1009:         conn = sqlite3.connect(self.metadata_db)\n    1010:         cursor = conn.cursor()\n    1011: \n>>> 1012:         cursor.execute(\n    1013:             \"\"\"\n    1014:             INSERT OR REPLACE INTO backups\n    1015:             (backup_id, backup_type, created_at, completed_at, status, size_bytes,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1013,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1010:         cursor = conn.cursor()\n    1011: \n    1012:         cursor.execute(\n>>> 1013:             \"\"\"\n    1014:             INSERT OR REPLACE INTO backups\n    1015:             (backup_id, backup_type, created_at, completed_at, status, size_bytes,\n    1016:              checksum, encrypted, compression_ratio, tenants_included, components_included,",
    "context": {
      "query_preview": "\n            INSERT OR REPLACE INTO backups\n            (backup_id, backup_type, created_at, complet..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1041,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1038:             ),\n    1039:         )\n    1040: \n>>> 1041:         conn.commit()\n    1042:         conn.close()\n    1043: \n    1044:     async def _get_backup_metadata(self, backup_id: str) -> BackupMetadata | None:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1045,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1042:         conn.close()\n    1043: \n    1044:     async def _get_backup_metadata(self, backup_id: str) -> BackupMetadata | None:\n>>> 1045:         \"\"\"Get backup metadata from database.\"\"\"\n    1046:         conn = sqlite3.connect(self.metadata_db)\n    1047:         cursor = conn.cursor()\n    1048: ",
    "context": {
      "query_preview": "Get backup metadata from database."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1049,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1046:         conn = sqlite3.connect(self.metadata_db)\n    1047:         cursor = conn.cursor()\n    1048: \n>>> 1049:         cursor.execute(\"SELECT * FROM backups WHERE backup_id = ?\", (backup_id,))\n    1050:         row = cursor.fetchone()\n    1051:         conn.close()\n    1052: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1049,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1046:         conn = sqlite3.connect(self.metadata_db)\n    1047:         cursor = conn.cursor()\n    1048: \n>>> 1049:         cursor.execute(\"SELECT * FROM backups WHERE backup_id = ?\", (backup_id,))\n    1050:         row = cursor.fetchone()\n    1051:         conn.close()\n    1052: ",
    "context": {
      "query_preview": "SELECT * FROM backups WHERE backup_id = ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1080,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1077:         conn = sqlite3.connect(self.metadata_db)\n    1078:         cursor = conn.cursor()\n    1079: \n>>> 1080:         cursor.execute(\"SELECT backup_id FROM backups WHERE status = 'completed' ORDER BY created_at DESC LIMIT 1\")\n    1081:         row = cursor.fetchone()\n    1082:         conn.close()\n    1083: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1080,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1077:         conn = sqlite3.connect(self.metadata_db)\n    1078:         cursor = conn.cursor()\n    1079: \n>>> 1080:         cursor.execute(\"SELECT backup_id FROM backups WHERE status = 'completed' ORDER BY created_at DESC LIMIT 1\")\n    1081:         row = cursor.fetchone()\n    1082:         conn.close()\n    1083: ",
    "context": {
      "query_preview": "SELECT backup_id FROM backups WHERE status = 'completed' ORDER BY created_at DESC LIMIT 1"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1162,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1159:         conn = sqlite3.connect(self.metadata_db)\n    1160:         cursor = conn.cursor()\n    1161: \n>>> 1162:         query = \"SELECT * FROM backups\"\n    1163:         params = []\n    1164:         conditions = []\n    1165: ",
    "context": {
      "query_preview": "SELECT * FROM backups"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1177,
    "column": 17,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1174:         if conditions:\n    1175:             query += \" WHERE \" + \" AND \".join(conditions)\n    1176: \n>>> 1177:         query += \" ORDER BY created_at DESC LIMIT ?\"\n    1178:         params.append(limit)\n    1179: \n    1180:         cursor.execute(query, params)",
    "context": {
      "query_preview": " ORDER BY created_at DESC LIMIT ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1180,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1177:         query += \" ORDER BY created_at DESC LIMIT ?\"\n    1178:         params.append(limit)\n    1179: \n>>> 1180:         cursor.execute(query, params)\n    1181:         rows = cursor.fetchall()\n    1182:         conn.close()\n    1183: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1222,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1219:         # Create full backup\n    1220:         print(\"Creating full backup...\")\n    1221:         backup_id = await backup_manager.create_full_backup()\n>>> 1222:         print(f\"Full backup created: {backup_id}\")\n    1223: \n    1224:         # List backups\n    1225:         backups = await backup_manager.list_backups()",
    "context": {
      "query_preview": "Full backup created: "
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (44 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 44,
      "methods": [
        "_backup_configurations",
        "_load_config",
        "_backup_agents",
        "_load_or_create_encryption_key",
        "_backup_p2p_networks",
        "_get_latest_backup_id",
        "_save_metadata",
        "_create_compressed_archive",
        "_find_changed_files",
        "_decrypt_file",
        "_encrypt_file",
        "_init_metadata_db",
        "_backup_tenant_data",
        "_backup_rag_collections",
        "_backup_rbac_system",
        "_verify_backup",
        "_backup_logs",
        "_backup_models",
        "_calculate_checksum",
        "_load_backup_metadata",
        "_get_backup_metadata"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (38 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 38,
      "methods": [
        "info",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'f' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "f",
      "method_count": 9,
      "methods": [
        "write",
        "stat",
        "read",
        "is_file"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'json' methods (28 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "json",
      "method_count": 28,
      "methods": [
        "dump",
        "dumps",
        "load",
        "loads"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'sqlite3' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "sqlite3",
      "method_count": 6,
      "methods": [
        "connect"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'conn' methods (14 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "conn",
      "method_count": 14,
      "methods": [
        "close",
        "cursor",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'cursor' methods (13 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "cursor",
      "method_count": 13,
      "methods": [
        "execute",
        "fetchone",
        "fetchall"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (17 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 17,
      "methods": [
        "utcnow",
        "fromisoformat"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'tasks' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "tasks",
      "method_count": 9,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'archive_path' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "archive_path",
      "method_count": 9,
      "methods": [
        "unlink",
        "stat",
        "with_suffix"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'shutil' methods (23 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "shutil",
      "method_count": 23,
      "methods": [
        "copytree",
        "rmtree",
        "copy2"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'warnings' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "warnings",
      "method_count": 8,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'dest_path' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "dest_path",
      "method_count": 8,
      "methods": [
        "rglob"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 142,
    "column": 27,
    "description": "Excessive magic literals detected (72 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    139:             with open(key_file, \"wb\") as f:\n    140:                 f.write(key)\n    141:             # Restrict permissions\n>>> 142:             key_file.chmod(0o600)\n    143:             return key\n    144: \n    145:     def _load_config(self) -> dict[str, Any]:",
    "context": {
      "total_magic_literals": 72,
      "current_value": 384
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 149,
    "column": 37,
    "description": "Excessive magic literals detected (72 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    146:         \"\"\"Load backup configuration.\"\"\"\n    147:         default_config = {\n    148:             \"retention_policy\": {\n>>> 149:                 \"full_backups_keep\": 30,  # Keep 30 full backups\n    150:                 \"incremental_keep_days\": 90,  # Keep incrementals for 90 days\n    151:                 \"tenant_backups_keep\": 10,  # Keep 10 tenant backups per tenant\n    152:             },",
    "context": {
      "total_magic_literals": 72,
      "current_value": 30
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 150,
    "column": 41,
    "description": "Excessive magic literals detected (72 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    147:         default_config = {\n    148:             \"retention_policy\": {\n    149:                 \"full_backups_keep\": 30,  # Keep 30 full backups\n>>> 150:                 \"incremental_keep_days\": 90,  # Keep incrementals for 90 days\n    151:                 \"tenant_backups_keep\": 10,  # Keep 10 tenant backups per tenant\n    152:             },\n    153:             \"compression\": {",
    "context": {
      "total_magic_literals": 72,
      "current_value": 90
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 155,
    "column": 25,
    "description": "Excessive magic literals detected (72 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    152:             },\n    153:             \"compression\": {\n    154:                 \"enabled\": True,\n>>> 155:                 \"level\": 6,  # gzip compression level\n    156:                 \"threshold_mb\": 10,  # Compress files larger than 10MB\n    157:             },\n    158:             \"encryption\": {\"enabled\": True, \"algorithm\": \"AES-256\", \"key_rotation_days\": 90},",
    "context": {
      "total_magic_literals": 72,
      "current_value": 6
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_manager.py",
    "line_number": 158,
    "column": 89,
    "description": "Excessive magic literals detected (72 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    155:                 \"level\": 6,  # gzip compression level\n    156:                 \"threshold_mb\": 10,  # Compress files larger than 10MB\n    157:             },\n>>> 158:             \"encryption\": {\"enabled\": True, \"algorithm\": \"AES-256\", \"key_rotation_days\": 90},\n    159:             \"scheduling\": {\n    160:                 \"full_backup_hour\": 2,  # 2 AM daily full backup\n    161:                 \"incremental_interval_hours\": 6,  # Every 6 hours",
    "context": {
      "total_magic_literals": 72,
      "current_value": 90
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 68,
    "column": 0,
    "description": "Class 'BackupScheduler' is a God Object: 13 methods, ~667 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "     65:     average_duration_minutes: float = 0.0\n     66: \n     67: \n>>>  68: class BackupScheduler:\n     69:     \"\"\"Automated backup scheduler with health monitoring.\"\"\"\n     70: \n     71:     def __init__(self, backup_manager: BackupManager, restore_manager: RestoreManager):",
    "context": {
      "method_count": 13,
      "estimated_lines": 667,
      "class_name": "BackupScheduler",
      "data_methods": 3,
      "business_methods": 10
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 129,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    126:         if config_path.exists():\n    127:             with open(config_path) as f:\n    128:                 user_config = json.load(f)\n>>> 129:                 default_config.update(user_config)\n    130:         else:\n    131:             config_path.parent.mkdir(parents=True, exist_ok=True)\n    132:             with open(config_path, \"w\") as f:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 179,
    "column": 4,
    "description": "Function 'add_scheduled_job' has 11 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    176:                 interval_hours=schedules[\"config_backup\"][\"interval_hours\"],\n    177:             )\n    178: \n>>> 179:     def add_scheduled_job(\n    180:         self,\n    181:         job_id: str,\n    182:         schedule_type: ScheduleType,",
    "context": {
      "parameter_count": 11,
      "function_name": "add_scheduled_job"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 251,
    "column": 4,
    "description": "Method '_calculate_next_run' is too complex: 13 complexity, 55 lines, 7 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    248: \n    249:         return False\n    250: \n>>> 251:     def _calculate_next_run(self, job: ScheduledJob):\n    252:         \"\"\"Calculate next run time for job.\"\"\"\n    253:         if not job.enabled:\n    254:             job.next_run = None",
    "context": {
      "complexity": 13,
      "lines": 55,
      "max_nesting": 7,
      "method_name": "_calculate_next_run"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 641,
    "column": 35,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    638:                     await self._delete_backup(backup.backup_id)\n    639:                     logger.info(f\"Deleted old backup: {backup.backup_id}\")\n    640:                 except Exception as e:\n>>> 641:                     logger.error(f\"Failed to delete backup {backup.backup_id}: {e}\")\n    642: \n    643:     async def _delete_backup(self, backup_id: str):\n    644:         \"\"\"Delete backup files and metadata.\"\"\"",
    "context": {
      "query_preview": "Failed to delete backup "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 644,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    641:                     logger.error(f\"Failed to delete backup {backup.backup_id}: {e}\")\n    642: \n    643:     async def _delete_backup(self, backup_id: str):\n>>> 644:         \"\"\"Delete backup files and metadata.\"\"\"\n    645:         # Find and delete backup files\n    646:         for backup_dir in [\n    647:             self.backup_manager.full_backups_dir,",
    "context": {
      "query_preview": "Delete backup files and metadata."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 660,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    657:         # Remove from database\n    658:         conn = sqlite3.connect(self.backup_manager.metadata_db)\n    659:         cursor = conn.cursor()\n>>> 660:         cursor.execute(\"DELETE FROM backups WHERE backup_id = ?\", (backup_id,))\n    661:         conn.commit()\n    662:         conn.close()\n    663: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 660,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    657:         # Remove from database\n    658:         conn = sqlite3.connect(self.backup_manager.metadata_db)\n    659:         cursor = conn.cursor()\n>>> 660:         cursor.execute(\"DELETE FROM backups WHERE backup_id = ?\", (backup_id,))\n    661:         conn.commit()\n    662:         conn.close()\n    663: ",
    "context": {
      "query_preview": "DELETE FROM backups WHERE backup_id = ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 661,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    658:         conn = sqlite3.connect(self.backup_manager.metadata_db)\n    659:         cursor = conn.cursor()\n    660:         cursor.execute(\"DELETE FROM backups WHERE backup_id = ?\", (backup_id,))\n>>> 661:         conn.commit()\n    662:         conn.close()\n    663: \n    664:     async def _send_alert(self, message: str, severity: str = \"info\"):",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 739,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    736: \n    737: \n    738: async def create_backup_scheduler(backup_manager: BackupManager, restore_manager: RestoreManager) -> BackupScheduler:\n>>> 739:     \"\"\"Create and configure backup scheduler.\"\"\"\n    740:     scheduler = BackupScheduler(backup_manager, restore_manager)\n    741: \n    742:     logger.info(\"Backup scheduler created\")",
    "context": {
      "query_preview": "Create and configure backup scheduler."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 742,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    739:     \"\"\"Create and configure backup scheduler.\"\"\"\n    740:     scheduler = BackupScheduler(backup_manager, restore_manager)\n    741: \n>>> 742:     logger.info(\"Backup scheduler created\")\n    743:     return scheduler\n    744: \n    745: ",
    "context": {
      "query_preview": "Backup scheduler created"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (21 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 21,
      "methods": [
        "_scheduler_loop",
        "_load_scheduler_config",
        "add_scheduled_job",
        "_execute_job",
        "_delete_backup",
        "get_job_status",
        "_send_alert",
        "_initialize_default_schedules",
        "_health_monitor_loop",
        "_cleanup_old_backups",
        "_retention_cleanup_loop",
        "_calculate_next_run",
        "_perform_health_checks"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (28 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 28,
      "methods": [
        "log",
        "warning",
        "debug",
        "info",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (14 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 14,
      "methods": [
        "utcnow",
        "fromisoformat"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'asyncio' methods (14 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "asyncio",
      "method_count": 14,
      "methods": [
        "sleep",
        "create_task",
        "gather",
        "run"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 71,
    "column": 4,
    "description": "Sequential coupling detected: Function '__init__' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     68: class BackupScheduler:\n     69:     \"\"\"Automated backup scheduler with health monitoring.\"\"\"\n     70: \n>>>  71:     def __init__(self, backup_manager: BackupManager, restore_manager: RestoreManager):\n     72:         \"\"\"Initialize backup scheduler.\"\"\"\n     73:         self.backup_manager = backup_manager\n     74:         self.restore_manager = restore_manager",
    "context": {
      "function_name": "__init__",
      "sequential_functions": [
        "__init__",
        "_initialize_default_schedules",
        "_calculate_next_run"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 137,
    "column": 4,
    "description": "Sequential coupling detected: Function '_initialize_default_schedules' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    134: \n    135:         return default_config\n    136: \n>>> 137:     def _initialize_default_schedules(self):\n    138:         \"\"\"Initialize default scheduled jobs.\"\"\"\n    139:         schedules = self.scheduler_config[\"default_schedules\"]\n    140: ",
    "context": {
      "function_name": "_initialize_default_schedules",
      "sequential_functions": [
        "__init__",
        "_initialize_default_schedules",
        "_calculate_next_run"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 251,
    "column": 4,
    "description": "Sequential coupling detected: Function '_calculate_next_run' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    248: \n    249:         return False\n    250: \n>>> 251:     def _calculate_next_run(self, job: ScheduledJob):\n    252:         \"\"\"Calculate next run time for job.\"\"\"\n    253:         if not job.enabled:\n    254:             job.next_run = None",
    "context": {
      "function_name": "_calculate_next_run",
      "sequential_functions": [
        "__init__",
        "_initialize_default_schedules",
        "_calculate_next_run"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 100,
    "column": 112,
    "description": "Excessive magic literals detected (45 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     97: \n     98:         default_config = {\n     99:             \"default_schedules\": {\n>>> 100:                 \"full_backup\": {\"enabled\": True, \"schedule\": \"daily\", \"hour\": 2, \"minute\": 0, \"retention_days\": 30},\n    101:                 \"incremental_backup\": {\"enabled\": True, \"schedule\": \"hourly\", \"interval_hours\": 6, \"retention_days\": 7},\n    102:                 \"tenant_backup\": {\n    103:                     \"enabled\": True,",
    "context": {
      "total_magic_literals": 45,
      "current_value": 30
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 101,
    "column": 96,
    "description": "Excessive magic literals detected (45 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     98:         default_config = {\n     99:             \"default_schedules\": {\n    100:                 \"full_backup\": {\"enabled\": True, \"schedule\": \"daily\", \"hour\": 2, \"minute\": 0, \"retention_days\": 30},\n>>> 101:                 \"incremental_backup\": {\"enabled\": True, \"schedule\": \"hourly\", \"interval_hours\": 6, \"retention_days\": 7},\n    102:                 \"tenant_backup\": {\n    103:                     \"enabled\": True,\n    104:                     \"schedule\": \"daily\",",
    "context": {
      "total_magic_literals": 45,
      "current_value": 6
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 101,
    "column": 117,
    "description": "Excessive magic literals detected (45 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     98:         default_config = {\n     99:             \"default_schedules\": {\n    100:                 \"full_backup\": {\"enabled\": True, \"schedule\": \"daily\", \"hour\": 2, \"minute\": 0, \"retention_days\": 30},\n>>> 101:                 \"incremental_backup\": {\"enabled\": True, \"schedule\": \"hourly\", \"interval_hours\": 6, \"retention_days\": 7},\n    102:                 \"tenant_backup\": {\n    103:                     \"enabled\": True,\n    104:                     \"schedule\": \"daily\",",
    "context": {
      "total_magic_literals": 45,
      "current_value": 7
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 105,
    "column": 28,
    "description": "Excessive magic literals detected (45 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    102:                 \"tenant_backup\": {\n    103:                     \"enabled\": True,\n    104:                     \"schedule\": \"daily\",\n>>> 105:                     \"hour\": 3,\n    106:                     \"minute\": 30,\n    107:                     \"retention_per_tenant\": 10,\n    108:                 },",
    "context": {
      "total_magic_literals": 45,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\backup_scheduler.py",
    "line_number": 106,
    "column": 30,
    "description": "Excessive magic literals detected (45 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    103:                     \"enabled\": True,\n    104:                     \"schedule\": \"daily\",\n    105:                     \"hour\": 3,\n>>> 106:                     \"minute\": 30,\n    107:                     \"retention_per_tenant\": 10,\n    108:                 },\n    109:                 \"config_backup\": {\"enabled\": True, \"schedule\": \"hourly\", \"interval_hours\": 4, \"retention_days\": 14},",
    "context": {
      "total_magic_literals": 45,
      "current_value": 30
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 92,
    "column": 0,
    "description": "Class 'RestoreManager' is a God Object: 2 methods, ~1164 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "     89:     verification_results: dict[str, bool] = field(default_factory=dict)\n     90: \n     91: \n>>>  92: class RestoreManager:\n     93:     \"\"\"Main restore management system.\"\"\"\n     94: \n     95:     def __init__(self, backup_manager: BackupManager):",
    "context": {
      "method_count": 2,
      "estimated_lines": 1164,
      "class_name": "RestoreManager",
      "data_methods": 0,
      "business_methods": 2
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 123,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    120:         conn = sqlite3.connect(self.restore_db)\n    121:         cursor = conn.cursor()\n    122: \n>>> 123:         cursor.execute(\n    124:             \"\"\"\n    125:             CREATE TABLE IF NOT EXISTS restores (\n    126:                 restore_id TEXT PRIMARY KEY,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 124,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    121:         cursor = conn.cursor()\n    122: \n    123:         cursor.execute(\n>>> 124:             \"\"\"\n    125:             CREATE TABLE IF NOT EXISTS restores (\n    126:                 restore_id TEXT PRIMARY KEY,\n    127:                 backup_id TEXT NOT NULL,",
    "context": {
      "query_preview": "\n            CREATE TABLE IF NOT EXISTS restores (\n                restore_id TEXT PRIMARY KEY,\n    ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 148,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    145:         \"\"\",\n    146:         )\n    147: \n>>> 148:         cursor.execute(\n    149:             \"\"\"\n    150:             CREATE INDEX IF NOT EXISTS idx_restore_created\n    151:             ON restores(created_at)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 149,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    146:         )\n    147: \n    148:         cursor.execute(\n>>> 149:             \"\"\"\n    150:             CREATE INDEX IF NOT EXISTS idx_restore_created\n    151:             ON restores(created_at)\n    152:         \"\"\",",
    "context": {
      "query_preview": "\n            CREATE INDEX IF NOT EXISTS idx_restore_created\n            ON restores(created_at)\n    ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 155,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    152:         \"\"\",\n    153:         )\n    154: \n>>> 155:         cursor.execute(\n    156:             \"\"\"\n    157:             CREATE INDEX IF NOT EXISTS idx_restore_backup\n    158:             ON restores(backup_id)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 156,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    153:         )\n    154: \n    155:         cursor.execute(\n>>> 156:             \"\"\"\n    157:             CREATE INDEX IF NOT EXISTS idx_restore_backup\n    158:             ON restores(backup_id)\n    159:         \"\"\",",
    "context": {
      "query_preview": "\n            CREATE INDEX IF NOT EXISTS idx_restore_backup\n            ON restores(backup_id)\n      ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 162,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    159:         \"\"\",\n    160:         )\n    161: \n>>> 162:         conn.commit()\n    163:         conn.close()\n    164: \n    165:     # Main restore operations",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 170,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    167:     async def restore_full_system(\n    168:         self, backup_id: str, strategy: RestoreStrategy = RestoreStrategy.REPLACE, create_rollback: bool = True,\n    169:     ) -> str:\n>>> 170:         \"\"\"Restore complete system from backup.\"\"\"\n    171:         restore_id = f\"full_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n    172: \n    173:         # Validate backup",
    "context": {
      "query_preview": "Restore complete system from backup."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 310,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    307:     async def restore_tenant(\n    308:         self, backup_id: str, tenant_id: str, strategy: RestoreStrategy = RestoreStrategy.REPLACE,\n    309:     ) -> str:\n>>> 310:         \"\"\"Restore specific tenant from backup.\"\"\"\n    311:         restore_id = f\"tenant_{tenant_id}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n    312: \n    313:         # Validate backup contains tenant",
    "context": {
      "query_preview": "Restore specific tenant from backup."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 388,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    385:     async def restore_component(\n    386:         self, backup_id: str, component: str, strategy: RestoreStrategy = RestoreStrategy.REPLACE,\n    387:     ) -> str:\n>>> 388:         \"\"\"Restore specific component from backup.\"\"\"\n    389:         restore_id = f\"comp_{component}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n    390: \n    391:         # Validate backup contains component",
    "context": {
      "query_preview": "Restore specific component from backup."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 985,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    982:             raise\n    983: \n    984:     async def _create_rollback_point(self, metadata: RestoreMetadata):\n>>> 985:         \"\"\"Create rollback point before restore.\"\"\"\n    986:         logger.info(\"Creating rollback point\")\n    987: \n    988:         try:",
    "context": {
      "query_preview": "Create rollback point before restore."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1022,
    "column": 26,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1019:             metadata.rollback_point_created = True\n    1020:             metadata.rollback_data_path = rollback_path\n    1021: \n>>> 1022:             logger.info(f\"Rollback point created at {rollback_path}\")\n    1023: \n    1024:         except Exception as e:\n    1025:             logger.warning(f\"Failed to create rollback point: {e}\")",
    "context": {
      "query_preview": "Rollback point created at "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1025,
    "column": 29,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1022:             logger.info(f\"Rollback point created at {rollback_path}\")\n    1023: \n    1024:         except Exception as e:\n>>> 1025:             logger.warning(f\"Failed to create rollback point: {e}\")\n    1026:             metadata.rollback_point_created = False\n    1027: \n    1028:     async def _rollback_restore(self, metadata: RestoreMetadata):",
    "context": {
      "query_preview": "Failed to create rollback point: "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1139,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1136:         conn = sqlite3.connect(self.restore_db)\n    1137:         cursor = conn.cursor()\n    1138: \n>>> 1139:         cursor.execute(\n    1140:             \"\"\"\n    1141:             INSERT OR REPLACE INTO restores\n    1142:             (restore_id, backup_id, restore_type, strategy, created_at, completed_at,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1140,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1137:         cursor = conn.cursor()\n    1138: \n    1139:         cursor.execute(\n>>> 1140:             \"\"\"\n    1141:             INSERT OR REPLACE INTO restores\n    1142:             (restore_id, backup_id, restore_type, strategy, created_at, completed_at,\n    1143:              status, components_to_restore, tenants_to_restore, rollback_point_created,",
    "context": {
      "query_preview": "\n            INSERT OR REPLACE INTO restores\n            (restore_id, backup_id, restore_type, strat..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1170,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1167:             ),\n    1168:         )\n    1169: \n>>> 1170:         conn.commit()\n    1171:         conn.close()\n    1172: \n    1173:     # Public query methods",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1180,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1177:         conn = sqlite3.connect(self.restore_db)\n    1178:         cursor = conn.cursor()\n    1179: \n>>> 1180:         query = \"SELECT * FROM restores\"\n    1181:         params = []\n    1182: \n    1183:         if status:",
    "context": {
      "query_preview": "SELECT * FROM restores"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1187,
    "column": 17,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1184:             query += \" WHERE status = ?\"\n    1185:             params.append(status.value)\n    1186: \n>>> 1187:         query += \" ORDER BY created_at DESC LIMIT ?\"\n    1188:         params.append(limit)\n    1189: \n    1190:         cursor.execute(query, params)",
    "context": {
      "query_preview": " ORDER BY created_at DESC LIMIT ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1190,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1187:         query += \" ORDER BY created_at DESC LIMIT ?\"\n    1188:         params.append(limit)\n    1189: \n>>> 1190:         cursor.execute(query, params)\n    1191:         rows = cursor.fetchall()\n    1192:         conn.close()\n    1193: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1230,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1227:         conn = sqlite3.connect(self.restore_db)\n    1228:         cursor = conn.cursor()\n    1229: \n>>> 1230:         cursor.execute(\"SELECT * FROM restores WHERE restore_id = ?\", (restore_id,))\n    1231:         row = cursor.fetchone()\n    1232:         conn.close()\n    1233: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1230,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1227:         conn = sqlite3.connect(self.restore_db)\n    1228:         cursor = conn.cursor()\n    1229: \n>>> 1230:         cursor.execute(\"SELECT * FROM restores WHERE restore_id = ?\", (restore_id,))\n    1231:         row = cursor.fetchone()\n    1232:         conn.close()\n    1233: ",
    "context": {
      "query_preview": "SELECT * FROM restores WHERE restore_id = ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (41 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 41,
      "methods": [
        "_restore_rag_collections",
        "_save_restore_metadata",
        "_restore_configurations",
        "_create_rollback_point",
        "_init_restore_db",
        "_rollback_restore",
        "_validate_restore_prerequisites",
        "_extract_backup",
        "_restore_tenant_data",
        "_restore_models",
        "_restore_rbac_system",
        "_restore_logs",
        "_restore_p2p_networks",
        "_restore_agents",
        "_verify_restore"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (40 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 40,
      "methods": [
        "info",
        "warning",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'conn' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "conn",
      "method_count": 10,
      "methods": [
        "close",
        "cursor",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'cursor' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "cursor",
      "method_count": 8,
      "methods": [
        "execute",
        "fetchone",
        "fetchall"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (13 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 13,
      "methods": [
        "utcnow",
        "fromisoformat"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'restore_tasks' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "restore_tasks",
      "method_count": 8,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'result' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "result",
      "method_count": 9,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'shutil' methods (48 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "shutil",
      "method_count": 48,
      "methods": [
        "copytree",
        "move",
        "disk_usage",
        "copy2",
        "rmtree"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'rbac_db_dest' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "rbac_db_dest",
      "method_count": 6,
      "methods": [
        "rename",
        "with_suffix",
        "exists"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'warnings' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "warnings",
      "method_count": 7,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'tenant_db_dest' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "tenant_db_dest",
      "method_count": 6,
      "methods": [
        "rename",
        "with_suffix",
        "exists"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'tenant_dir' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "tenant_dir",
      "method_count": 10,
      "methods": [
        "is_dir",
        "rglob"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'dest_path' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "dest_path",
      "method_count": 11,
      "methods": [
        "mkdir",
        "with_suffix",
        "exists"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'item' methods (16 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "item",
      "method_count": 16,
      "methods": [
        "relative_to",
        "is_file"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'json' methods (18 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "json",
      "method_count": 18,
      "methods": [
        "dumps",
        "loads"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1175,
    "column": 84,
    "description": "Excessive magic literals detected (43 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    1172: \n    1173:     # Public query methods\n    1174: \n>>> 1175:     async def list_restores(self, status: RestoreStatus | None = None, limit: int = 50) -> list[RestoreMetadata]:\n    1176:         \"\"\"List restore operations.\"\"\"\n    1177:         conn = sqlite3.connect(self.restore_db)\n    1178:         cursor = conn.cursor()",
    "context": {
      "total_magic_literals": 43,
      "current_value": 50
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1200,
    "column": 45,
    "description": "Excessive magic literals detected (43 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    1197:                 restore_id=row[0],\n    1198:                 backup_id=row[1],\n    1199:                 restore_type=RestoreType(row[2]),\n>>> 1200:                 strategy=RestoreStrategy(row[3]),\n    1201:                 created_at=datetime.fromisoformat(row[4]),\n    1202:                 completed_at=datetime.fromisoformat(row[5]) if row[5] else None,\n    1203:                 status=RestoreStatus(row[6]),",
    "context": {
      "total_magic_literals": 43,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1201,
    "column": 54,
    "description": "Excessive magic literals detected (43 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    1198:                 backup_id=row[1],\n    1199:                 restore_type=RestoreType(row[2]),\n    1200:                 strategy=RestoreStrategy(row[3]),\n>>> 1201:                 created_at=datetime.fromisoformat(row[4]),\n    1202:                 completed_at=datetime.fromisoformat(row[5]) if row[5] else None,\n    1203:                 status=RestoreStatus(row[6]),\n    1204:                 components_to_restore=json.loads(row[7]) if row[7] else [],",
    "context": {
      "total_magic_literals": 43,
      "current_value": 4
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1202,
    "column": 67,
    "description": "Excessive magic literals detected (43 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    1199:                 restore_type=RestoreType(row[2]),\n    1200:                 strategy=RestoreStrategy(row[3]),\n    1201:                 created_at=datetime.fromisoformat(row[4]),\n>>> 1202:                 completed_at=datetime.fromisoformat(row[5]) if row[5] else None,\n    1203:                 status=RestoreStatus(row[6]),\n    1204:                 components_to_restore=json.loads(row[7]) if row[7] else [],\n    1205:                 tenants_to_restore=json.loads(row[8]) if row[8] else [],",
    "context": {
      "total_magic_literals": 43,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\backup\\restore_manager.py",
    "line_number": 1202,
    "column": 56,
    "description": "Excessive magic literals detected (43 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    1199:                 restore_type=RestoreType(row[2]),\n    1200:                 strategy=RestoreStrategy(row[3]),\n    1201:                 created_at=datetime.fromisoformat(row[4]),\n>>> 1202:                 completed_at=datetime.fromisoformat(row[5]) if row[5] else None,\n    1203:                 status=RestoreStatus(row[6]),\n    1204:                 components_to_restore=json.loads(row[7]) if row[7] else [],\n    1205:                 tenants_to_restore=json.loads(row[8]) if row[8] else [],",
    "context": {
      "total_magic_literals": 43,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\benchmark_advanced_compression.py",
    "line_number": 12,
    "column": 0,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "      9: \n     10: from torch import nn\n     11: \n>>>  12: sys.path.insert(0, str(Path(__file__).resolve().parents[1] / \"src\"))\n     13: \n     14: from core.compression.advanced_pipeline import AdvancedCompressionPipeline\n     15: from core.compression.simple_quantizer import SimpleQuantizer",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\benchmark_compression.py",
    "line_number": 14,
    "column": 0,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     11: from torch import nn\n     12: \n     13: src_root = Path(__file__).parent.parent / \"src\"\n>>>  14: sys.path.insert(0, str(src_root))\n     15: spec = importlib.util.spec_from_file_location(\n     16:     \"simple_quantizer\", src_root / \"core\" / \"compression\" / \"simple_quantizer.py\",\n     17: )",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\benchmark_compression.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'nn' methods (28 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "nn",
      "method_count": 28,
      "methods": [
        "Sequential",
        "Linear",
        "ReLU"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\benchmark_compression.py",
    "line_number": 27,
    "column": 22,
    "description": "Excessive magic literals detected (29 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     24: def create_test_models():\n     25:     models = {\n     26:         \"tiny\": nn.Sequential(\n>>>  27:             nn.Linear(128, 64),\n     28:             nn.ReLU(),\n     29:             nn.Linear(64, 10),\n     30:         ),",
    "context": {
      "total_magic_literals": 29,
      "current_value": 128
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\benchmark_compression.py",
    "line_number": 27,
    "column": 27,
    "description": "Excessive magic literals detected (29 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     24: def create_test_models():\n     25:     models = {\n     26:         \"tiny\": nn.Sequential(\n>>>  27:             nn.Linear(128, 64),\n     28:             nn.ReLU(),\n     29:             nn.Linear(64, 10),\n     30:         ),",
    "context": {
      "total_magic_literals": 29,
      "current_value": 64
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\benchmark_compression.py",
    "line_number": 29,
    "column": 22,
    "description": "Excessive magic literals detected (29 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     26:         \"tiny\": nn.Sequential(\n     27:             nn.Linear(128, 64),\n     28:             nn.ReLU(),\n>>>  29:             nn.Linear(64, 10),\n     30:         ),\n     31:         \"small\": nn.Sequential(\n     32:             nn.Linear(784, 256),",
    "context": {
      "total_magic_literals": 29,
      "current_value": 64
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\benchmark_compression.py",
    "line_number": 32,
    "column": 22,
    "description": "Excessive magic literals detected (29 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     29:             nn.Linear(64, 10),\n     30:         ),\n     31:         \"small\": nn.Sequential(\n>>>  32:             nn.Linear(784, 256),\n     33:             nn.ReLU(),\n     34:             nn.Linear(256, 128),\n     35:             nn.ReLU(),",
    "context": {
      "total_magic_literals": 29,
      "current_value": 784
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\benchmark_compression.py",
    "line_number": 32,
    "column": 27,
    "description": "Excessive magic literals detected (29 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     29:             nn.Linear(64, 10),\n     30:         ),\n     31:         \"small\": nn.Sequential(\n>>>  32:             nn.Linear(784, 256),\n     33:             nn.ReLU(),\n     34:             nn.Linear(256, 128),\n     35:             nn.ReLU(),",
    "context": {
      "total_magic_literals": 29,
      "current_value": 256
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\benchmark_unified_compression.py",
    "line_number": 12,
    "column": 0,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "      9: import psutil\n     10: from torch import nn\n     11: \n>>>  12: sys.path.insert(0, str(Path(__file__).parent.parent / \"src\"))\n     13: \n     14: from compression.pipeline import UnifiedCompressor\n     15: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\benchmark_unified_compression.py",
    "line_number": 34,
    "column": 0,
    "description": "Method 'benchmark_all_methods' is too complex: 11 complexity, 81 lines, 9 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     31:     }\n     32: \n     33: \n>>>  34: def benchmark_all_methods() -> None:\n     35:     print(\"Comprehensive Compression Benchmark\")\n     36:     print(\"=\" * 80)\n     37:     print(\"Comparing: Sprint 9 SimpleQuantizer vs Advanced Pipeline vs Unified\")",
    "context": {
      "complexity": 11,
      "lines": 81,
      "max_nesting": 9,
      "method_name": "benchmark_all_methods"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\benchmark_unified_compression.py",
    "line_number": 81,
    "column": 28,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     78:                 print(f\"    Time: {elapsed:.2f}s\")\n     79:                 print(f\"    Memory used: {mem_used:.1f}MB\")\n     80:                 if \"Unified\" in comp_name:\n>>>  81:                     print(f\"    Method selected: {result['method']}\")\n     82:                 results.append(\n     83:                     {\n     84:                         \"model\": model_name,",
    "context": {
      "query_preview": "    Method selected: "
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\benchmark_unified_compression.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'nn' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "nn",
      "method_count": 11,
      "methods": [
        "Sequential",
        "Linear",
        "ReLU"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\benchmark_unified_compression.py",
    "line_number": 25,
    "column": 22,
    "description": "Excessive magic literals detected (30 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     22:         \"tiny\": nn.Linear(100, 100),\n     23:         \"small\": nn.Sequential(nn.Linear(1000, 1000), nn.ReLU(), nn.Linear(1000, 1000)),\n     24:         \"medium\": nn.Sequential(\n>>>  25:             nn.Linear(2048, 2048),\n     26:             nn.ReLU(),\n     27:             nn.Linear(2048, 2048),\n     28:             nn.ReLU(),",
    "context": {
      "total_magic_literals": 30,
      "current_value": 2048
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\benchmark_unified_compression.py",
    "line_number": 25,
    "column": 28,
    "description": "Excessive magic literals detected (30 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     22:         \"tiny\": nn.Linear(100, 100),\n     23:         \"small\": nn.Sequential(nn.Linear(1000, 1000), nn.ReLU(), nn.Linear(1000, 1000)),\n     24:         \"medium\": nn.Sequential(\n>>>  25:             nn.Linear(2048, 2048),\n     26:             nn.ReLU(),\n     27:             nn.Linear(2048, 2048),\n     28:             nn.ReLU(),",
    "context": {
      "total_magic_literals": 30,
      "current_value": 2048
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\benchmark_unified_compression.py",
    "line_number": 27,
    "column": 22,
    "description": "Excessive magic literals detected (30 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     24:         \"medium\": nn.Sequential(\n     25:             nn.Linear(2048, 2048),\n     26:             nn.ReLU(),\n>>>  27:             nn.Linear(2048, 2048),\n     28:             nn.ReLU(),\n     29:             nn.Linear(2048, 2048),\n     30:         ),",
    "context": {
      "total_magic_literals": 30,
      "current_value": 2048
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\benchmark_unified_compression.py",
    "line_number": 27,
    "column": 28,
    "description": "Excessive magic literals detected (30 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     24:         \"medium\": nn.Sequential(\n     25:             nn.Linear(2048, 2048),\n     26:             nn.ReLU(),\n>>>  27:             nn.Linear(2048, 2048),\n     28:             nn.ReLU(),\n     29:             nn.Linear(2048, 2048),\n     30:         ),",
    "context": {
      "total_magic_literals": 30,
      "current_value": 2048
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\benchmark_unified_compression.py",
    "line_number": 29,
    "column": 22,
    "description": "Excessive magic literals detected (30 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     26:             nn.ReLU(),\n     27:             nn.Linear(2048, 2048),\n     28:             nn.ReLU(),\n>>>  29:             nn.Linear(2048, 2048),\n     30:         ),\n     31:     }\n     32: ",
    "context": {
      "total_magic_literals": 30,
      "current_value": 2048
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_creativity.py",
    "line_number": 2,
    "column": 0,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "      1: #!/usr/bin/env python3\n>>>   2: \"\"\"HypeRAG Creativity Benchmark Suite.\n      3: \n      4: Measures novelty and plausibility of creative connections generated by the HypeRAG system.\n      5: ",
    "context": {
      "query_preview": "HypeRAG Creativity Benchmark Suite.\n\nMeasures novelty and plausibility of creative connections gener..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_creativity.py",
    "line_number": 83,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     80:         self.cross_domain_pairs = self._create_cross_domain_pairs()\n     81: \n     82:     def _create_remote_association_tasks(self) -> list[RemoteAssociationTask]:\n>>>  83:         \"\"\"Create remote association challenge tasks.\"\"\"\n     84:         tasks = [\n     85:             # Easy tasks\n     86:             RemoteAssociationTask(\"rat_001\", [\"cottage\", \"swiss\", \"cake\"], \"cheese\", \"food\", \"easy\"),",
    "context": {
      "query_preview": "Create remote association challenge tasks."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\hyperag_creativity.py",
    "line_number": 106,
    "column": 4,
    "description": "Method '_create_cross_domain_pairs' is too complex: 1 complexity, 129 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    103:         ]\n    104:         return tasks\n    105: \n>>> 106:     def _create_cross_domain_pairs(self) -> list[CrossDomainPair]:\n    107:         \"\"\"Create cross-domain concept connection tasks.\"\"\"\n    108:         pairs = [\n    109:             # Biology \u2194 Finance",
    "context": {
      "complexity": 1,
      "lines": 129,
      "max_nesting": 0,
      "method_name": "_create_cross_domain_pairs"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_creativity.py",
    "line_number": 107,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    104:         return tasks\n    105: \n    106:     def _create_cross_domain_pairs(self) -> list[CrossDomainPair]:\n>>> 107:         \"\"\"Create cross-domain concept connection tasks.\"\"\"\n    108:         pairs = [\n    109:             # Biology \u2194 Finance\n    110:             CrossDomainPair(",
    "context": {
      "query_preview": "Create cross-domain concept connection tasks."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_creativity.py",
    "line_number": 262,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    259:         self.user_scores = {}\n    260: \n    261:     def load_user_evaluation_scores(self, scores_path: Path) -> None:\n>>> 262:         \"\"\"Load manual user evaluation scores from JSON file.\"\"\"\n    263:         try:\n    264:             with open(scores_path) as f:\n    265:                 self.user_scores = json.load(f)",
    "context": {
      "query_preview": "Load manual user evaluation scores from JSON file."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_creativity.py",
    "line_number": 590,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    587:         return creativity_metrics\n    588: \n    589:     def _combine_results(self, rat_results: dict, cd_results: dict) -> dict[str, float]:\n>>> 590:         \"\"\"Combine results from both evaluation types.\"\"\"\n    591:         rat_metrics = rat_results[\"summary_metrics\"]\n    592:         cd_metrics = cd_results[\"summary_metrics\"]\n    593: ",
    "context": {
      "query_preview": "Combine results from both evaluation types."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\hyperag_creativity.py",
    "line_number": 647,
    "column": 0,
    "description": "Method 'create_sample_user_scores' is too complex: 7 complexity, 23 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    644:         logger.info(f\"Metrics saved to {metrics_file}\")\n    645: \n    646: \n>>> 647: def create_sample_user_scores():\n    648:     \"\"\"Create a sample user evaluation scores file.\"\"\"\n    649:     sample_scores = {}\n    650: ",
    "context": {
      "complexity": 7,
      "lines": 23,
      "max_nesting": 6,
      "method_name": "create_sample_user_scores"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_creativity.py",
    "line_number": 648,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    645: \n    646: \n    647: def create_sample_user_scores():\n>>> 648:     \"\"\"Create a sample user evaluation scores file.\"\"\"\n    649:     sample_scores = {}\n    650: \n    651:     # Generate sample scores for common bridge IDs",
    "context": {
      "query_preview": "Create a sample user evaluation scores file."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_creativity.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (15 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 15,
      "methods": [
        "load_user_evaluation_scores",
        "_generate_cross_domain_bridges",
        "_calculate_summary_metrics",
        "_generate_creative_bridges_for_task",
        "_evaluate_creative_bridge",
        "_create_cross_domain_pairs",
        "_calculate_surprise_score",
        "_create_remote_association_tasks",
        "evaluate_remote_association_tasks",
        "evaluate_cross_domain_pairs",
        "_save_results",
        "_combine_results",
        "_calculate_precision_score"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_creativity.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (13 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 13,
      "methods": [
        "info",
        "warning",
        "exception"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_creativity.py",
    "line_number": 368,
    "column": 45,
    "description": "Excessive magic literals detected (29 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    365:         for i, cue_word in enumerate(task.cue_words):\n    366:             bridge = CreativeBridge(\n    367:                 id=f\"{task.task_id}_bridge_{i}\",\n>>> 368:                 confidence=np.random.uniform(0.4, 0.9),\n    369:                 bridge_type=\"semantic_association\",\n    370:                 source_nodes=[cue_word],\n    371:                 target_nodes=[task.target_word],",
    "context": {
      "total_magic_literals": 29,
      "current_value": 0.4
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_creativity.py",
    "line_number": 368,
    "column": 50,
    "description": "Excessive magic literals detected (29 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    365:         for i, cue_word in enumerate(task.cue_words):\n    366:             bridge = CreativeBridge(\n    367:                 id=f\"{task.task_id}_bridge_{i}\",\n>>> 368:                 confidence=np.random.uniform(0.4, 0.9),\n    369:                 bridge_type=\"semantic_association\",\n    370:                 source_nodes=[cue_word],\n    371:                 target_nodes=[task.target_word],",
    "context": {
      "total_magic_literals": 29,
      "current_value": 0.9
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_creativity.py",
    "line_number": 379,
    "column": 45,
    "description": "Excessive magic literals detected (29 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    376:         for i in range(2):  # Generate 2 additional creative bridges\n    377:             bridge = CreativeBridge(\n    378:                 id=f\"{task.task_id}_creative_{i}\",\n>>> 379:                 confidence=np.random.uniform(0.3, 0.8),\n    380:                 bridge_type=\"creative_leap\",\n    381:                 source_nodes=task.cue_words,\n    382:                 target_nodes=[task.target_word, f\"creative_concept_{i}\"],",
    "context": {
      "total_magic_literals": 29,
      "current_value": 0.3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_creativity.py",
    "line_number": 379,
    "column": 50,
    "description": "Excessive magic literals detected (29 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    376:         for i in range(2):  # Generate 2 additional creative bridges\n    377:             bridge = CreativeBridge(\n    378:                 id=f\"{task.task_id}_creative_{i}\",\n>>> 379:                 confidence=np.random.uniform(0.3, 0.8),\n    380:                 bridge_type=\"creative_leap\",\n    381:                 source_nodes=task.cue_words,\n    382:                 target_nodes=[task.target_word, f\"creative_concept_{i}\"],",
    "context": {
      "total_magic_literals": 29,
      "current_value": 0.8
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_creativity.py",
    "line_number": 393,
    "column": 66,
    "description": "Excessive magic literals detected (29 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    390:         bridges = []\n    391: \n    392:         # Generate bridges based on expected connections\n>>> 393:         for i, connection in enumerate(pair.expected_connections[:3]):  # Top 3 expected\n    394:             bridge = CreativeBridge(\n    395:                 id=f\"{pair.pair_id}_bridge_{i}\",\n    396:                 confidence=np.random.uniform(0.5, 0.9),",
    "context": {
      "total_magic_literals": 29,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 87,
    "column": 4,
    "description": "Method '_create_movielens_queries' is too complex: 1 complexity, 94 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     84:         self.movielens_queries = self._create_movielens_queries()\n     85:         self.doc_click_queries = self._create_doc_click_queries()\n     86: \n>>>  87:     def _create_movielens_queries(self) -> list[UserQuery]:\n     88:         \"\"\"Create MovieLens-style queries.\"\"\"\n     89:         queries = []\n     90: ",
    "context": {
      "complexity": 1,
      "lines": 94,
      "max_nesting": 0,
      "method_name": "_create_movielens_queries"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 88,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     85:         self.doc_click_queries = self._create_doc_click_queries()\n     86: \n     87:     def _create_movielens_queries(self) -> list[UserQuery]:\n>>>  88:         \"\"\"Create MovieLens-style queries.\"\"\"\n     89:         queries = []\n     90: \n     91:         # User 1: Action movie enthusiast",
    "context": {
      "query_preview": "Create MovieLens-style queries."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 183,
    "column": 4,
    "description": "Method '_create_doc_click_queries' is too complex: 1 complexity, 94 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    180: \n    181:         return queries\n    182: \n>>> 183:     def _create_doc_click_queries(self) -> list[UserQuery]:\n    184:         \"\"\"Create document click-based queries.\"\"\"\n    185:         queries = []\n    186: ",
    "context": {
      "complexity": 1,
      "lines": 94,
      "max_nesting": 0,
      "method_name": "_create_doc_click_queries"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 184,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    181:         return queries\n    182: \n    183:     def _create_doc_click_queries(self) -> list[UserQuery]:\n>>> 184:         \"\"\"Create document click-based queries.\"\"\"\n    185:         queries = []\n    186: \n    187:         # User 1: Machine Learning researcher",
    "context": {
      "query_preview": "Create document click-based queries."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 279,
    "column": 4,
    "description": "Method 'get_personalization_contexts' is too complex: 1 complexity, 82 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    276: \n    277:         return queries\n    278: \n>>> 279:     def get_personalization_contexts(self) -> dict[str, PersonalizationContext]:\n    280:         \"\"\"Get user personalization contexts.\"\"\"\n    281:         contexts = {}\n    282: ",
    "context": {
      "complexity": 1,
      "lines": 82,
      "max_nesting": 0,
      "method_name": "get_personalization_contexts"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 534,
    "column": 4,
    "description": "Method '_calculate_alpha_factor' is too complex: 12 complexity, 27 lines, 7 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    531: \n    532:         return results\n    533: \n>>> 534:     def _calculate_alpha_factor(self, item_id: str, context: PersonalizationContext) -> float:\n    535:         \"\"\"Calculate \u03b1 rescoring factor based on user preferences.\"\"\"\n    536:         # Mock \u03b1 calculation based on user preferences\n    537:         alpha_score = 0.5",
    "context": {
      "complexity": 12,
      "lines": 27,
      "max_nesting": 7,
      "method_name": "_calculate_alpha_factor"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 612,
    "column": 4,
    "description": "Method '_calculate_icl_factor' is too complex: 12 complexity, 42 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    609: \n    610:         return results\n    611: \n>>> 612:     def _calculate_icl_factor(self, query: UserQuery, item_id: str, context: PersonalizationContext) -> float:\n    613:         \"\"\"Calculate ICL enhancement factor using single triple context.\"\"\"\n    614:         # Mock ICL calculation - in reality would use language models\n    615:         icl_score = 0.5",
    "context": {
      "complexity": 12,
      "lines": 42,
      "max_nesting": 6,
      "method_name": "_calculate_icl_factor"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 854,
    "column": 4,
    "description": "Method '_generate_comparison_analysis' is too complex: 8 complexity, 38 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    851:         logger.info(f\"Results saved to {results_file}\")\n    852:         logger.info(f\"Metrics saved to {metrics_file}\")\n    853: \n>>> 854:     def _generate_comparison_analysis(self, results: dict[str, PersonalizationMetrics]) -> dict[str, Any]:\n    855:         \"\"\"Generate comparative analysis of approaches.\"\"\"\n    856:         base_result = results.get(\"Base PPR\")\n    857:         if not base_result:",
    "context": {
      "complexity": 8,
      "lines": 38,
      "max_nesting": 6,
      "method_name": "_generate_comparison_analysis"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 87,
    "column": 4,
    "description": "Duplicate code block detected in function '_create_movielens_queries'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "     84:         self.movielens_queries = self._create_movielens_queries()\n     85:         self.doc_click_queries = self._create_doc_click_queries()\n     86: \n>>>  87:     def _create_movielens_queries(self) -> list[UserQuery]:\n     88:         \"\"\"Create MovieLens-style queries.\"\"\"\n     89:         queries = []\n     90: ",
    "context": {
      "duplicate_count": 2,
      "function_name": "_create_movielens_queries",
      "signature": "ASSIGN|CALL_append|CALL_append|CALL_append|CALL_append|CALL_append|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 183,
    "column": 4,
    "description": "Duplicate code block detected in function '_create_doc_click_queries'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    180: \n    181:         return queries\n    182: \n>>> 183:     def _create_doc_click_queries(self) -> list[UserQuery]:\n    184:         \"\"\"Create document click-based queries.\"\"\"\n    185:         queries = []\n    186: ",
    "context": {
      "duplicate_count": 2,
      "function_name": "_create_doc_click_queries",
      "signature": "ASSIGN|CALL_append|CALL_append|CALL_append|CALL_append|CALL_append|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (13 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 13,
      "methods": [
        "_calculate_alpha_factor",
        "_calculate_recall_at_k",
        "_calculate_icl_factor",
        "_calculate_ndcg_at_k",
        "calculate_token_cost",
        "_evaluate_approach",
        "_create_doc_click_queries",
        "_generate_comparison_analysis",
        "_save_benchmark_results",
        "_create_movielens_queries",
        "_calculate_map"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'queries' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "queries",
      "method_count": 10,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'results' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "results",
      "method_count": 10,
      "methods": [
        "get",
        "sort",
        "keys",
        "items",
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 9,
      "methods": [
        "now"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 8,
      "methods": [
        "info",
        "warning",
        "exception"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 99,
    "column": 33,
    "description": "Excessive magic literals detected (140 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     96:                 query_text=\"exciting action movies with great special effects\",\n     97:                 relevant_items=[\"movie_001\", \"movie_005\", \"movie_012\", \"movie_018\"],\n     98:                 relevance_scores={\n>>>  99:                     \"movie_001\": 0.95,  # Top Gun: Maverick\n    100:                     \"movie_005\": 0.88,  # John Wick 4\n    101:                     \"movie_012\": 0.82,  # Fast X\n    102:                     \"movie_018\": 0.79,  # Mission Impossible",
    "context": {
      "total_magic_literals": 140,
      "current_value": 0.95
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 100,
    "column": 33,
    "description": "Excessive magic literals detected (140 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     97:                 relevant_items=[\"movie_001\", \"movie_005\", \"movie_012\", \"movie_018\"],\n     98:                 relevance_scores={\n     99:                     \"movie_001\": 0.95,  # Top Gun: Maverick\n>>> 100:                     \"movie_005\": 0.88,  # John Wick 4\n    101:                     \"movie_012\": 0.82,  # Fast X\n    102:                     \"movie_018\": 0.79,  # Mission Impossible\n    103:                     \"movie_023\": 0.65,  # Marvel movie",
    "context": {
      "total_magic_literals": 140,
      "current_value": 0.88
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 101,
    "column": 33,
    "description": "Excessive magic literals detected (140 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     98:                 relevance_scores={\n     99:                     \"movie_001\": 0.95,  # Top Gun: Maverick\n    100:                     \"movie_005\": 0.88,  # John Wick 4\n>>> 101:                     \"movie_012\": 0.82,  # Fast X\n    102:                     \"movie_018\": 0.79,  # Mission Impossible\n    103:                     \"movie_023\": 0.65,  # Marvel movie\n    104:                 },",
    "context": {
      "total_magic_literals": 140,
      "current_value": 0.82
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 102,
    "column": 33,
    "description": "Excessive magic literals detected (140 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     99:                     \"movie_001\": 0.95,  # Top Gun: Maverick\n    100:                     \"movie_005\": 0.88,  # John Wick 4\n    101:                     \"movie_012\": 0.82,  # Fast X\n>>> 102:                     \"movie_018\": 0.79,  # Mission Impossible\n    103:                     \"movie_023\": 0.65,  # Marvel movie\n    104:                 },\n    105:                 domain=\"movies\",",
    "context": {
      "total_magic_literals": 140,
      "current_value": 0.79
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_personalization.py",
    "line_number": 103,
    "column": 33,
    "description": "Excessive magic literals detected (140 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    100:                     \"movie_005\": 0.88,  # John Wick 4\n    101:                     \"movie_012\": 0.82,  # Fast X\n    102:                     \"movie_018\": 0.79,  # Mission Impossible\n>>> 103:                     \"movie_023\": 0.65,  # Marvel movie\n    104:                 },\n    105:                 domain=\"movies\",\n    106:             ),",
    "context": {
      "total_magic_literals": 140,
      "current_value": 0.65
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 2,
    "column": 0,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "      1: #!/usr/bin/env python3\n>>>   2: \"\"\"HypeRAG Graph Repair Test Suite.\n      3: \n      4: Injects controlled violations into test knowledge graphs and measures the repair pipeline's ability to:\n      5: - Detect violations (Detection Recall)",
    "context": {
      "query_preview": "HypeRAG Graph Repair Test Suite.\n\nInjects controlled violations into test knowledge graphs and measu..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 97,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     94:         self.violation_templates = self._create_violation_templates()\n     95: \n     96:     def _create_violation_templates(self) -> dict[str, dict]:\n>>>  97:         \"\"\"Create templates for different violation types.\"\"\"\n     98:         return {\n     99:             \"allergy_conflict\": {\n    100:                 \"description\": \"Patient prescribed drug they are allergic to\",",
    "context": {
      "query_preview": "Create templates for different violation types."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 118,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    115:                 \"repair_operations\": [\"update_property\"],\n    116:             },\n    117:             \"missing_critical_property\": {\n>>> 118:                 \"description\": \"Critical property missing from entity\",\n    119:                 \"severity\": \"medium\",\n    120:                 \"detection_expected\": True,\n    121:                 \"repair_operations\": [\"add_property\", \"update_property\"],",
    "context": {
      "query_preview": "Critical property missing from entity"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 146,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    143:     def create_medical_test_graph(\n    144:         self,\n    145:     ) -> tuple[list[TestGraphNode], list[TestGraphEdge]]:\n>>> 146:         \"\"\"Create a medical domain test graph.\"\"\"\n    147:         nodes = [\n    148:             # Patients\n    149:             TestGraphNode(\"P001\", \"Patient\", {\"name\": \"John Doe\", \"age\": 45, \"gender\": \"M\"}),",
    "context": {
      "query_preview": "Create a medical domain test graph."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 193,
    "column": 4,
    "description": "Method 'inject_allergy_conflict' is too complex: 13 complexity, 71 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    190: \n    191:         return nodes, edges\n    192: \n>>> 193:     def inject_allergy_conflict(self, nodes: list[TestGraphNode], edges: list[TestGraphEdge]) -> InjectedViolation:\n    194:         \"\"\"Inject an allergy conflict violation.\"\"\"\n    195:         violation_id = f\"violation_{uuid.uuid4().hex[:8]}\"\n    196: ",
    "context": {
      "complexity": 13,
      "lines": 71,
      "max_nesting": 8,
      "method_name": "inject_allergy_conflict"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 795,
    "column": 4,
    "description": "Method '_calculate_repair_metrics' is too complex: 4 complexity, 51 lines, 2 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    792: \n    793:         return residual_violations\n    794: \n>>> 795:     def _calculate_repair_metrics(\n    796:         self,\n    797:         violations: list[InjectedViolation],\n    798:         detections: list[dict[str, Any]],",
    "context": {
      "complexity": 4,
      "lines": 51,
      "max_nesting": 2,
      "method_name": "_calculate_repair_metrics"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 312,
    "column": 4,
    "description": "Duplicate code block detected in function 'inject_temporal_inconsistency'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    309:             },\n    310:         )\n    311: \n>>> 312:     def inject_temporal_inconsistency(\n    313:         self, nodes: list[TestGraphNode], edges: list[TestGraphEdge],\n    314:     ) -> InjectedViolation:\n    315:         \"\"\"Inject a temporal inconsistency violation.\"\"\"",
    "context": {
      "duplicate_count": 2,
      "function_name": "inject_temporal_inconsistency",
      "signature": "ASSIGN|ASSIGN|FOR|IF|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 360,
    "column": 4,
    "description": "Duplicate code block detected in function 'inject_missing_critical_property'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    357:             },\n    358:         )\n    359: \n>>> 360:     def inject_missing_critical_property(\n    361:         self, nodes: list[TestGraphNode], edges: list[TestGraphEdge],\n    362:     ) -> InjectedViolation:\n    363:         \"\"\"Inject a missing critical property violation.\"\"\"",
    "context": {
      "duplicate_count": 2,
      "function_name": "inject_missing_critical_property",
      "signature": "ASSIGN|ASSIGN|FOR|IF|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 9,
      "methods": [
        "_generate_repair_proposals",
        "_validate_with_guardian",
        "_create_violation_templates",
        "_run_single_violation_test",
        "_detect_violations",
        "_save_test_results",
        "_calculate_repair_metrics",
        "_convert_to_graph_format",
        "_check_residual_violations"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'edges' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "edges",
      "method_count": 6,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 8,
      "methods": [
        "now",
        "strptime"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 8,
      "methods": [
        "info",
        "exception",
        "debug"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'proposal' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "proposal",
      "method_count": 6,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 149,
    "column": 73,
    "description": "Excessive magic literals detected (23 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    146:         \"\"\"Create a medical domain test graph.\"\"\"\n    147:         nodes = [\n    148:             # Patients\n>>> 149:             TestGraphNode(\"P001\", \"Patient\", {\"name\": \"John Doe\", \"age\": 45, \"gender\": \"M\"}),\n    150:             TestGraphNode(\"P002\", \"Patient\", {\"name\": \"Jane Smith\", \"age\": 32, \"gender\": \"F\"}),\n    151:             TestGraphNode(\"P003\", \"Patient\", {\"name\": \"Bob Johnson\", \"age\": 67, \"gender\": \"M\"}),\n    152:             # Drugs",
    "context": {
      "total_magic_literals": 23,
      "current_value": 45
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 150,
    "column": 75,
    "description": "Excessive magic literals detected (23 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    147:         nodes = [\n    148:             # Patients\n    149:             TestGraphNode(\"P001\", \"Patient\", {\"name\": \"John Doe\", \"age\": 45, \"gender\": \"M\"}),\n>>> 150:             TestGraphNode(\"P002\", \"Patient\", {\"name\": \"Jane Smith\", \"age\": 32, \"gender\": \"F\"}),\n    151:             TestGraphNode(\"P003\", \"Patient\", {\"name\": \"Bob Johnson\", \"age\": 67, \"gender\": \"M\"}),\n    152:             # Drugs\n    153:             TestGraphNode(\"D001\", \"Drug\", {\"name\": \"Aspirin\", \"class\": \"NSAID\"}),",
    "context": {
      "total_magic_literals": 23,
      "current_value": 32
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 151,
    "column": 76,
    "description": "Excessive magic literals detected (23 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    148:             # Patients\n    149:             TestGraphNode(\"P001\", \"Patient\", {\"name\": \"John Doe\", \"age\": 45, \"gender\": \"M\"}),\n    150:             TestGraphNode(\"P002\", \"Patient\", {\"name\": \"Jane Smith\", \"age\": 32, \"gender\": \"F\"}),\n>>> 151:             TestGraphNode(\"P003\", \"Patient\", {\"name\": \"Bob Johnson\", \"age\": 67, \"gender\": \"M\"}),\n    152:             # Drugs\n    153:             TestGraphNode(\"D001\", \"Drug\", {\"name\": \"Aspirin\", \"class\": \"NSAID\"}),\n    154:             TestGraphNode(\"D002\", \"Drug\", {\"name\": \"Penicillin\", \"class\": \"Antibiotic\"}),",
    "context": {
      "total_magic_literals": 23,
      "current_value": 67
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 195,
    "column": 54,
    "description": "Excessive magic literals detected (23 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    192: \n    193:     def inject_allergy_conflict(self, nodes: list[TestGraphNode], edges: list[TestGraphEdge]) -> InjectedViolation:\n    194:         \"\"\"Inject an allergy conflict violation.\"\"\"\n>>> 195:         violation_id = f\"violation_{uuid.uuid4().hex[:8]}\"\n    196: \n    197:         # Find a patient with an allergy\n    198:         allergic_patient = None",
    "context": {
      "total_magic_literals": 23,
      "current_value": 8
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\hyperag_repair_test_suite.py",
    "line_number": 268,
    "column": 54,
    "description": "Excessive magic literals detected (23 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    265: \n    266:     def inject_duplicate_identity(self, nodes: list[TestGraphNode], edges: list[TestGraphEdge]) -> InjectedViolation:\n    267:         \"\"\"Inject a duplicate identity violation.\"\"\"\n>>> 268:         violation_id = f\"violation_{uuid.uuid4().hex[:8]}\"\n    269: \n    270:         # Create a duplicate of an existing patient\n    271:         original_patient = nodes[0]  # Take first patient",
    "context": {
      "total_magic_literals": 23,
      "current_value": 8
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\p2p_network_benchmark.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'writer' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "writer",
      "method_count": 7,
      "methods": [
        "close",
        "write",
        "drain",
        "wait_closed"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 27,
    "column": 0,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     24:     sys.exit(1)\n     25: \n     26: # Add src to path for imports\n>>>  27: sys.path.insert(0, str(Path(__file__).parent.parent / \"src\"))\n     28: \n     29: # Configure logging\n     30: logging.basicConfig(",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 84,
    "column": 4,
    "description": "Method 'run_compression_test' is too complex: 5 complexity, 65 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     81:     def __init__(self) -> None:\n     82:         self.results = {}\n     83: \n>>>  84:     def run_compression_test(self) -> dict[str, Any]:\n     85:         \"\"\"Test compression pipeline with sample model.\"\"\"\n     86:         logger.info(\"Starting compression pipeline benchmark...\")\n     87:         monitor = PerformanceMonitor()",
    "context": {
      "complexity": 5,
      "lines": 65,
      "max_nesting": 1,
      "method_name": "run_compression_test"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 158,
    "column": 4,
    "description": "Method 'run_evolution_test' is too complex: 3 complexity, 51 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    155:     def __init__(self) -> None:\n    156:         self.results = {}\n    157: \n>>> 158:     def run_evolution_test(self) -> dict[str, Any]:\n    159:         \"\"\"Test evolution system with mini tournament.\"\"\"\n    160:         logger.info(\"Starting evolution system benchmark...\")\n    161:         monitor = PerformanceMonitor()",
    "context": {
      "complexity": 3,
      "lines": 51,
      "max_nesting": 0,
      "method_name": "run_evolution_test"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 218,
    "column": 4,
    "description": "Method 'run_rag_test' is too complex: 4 complexity, 80 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    215:     def __init__(self) -> None:\n    216:         self.results = {}\n    217: \n>>> 218:     def run_rag_test(self) -> dict[str, Any]:\n    219:         \"\"\"Test RAG pipeline with sample documents and queries.\"\"\"\n    220:         logger.info(\"Starting RAG pipeline benchmark...\")\n    221:         monitor = PerformanceMonitor()",
    "context": {
      "complexity": 4,
      "lines": 80,
      "max_nesting": 1,
      "method_name": "run_rag_test"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 259,
    "column": 25,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    256: \n    257:             for query in test_queries:\n    258:                 query_start = time.time()\n>>> 259:                 result = rag_manager.query(query, top_k=3)\n    260:                 query_time = time.time() - query_start\n    261:                 total_query_time += query_time\n    262: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 361,
    "column": 4,
    "description": "Method 'compare_with_baseline' is too complex: 10 complexity, 40 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    358:         logger.info(f\"Results saved to {filepath}\")\n    359:         return str(filepath)\n    360: \n>>> 361:     def compare_with_baseline(self, results: dict[str, Any]) -> dict[str, Any]:\n    362:         \"\"\"Compare current results with baseline if available.\"\"\"\n    363:         try:\n    364:             baseline_path = Path(__file__).parent / \"benchmark_results\" / \"baseline.json\"",
    "context": {
      "complexity": 10,
      "lines": 40,
      "max_nesting": 6,
      "method_name": "compare_with_baseline"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 404,
    "column": 0,
    "description": "Method 'main' is too complex: 11 complexity, 91 lines, 9 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    401:             return {\"status\": \"comparison_failed\", \"error\": str(e)}\n    402: \n    403: \n>>> 404: def main() -> int | None:\n    405:     \"\"\"Run the production benchmark suite.\"\"\"\n    406:     print(\"=\" * 60)\n    407:     print(\"AIVillage Production System Benchmark Suite\")",
    "context": {
      "complexity": 11,
      "lines": 91,
      "max_nesting": 9,
      "method_name": "main"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 84,
    "column": 4,
    "description": "Duplicate code block detected in function 'run_compression_test'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "     81:     def __init__(self) -> None:\n     82:         self.results = {}\n     83: \n>>>  84:     def run_compression_test(self) -> dict[str, Any]:\n     85:         \"\"\"Test compression pipeline with sample model.\"\"\"\n     86:         logger.info(\"Starting compression pipeline benchmark...\")\n     87:         monitor = PerformanceMonitor()",
    "context": {
      "duplicate_count": 3,
      "function_name": "run_compression_test",
      "signature": "CALL_info|ASSIGN|CALL_start|TRY"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 158,
    "column": 4,
    "description": "Duplicate code block detected in function 'run_evolution_test'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    155:     def __init__(self) -> None:\n    156:         self.results = {}\n    157: \n>>> 158:     def run_evolution_test(self) -> dict[str, Any]:\n    159:         \"\"\"Test evolution system with mini tournament.\"\"\"\n    160:         logger.info(\"Starting evolution system benchmark...\")\n    161:         monitor = PerformanceMonitor()",
    "context": {
      "duplicate_count": 3,
      "function_name": "run_evolution_test",
      "signature": "CALL_info|ASSIGN|CALL_start|TRY"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 218,
    "column": 4,
    "description": "Duplicate code block detected in function 'run_rag_test'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    215:     def __init__(self) -> None:\n    216:         self.results = {}\n    217: \n>>> 218:     def run_rag_test(self) -> dict[str, Any]:\n    219:         \"\"\"Test RAG pipeline with sample documents and queries.\"\"\"\n    220:         logger.info(\"Starting RAG pipeline benchmark...\")\n    221:         monitor = PerformanceMonitor()",
    "context": {
      "duplicate_count": 3,
      "function_name": "run_rag_test",
      "signature": "CALL_info|ASSIGN|CALL_start|TRY"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'time' methods (12 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "time",
      "method_count": 12,
      "methods": [
        "time"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (19 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 19,
      "methods": [
        "info",
        "exception"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'monitor' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "monitor",
      "method_count": 10,
      "methods": [
        "start",
        "get_metrics",
        "update_peak_memory"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 304,
    "column": 4,
    "description": "Sequential coupling detected: Function '__init__' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    301: class ProductionBenchmarkSuite:\n    302:     \"\"\"Main benchmark suite orchestrator.\"\"\"\n    303: \n>>> 304:     def __init__(self) -> None:\n    305:         self.results = {}\n    306:         self.timestamp = datetime.now().isoformat()\n    307: ",
    "context": {
      "function_name": "__init__",
      "sequential_functions": [
        "__init__",
        "run_compression_test",
        "run_evolution_test",
        "run_rag_test",
        "run_all_benchmarks"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 84,
    "column": 4,
    "description": "Sequential coupling detected: Function 'run_compression_test' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     81:     def __init__(self) -> None:\n     82:         self.results = {}\n     83: \n>>>  84:     def run_compression_test(self) -> dict[str, Any]:\n     85:         \"\"\"Test compression pipeline with sample model.\"\"\"\n     86:         logger.info(\"Starting compression pipeline benchmark...\")\n     87:         monitor = PerformanceMonitor()",
    "context": {
      "function_name": "run_compression_test",
      "sequential_functions": [
        "__init__",
        "run_compression_test",
        "run_evolution_test",
        "run_rag_test",
        "run_all_benchmarks"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 158,
    "column": 4,
    "description": "Sequential coupling detected: Function 'run_evolution_test' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    155:     def __init__(self) -> None:\n    156:         self.results = {}\n    157: \n>>> 158:     def run_evolution_test(self) -> dict[str, Any]:\n    159:         \"\"\"Test evolution system with mini tournament.\"\"\"\n    160:         logger.info(\"Starting evolution system benchmark...\")\n    161:         monitor = PerformanceMonitor()",
    "context": {
      "function_name": "run_evolution_test",
      "sequential_functions": [
        "__init__",
        "run_compression_test",
        "run_evolution_test",
        "run_rag_test",
        "run_all_benchmarks"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 218,
    "column": 4,
    "description": "Sequential coupling detected: Function 'run_rag_test' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    215:     def __init__(self) -> None:\n    216:         self.results = {}\n    217: \n>>> 218:     def run_rag_test(self) -> dict[str, Any]:\n    219:         \"\"\"Test RAG pipeline with sample documents and queries.\"\"\"\n    220:         logger.info(\"Starting RAG pipeline benchmark...\")\n    221:         monitor = PerformanceMonitor()",
    "context": {
      "function_name": "run_rag_test",
      "sequential_functions": [
        "__init__",
        "run_compression_test",
        "run_evolution_test",
        "run_rag_test",
        "run_all_benchmarks"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 308,
    "column": 4,
    "description": "Sequential coupling detected: Function 'run_all_benchmarks' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    305:         self.results = {}\n    306:         self.timestamp = datetime.now().isoformat()\n    307: \n>>> 308:     def run_all_benchmarks(self) -> dict[str, Any]:\n    309:         \"\"\"Run all production system benchmarks.\"\"\"\n    310:         logger.info(\"Starting production benchmark suite...\")\n    311: ",
    "context": {
      "function_name": "run_all_benchmarks",
      "sequential_functions": [
        "__init__",
        "run_compression_test",
        "run_evolution_test",
        "run_rag_test",
        "run_all_benchmarks"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 71,
    "column": 51,
    "description": "Excessive magic literals detected (30 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     68:         memory_delta = self.peak_memory - self.start_memory\n     69: \n     70:         return {\n>>>  71:             \"elapsed_time_seconds\": round(elapsed, 3),\n     72:             \"memory_delta_mb\": round(memory_delta / (1024 * 1024), 2),\n     73:             \"peak_memory_mb\": round(self.peak_memory / (1024 * 1024), 2),\n     74:             \"cpu_percent\": psutil.cpu_percent(interval=1),",
    "context": {
      "total_magic_literals": 30,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 72,
    "column": 53,
    "description": "Excessive magic literals detected (30 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     69: \n     70:         return {\n     71:             \"elapsed_time_seconds\": round(elapsed, 3),\n>>>  72:             \"memory_delta_mb\": round(memory_delta / (1024 * 1024), 2),\n     73:             \"peak_memory_mb\": round(self.peak_memory / (1024 * 1024), 2),\n     74:             \"cpu_percent\": psutil.cpu_percent(interval=1),\n     75:         }",
    "context": {
      "total_magic_literals": 30,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 72,
    "column": 60,
    "description": "Excessive magic literals detected (30 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     69: \n     70:         return {\n     71:             \"elapsed_time_seconds\": round(elapsed, 3),\n>>>  72:             \"memory_delta_mb\": round(memory_delta / (1024 * 1024), 2),\n     73:             \"peak_memory_mb\": round(self.peak_memory / (1024 * 1024), 2),\n     74:             \"cpu_percent\": psutil.cpu_percent(interval=1),\n     75:         }",
    "context": {
      "total_magic_literals": 30,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 73,
    "column": 56,
    "description": "Excessive magic literals detected (30 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     70:         return {\n     71:             \"elapsed_time_seconds\": round(elapsed, 3),\n     72:             \"memory_delta_mb\": round(memory_delta / (1024 * 1024), 2),\n>>>  73:             \"peak_memory_mb\": round(self.peak_memory / (1024 * 1024), 2),\n     74:             \"cpu_percent\": psutil.cpu_percent(interval=1),\n     75:         }\n     76: ",
    "context": {
      "total_magic_literals": 30,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\production_benchmark_suite.py",
    "line_number": 73,
    "column": 63,
    "description": "Excessive magic literals detected (30 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     70:         return {\n     71:             \"elapsed_time_seconds\": round(elapsed, 3),\n     72:             \"memory_delta_mb\": round(memory_delta / (1024 * 1024), 2),\n>>>  73:             \"peak_memory_mb\": round(self.peak_memory / (1024 * 1024), 2),\n     74:             \"cpu_percent\": psutil.cpu_percent(interval=1),\n     75:         }\n     76: ",
    "context": {
      "total_magic_literals": 30,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\run_all.py",
    "line_number": 19,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     16: \n     17: \n     18: async def run_all(output_file: Path) -> dict:\n>>>  19:     \"\"\"Run all benchmarks and write aggregated metrics to *output_file*.\n     20: \n     21:     Parameters\n     22:     ----------",
    "context": {
      "query_preview": "Run all benchmarks and write aggregated metrics to *output_file*.\n\n    Parameters\n    ----------\n   ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\benchmarks\\__init__.py",
    "line_number": 1,
    "column": 0,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": ">>>   1: \"\"\"Auto-generated __init__.py for proper module imports.\n      2: Created by test infrastructure repair script.\n      3: \"\"\"",
    "context": {
      "query_preview": "Auto-generated __init__.py for proper module imports.\nCreated by test infrastructure repair script.\n"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\bin\\admin_server.py",
    "line_number": 25,
    "column": 0,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     22: \n     23: # Add the project root to the Python path\n     24: project_root = Path(__file__).parent.parent.parent.parent\n>>>  25: sys.path.insert(0, str(project_root))\n     26: \n     27: # Configure logging\n     28: logging.basicConfig(",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\bin\\admin_server.py",
    "line_number": 58,
    "column": 4,
    "description": "Method 'setup_routes' is too complex: 6 complexity, 147 lines, 2 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     55:             allow_headers=[\"*\"],\n     56:         )\n     57: \n>>>  58:     def setup_routes(self):\n     59:         \"\"\"Setup API routes\"\"\"\n     60: \n     61:         @self.app.get(\"/\", response_class=HTMLResponse)",
    "context": {
      "complexity": 6,
      "lines": 147,
      "max_nesting": 2,
      "method_name": "setup_routes"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\bin\\admin_server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 8,
      "methods": [
        "now"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\bin\\admin_server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'psutil' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "psutil",
      "method_count": 6,
      "methods": [
        "net_connections",
        "disk_usage",
        "virtual_memory",
        "cpu_percent",
        "boot_time"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\bin\\admin_server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'random' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "random",
      "method_count": 6,
      "methods": [
        "uniform",
        "random",
        "randint"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\bin\\admin_server.py",
    "line_number": 37,
    "column": 4,
    "description": "Sequential coupling detected: Function '__init__' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     34: class AdminDashboardServer:\n     35:     \"\"\"Admin dashboard server for backend monitoring\"\"\"\n     36: \n>>>  37:     def __init__(self, port: int = 3006):\n     38:         self.port = port\n     39:         self.app = FastAPI(\n     40:             title=\"AIVillage Admin Dashboard\",",
    "context": {
      "function_name": "__init__",
      "sequential_functions": [
        "__init__",
        "setup_middleware",
        "setup_routes"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\bin\\admin_server.py",
    "line_number": 48,
    "column": 4,
    "description": "Sequential coupling detected: Function 'setup_middleware' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     45:         self.setup_middleware()\n     46:         self.setup_routes()\n     47: \n>>>  48:     def setup_middleware(self):\n     49:         \"\"\"Configure CORS and other middleware\"\"\"\n     50:         self.app.add_middleware(\n     51:             CORSMiddleware,",
    "context": {
      "function_name": "setup_middleware",
      "sequential_functions": [
        "__init__",
        "setup_middleware",
        "setup_routes"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\bin\\admin_server.py",
    "line_number": 58,
    "column": 4,
    "description": "Sequential coupling detected: Function 'setup_routes' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     55:             allow_headers=[\"*\"],\n     56:         )\n     57: \n>>>  58:     def setup_routes(self):\n     59:         \"\"\"Setup API routes\"\"\"\n     60: \n     61:         @self.app.get(\"/\", response_class=HTMLResponse)",
    "context": {
      "function_name": "setup_routes",
      "sequential_functions": [
        "__init__",
        "setup_middleware",
        "setup_routes"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\bin\\main.py",
    "line_number": 30,
    "column": 0,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     27: from src.cli.base import build_parser, dispatch\n     28: \n     29: # Add project root to path\n>>>  30: sys.path.insert(0, str(Path(__file__).parent))\n     31: \n     32: \n     33: def _configure(parser) -> None:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\bin\\main.py",
    "line_number": 47,
    "column": 13,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     44:         \"--agent-type\",\n     45:         choices=[\"king\", \"sage\", \"magi\", \"base\"],\n     46:         default=\"base\",\n>>>  47:         help=\"Type of agent to create/train (for agent-forge mode)\",\n     48:     )\n     49:     parser.add_argument(\"--name\", help=\"Agent name (for agent-forge mode)\")\n     50:     parser.add_argument(\"--input\", help=\"Input file or directory\")",
    "context": {
      "query_preview": "Type of agent to create/train (for agent-forge mode)"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\bin\\main.py",
    "line_number": 75,
    "column": 0,
    "description": "Method 'run_king_mode' is too complex: 7 complexity, 20 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     72:         return 1\n     73: \n     74: \n>>>  75: def run_king_mode(args):\n     76:     \"\"\"Run KING agent mode.\"\"\"\n     77:     try:\n     78:         from agents.king.main import main as king_main",
    "context": {
      "complexity": 7,
      "lines": 20,
      "max_nesting": 5,
      "method_name": "run_king_mode"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\bin\\main.py",
    "line_number": 98,
    "column": 0,
    "description": "Method 'run_rag_mode' is too complex: 8 complexity, 22 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     95:         return 1\n     96: \n     97: \n>>>  98: def run_rag_mode(args):\n     99:     \"\"\"Run RAG system mode.\"\"\"\n    100:     try:\n    101:         from rag_system.main import main as rag_main",
    "context": {
      "complexity": 8,
      "lines": 22,
      "max_nesting": 6,
      "method_name": "run_rag_mode"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\bin\\main.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'parser' methods (12 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "parser",
      "method_count": 12,
      "methods": [
        "parse_args",
        "add_argument"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\bin\\main.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'rag_args' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "rag_args",
      "method_count": 6,
      "methods": [
        "append",
        "extend"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\bin\\main.py",
    "line_number": 54,
    "column": 0,
    "description": "Sequential coupling detected: Function 'run_agent_forge_mode' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     51:     parser.add_argument(\"--output\", help=\"Output file or directory\")\n     52: \n     53: \n>>>  54: def run_agent_forge_mode(args):\n     55:     \"\"\"Run Agent Forge mode.\"\"\"\n     56:     try:\n     57:         from agent_forge.main import main as agent_forge_main",
    "context": {
      "function_name": "run_agent_forge_mode",
      "sequential_functions": [
        "run_agent_forge_mode",
        "run_king_mode",
        "run_rag_mode",
        "run_core_mode"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\bin\\main.py",
    "line_number": 75,
    "column": 0,
    "description": "Sequential coupling detected: Function 'run_king_mode' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     72:         return 1\n     73: \n     74: \n>>>  75: def run_king_mode(args):\n     76:     \"\"\"Run KING agent mode.\"\"\"\n     77:     try:\n     78:         from agents.king.main import main as king_main",
    "context": {
      "function_name": "run_king_mode",
      "sequential_functions": [
        "run_agent_forge_mode",
        "run_king_mode",
        "run_rag_mode",
        "run_core_mode"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\bin\\main.py",
    "line_number": 98,
    "column": 0,
    "description": "Sequential coupling detected: Function 'run_rag_mode' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     95:         return 1\n     96: \n     97: \n>>>  98: def run_rag_mode(args):\n     99:     \"\"\"Run RAG system mode.\"\"\"\n    100:     try:\n    101:         from rag_system.main import main as rag_main",
    "context": {
      "function_name": "run_rag_mode",
      "sequential_functions": [
        "run_agent_forge_mode",
        "run_king_mode",
        "run_rag_mode",
        "run_core_mode"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\bin\\main.py",
    "line_number": 123,
    "column": 0,
    "description": "Sequential coupling detected: Function 'run_core_mode' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    120:         return 1\n    121: \n    122: \n>>> 123: def run_core_mode(args):\n    124:     \"\"\"Run core utilities mode.\"\"\"\n    125:     try:\n    126:         from agent_forge.core.main import main as core_main",
    "context": {
      "function_name": "run_core_mode",
      "sequential_functions": [
        "run_agent_forge_mode",
        "run_king_mode",
        "run_rag_mode",
        "run_core_mode"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\bin\\server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 10,
      "methods": [
        "exception",
        "info",
        "warning"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\bin\\server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'app' methods (12 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "app",
      "method_count": 12,
      "methods": [
        "post",
        "get",
        "on_event",
        "mount"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\common\\flags.py",
    "line_number": 34,
    "column": 4,
    "description": "Function '__init__' has 8 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "     31: class FeatureFlag:\n     32:     \"\"\"Individual feature flag configuration.\"\"\"\n     33: \n>>>  34:     def __init__(\n     35:         self,\n     36:         key: str,\n     37:         state: FlagState = FlagState.DISABLED,",
    "context": {
      "parameter_count": 8,
      "function_name": "__init__"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\common\\flags.py",
    "line_number": 54,
    "column": 4,
    "description": "Method 'is_enabled_for_user' is too complex: 11 complexity, 32 lines, 7 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     51:         self.created_at = time.time()\n     52:         self.updated_at = time.time()\n     53: \n>>>  54:     def is_enabled_for_user(self, user_id: str | None = None, environment: str = \"production\") -> bool:\n     55:         \"\"\"Check if flag is enabled for a specific user/environment.\"\"\"\n     56:         # Check environment filter\n     57:         if self.environments != [\"all\"] and environment not in self.environments:",
    "context": {
      "complexity": 11,
      "lines": 32,
      "max_nesting": 7,
      "method_name": "is_enabled_for_user"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\common\\flags.py",
    "line_number": 122,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    119:         return str(project_root / \"config\" / \"flags.yaml\")\n    120: \n    121:     def load_flags(self) -> None:\n>>> 122:         \"\"\"Load flags from configuration file.\"\"\"\n    123:         with self._lock:\n    124:             try:\n    125:                 if os.path.exists(self.config_path):",
    "context": {
      "query_preview": "Load flags from configuration file."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\common\\flags.py",
    "line_number": 148,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    145:                     self._create_default_config()\n    146: \n    147:             except Exception as e:\n>>> 148:                 print(f\"Warning: Failed to load feature flags from {self.config_path}: {e}\")\n    149:                 # Continue with empty flags rather than failing\n    150: \n    151:     def _create_default_config(self) -> None:",
    "context": {
      "query_preview": "Warning: Failed to load feature flags from "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\common\\flags.py",
    "line_number": 152,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    149:                 # Continue with empty flags rather than failing\n    150: \n    151:     def _create_default_config(self) -> None:\n>>> 152:         \"\"\"Create default configuration file.\"\"\"\n    153:         os.makedirs(os.path.dirname(self.config_path), exist_ok=True)\n    154: \n    155:         default_config = {",
    "context": {
      "query_preview": "Create default configuration file."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\common\\flags.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'flag_data' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "flag_data",
      "method_count": 6,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\common\\http_client.py",
    "line_number": 208,
    "column": 4,
    "description": "Function '__init__' has 6 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    205: class ResilientHttpClient:\n    206:     \"\"\"Production HTTP client with retries, circuit breakers, and idempotency.\"\"\"\n    207: \n>>> 208:     def __init__(\n    209:         self,\n    210:         retry_config: RetryConfig | None = None,\n    211:         circuit_config: CircuitBreakerConfig | None = None,",
    "context": {
      "parameter_count": 6,
      "function_name": "__init__"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\common\\http_client.py",
    "line_number": 234,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    231:         )\n    232: \n    233:     def _get_circuit_breaker(self, url: str) -> CircuitBreaker:\n>>> 234:         \"\"\"Get or create circuit breaker for service.\"\"\"\n    235:         try:\n    236:             parsed_url = httpx.URL(url)\n    237:             service_name = f\"{parsed_url.scheme}://{parsed_url.host}:{parsed_url.port or (443 if parsed_url.scheme == 'https' else 80)}\"",
    "context": {
      "query_preview": "Get or create circuit breaker for service."
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\common\\http_client.py",
    "line_number": 461,
    "column": 16,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    458:         try:\n    459:             # Make idempotent POST request\n    460:             response = await client.post(\n>>> 461:                 \"https://api.example.com/users\",\n    462:                 json={\"name\": \"John\", \"email\": \"john@example.com\"},\n    463:                 idempotency_key=\"create-user-123\",\n    464:             )",
    "context": {
      "hardcoded_value": "https://api.example.com/users"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\common\\http_client.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'time' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "time",
      "method_count": 6,
      "methods": [
        "time"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\common\\http_client.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (18 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 18,
      "methods": [
        "_record_success",
        "_generate_idempotency_key",
        "_cleanup_expired",
        "_calculate_delay",
        "_should_retry",
        "_get_circuit_breaker",
        "original_request",
        "_record_failure",
        "request"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\common\\http_client.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 8,
      "methods": [
        "info",
        "warning",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\common\\http_client.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'httpx' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "httpx",
      "method_count": 6,
      "methods": [
        "URL",
        "Timeout",
        "Response",
        "Limits",
        "RequestError",
        "AsyncClient"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\common\\http_client.py",
    "line_number": 37,
    "column": 24,
    "description": "Excessive magic literals detected (28 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     34: class RetryConfig:\n     35:     \"\"\"Configuration for retry behavior.\"\"\"\n     36: \n>>>  37:     max_attempts: int = 3\n     38:     base_delay: float = 1.0  # seconds\n     39:     max_delay: float = 60.0  # seconds\n     40:     exponential_base: float = 2.0",
    "context": {
      "total_magic_literals": 28,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\common\\http_client.py",
    "line_number": 39,
    "column": 23,
    "description": "Excessive magic literals detected (28 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     36: \n     37:     max_attempts: int = 3\n     38:     base_delay: float = 1.0  # seconds\n>>>  39:     max_delay: float = 60.0  # seconds\n     40:     exponential_base: float = 2.0\n     41:     jitter: bool = True\n     42:     retry_on_status_codes: set[int] = field(default_factory=lambda: {500, 502, 503, 504, 520, 521, 522, 523, 524})",
    "context": {
      "total_magic_literals": 28,
      "current_value": 60.0
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\common\\http_client.py",
    "line_number": 42,
    "column": 69,
    "description": "Excessive magic literals detected (28 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     39:     max_delay: float = 60.0  # seconds\n     40:     exponential_base: float = 2.0\n     41:     jitter: bool = True\n>>>  42:     retry_on_status_codes: set[int] = field(default_factory=lambda: {500, 502, 503, 504, 520, 521, 522, 523, 524})\n     43: \n     44: \n     45: @dataclass",
    "context": {
      "total_magic_literals": 28,
      "current_value": 500
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\common\\http_client.py",
    "line_number": 42,
    "column": 74,
    "description": "Excessive magic literals detected (28 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     39:     max_delay: float = 60.0  # seconds\n     40:     exponential_base: float = 2.0\n     41:     jitter: bool = True\n>>>  42:     retry_on_status_codes: set[int] = field(default_factory=lambda: {500, 502, 503, 504, 520, 521, 522, 523, 524})\n     43: \n     44: \n     45: @dataclass",
    "context": {
      "total_magic_literals": 28,
      "current_value": 502
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\common\\http_client.py",
    "line_number": 42,
    "column": 79,
    "description": "Excessive magic literals detected (28 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     39:     max_delay: float = 60.0  # seconds\n     40:     exponential_base: float = 2.0\n     41:     jitter: bool = True\n>>>  42:     retry_on_status_codes: set[int] = field(default_factory=lambda: {500, 502, 503, 504, 520, 521, 522, 523, 524})\n     43: \n     44: \n     45: @dataclass",
    "context": {
      "total_magic_literals": 28,
      "current_value": 503
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\compliance\\aivillage_integration.py",
    "line_number": 33,
    "column": 0,
    "description": "Class 'AIVillageComplianceIntegration' is a God Object: 1 methods, ~569 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "     30: logger = logging.getLogger(__name__)\n     31: \n     32: \n>>>  33: class AIVillageComplianceIntegration:\n     34:     \"\"\"Comprehensive integration between PII/PHI compliance and AIVillage infrastructure.\n     35: \n     36:     This class provides seamless integration with:",
    "context": {
      "method_count": 1,
      "estimated_lines": 569,
      "class_name": "AIVillageComplianceIntegration",
      "data_methods": 0,
      "business_methods": 1
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\aivillage_integration.py",
    "line_number": 94,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     91:                 \"permissions\": [\n     92:                     \"compliance:discover:all\",\n     93:                     \"compliance:manage_locations:all\",\n>>>  94:                     \"compliance:create_retention_jobs:all\",\n     95:                     \"compliance:execute_retention_jobs:all\",\n     96:                     \"compliance:approve_retention_jobs:all\",\n     97:                     \"compliance:generate_reports:all\",",
    "context": {
      "query_preview": "compliance:create_retention_jobs:all"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\aivillage_integration.py",
    "line_number": 107,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    104:                 \"permissions\": [\n    105:                     \"compliance:discover:tenant\",\n    106:                     \"compliance:manage_locations:tenant\",\n>>> 107:                     \"compliance:create_retention_jobs:tenant\",\n    108:                     \"compliance:generate_reports:tenant\",\n    109:                     \"compliance:audit_trail:read\",\n    110:                 ],",
    "context": {
      "query_preview": "compliance:create_retention_jobs:tenant"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\aivillage_integration.py",
    "line_number": 140,
    "column": 30,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    137:                     description=role_config[\"description\"],\n    138:                     permissions=role_config[\"permissions\"],\n    139:                 )\n>>> 140:                 logger.info(f\"Created compliance role: {role_config['role_name']} ({role_id})\")\n    141:             except Exception as e:\n    142:                 logger.warning(f\"Failed to create role {role_config['role_name']}: {e}\")\n    143: ",
    "context": {
      "query_preview": "Created compliance role: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\aivillage_integration.py",
    "line_number": 142,
    "column": 33,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    139:                 )\n    140:                 logger.info(f\"Created compliance role: {role_config['role_name']} ({role_id})\")\n    141:             except Exception as e:\n>>> 142:                 logger.warning(f\"Failed to create role {role_config['role_name']}: {e}\")\n    143: \n    144:     async def _setup_backup_integration(self):\n    145:         \"\"\"Integrate PII/PHI compliance with backup system.\"\"\"",
    "context": {
      "query_preview": "Failed to create role "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\aivillage_integration.py",
    "line_number": 192,
    "column": 30,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    189:                     retention_days=job_config[\"retention_days\"],\n    190:                     encryption=job_config[\"encryption\"],\n    191:                 )\n>>> 192:                 logger.info(f\"Created compliance backup job: {backup_id}\")\n    193:             except Exception as e:\n    194:                 logger.warning(f\"Failed to create backup job {job_config['name']}: {e}\")\n    195: ",
    "context": {
      "query_preview": "Created compliance backup job: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\aivillage_integration.py",
    "line_number": 194,
    "column": 33,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    191:                 )\n    192:                 logger.info(f\"Created compliance backup job: {backup_id}\")\n    193:             except Exception as e:\n>>> 194:                 logger.warning(f\"Failed to create backup job {job_config['name']}: {e}\")\n    195: \n    196:     async def _setup_governance_integration(self):\n    197:         \"\"\"Integrate compliance workflows with MCP governance dashboard.\"\"\"",
    "context": {
      "query_preview": "Failed to create backup job "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\aivillage_integration.py",
    "line_number": 215,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    212:             },\n    213:             {\n    214:                 \"tool_id\": \"retention_job_create\",\n>>> 215:                 \"name\": \"Create Data Retention Job\",\n    216:                 \"description\": \"Create automated data retention job\",\n    217:                 \"category\": \"compliance\",\n    218:                 \"requires_approval\": True,",
    "context": {
      "query_preview": "Create Data Retention Job"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\aivillage_integration.py",
    "line_number": 216,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    213:             {\n    214:                 \"tool_id\": \"retention_job_create\",\n    215:                 \"name\": \"Create Data Retention Job\",\n>>> 216:                 \"description\": \"Create automated data retention job\",\n    217:                 \"category\": \"compliance\",\n    218:                 \"requires_approval\": True,\n    219:                 \"approval_roles\": [\"compliance_admin\", \"data_protection_officer\"],",
    "context": {
      "query_preview": "Create automated data retention job"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\aivillage_integration.py",
    "line_number": 339,
    "column": 72,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    336:                 custom_retention_days=custom_days,\n    337:             )\n    338: \n>>> 339:             return {\"status\": \"success\", \"job_id\": job_id, \"message\": f\"Created retention job: {job_id}\"}\n    340: \n    341:         except Exception as e:\n    342:             logger.error(f\"Retention job creation failed: {e}\")",
    "context": {
      "query_preview": "Created retention job: "
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\aivillage_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (29 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 29,
      "methods": [
        "info",
        "warning",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\aivillage_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'request' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "request",
      "method_count": 11,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 25,
    "column": 0,
    "description": "Class 'ComplianceCLI' is a God Object: 6 methods, ~552 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "     22: from .pii_phi_manager import DataClassification, PIIPHIManager, RetentionPolicy\n     23: \n     24: \n>>>  25: class ComplianceCLI:\n     26:     \"\"\"PII/PHI compliance command line interface.\"\"\"\n     27: \n     28:     def __init__(self):",
    "context": {
      "method_count": 6,
      "estimated_lines": 552,
      "class_name": "ComplianceCLI",
      "data_methods": 0,
      "business_methods": 6
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 274,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    271:         custom_days: int = None,\n    272:         schedule: str = \"0 2 * * 0\",\n    273:     ):\n>>> 274:         \"\"\"Create a new data retention job.\"\"\"\n    275:         await self._initialize_manager()\n    276: \n    277:         try:",
    "context": {
      "query_preview": "Create a new data retention job."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 289,
    "column": 28,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    286:                 schedule_cron=schedule,\n    287:             )\n    288: \n>>> 289:             self._success(f\"Retention job created: {job_id}\")\n    290:             self._info(f\"Name: {name}\")\n    291:             self._info(f\"Policy: {retention_policy}\")\n    292:             if custom_days:",
    "context": {
      "query_preview": "Retention job created: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 298,
    "column": 26,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    295:             self._info(f\"Schedule: {schedule}\")\n    296: \n    297:         except Exception as e:\n>>> 298:             self._error(f\"Failed to create retention job: {e}\")\n    299: \n    300:     async def list_retention_jobs(self, output_format: str = \"table\"):\n    301:         \"\"\"List retention jobs.\"\"\"",
    "context": {
      "query_preview": "Failed to create retention job: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 485,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    482:                         \"approval_status\": job.approval_status,\n    483:                         \"run_count\": job.run_count,\n    484:                         \"success_count\": job.success_count,\n>>> 485:                         \"total_records_deleted\": job.total_records_deleted,\n    486:                     },\n    487:                 )\n    488: ",
    "context": {
      "query_preview": "total_records_deleted"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 640,
    "column": 4,
    "description": "Function 'create_retention_job' has 6 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    637:     )\n    638:     @click.option(\"--custom-days\", type=int, help=\"Custom retention days (for custom policy)\")\n    639:     @click.option(\"--schedule\", default=\"0 2 * * 0\", help=\"Cron schedule\")\n>>> 640:     def create_retention_job(name, description, locations, retention_policy, custom_days, schedule):\n    641:         \"\"\"Create data retention job\"\"\"\n    642:         cli = ComplianceCLI()\n    643:         location_list = [loc.strip() for loc in locations.split(\",\")]",
    "context": {
      "parameter_count": 6,
      "function_name": "create_retention_job"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 641,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    638:     @click.option(\"--custom-days\", type=int, help=\"Custom retention days (for custom policy)\")\n    639:     @click.option(\"--schedule\", default=\"0 2 * * 0\", help=\"Cron schedule\")\n    640:     def create_retention_job(name, description, locations, retention_policy, custom_days, schedule):\n>>> 641:         \"\"\"Create data retention job\"\"\"\n    642:         cli = ComplianceCLI()\n    643:         location_list = [loc.strip() for loc in locations.split(\",\")]\n    644:         asyncio.run(cli.create_retention_job(name, description, location_list, retention_policy, custom_days, schedule))",
    "context": {
      "query_preview": "Create data retention job"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (67 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 67,
      "methods": [
        "_success",
        "_error",
        "_info",
        "_output_json",
        "_initialize_manager",
        "_warning"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'f' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "f",
      "method_count": 9,
      "methods": [
        "write",
        "writelines"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'click' methods (32 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "click",
      "method_count": 32,
      "methods": [
        "group",
        "Choice",
        "argument",
        "option"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'asyncio' methods (12 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "asyncio",
      "method_count": 12,
      "methods": [
        "run"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'cli' methods (12 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "cli",
      "method_count": 12,
      "methods": [
        "compliance_summary",
        "create_retention_job",
        "generate_compliance_report",
        "location_info",
        "list_locations",
        "approve_retention_job",
        "list_retention_jobs",
        "discover_pii_phi",
        "execute_retention_job"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'compliance_cli' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "compliance_cli",
      "method_count": 9,
      "methods": [
        "command"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 85,
    "column": 59,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     82:                     rows.append(\n     83:                         [\n     84:                             location.location_id[:20] + \"...\"\n>>>  85:                             if len(location.location_id) > 20\n     86:                             else location.location_id,\n     87:                             location.source_type,\n     88:                             (location.path[:30] + \"...\") if len(location.path) > 30 else location.path,",
    "context": {
      "total_magic_literals": 21,
      "current_value": 20
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 84,
    "column": 50,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     81:                 for location in discoveries:\n     82:                     rows.append(\n     83:                         [\n>>>  84:                             location.location_id[:20] + \"...\"\n     85:                             if len(location.location_id) > 20\n     86:                             else location.location_id,\n     87:                             location.source_type,",
    "context": {
      "total_magic_literals": 21,
      "current_value": 20
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 88,
    "column": 81,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     85:                             if len(location.location_id) > 20\n     86:                             else location.location_id,\n     87:                             location.source_type,\n>>>  88:                             (location.path[:30] + \"...\") if len(location.path) > 30 else location.path,\n     89:                             location.classification.value,\n     90:                             f\"{location.confidence_score:.2f}\",\n     91:                             str(location.estimated_records),",
    "context": {
      "total_magic_literals": 21,
      "current_value": 30
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 88,
    "column": 44,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     85:                             if len(location.location_id) > 20\n     86:                             else location.location_id,\n     87:                             location.source_type,\n>>>  88:                             (location.path[:30] + \"...\") if len(location.path) > 30 else location.path,\n     89:                             location.classification.value,\n     90:                             f\"{location.confidence_score:.2f}\",\n     91:                             str(location.estimated_records),",
    "context": {
      "total_magic_literals": 21,
      "current_value": 30
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\compliance_cli.py",
    "line_number": 113,
    "column": 78,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    110:             self._error(f\"Discovery failed: {e}\")\n    111: \n    112:     async def list_locations(\n>>> 113:         self, classification: str = None, tenant_id: str = None, limit: int = 50, output_format: str = \"table\",\n    114:     ):\n    115:         \"\"\"List discovered PII/PHI locations.\"\"\"\n    116:         await self._initialize_manager()",
    "context": {
      "total_magic_literals": 21,
      "current_value": 50
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 83,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     80: \n     81: @dataclass\n     82: class DataLocation:\n>>>  83:     \"\"\"Location where PII/PHI data is found.\"\"\"\n     84: \n     85:     location_id: str\n     86:     source_type: str  # database, file, api_endpoint, etc.",
    "context": {
      "query_preview": "Location where PII/PHI data is found."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 155,
    "column": 4,
    "description": "Method '_initialize_builtin_rules' is too complex: 2 complexity, 143 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    152:         self.compiled_patterns: dict[str, re.Pattern] = {}\n    153:         self._initialize_builtin_rules()\n    154: \n>>> 155:     def _initialize_builtin_rules(self):\n    156:         \"\"\"Initialize built-in detection rules for common PII/PHI.\"\"\"\n    157:         rules = [\n    158:             # Personal Identifiers",
    "context": {
      "complexity": 2,
      "lines": 143,
      "max_nesting": 1,
      "method_name": "_initialize_builtin_rules"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 308,
    "column": 4,
    "description": "Method 'detect_in_text' is too complex: 9 complexity, 30 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    305:         except re.error as e:\n    306:             logger.error(f\"Invalid regex pattern for rule {rule.rule_id}: {e}\")\n    307: \n>>> 308:     def detect_in_text(self, text: str) -> list[tuple[PIIDetectionRule, list[str]]]:\n    309:         \"\"\"Detect PII/PHI in text content.\"\"\"\n    310:         detections = []\n    311: ",
    "context": {
      "complexity": 9,
      "lines": 30,
      "max_nesting": 8,
      "method_name": "detect_in_text"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 353,
    "column": 4,
    "description": "Method 'calculate_confidence' is too complex: 7 complexity, 28 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    350: \n    351:         return matches\n    352: \n>>> 353:     def calculate_confidence(\n    354:         self, rule: PIIDetectionRule, matches: list[str], field_name: str = \"\", total_samples: int = 1,\n    355:     ) -> float:\n    356:         \"\"\"Calculate confidence score for a detection.\"\"\"",
    "context": {
      "complexity": 7,
      "lines": 28,
      "max_nesting": 6,
      "method_name": "calculate_confidence"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 383,
    "column": 4,
    "description": "Method '_validate_match' is too complex: 9 complexity, 25 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    380: \n    381:         return min(base_confidence, 1.0)\n    382: \n>>> 383:     def _validate_match(self, rule: PIIDetectionRule, match: str) -> bool:\n    384:         \"\"\"Validate a match using additional checks.\"\"\"\n    385:         # Add specific validation logic for different data types\n    386:         if rule.rule_id == \"ssn\":",
    "context": {
      "complexity": 9,
      "lines": 25,
      "max_nesting": 6,
      "method_name": "_validate_match"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 428,
    "column": 0,
    "description": "Class 'PIIPHIManager' is a God Object: 8 methods, ~1302 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "    425:         return luhn_checksum(card_number) == 0\n    426: \n    427: \n>>> 428: class PIIPHIManager:\n    429:     \"\"\"Main PII/PHI management and compliance system.\"\"\"\n    430: \n    431:     def __init__(self, config_path: Path | None = None):",
    "context": {
      "method_count": 8,
      "estimated_lines": 1302,
      "class_name": "PIIPHIManager",
      "data_methods": 2,
      "business_methods": 6
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 488,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    485:         if self.config_path.exists():\n    486:             with open(self.config_path) as f:\n    487:                 user_config = json.load(f)\n>>> 488:                 default_config.update(user_config)\n    489:         else:\n    490:             self.config_path.parent.mkdir(parents=True, exist_ok=True)\n    491:             with open(self.config_path, \"w\") as f:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 496,
    "column": 4,
    "description": "Method '_init_database' is too complex: 1 complexity, 114 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    493: \n    494:         return default_config\n    495: \n>>> 496:     def _init_database(self):\n    497:         \"\"\"Initialize compliance database.\"\"\"\n    498:         conn = sqlite3.connect(self.compliance_db)\n    499:         cursor = conn.cursor()",
    "context": {
      "complexity": 1,
      "lines": 114,
      "max_nesting": 0,
      "method_name": "_init_database"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 502,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    499:         cursor = conn.cursor()\n    500: \n    501:         # Data locations table\n>>> 502:         cursor.execute(\n    503:             \"\"\"\n    504:             CREATE TABLE IF NOT EXISTS data_locations (\n    505:                 location_id TEXT PRIMARY KEY,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 503,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    500: \n    501:         # Data locations table\n    502:         cursor.execute(\n>>> 503:             \"\"\"\n    504:             CREATE TABLE IF NOT EXISTS data_locations (\n    505:                 location_id TEXT PRIMARY KEY,\n    506:                 source_type TEXT NOT NULL,",
    "context": {
      "query_preview": "\n            CREATE TABLE IF NOT EXISTS data_locations (\n                location_id TEXT PRIMARY KE..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 533,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    530:         )\n    531: \n    532:         # Retention jobs table\n>>> 533:         cursor.execute(\n    534:             \"\"\"\n    535:             CREATE TABLE IF NOT EXISTS retention_jobs (\n    536:                 job_id TEXT PRIMARY KEY,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 534,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    531: \n    532:         # Retention jobs table\n    533:         cursor.execute(\n>>> 534:             \"\"\"\n    535:             CREATE TABLE IF NOT EXISTS retention_jobs (\n    536:                 job_id TEXT PRIMARY KEY,\n    537:                 name TEXT NOT NULL,",
    "context": {
      "query_preview": "\n            CREATE TABLE IF NOT EXISTS retention_jobs (\n                job_id TEXT PRIMARY KEY,\n  ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 563,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    560:         )\n    561: \n    562:         # Audit log table\n>>> 563:         cursor.execute(\n    564:             \"\"\"\n    565:             CREATE TABLE IF NOT EXISTS audit_log (\n    566:                 audit_id TEXT PRIMARY KEY,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 564,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    561: \n    562:         # Audit log table\n    563:         cursor.execute(\n>>> 564:             \"\"\"\n    565:             CREATE TABLE IF NOT EXISTS audit_log (\n    566:                 audit_id TEXT PRIMARY KEY,\n    567:                 event_type TEXT NOT NULL,",
    "context": {
      "query_preview": "\n            CREATE TABLE IF NOT EXISTS audit_log (\n                audit_id TEXT PRIMARY KEY,\n     ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 583,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    580:         )\n    581: \n    582:         # Detection history table\n>>> 583:         cursor.execute(\n    584:             \"\"\"\n    585:             CREATE TABLE IF NOT EXISTS detection_history (\n    586:                 detection_id TEXT PRIMARY KEY,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 584,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    581: \n    582:         # Detection history table\n    583:         cursor.execute(\n>>> 584:             \"\"\"\n    585:             CREATE TABLE IF NOT EXISTS detection_history (\n    586:                 detection_id TEXT PRIMARY KEY,\n    587:                 location_id TEXT NOT NULL,",
    "context": {
      "query_preview": "\n            CREATE TABLE IF NOT EXISTS detection_history (\n                detection_id TEXT PRIMAR..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 601,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    598:         )\n    599: \n    600:         # Create indexes\n>>> 601:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_classification ON data_locations(classification)\")\n    602:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_tenant ON data_locations(tenant_id)\")\n    603:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_compliance ON data_locations(compliant)\")\n    604:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_enabled ON retention_jobs(enabled)\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 601,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    598:         )\n    599: \n    600:         # Create indexes\n>>> 601:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_classification ON data_locations(classification)\")\n    602:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_tenant ON data_locations(tenant_id)\")\n    603:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_compliance ON data_locations(compliant)\")\n    604:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_enabled ON retention_jobs(enabled)\")",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_locations_classification ON data_locations(classification)"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 602,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    599: \n    600:         # Create indexes\n    601:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_classification ON data_locations(classification)\")\n>>> 602:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_tenant ON data_locations(tenant_id)\")\n    603:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_compliance ON data_locations(compliant)\")\n    604:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_enabled ON retention_jobs(enabled)\")\n    605:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_next_run ON retention_jobs(next_run)\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 602,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    599: \n    600:         # Create indexes\n    601:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_classification ON data_locations(classification)\")\n>>> 602:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_tenant ON data_locations(tenant_id)\")\n    603:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_compliance ON data_locations(compliant)\")\n    604:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_enabled ON retention_jobs(enabled)\")\n    605:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_next_run ON retention_jobs(next_run)\")",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_locations_tenant ON data_locations(tenant_id)"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 603,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    600:         # Create indexes\n    601:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_classification ON data_locations(classification)\")\n    602:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_tenant ON data_locations(tenant_id)\")\n>>> 603:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_compliance ON data_locations(compliant)\")\n    604:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_enabled ON retention_jobs(enabled)\")\n    605:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_next_run ON retention_jobs(next_run)\")\n    606:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON audit_log(timestamp)\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 603,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    600:         # Create indexes\n    601:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_classification ON data_locations(classification)\")\n    602:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_tenant ON data_locations(tenant_id)\")\n>>> 603:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_compliance ON data_locations(compliant)\")\n    604:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_enabled ON retention_jobs(enabled)\")\n    605:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_next_run ON retention_jobs(next_run)\")\n    606:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON audit_log(timestamp)\")",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_locations_compliance ON data_locations(compliant)"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 604,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    601:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_classification ON data_locations(classification)\")\n    602:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_tenant ON data_locations(tenant_id)\")\n    603:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_compliance ON data_locations(compliant)\")\n>>> 604:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_enabled ON retention_jobs(enabled)\")\n    605:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_next_run ON retention_jobs(next_run)\")\n    606:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON audit_log(timestamp)\")\n    607:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_event_type ON audit_log(event_type)\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 604,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    601:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_classification ON data_locations(classification)\")\n    602:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_tenant ON data_locations(tenant_id)\")\n    603:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_compliance ON data_locations(compliant)\")\n>>> 604:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_enabled ON retention_jobs(enabled)\")\n    605:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_next_run ON retention_jobs(next_run)\")\n    606:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON audit_log(timestamp)\")\n    607:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_event_type ON audit_log(event_type)\")",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_jobs_enabled ON retention_jobs(enabled)"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 605,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    602:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_tenant ON data_locations(tenant_id)\")\n    603:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_compliance ON data_locations(compliant)\")\n    604:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_enabled ON retention_jobs(enabled)\")\n>>> 605:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_next_run ON retention_jobs(next_run)\")\n    606:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON audit_log(timestamp)\")\n    607:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_event_type ON audit_log(event_type)\")\n    608: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 605,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    602:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_tenant ON data_locations(tenant_id)\")\n    603:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_compliance ON data_locations(compliant)\")\n    604:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_enabled ON retention_jobs(enabled)\")\n>>> 605:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_next_run ON retention_jobs(next_run)\")\n    606:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON audit_log(timestamp)\")\n    607:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_event_type ON audit_log(event_type)\")\n    608: ",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_jobs_next_run ON retention_jobs(next_run)"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 606,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    603:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_compliance ON data_locations(compliant)\")\n    604:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_enabled ON retention_jobs(enabled)\")\n    605:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_next_run ON retention_jobs(next_run)\")\n>>> 606:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON audit_log(timestamp)\")\n    607:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_event_type ON audit_log(event_type)\")\n    608: \n    609:         conn.commit()",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 606,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    603:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_locations_compliance ON data_locations(compliant)\")\n    604:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_enabled ON retention_jobs(enabled)\")\n    605:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_next_run ON retention_jobs(next_run)\")\n>>> 606:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON audit_log(timestamp)\")\n    607:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_event_type ON audit_log(event_type)\")\n    608: \n    609:         conn.commit()",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON audit_log(timestamp)"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 607,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    604:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_enabled ON retention_jobs(enabled)\")\n    605:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_next_run ON retention_jobs(next_run)\")\n    606:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON audit_log(timestamp)\")\n>>> 607:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_event_type ON audit_log(event_type)\")\n    608: \n    609:         conn.commit()\n    610:         conn.close()",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 607,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    604:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_enabled ON retention_jobs(enabled)\")\n    605:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_jobs_next_run ON retention_jobs(next_run)\")\n    606:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON audit_log(timestamp)\")\n>>> 607:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_event_type ON audit_log(event_type)\")\n    608: \n    609:         conn.commit()\n    610:         conn.close()",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_audit_event_type ON audit_log(event_type)"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 609,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    606:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON audit_log(timestamp)\")\n    607:         cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_audit_event_type ON audit_log(event_type)\")\n    608: \n>>> 609:         conn.commit()\n    610:         conn.close()\n    611: \n    612:     def _load_existing_data(self):",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 612,
    "column": 4,
    "description": "Method '_load_existing_data' is too complex: 6 complexity, 63 lines, 2 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    609:         conn.commit()\n    610:         conn.close()\n    611: \n>>> 612:     def _load_existing_data(self):\n    613:         \"\"\"Load existing data locations and retention jobs from database.\"\"\"\n    614:         conn = sqlite3.connect(self.compliance_db)\n    615:         conn.row_factory = sqlite3.Row",
    "context": {
      "complexity": 6,
      "lines": 63,
      "max_nesting": 2,
      "method_name": "_load_existing_data"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 613,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    610:         conn.close()\n    611: \n    612:     def _load_existing_data(self):\n>>> 613:         \"\"\"Load existing data locations and retention jobs from database.\"\"\"\n    614:         conn = sqlite3.connect(self.compliance_db)\n    615:         conn.row_factory = sqlite3.Row\n    616:         cursor = conn.cursor()",
    "context": {
      "query_preview": "Load existing data locations and retention jobs from database."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 619,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    616:         cursor = conn.cursor()\n    617: \n    618:         # Load data locations\n>>> 619:         cursor.execute(\"SELECT * FROM data_locations\")\n    620:         for row in cursor.fetchall():\n    621:             location = DataLocation(\n    622:                 location_id=row[\"location_id\"],",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 619,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    616:         cursor = conn.cursor()\n    617: \n    618:         # Load data locations\n>>> 619:         cursor.execute(\"SELECT * FROM data_locations\")\n    620:         for row in cursor.fetchall():\n    621:             location = DataLocation(\n    622:                 location_id=row[\"location_id\"],",
    "context": {
      "query_preview": "SELECT * FROM data_locations"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 647,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    644:             self.data_locations[location.location_id] = location\n    645: \n    646:         # Load retention jobs\n>>> 647:         cursor.execute(\"SELECT * FROM retention_jobs\")\n    648:         for row in cursor.fetchall():\n    649:             job = RetentionJob(\n    650:                 job_id=row[\"job_id\"],",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 647,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    644:             self.data_locations[location.location_id] = location\n    645: \n    646:         # Load retention jobs\n>>> 647:         cursor.execute(\"SELECT * FROM retention_jobs\")\n    648:         for row in cursor.fetchall():\n    649:             job = RetentionJob(\n    650:                 job_id=row[\"job_id\"],",
    "context": {
      "query_preview": "SELECT * FROM retention_jobs"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 664,
    "column": 42,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    661:                 success_count=row[\"success_count\"],\n    662:                 failure_count=row[\"failure_count\"],\n    663:                 total_records_processed=row[\"total_records_processed\"],\n>>> 664:                 total_records_deleted=row[\"total_records_deleted\"],\n    665:                 last_error=row[\"last_error\"],\n    666:                 requires_approval=bool(row[\"requires_approval\"]),\n    667:                 approval_status=row[\"approval_status\"],",
    "context": {
      "query_preview": "total_records_deleted"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 688,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    685:             cursor = conn.cursor()\n    686: \n    687:             # Get all tables\n>>> 688:             cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n    689:             tables = [row[0] for row in cursor.fetchall()]\n    690: \n    691:             for table_name in tables:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 688,
    "column": 27,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    685:             cursor = conn.cursor()\n    686: \n    687:             # Get all tables\n>>> 688:             cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n    689:             tables = [row[0] for row in cursor.fetchall()]\n    690: \n    691:             for table_name in tables:",
    "context": {
      "query_preview": "SELECT name FROM sqlite_master WHERE type='table'"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 697,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    694:                     continue\n    695: \n    696:                 # Get table schema\n>>> 697:                 cursor.execute(f\"PRAGMA table_info({table_name})\")\n    698:                 columns = cursor.fetchall()\n    699: \n    700:                 for col_info in columns:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 708,
    "column": 24,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    705: \n    706:                     if field_rules:\n    707:                         # Sample data from column\n>>> 708:                         cursor.execute(\n    709:                             f\"SELECT DISTINCT {col_name} FROM {table_name} WHERE {col_name} IS NOT NULL LIMIT 100\",\n    710:                         )\n    711:                         samples = [row[0] for row in cursor.fetchall() if row[0]]",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 733,
    "column": 32,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    730:                                 )\n    731: \n    732:                                 # Get record count\n>>> 733:                                 cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n    734:                                 record_count = cursor.fetchone()[0]\n    735: \n    736:                                 location = DataLocation(",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 733,
    "column": 49,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    730:                                 )\n    731: \n    732:                                 # Get record count\n>>> 733:                                 cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n    734:                                 record_count = cursor.fetchone()[0]\n    735: \n    736:                                 location = DataLocation(",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 923,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    920:         custom_retention_days: int | None = None,\n    921:         schedule_cron: str = \"0 2 * * 0\",\n    922:     ) -> str:\n>>> 923:         \"\"\"Create a new data retention job.\"\"\"\n    924:         job_id = f\"retention_{int(time.time())}_{hashlib.md5(name.encode()).hexdigest()[:8]}\"\n    925: \n    926:         job = RetentionJob(",
    "context": {
      "query_preview": "Create a new data retention job."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 940,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    937:         await self._save_retention_job(job)\n    938: \n    939:         await self._log_audit_event(\n>>> 940:             \"retention_job_created\",\n    941:             job_id=job_id,\n    942:             details={\n    943:                 \"name\": name,",
    "context": {
      "query_preview": "retention_job_created"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 950,
    "column": 22,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    947:             },\n    948:         )\n    949: \n>>> 950:         logger.info(f\"Created retention job: {job_id} ({name})\")\n    951:         return job_id\n    952: \n    953:     async def execute_retention_job(self, job_id: str) -> dict[str, Any]:",
    "context": {
      "query_preview": "Created retention job: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1055,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1052:         return policy_days.get(policy, 365)\n    1053: \n    1054:     async def _delete_expired_data(self, location: DataLocation, cutoff_date: datetime) -> int:\n>>> 1055:         \"\"\"Delete expired data from a specific location.\"\"\"\n    1056:         deleted_count = 0\n    1057: \n    1058:         if location.source_type == \"database\":",
    "context": {
      "query_preview": "Delete expired data from a specific location."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1066,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1063:         return deleted_count\n    1064: \n    1065:     async def _delete_from_database(self, location: DataLocation, cutoff_date: datetime) -> int:\n>>> 1066:         \"\"\"Delete expired data from database.\"\"\"\n    1067:         try:\n    1068:             conn = sqlite3.connect(location.path)\n    1069:             cursor = conn.cursor()",
    "context": {
      "query_preview": "Delete expired data from database."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1075,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1072:             # In production, this would be customized per table structure\n    1073: \n    1074:             # Try to find a timestamp column\n>>> 1075:             cursor.execute(f\"PRAGMA table_info({location.table_name})\")\n    1076:             columns = cursor.fetchall()\n    1077: \n    1078:             timestamp_columns = []",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1087,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1084:             if timestamp_columns:\n    1085:                 # Delete records older than cutoff date\n    1086:                 timestamp_col = timestamp_columns[0]\n>>> 1087:                 cursor.execute(\n    1088:                     f\"\"\"\n    1089:                     DELETE FROM {location.table_name}\n    1090:                     WHERE {timestamp_col} < ?",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1088,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1085:                 # Delete records older than cutoff date\n    1086:                 timestamp_col = timestamp_columns[0]\n    1087:                 cursor.execute(\n>>> 1088:                     f\"\"\"\n    1089:                     DELETE FROM {location.table_name}\n    1090:                     WHERE {timestamp_col} < ?\n    1091:                 \"\"\",",
    "context": {
      "query_preview": "\n                    DELETE FROM "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1089,
    "column": 53,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1086:                 timestamp_col = timestamp_columns[0]\n    1087:                 cursor.execute(\n    1088:                     f\"\"\"\n>>> 1089:                     DELETE FROM {location.table_name}\n    1090:                     WHERE {timestamp_col} < ?\n    1091:                 \"\"\",\n    1092:                     (cutoff_date.isoformat(),),",
    "context": {
      "query_preview": "\n                    WHERE "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1096,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1093:                 )\n    1094: \n    1095:                 deleted_count = cursor.rowcount\n>>> 1096:                 conn.commit()\n    1097: \n    1098:                 logger.info(f\"Deleted {deleted_count} records from {location.table_name}\")\n    1099:             else:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1107,
    "column": 27,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1104:             return deleted_count\n    1105: \n    1106:         except Exception as e:\n>>> 1107:             logger.error(f\"Error deleting from database {location.path}: {e}\")\n    1108:             raise\n    1109: \n    1110:     async def _delete_from_file(self, location: DataLocation, cutoff_date: datetime) -> int:",
    "context": {
      "query_preview": "Error deleting from database "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1111,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1108:             raise\n    1109: \n    1110:     async def _delete_from_file(self, location: DataLocation, cutoff_date: datetime) -> int:\n>>> 1111:         \"\"\"Delete expired data from file.\"\"\"\n    1112:         try:\n    1113:             file_path = Path(location.path)\n    1114: ",
    "context": {
      "query_preview": "Delete expired data from file."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1121,
    "column": 34,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1118: \n    1119:                 if file_mtime < cutoff_date:\n    1120:                     file_path.unlink()\n>>> 1121:                     logger.info(f\"Deleted expired file: {file_path}\")\n    1122:                     return 1\n    1123: \n    1124:             return 0",
    "context": {
      "query_preview": "Deleted expired file: "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1137,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1134:         conn = sqlite3.connect(self.compliance_db)\n    1135:         cursor = conn.cursor()\n    1136: \n>>> 1137:         cursor.execute(\n    1138:             \"\"\"\n    1139:             INSERT OR REPLACE INTO data_locations\n    1140:             (location_id, source_type, path, table_name, column_name, field_name, tenant_id,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1138,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1135:         cursor = conn.cursor()\n    1136: \n    1137:         cursor.execute(\n>>> 1138:             \"\"\"\n    1139:             INSERT OR REPLACE INTO data_locations\n    1140:             (location_id, source_type, path, table_name, column_name, field_name, tenant_id,\n    1141:              classification, retention_policy, regulations, discovered_at, last_verified,",
    "context": {
      "query_preview": "\n            INSERT OR REPLACE INTO data_locations\n            (location_id, source_type, path, tabl..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1171,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1168:             ),\n    1169:         )\n    1170: \n>>> 1171:         conn.commit()\n    1172:         conn.close()\n    1173: \n    1174:     async def _save_retention_job(self, job: RetentionJob):",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1179,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1176:         conn = sqlite3.connect(self.compliance_db)\n    1177:         cursor = conn.cursor()\n    1178: \n>>> 1179:         cursor.execute(\n    1180:             \"\"\"\n    1181:             INSERT OR REPLACE INTO retention_jobs\n    1182:             (job_id, name, description, location_ids, retention_policy, custom_retention_days,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1180,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1177:         cursor = conn.cursor()\n    1178: \n    1179:         cursor.execute(\n>>> 1180:             \"\"\"\n    1181:             INSERT OR REPLACE INTO retention_jobs\n    1182:             (job_id, name, description, location_ids, retention_policy, custom_retention_days,\n    1183:              enabled, schedule_cron, last_run, next_run, run_count, success_count, failure_count,",
    "context": {
      "query_preview": "\n            INSERT OR REPLACE INTO retention_jobs\n            (job_id, name, description, location_..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1212,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1209:             ),\n    1210:         )\n    1211: \n>>> 1212:         conn.commit()\n    1213:         conn.close()\n    1214: \n    1215:     async def _log_audit_event(",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1232,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1229:         conn = sqlite3.connect(self.compliance_db)\n    1230:         cursor = conn.cursor()\n    1231: \n>>> 1232:         cursor.execute(\n    1233:             \"\"\"\n    1234:             INSERT INTO audit_log\n    1235:             (audit_id, event_type, timestamp, user_id, tenant_id, location_id, job_id,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1233,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1230:         cursor = conn.cursor()\n    1231: \n    1232:         cursor.execute(\n>>> 1233:             \"\"\"\n    1234:             INSERT INTO audit_log\n    1235:             (audit_id, event_type, timestamp, user_id, tenant_id, location_id, job_id,\n    1236:              details, classification, regulation, compliance_status, risk_level)",
    "context": {
      "query_preview": "\n            INSERT INTO audit_log\n            (audit_id, event_type, timestamp, user_id, tenant_id,..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1254,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1251:             ),\n    1252:         )\n    1253: \n>>> 1254:         conn.commit()\n    1255:         conn.close()\n    1256: \n    1257:     def _calculate_risk_level(self, classification: DataClassification | None, details: dict | None) -> str:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1770,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1767:                     location_ids=pii_locations[:5],\n    1768:                     retention_policy=RetentionPolicy.STANDARD,\n    1769:                 )\n>>> 1770:                 print(f\"\\nCreated retention job: {job_id}\")\n    1771: \n    1772:     asyncio.run(main())",
    "context": {
      "query_preview": "\nCreated retention job: "
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (47 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 47,
      "methods": [
        "_log_audit_event",
        "_validate_match",
        "_scan_metadata",
        "discover_pii_phi_in_files",
        "_delete_expired_data",
        "_delete_from_database",
        "_luhn_check",
        "_load_config",
        "_scan_input_data",
        "_scan_environment_variables",
        "_scan_command_arguments",
        "add_detection_rule",
        "discover_pii_phi_in_database",
        "_delete_from_file",
        "_calculate_risk_level",
        "_generate_remediation_recommendations",
        "_save_data_location",
        "_init_database",
        "_scan_job_payload",
        "_load_existing_data",
        "_determine_retention_policy",
        "detect_in_field_name",
        "_get_retention_days",
        "_save_retention_job",
        "_initialize_builtin_rules",
        "_get_violation_severity",
        "scan_job_inputs_for_compliance"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (21 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 21,
      "methods": [
        "info",
        "warning",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'json' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "json",
      "method_count": 10,
      "methods": [
        "dump",
        "dumps",
        "load",
        "loads"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'sqlite3' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "sqlite3",
      "method_count": 7,
      "methods": [
        "connect"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'conn' methods (19 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "conn",
      "method_count": 19,
      "methods": [
        "close",
        "cursor",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'cursor' methods (29 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "cursor",
      "method_count": 29,
      "methods": [
        "execute",
        "fetchone",
        "fetchall"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (14 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 14,
      "methods": [
        "utcnow",
        "fromtimestamp",
        "fromisoformat"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'file_path' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "file_path",
      "method_count": 6,
      "methods": [
        "unlink",
        "stat",
        "exists",
        "is_file"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'violations' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "violations",
      "method_count": 8,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'recommendations' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "recommendations",
      "method_count": 11,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 431,
    "column": 4,
    "description": "Sequential coupling detected: Function '__init__' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    428: class PIIPHIManager:\n    429:     \"\"\"Main PII/PHI management and compliance system.\"\"\"\n    430: \n>>> 431:     def __init__(self, config_path: Path | None = None):\n    432:         \"\"\"Initialize PII/PHI manager.\"\"\"\n    433:         self.config_path = config_path or Path(\"config/compliance/pii_phi_config.json\")\n    434:         self.detection_engine = PIIDetectionEngine()",
    "context": {
      "function_name": "__init__",
      "sequential_functions": [
        "__init__",
        "_initialize_builtin_rules",
        "_init_database"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 155,
    "column": 4,
    "description": "Sequential coupling detected: Function '_initialize_builtin_rules' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    152:         self.compiled_patterns: dict[str, re.Pattern] = {}\n    153:         self._initialize_builtin_rules()\n    154: \n>>> 155:     def _initialize_builtin_rules(self):\n    156:         \"\"\"Initialize built-in detection rules for common PII/PHI.\"\"\"\n    157:         rules = [\n    158:             # Personal Identifiers",
    "context": {
      "function_name": "_initialize_builtin_rules",
      "sequential_functions": [
        "__init__",
        "_initialize_builtin_rules",
        "_init_database"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 496,
    "column": 4,
    "description": "Sequential coupling detected: Function '_init_database' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    493: \n    494:         return default_config\n    495: \n>>> 496:     def _init_database(self):\n    497:         \"\"\"Initialize compliance database.\"\"\"\n    498:         conn = sqlite3.connect(self.compliance_db)\n    499:         cursor = conn.cursor()",
    "context": {
      "function_name": "_init_database",
      "sequential_functions": [
        "__init__",
        "_initialize_builtin_rules",
        "_init_database"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 75,
    "column": 34,
    "description": "Excessive magic literals detected (55 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     72:     classification: DataClassification\n     73:     pattern: str  # Regex pattern for detection\n     74:     field_names: list[str] = field(default_factory=list)  # Common field names\n>>>  75:     confidence_threshold: float = 0.8  # Confidence threshold for match\n     76:     regulation: ComplianceRegulation | None = None\n     77:     examples: list[str] = field(default_factory=list)\n     78:     false_positive_patterns: list[str] = field(default_factory=list)",
    "context": {
      "total_magic_literals": 55,
      "current_value": 0.8
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 357,
    "column": 26,
    "description": "Excessive magic literals detected (55 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    354:         self, rule: PIIDetectionRule, matches: list[str], field_name: str = \"\", total_samples: int = 1,\n    355:     ) -> float:\n    356:         \"\"\"Calculate confidence score for a detection.\"\"\"\n>>> 357:         base_confidence = 0.5\n    358: \n    359:         # Boost confidence for field name matches\n    360:         if field_name:",
    "context": {
      "total_magic_literals": 55,
      "current_value": 0.5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 363,
    "column": 35,
    "description": "Excessive magic literals detected (55 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    360:         if field_name:\n    361:             field_matches = self.detect_in_field_name(field_name)\n    362:             if rule in field_matches:\n>>> 363:                 base_confidence += 0.3\n    364: \n    365:         # Boost confidence based on match quality\n    366:         if matches:",
    "context": {
      "total_magic_literals": 55,
      "current_value": 0.3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 368,
    "column": 60,
    "description": "Excessive magic literals detected (55 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    365:         # Boost confidence based on match quality\n    366:         if matches:\n    367:             # Higher confidence for more matches (up to a point)\n>>> 368:             match_ratio = min(len(matches) / total_samples, 0.5)\n    369:             base_confidence += match_ratio * 0.3\n    370: \n    371:             # Boost confidence for well-formed matches",
    "context": {
      "total_magic_literals": 55,
      "current_value": 0.5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\compliance\\pii_phi_manager.py",
    "line_number": 369,
    "column": 45,
    "description": "Excessive magic literals detected (55 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    366:         if matches:\n    367:             # Higher confidence for more matches (up to a point)\n    368:             match_ratio = min(len(matches) / total_samples, 0.5)\n>>> 369:             base_confidence += match_ratio * 0.3\n    370: \n    371:             # Boost confidence for well-formed matches\n    372:             valid_matches = 0",
    "context": {
      "total_magic_literals": 55,
      "current_value": 0.3
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 177,
    "column": 0,
    "description": "Class 'CloudCostManager' is a God Object: 5 methods, ~518 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "    174:     resource_utilization: float | None = None\n    175: \n    176: \n>>> 177: class CloudCostManager:\n    178:     \"\"\"Multi-cloud cost management for AIVillage Agent Forge deployments.\n    179: \n    180:     Handles cost tagging, resource tracking, and cost optimization across",
    "context": {
      "method_count": 5,
      "estimated_lines": 518,
      "class_name": "CloudCostManager",
      "data_methods": 2,
      "business_methods": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 227,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    224:             \"default_region_aws\": \"us-west-2\",\n    225:             \"default_region_azure\": \"West US 2\",\n    226:             \"default_region_gcp\": \"us-west2\",\n>>> 227:             \"cost_update_interval_hours\": 1,\n    228:             \"auto_tagging_enabled\": True,\n    229:             \"cost_optimization_enabled\": True,\n    230:             \"unused_resource_detection\": True,",
    "context": {
      "query_preview": "cost_update_interval_hours"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 238,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    235:         try:\n    236:             with open(self.config_path) as f:\n    237:                 user_config = json.load(f)\n>>> 238:             default_config.update(user_config)\n    239:         except Exception as e:\n    240:             logger.warning(f\"Could not load config from {self.config_path}: {e}\")\n    241: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 240,
    "column": 29,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    237:                 user_config = json.load(f)\n    238:             default_config.update(user_config)\n    239:         except Exception as e:\n>>> 240:             logger.warning(f\"Could not load config from {self.config_path}: {e}\")\n    241: \n    242:         return default_config\n    243: ",
    "context": {
      "query_preview": "Could not load config from "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 275,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    272:         # Add custom tags\n    273:         tag_dict = phase_tags.to_dict()\n    274:         if custom_tags:\n>>> 275:             tag_dict.update(custom_tags)\n    276: \n    277:         tagged_count = 0\n    278: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 488,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    485:         return allocation\n    486: \n    487:     async def _update_resource_costs(self, resources: list[CloudResource]):\n>>> 488:         \"\"\"Update cost information for resources.\"\"\"\n    489:         current_time = time.time()\n    490: \n    491:         for resource in resources:",
    "context": {
      "query_preview": "Update cost information for resources."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 512,
    "column": 33,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    509:                 resource.cost_last_updated = current_time\n    510: \n    511:             except Exception as e:\n>>> 512:                 logger.warning(f\"Could not update cost for {resource.resource_id}: {e}\")\n    513: \n    514:     async def _get_aws_resource_cost(self, resource: CloudResource) -> float:\n    515:         \"\"\"Get AWS resource cost per hour.\"\"\"",
    "context": {
      "query_preview": "Could not update cost for "
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 648,
    "column": 4,
    "description": "Method 'get_cost_allocation_report' is too complex: 7 complexity, 47 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    645:             \"recommendations\": recommendations,\n    646:         }\n    647: \n>>> 648:     def get_cost_allocation_report(self, phase: str | None = None) -> dict[str, Any]:\n    649:         \"\"\"Generate comprehensive cost allocation report.\"\"\"\n    650:         if phase:\n    651:             allocations = [a for a in self.cost_allocations if a.phase == phase]",
    "context": {
      "complexity": 7,
      "lines": 47,
      "max_nesting": 5,
      "method_name": "get_cost_allocation_report"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 700,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    697: \n    698: # Helper functions\n    699: async def create_cloud_cost_manager_with_infrastructure() -> CloudCostManager:\n>>> 700:     \"\"\"Create cloud cost manager with available infrastructure.\"\"\"\n    701:     fog_orchestrator = None\n    702:     cost_tracker = None\n    703: ",
    "context": {
      "query_preview": "Create cloud cost manager with available infrastructure."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (14 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 14,
      "methods": [
        "_get_gcp_resource_cost",
        "_get_aws_resource_cost",
        "_tag_gcp_resource",
        "_update_resource_costs",
        "_calculate_resource_utilization",
        "_initialize_standard_tags",
        "_tag_azure_resource",
        "_get_azure_resource_cost",
        "to_dict",
        "_load_config",
        "_tag_aws_resource",
        "_apply_resource_tags",
        "_get_default_region"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (15 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 15,
      "methods": [
        "info",
        "warning",
        "error",
        "debug"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'resource_spec' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "resource_spec",
      "method_count": 9,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 216,
    "column": 36,
    "description": "Excessive magic literals detected (39 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    213: \n    214:         # Monitoring\n    215:         self.last_cost_update = 0.0\n>>> 216:         self.cost_update_interval = 3600  # 1 hour\n    217: \n    218:         logger.info(\"Cloud cost manager initialized\")\n    219: ",
    "context": {
      "total_magic_literals": 39,
      "current_value": 3600
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 359,
    "column": 29,
    "description": "Excessive magic literals detected (39 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    356:             # Parse resource ID to get resource group and resource name\n    357:             # Format: /subscriptions/{sub}/resourceGroups/{rg}/providers/{provider}/{type}/{name}\n    358:             parts = resource_id.split(\"/\")\n>>> 359:             if len(parts) >= 9:\n    360:                 resource_group = parts[4]\n    361:                 provider_namespace = parts[6]\n    362:                 resource_type = parts[7]",
    "context": {
      "total_magic_literals": 39,
      "current_value": 9
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 360,
    "column": 39,
    "description": "Excessive magic literals detected (39 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    357:             # Format: /subscriptions/{sub}/resourceGroups/{rg}/providers/{provider}/{type}/{name}\n    358:             parts = resource_id.split(\"/\")\n    359:             if len(parts) >= 9:\n>>> 360:                 resource_group = parts[4]\n    361:                 provider_namespace = parts[6]\n    362:                 resource_type = parts[7]\n    363:                 resource_name = parts[8]",
    "context": {
      "total_magic_literals": 39,
      "current_value": 4
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 361,
    "column": 43,
    "description": "Excessive magic literals detected (39 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    358:             parts = resource_id.split(\"/\")\n    359:             if len(parts) >= 9:\n    360:                 resource_group = parts[4]\n>>> 361:                 provider_namespace = parts[6]\n    362:                 resource_type = parts[7]\n    363:                 resource_name = parts[8]\n    364: ",
    "context": {
      "total_magic_literals": 39,
      "current_value": 6
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cloud_cost_tagging.py",
    "line_number": 362,
    "column": 38,
    "description": "Excessive magic literals detected (39 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    359:             if len(parts) >= 9:\n    360:                 resource_group = parts[4]\n    361:                 provider_namespace = parts[6]\n>>> 362:                 resource_type = parts[7]\n    363:                 resource_name = parts[8]\n    364: \n    365:                 # Update tags",
    "context": {
      "total_magic_literals": 39,
      "current_value": 7
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 143,
    "column": 0,
    "description": "Class 'CostGovernanceDashboard' is a God Object: 4 methods, ~643 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "    140:     pending_approvals_count: int\n    141: \n    142: \n>>> 143: class CostGovernanceDashboard:\n    144:     \"\"\"Comprehensive cost governance dashboard for AIVillage infrastructure.\n    145: \n    146:     Provides centralized cost monitoring, budget management, governance workflows,",
    "context": {
      "method_count": 4,
      "estimated_lines": 643,
      "class_name": "CostGovernanceDashboard",
      "data_methods": 1,
      "business_methods": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 212,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    209:         try:\n    210:             with open(config_path) as f:\n    211:                 user_config = json.load(f)\n>>> 212:             default_config.update(user_config)\n    213:         except Exception as e:\n    214:             logger.warning(f\"Could not load config from {config_path}: {e}\")\n    215: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 214,
    "column": 29,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    211:                 user_config = json.load(f)\n    212:             default_config.update(user_config)\n    213:         except Exception as e:\n>>> 214:             logger.warning(f\"Could not load config from {config_path}: {e}\")\n    215: \n    216:         return default_config\n    217: ",
    "context": {
      "query_preview": "Could not load config from "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 265,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    262:         )\n    263: \n    264:     async def update_dashboard_metrics(self) -> CostDashboardMetrics:\n>>> 265:         \"\"\"Update and return current dashboard metrics.\"\"\"\n    266:         current_time = time.time()\n    267: \n    268:         # Skip update if too recent",
    "context": {
      "query_preview": "Update and return current dashboard metrics."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 348,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    345:         return metrics\n    346: \n    347:     async def _get_cached_metrics(self) -> CostDashboardMetrics:\n>>> 348:         \"\"\"Return cached cost metrics from system monitoring.\"\"\"\n    349:         # Return current metrics from cost tracking systems\n    350:         return CostDashboardMetrics(\n    351:             total_cost_current_period=0,",
    "context": {
      "query_preview": "Return cached cost metrics from system monitoring."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 433,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    430:         return total_savings\n    431: \n    432:     async def _check_budget_alerts(self, metrics: CostDashboardMetrics):\n>>> 433:         \"\"\"Check for budget alerts and create new alerts as needed.\"\"\"\n    434:         for category, governance in self.budget_governance.items():\n    435:             # Get category-specific cost\n    436:             category_cost = 0.0",
    "context": {
      "query_preview": "Check for budget alerts and create new alerts as needed."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 519,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    516:         threshold_value: float,\n    517:         recommended_actions: list[str],\n    518:     ):\n>>> 519:         \"\"\"Create and store new cost alert.\"\"\"\n    520:         alert = CostAlert(\n    521:             alert_id=alert_id,\n    522:             timestamp=time.time(),",
    "context": {
      "query_preview": "Create and store new cost alert."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 708,
    "column": 4,
    "description": "Method 'get_governance_report' is too complex: 2 complexity, 56 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    705:         # This would implement actual shutdown logic\n    706:         logger.critical(f\"Emergency shutdown executed for {category}\")\n    707: \n>>> 708:     def get_governance_report(self) -> dict[str, Any]:\n    709:         \"\"\"Generate comprehensive governance report.\"\"\"\n    710:         # Budget status summary\n    711:         budget_status = {}",
    "context": {
      "complexity": 2,
      "lines": 56,
      "max_nesting": 1,
      "method_name": "get_governance_report"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 791,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    788: \n    789: # Helper functions\n    790: async def create_cost_governance_dashboard_with_infrastructure() -> CostGovernanceDashboard:\n>>> 791:     \"\"\"Create cost governance dashboard with all available infrastructure.\"\"\"\n    792:     cost_tracker = None\n    793:     transport_optimizer = None\n    794:     cloud_manager = None",
    "context": {
      "query_preview": "Create cost governance dashboard with all available infrastructure."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (19 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 19,
      "methods": [
        "_check_budget_alerts",
        "_initialize_default_governance",
        "_create_alert",
        "_get_cached_metrics",
        "update_dashboard_metrics",
        "_calculate_resource_utilization",
        "_send_slack_notification",
        "_calculate_cost_per_gpu_hour",
        "_calculate_optimization_savings",
        "get_governance_report",
        "_load_config",
        "_send_alert_notifications",
        "_calculate_cost_per_task",
        "_send_email_notification",
        "_execute_emergency_shutdown",
        "_get_category_budget_utilization",
        "_send_approval_request_notifications"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (20 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 20,
      "methods": [
        "info",
        "critical",
        "warning",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'time' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "time",
      "method_count": 8,
      "methods": [
        "time"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 87,
    "column": 37,
    "description": "Excessive magic literals detected (41 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     84:     # Approval settings\n     85:     requires_approval: bool = True\n     86:     approvers: list[str] = field(default_factory=list)  # User IDs who can approve\n>>>  87:     auto_approve_percentage: float = 0.8  # Auto-approve up to 80% of budget\n     88: \n     89:     # Alert settings\n     90:     warning_threshold: float = 0.75  # Alert at 75% of budget",
    "context": {
      "total_magic_literals": 41,
      "current_value": 0.8
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 90,
    "column": 31,
    "description": "Excessive magic literals detected (41 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     87:     auto_approve_percentage: float = 0.8  # Auto-approve up to 80% of budget\n     88: \n     89:     # Alert settings\n>>>  90:     warning_threshold: float = 0.75  # Alert at 75% of budget\n     91:     critical_threshold: float = 0.90  # Critical alert at 90%\n     92: \n     93:     # Governance rules",
    "context": {
      "total_magic_literals": 41,
      "current_value": 0.75
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 91,
    "column": 32,
    "description": "Excessive magic literals detected (41 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     88: \n     89:     # Alert settings\n     90:     warning_threshold: float = 0.75  # Alert at 75% of budget\n>>>  91:     critical_threshold: float = 0.90  # Critical alert at 90%\n     92: \n     93:     # Governance rules\n     94:     allow_budget_extension: bool = False",
    "context": {
      "total_magic_literals": 41,
      "current_value": 0.9
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 95,
    "column": 38,
    "description": "Excessive magic literals detected (41 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     92: \n     93:     # Governance rules\n     94:     allow_budget_extension: bool = False\n>>>  95:     max_extension_percentage: float = 0.20  # Max 20% extension\n     96:     require_justification: bool = True\n     97: \n     98: ",
    "context": {
      "total_magic_literals": 41,
      "current_value": 0.2
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\cost_governance_dashboard.py",
    "line_number": 181,
    "column": 36,
    "description": "Excessive magic literals detected (41 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    178: \n    179:         # Dashboard state\n    180:         self.last_update_time: float = 0\n>>> 181:         self.update_interval: int = 300  # 5 minutes\n    182: \n    183:         # Configuration\n    184:         self.config = self._load_config()",
    "context": {
      "total_magic_literals": 41,
      "current_value": 300
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\cost_management\\edge_cost_allocation.py",
    "line_number": 132,
    "column": 0,
    "description": "Class 'EdgeCostAllocator' is a God Object: 6 methods, ~600 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "    129:     covers_data_costs: bool = False  # Whether rewards cover cellular data\n    130: \n    131: \n>>> 132: class EdgeCostAllocator:\n    133:     \"\"\"Cost-aware resource allocation system for edge devices.\n    134: \n    135:     Manages fair and efficient allocation of computing tasks across edge devices",
    "context": {
      "method_count": 6,
      "estimated_lines": 600,
      "class_name": "EdgeCostAllocator",
      "data_methods": 1,
      "business_methods": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\cost_management\\edge_cost_allocation.py",
    "line_number": 231,
    "column": 4,
    "description": "Method '_validate_device_capabilities' is too complex: 7 complexity, 20 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    228: \n    229:         return True\n    230: \n>>> 231:     def _validate_device_capabilities(self, capabilities: DeviceCapabilities) -> bool:\n    232:         \"\"\"Validate device capabilities for minimum requirements.\"\"\"\n    233:         # Minimum hardware requirements\n    234:         if capabilities.cpu_cores < 1:",
    "context": {
      "complexity": 7,
      "lines": 20,
      "max_nesting": 5,
      "method_name": "_validate_device_capabilities"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\edge_cost_allocation.py",
    "line_number": 256,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    253:     async def allocate_resources_for_task(\n    254:         self, task_id: str, task_requirements: dict[str, Any], preferred_devices: list[str] | None = None,\n    255:     ) -> list[ResourceAllocation]:\n>>> 256:         \"\"\"Allocate edge device resources for specific task.\n    257: \n    258:         Args:\n    259:             task_id: Unique task identifier",
    "context": {
      "query_preview": "Allocate edge device resources for specific task.\n\n        Args:\n            task_id: Unique task id..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\edge_cost_allocation.py",
    "line_number": 446,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    443:     async def _calculate_device_score(\n    444:         self, device: DeviceCapabilities, task_requirements: dict[str, Any],\n    445:     ) -> dict[str, Any]:\n>>> 446:         \"\"\"Calculate scoring for device selection.\"\"\"\n    447:         # Check constraints\n    448:         constraints = await self._check_device_constraints(device)\n    449: ",
    "context": {
      "query_preview": "Calculate scoring for device selection."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\cost_management\\edge_cost_allocation.py",
    "line_number": 503,
    "column": 4,
    "description": "Method '_determine_participation_level' is too complex: 9 complexity, 28 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    500:             \"hourly_cost\": hourly_cost,\n    501:         }\n    502: \n>>> 503:     def _determine_participation_level(\n    504:         self,\n    505:         device: DeviceCapabilities,\n    506:         cpu_allocation: float,",
    "context": {
      "complexity": 9,
      "lines": 28,
      "max_nesting": 6,
      "method_name": "_determine_participation_level"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\edge_cost_allocation.py",
    "line_number": 615,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    612:         return 0.5 + (success_rate * 0.5)  # 0.5 to 1.0 multiplier\n    613: \n    614:     async def update_device_status(self, device_id: str, status_update: dict[str, Any]) -> bool:\n>>> 615:         \"\"\"Update device status and check for reallocation needs.\"\"\"\n    616:         if device_id not in self.registered_devices:\n    617:             return False\n    618: ",
    "context": {
      "query_preview": "Update device status and check for reallocation needs."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\edge_cost_allocation.py",
    "line_number": 644,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    641:         return True\n    642: \n    643:     async def _deallocate_device(self, device_id: str, reason: str):\n>>> 644:         \"\"\"Remove device from current allocations.\"\"\"\n    645:         if device_id in self.current_allocations:\n    646:             allocation = self.current_allocations.pop(device_id)\n    647: ",
    "context": {
      "query_preview": "Remove device from current allocations."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\edge_cost_allocation.py",
    "line_number": 737,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    734: \n    735: # Helper functions\n    736: async def create_edge_cost_allocator_with_infrastructure() -> EdgeCostAllocator:\n>>> 737:     \"\"\"Create edge cost allocator with available infrastructure.\"\"\"\n    738:     edge_manager = None\n    739:     cost_tracker = None\n    740:     transport_optimizer = None",
    "context": {
      "query_preview": "Create edge cost allocator with available infrastructure."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\edge_cost_allocation.py",
    "line_number": 840,
    "column": 14,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    837:         await allocator.update_device_status(\n    838:             \"mobile-pixel-7\", {\"battery_percent\": 18, \"cpu_temp_celsius\": 45},  # Low battery\n    839:         )\n>>> 840:         print(\"\ud83d\udcf1 Updated mobile device status (low battery)\")\n    841: \n    842:         # Generate allocation report\n    843:         report = allocator.get_allocation_report()",
    "context": {
      "query_preview": "\ud83d\udcf1 Updated mobile device status (low battery)"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\edge_cost_allocation.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (14 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 14,
      "methods": [
        "_calculate_participation_cost",
        "_calculate_optimal_allocation",
        "_determine_participation_level",
        "_calculate_device_score",
        "_calculate_uptime_multiplier",
        "_get_available_devices",
        "_validate_device_capabilities",
        "_deallocate_device",
        "_check_device_constraints",
        "_reduce_device_allocation",
        "_load_config"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\edge_cost_allocation.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 11,
      "methods": [
        "info",
        "warning"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\edge_cost_allocation.py",
    "line_number": 70,
    "column": 30,
    "description": "Excessive magic literals detected (68 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     67: \n     68:     # Current state\n     69:     battery_percent: float | None = None\n>>>  70:     cpu_temp_celsius: float = 25.0\n     71:     memory_usage_percent: float = 50.0\n     72:     network_type: str = \"wifi\"  # wifi, cellular, ethernet\n     73: ",
    "context": {
      "total_magic_literals": 68,
      "current_value": 25.0
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\edge_cost_allocation.py",
    "line_number": 71,
    "column": 34,
    "description": "Excessive magic literals detected (68 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     68:     # Current state\n     69:     battery_percent: float | None = None\n     70:     cpu_temp_celsius: float = 25.0\n>>>  71:     memory_usage_percent: float = 50.0\n     72:     network_type: str = \"wifi\"  # wifi, cellular, ethernet\n     73: \n     74:     # Cost factors",
    "context": {
      "total_magic_literals": 68,
      "current_value": 50.0
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\edge_cost_allocation.py",
    "line_number": 75,
    "column": 38,
    "description": "Excessive magic literals detected (68 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     72:     network_type: str = \"wifi\"  # wifi, cellular, ethernet\n     73: \n     74:     # Cost factors\n>>>  75:     electricity_cost_per_kwh: float = 0.12\n     76:     data_cost_per_gb: float = 0.0  # 0 for unlimited plans\n     77:     device_depreciation_per_hour: float = 0.001\n     78: ",
    "context": {
      "total_magic_literals": 68,
      "current_value": 0.12
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\edge_cost_allocation.py",
    "line_number": 77,
    "column": 42,
    "description": "Excessive magic literals detected (68 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     74:     # Cost factors\n     75:     electricity_cost_per_kwh: float = 0.12\n     76:     data_cost_per_gb: float = 0.0  # 0 for unlimited plans\n>>>  77:     device_depreciation_per_hour: float = 0.001\n     78: \n     79:     # Participation preferences\n     80:     max_participation_level: DeviceParticipationLevel = DeviceParticipationLevel.STANDARD",
    "context": {
      "total_magic_literals": 68,
      "current_value": 0.001
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\edge_cost_allocation.py",
    "line_number": 82,
    "column": 35,
    "description": "Excessive magic literals detected (68 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     79:     # Participation preferences\n     80:     max_participation_level: DeviceParticipationLevel = DeviceParticipationLevel.STANDARD\n     81:     allow_cellular_participation: bool = False\n>>>  82:     min_battery_threshold: float = 20.0\n     83:     max_thermal_threshold: float = 55.0\n     84: \n     85: ",
    "context": {
      "total_magic_literals": 68,
      "current_value": 20.0
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 1,
    "column": 0,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": ">>>   1: \"\"\"AIVillage P2P Transport Cost Optimizer\n      2: \n      3: This module provides intelligent P2P transport cost optimization and budget alerts\n      4: by integrating with the existing transport management system and cost tracking.",
    "context": {
      "query_preview": "AIVillage P2P Transport Cost Optimizer\n\nThis module provides intelligent P2P transport cost optimiza..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 82,
    "column": 0,
    "description": "Class 'P2PTransportOptimizer' is a God Object: 6 methods, ~505 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "     79:     recommendations: list[str]\n     80: \n     81: \n>>>  82: class P2PTransportOptimizer:\n     83:     \"\"\"P2P transport cost optimizer that integrates with existing transport management\n     84:     to provide intelligent, cost-aware routing decisions.\n     85:     \"\"\"",
    "context": {
      "method_count": 6,
      "estimated_lines": 505,
      "class_name": "P2PTransportOptimizer",
      "data_methods": 3,
      "business_methods": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 177,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    174:         priority: str = \"normal\",\n    175:         device_context: dict[str, Any] | None = None,\n    176:     ) -> RoutingDecision:\n>>> 177:         \"\"\"Optimize transport selection based on cost, device context, and conditions.\n    178: \n    179:         Args:\n    180:             message_size_bytes: Size of message to transmit",
    "context": {
      "query_preview": "Optimize transport selection based on cost, device context, and conditions.\n\n        Args:\n         ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 324,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    321:         priority: str,\n    322:         device_context: dict[str, Any],\n    323:     ) -> TransportType:\n>>> 324:         \"\"\"Apply the configured optimization strategy to select transport.\"\"\"\n    325:         if self.optimization_strategy == CostOptimizationStrategy.MINIMIZE_COST:\n    326:             # Select lowest total cost\n    327:             return min(transport_costs.keys(), key=lambda t: transport_costs[t][\"total_cost\"])",
    "context": {
      "query_preview": "Apply the configured optimization strategy to select transport."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 379,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    376:         return max(transport_costs.keys(), key=balanced_score)\n    377: \n    378:     async def _get_device_context(self) -> dict[str, Any]:\n>>> 379:         \"\"\"Get current device context from edge manager.\"\"\"\n    380:         context = {\"battery_percent\": 100, \"cpu_temp_celsius\": 25, \"network_type\": \"wifi\", \"data_budget_mb\": 1000}\n    381: \n    382:         if self.edge_manager and hasattr(self.edge_manager, \"get_device_status\"):",
    "context": {
      "query_preview": "Get current device context from edge manager."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 385,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    382:         if self.edge_manager and hasattr(self.edge_manager, \"get_device_status\"):\n    383:             try:\n    384:                 status = await self.edge_manager.get_device_status()\n>>> 385:                 context.update(status)\n    386:             except Exception as e:\n    387:                 logger.warning(f\"Could not get device context: {e}\")\n    388: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 487,
    "column": 4,
    "description": "Method 'get_cost_optimization_report' is too complex: 4 complexity, 52 lines, 3 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    484: \n    485:         return usage_cost\n    486: \n>>> 487:     def get_cost_optimization_report(self) -> dict[str, Any]:\n    488:         \"\"\"Generate comprehensive cost optimization report.\"\"\"\n    489:         if not self.routing_decisions:\n    490:             return {\"message\": \"No routing decisions recorded yet\"}",
    "context": {
      "complexity": 4,
      "lines": 52,
      "max_nesting": 3,
      "method_name": "get_cost_optimization_report"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 541,
    "column": 4,
    "description": "Method '_generate_optimization_recommendations' is too complex: 10 complexity, 40 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    538:             \"recommendations\": self._generate_optimization_recommendations(),\n    539:         }\n    540: \n>>> 541:     def _generate_optimization_recommendations(self) -> list[str]:\n    542:         \"\"\"Generate optimization recommendations based on usage patterns.\"\"\"\n    543:         recommendations = []\n    544: ",
    "context": {
      "complexity": 10,
      "lines": 40,
      "max_nesting": 8,
      "method_name": "_generate_optimization_recommendations"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 584,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    581:         return recommendations\n    582: \n    583:     def set_optimization_strategy(self, strategy: CostOptimizationStrategy):\n>>> 584:         \"\"\"Update the optimization strategy.\"\"\"\n    585:         old_strategy = self.optimization_strategy\n    586:         self.optimization_strategy = strategy\n    587:         logger.info(f\"Optimization strategy changed: {old_strategy.value} -> {strategy.value}\")",
    "context": {
      "query_preview": "Update the optimization strategy."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 592,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    589: \n    590: # Helper functions for integration\n    591: async def create_transport_optimizer_with_infrastructure() -> P2PTransportOptimizer:\n>>> 592:     \"\"\"Create P2P transport optimizer with all available infrastructure.\"\"\"\n    593:     transport_manager = None\n    594:     edge_manager = None\n    595:     cost_tracker = None",
    "context": {
      "query_preview": "Create P2P transport optimizer with all available infrastructure."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 6,
      "methods": [
        "_calculate_recent_transport_usage",
        "_apply_optimization_strategy",
        "_generate_optimization_recommendations",
        "_initialize_cost_profiles",
        "_calculate_transport_cost",
        "_get_device_context"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 10,
      "methods": [
        "info",
        "warning",
        "critical"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'transport_costs' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "transport_costs",
      "method_count": 7,
      "methods": [
        "items",
        "get",
        "keys"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'recommendations' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "recommendations",
      "method_count": 7,
      "methods": [
        "append",
        "extend"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'optimizer' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "optimizer",
      "method_count": 6,
      "methods": [
        "set_optimization_strategy",
        "check_budget_alerts",
        "get_cost_optimization_report",
        "set_transport_budget",
        "optimize_transport_selection"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 52,
    "column": 31,
    "description": "Excessive magic literals detected (48 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     49:     battery_cost_per_mb: float  # Battery drain cost per MB\n     50:     cellular_multiplier: float = 2.0  # Cellular cost multiplier\n     51:     wifi_multiplier: float = 1.0  # WiFi cost multiplier\n>>>  52:     reliability_score: float = 0.8  # Transport reliability (0-1)\n     53:     setup_latency_ms: int = 100  # Connection setup latency\n     54:     throughput_mbps: float = 1.0  # Expected throughput\n     55: ",
    "context": {
      "total_magic_literals": 48,
      "current_value": 0.8
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 119,
    "column": 41,
    "description": "Excessive magic literals detected (48 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    116:         # Configuration\n    117:         self.config = {\n    118:             \"cost_optimization_enabled\": True,\n>>> 119:             \"battery_threshold_percent\": 20,  # Switch to BitChat below 20%\n    120:             \"cellular_cost_awareness\": True,  # Factor in cellular costs\n    121:             \"budget_alert_threshold\": 0.8,  # Alert at 80% budget\n    122:             \"max_routing_history\": 1000,  # Keep last 1000 decisions",
    "context": {
      "total_magic_literals": 48,
      "current_value": 20
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 121,
    "column": 38,
    "description": "Excessive magic literals detected (48 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    118:             \"cost_optimization_enabled\": True,\n    119:             \"battery_threshold_percent\": 20,  # Switch to BitChat below 20%\n    120:             \"cellular_cost_awareness\": True,  # Factor in cellular costs\n>>> 121:             \"budget_alert_threshold\": 0.8,  # Alert at 80% budget\n    122:             \"max_routing_history\": 1000,  # Keep last 1000 decisions\n    123:             \"cost_calculation_interval\": 60,  # Recalculate costs every minute\n    124:         }",
    "context": {
      "total_magic_literals": 48,
      "current_value": 0.8
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 123,
    "column": 41,
    "description": "Excessive magic literals detected (48 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    120:             \"cellular_cost_awareness\": True,  # Factor in cellular costs\n    121:             \"budget_alert_threshold\": 0.8,  # Alert at 80% budget\n    122:             \"max_routing_history\": 1000,  # Keep last 1000 decisions\n>>> 123:             \"cost_calculation_interval\": 60,  # Recalculate costs every minute\n    124:         }\n    125: \n    126:         logger.info(\"P2P transport optimizer initialized\")",
    "context": {
      "total_magic_literals": 48,
      "current_value": 60
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\cost_management\\p2p_transport_optimizer.py",
    "line_number": 136,
    "column": 32,
    "description": "Excessive magic literals detected (48 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    133:         profiles[TransportType.BITCHAT] = TransportCostProfile(\n    134:             transport_type=TransportType.BITCHAT,\n    135:             base_cost_per_mb=0.0,  # No direct data cost\n>>> 136:             battery_cost_per_mb=0.001,  # Minimal battery per MB\n    137:             cellular_multiplier=1.0,  # Not cellular dependent\n    138:             wifi_multiplier=1.0,  # Not wifi dependent\n    139:             reliability_score=0.7,  # Medium reliability (mesh dependent)",
    "context": {
      "total_magic_literals": 48,
      "current_value": 0.001
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 136,
    "column": 0,
    "description": "Class 'CloudCostAnalyzer' is a God Object: 10 methods, ~676 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "    133:             self.potential_savings[category] = potential_savings\n    134: \n    135: \n>>> 136: class CloudCostAnalyzer:\n    137:     \"\"\"Cloud cost analyzer for AIVillage deployments.\"\"\"\n    138: \n    139:     def __init__(self):",
    "context": {
      "method_count": 10,
      "estimated_lines": 676,
      "class_name": "CloudCostAnalyzer",
      "data_methods": 0,
      "business_methods": 10
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 155,
    "column": 4,
    "description": "Method '_load_pricing_data' is too complex: 1 complexity, 102 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    152: \n    153:         logger.info(\"Cloud cost analyzer initialized\")\n    154: \n>>> 155:     def _load_pricing_data(self) -> dict[str, Any]:\n    156:         \"\"\"Load cloud provider pricing data.\"\"\"\n    157:         # In production, this would load from external pricing APIs\n    158:         # For now, we'll use estimated pricing based on recent data (August 2025)",
    "context": {
      "complexity": 1,
      "lines": 102,
      "max_nesting": 0,
      "method_name": "_load_pricing_data"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 259,
    "column": 4,
    "description": "Method '_load_deployment_configs' is too complex: 1 complexity, 220 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    256:             },\n    257:         }\n    258: \n>>> 259:     def _load_deployment_configs(self) -> dict[DeploymentType, dict[str, Any]]:\n    260:         \"\"\"Load deployment configurations.\"\"\"\n    261:         return {\n    262:             DeploymentType.DEVELOPMENT: {",
    "context": {
      "complexity": 1,
      "lines": 220,
      "max_nesting": 0,
      "method_name": "_load_deployment_configs"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 481,
    "column": 4,
    "description": "Method 'estimate_resource_cost' is too complex: 16 complexity, 107 lines, 15 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    478:             },\n    479:         }\n    480: \n>>> 481:     def estimate_resource_cost(\n    482:         self, resource_spec: ResourceSpecification, provider: CloudProvider, region: str = \"us-east-1\",\n    483:     ) -> CostEstimate:\n    484:         \"\"\"Estimate cost for a single resource.\"\"\"",
    "context": {
      "complexity": 16,
      "lines": 107,
      "max_nesting": 15,
      "method_name": "estimate_resource_cost"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 504,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    501:             if instance_type:\n    502:                 compute_cost = Decimal(str(instance_hourly)) * resource_spec.instance_count\n    503:                 hourly_cost += compute_cost\n>>> 504:                 notes.append(f\"Selected instance type: {instance_type}\")\n    505: \n    506:             # Add storage cost\n    507:             if resource_spec.storage_gb:",
    "context": {
      "query_preview": "Selected instance type: "
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 643,
    "column": 4,
    "description": "Method '_generate_optimization_recommendations' is too complex: 10 complexity, 81 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    640:         logger.info(f\"Analysis complete: ${total_monthly}/month, ${total_annual}/year\")\n    641:         return analysis\n    642: \n>>> 643:     def _generate_optimization_recommendations(self, analysis: DeploymentCostAnalysis):\n    644:         \"\"\"Generate cost optimization recommendations.\"\"\"\n    645:         monthly_cost = analysis.total_monthly_cost\n    646: ",
    "context": {
      "complexity": 10,
      "lines": 81,
      "max_nesting": 8,
      "method_name": "_generate_optimization_recommendations"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 739,
    "column": 4,
    "description": "Method 'generate_cost_report' is too complex: 5 complexity, 61 lines, 4 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    736: \n    737:         return comparisons\n    738: \n>>> 739:     def generate_cost_report(self, analysis: DeploymentCostAnalysis, output_format: str = \"detailed\") -> dict[str, Any]:\n    740:         \"\"\"Generate comprehensive cost report.\"\"\"\n    741:         report = {\n    742:             \"summary\": {",
    "context": {
      "complexity": 5,
      "lines": 61,
      "max_nesting": 4,
      "method_name": "generate_cost_report"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 774,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    771:             }\n    772: \n    773:             if output_format == \"detailed\":\n>>> 774:                 resource_info.update(\n    775:                     {\n    776:                         \"hourly_cost\": float(cost_estimate.hourly_cost),\n    777:                         \"compute_cost\": float(cost_estimate.compute_cost) if cost_estimate.compute_cost else None,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 816,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    813: \n    814: \n    815: async def create_cost_analyzer() -> CloudCostAnalyzer:\n>>> 816:     \"\"\"Create and initialize cloud cost analyzer.\"\"\"\n    817:     analyzer = CloudCostAnalyzer()\n    818:     logger.info(\"Cloud cost analyzer created successfully\")\n    819:     return analyzer",
    "context": {
      "query_preview": "Create and initialize cloud cost analyzer."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 818,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    815: async def create_cost_analyzer() -> CloudCostAnalyzer:\n    816:     \"\"\"Create and initialize cloud cost analyzer.\"\"\"\n    817:     analyzer = CloudCostAnalyzer()\n>>> 818:     logger.info(\"Cloud cost analyzer created successfully\")\n    819:     return analyzer\n    820: \n    821: ",
    "context": {
      "query_preview": "Cloud cost analyzer created successfully"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 8,
      "methods": [
        "_load_pricing_data",
        "generate_cost_report",
        "_load_deployment_configs",
        "estimate_resource_cost",
        "analyze_deployment",
        "_generate_optimization_recommendations",
        "_find_best_instance"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 6,
      "methods": [
        "info"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'provider_pricing' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "provider_pricing",
      "method_count": 9,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'analysis' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "analysis",
      "method_count": 8,
      "methods": [
        "add_recommendation"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 77,
    "column": 34,
    "description": "Excessive magic literals detected (178 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     74: \n     75:     # Instance specs\n     76:     instance_count: int = 1\n>>>  77:     uptime_hours_per_month: int = 744  # 24 * 31\n     78: \n     79:     # Additional metadata\n     80:     tags: dict[str, str] = field(default_factory=dict)",
    "context": {
      "total_magic_literals": 178,
      "current_value": 744
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 127,
    "column": 30,
    "description": "Excessive magic literals detected (178 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    124: \n    125:     # Analysis metadata\n    126:     analysis_date: datetime = field(default_factory=datetime.utcnow)\n>>> 127:     confidence_level: float = 0.85  # 85% confidence in estimates\n    128: \n    129:     def add_recommendation(self, category: str, description: str, potential_savings: Decimal = Decimal(0)):\n    130:         \"\"\"Add optimization recommendation.\"\"\"",
    "context": {
      "total_magic_literals": 178,
      "current_value": 0.85
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 147,
    "column": 25,
    "description": "Excessive magic literals detected (178 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    144:         # Regional cost multipliers (USD base pricing)\n    145:         self.region_multipliers = {\n    146:             \"us-east-1\": 1.0,  # AWS Virginia (baseline)\n>>> 147:             \"us-west-2\": 1.05,  # AWS Oregon\n    148:             \"eu-west-1\": 1.15,  # AWS Ireland\n    149:             \"ap-southeast-1\": 1.2,  # AWS Singapore\n    150:             \"ap-northeast-1\": 1.25,  # AWS Tokyo",
    "context": {
      "total_magic_literals": 178,
      "current_value": 1.05
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 148,
    "column": 25,
    "description": "Excessive magic literals detected (178 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    145:         self.region_multipliers = {\n    146:             \"us-east-1\": 1.0,  # AWS Virginia (baseline)\n    147:             \"us-west-2\": 1.05,  # AWS Oregon\n>>> 148:             \"eu-west-1\": 1.15,  # AWS Ireland\n    149:             \"ap-southeast-1\": 1.2,  # AWS Singapore\n    150:             \"ap-northeast-1\": 1.25,  # AWS Tokyo\n    151:         }",
    "context": {
      "total_magic_literals": 178,
      "current_value": 1.15
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\cloud_cost_analyzer.py",
    "line_number": 149,
    "column": 30,
    "description": "Excessive magic literals detected (178 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    146:             \"us-east-1\": 1.0,  # AWS Virginia (baseline)\n    147:             \"us-west-2\": 1.05,  # AWS Oregon\n    148:             \"eu-west-1\": 1.15,  # AWS Ireland\n>>> 149:             \"ap-southeast-1\": 1.2,  # AWS Singapore\n    150:             \"ap-northeast-1\": 1.25,  # AWS Tokyo\n    151:         }\n    152: ",
    "context": {
      "total_magic_literals": 178,
      "current_value": 1.2
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\continuous_deployment_automation.py",
    "line_number": 59,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     56: \n     57: @dataclass\n     58: class GitWorkflowResult:\n>>>  59:     \"\"\"Results from git workflow operations\"\"\"\n     60: \n     61:     staged_files: list[str]\n     62:     changed_files: list[str]",
    "context": {
      "query_preview": "Results from git workflow operations"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\continuous_deployment_automation.py",
    "line_number": 69,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     66: \n     67: \n     68: class ContinuousDeploymentAutomation:\n>>>  69:     \"\"\"Automated continuous deployment system for AIVillage\n     70: \n     71:     Handles complete deployment pipeline from git operations to production deployment\n     72:     with comprehensive error handling, rollback capabilities, and documentation sync.",
    "context": {
      "query_preview": "Automated continuous deployment system for AIVillage\n\n    Handles complete deployment pipeline from ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\continuous_deployment_automation.py",
    "line_number": 137,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    134:             return False\n    135: \n    136:     async def stage_and_commit_changes(self, commit_message: str) -> GitWorkflowResult:\n>>> 137:         \"\"\"Execute git workflow: stage changed files, list changes, update docs, commit\n    138: \n    139:         Args:\n    140:             commit_message: Commit message for the changes",
    "context": {
      "query_preview": "Execute git workflow: stage changed files, list changes, update docs, commit\n\n        Args:\n        ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\continuous_deployment_automation.py",
    "line_number": 252,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    249:         return True\n    250: \n    251:     async def _update_documentation(self) -> bool:\n>>> 252:         \"\"\"Update project documentation\"\"\"\n    253:         logger.info(\"Updating documentation...\")\n    254: \n    255:         try:",
    "context": {
      "query_preview": "Update project documentation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\continuous_deployment_automation.py",
    "line_number": 260,
    "column": 27,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    257:             await self._update_project_documentation()\n    258:             return True\n    259:         except Exception as e:\n>>> 260:             logger.error(f\"Documentation update failed: {e}\")\n    261:             return False\n    262: \n    263:     async def _deploy_to_environment(self) -> bool:",
    "context": {
      "query_preview": "Documentation update failed: "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\deployment\\continuous_deployment_automation.py",
    "line_number": 272,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    269:             try:\n    270:                 import sys\n    271: \n>>> 272:                 sys.path.insert(0, str(self.project_root))\n    273: \n    274:                 # Test core imports\n    275:                 logger.info(\"Core imports successful\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\continuous_deployment_automation.py",
    "line_number": 341,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    338:         return []\n    339: \n    340:     async def _update_project_documentation(self) -> bool:\n>>> 341:         \"\"\"Update TABLE_OF_CONTENTS.md and README.md\"\"\"\n    342:         logger.info(\"Updating project documentation...\")\n    343: \n    344:         try:",
    "context": {
      "query_preview": "Update TABLE_OF_CONTENTS.md and README.md"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\continuous_deployment_automation.py",
    "line_number": 414,
    "column": 28,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    411:                 with open(toc_path, \"w\", encoding=\"utf-8\") as f:\n    412:                     f.write(toc_content)\n    413: \n>>> 414:                 logger.info(\"Updated TABLE_OF_CONTENTS.md\")\n    415: \n    416:             # Update README with Global South achievement\n    417:             if readme_path.exists():",
    "context": {
      "query_preview": "Updated TABLE_OF_CONTENTS.md"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\deployment\\continuous_deployment_automation.py",
    "line_number": 440,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    437:                 # Insert at beginning after title\n    438:                 lines = readme_content.split(\"\\n\")\n    439:                 insert_pos = 2  # After title and first blank line\n>>> 440:                 lines.insert(insert_pos, achievement_update.strip())\n    441:                 readme_content = \"\\n\".join(lines)\n    442: \n    443:                 with open(readme_path, \"w\", encoding=\"utf-8\") as f:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\continuous_deployment_automation.py",
    "line_number": 451,
    "column": 27,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    448:             return True\n    449: \n    450:         except Exception as e:\n>>> 451:             logger.error(f\"Failed to update documentation: {e}\")\n    452:             return False\n    453: \n    454:     async def _commit_changes(self, message: str) -> str | None:",
    "context": {
      "query_preview": "Failed to update documentation: "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\deployment\\continuous_deployment_automation.py",
    "line_number": 491,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    488:         try:\n    489:             import sys\n    490: \n>>> 491:             sys.path.insert(0, str(self.project_root))\n    492: \n    493:             # Test key imports\n    494:             return True",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\continuous_deployment_automation.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (38 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 38,
      "methods": [
        "info",
        "warning",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\deployment\\continuous_deployment_automation.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (23 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 23,
      "methods": [
        "_run_command",
        "_get_changed_files_since_push",
        "_update_project_documentation",
        "_rollback_deployment",
        "_record_deployment_success",
        "_commit_changes",
        "_execute_stage",
        "_stage_changed_files"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\global_south\\mobile_optimization_bridge.py",
    "line_number": 69,
    "column": 4,
    "description": "Method 'detect_current_state' is too complex: 18 complexity, 95 lines, 14 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     66:     timestamp: datetime = field(default_factory=datetime.utcnow)\n     67: \n     68:     @classmethod\n>>>  69:     def detect_current_state(cls) -> \"MobileDeviceState\":\n     70:         \"\"\"Detect current mobile device state.\"\"\"\n     71:         try:\n     72:             # Battery detection",
    "context": {
      "complexity": 18,
      "lines": 95,
      "max_nesting": 14,
      "method_name": "detect_current_state"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\global_south\\mobile_optimization_bridge.py",
    "line_number": 182,
    "column": 4,
    "description": "Method 'for_device_state' is too complex: 9 complexity, 69 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    179:     cache_aggressive_eviction: bool = False\n    180: \n    181:     @classmethod\n>>> 182:     def for_device_state(cls, state: MobileDeviceState) -> \"OptimizationPolicy\":\n    183:         \"\"\"Create optimization policy based on device state.\"\"\"\n    184:         policy = cls()\n    185: ",
    "context": {
      "complexity": 9,
      "lines": 69,
      "max_nesting": 8,
      "method_name": "for_device_state"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\mobile_optimization_bridge.py",
    "line_number": 183,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    180: \n    181:     @classmethod\n    182:     def for_device_state(cls, state: MobileDeviceState) -> \"OptimizationPolicy\":\n>>> 183:         \"\"\"Create optimization policy based on device state.\"\"\"\n    184:         policy = cls()\n    185: \n    186:         # Battery-based optimizations",
    "context": {
      "query_preview": "Create optimization policy based on device state."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\mobile_optimization_bridge.py",
    "line_number": 342,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    339:                 await asyncio.sleep(self.monitoring_interval)\n    340: \n    341:     async def _update_device_state(self, state: MobileDeviceState) -> None:\n>>> 342:         \"\"\"Update device state and apply optimizations.\"\"\"\n    343:         previous_state = self.current_state\n    344:         self.current_state = state\n    345: ",
    "context": {
      "query_preview": "Update device state and apply optimizations."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\mobile_optimization_bridge.py",
    "line_number": 593,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    590: async def create_mobile_optimization_bridge(\n    591:     offline_coordinator=None, monitoring_interval: int = 30, start_monitoring: bool = True,\n    592: ) -> MobileOptimizationBridge:\n>>> 593:     \"\"\"Create and optionally start mobile optimization bridge.\"\"\"\n    594:     bridge = MobileOptimizationBridge(offline_coordinator=offline_coordinator, monitoring_interval=monitoring_interval)\n    595: \n    596:     if start_monitoring:",
    "context": {
      "query_preview": "Create and optionally start mobile optimization bridge."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\mobile_optimization_bridge.py",
    "line_number": 599,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    596:     if start_monitoring:\n    597:         await bridge.start_monitoring()\n    598: \n>>> 599:     logger.info(\"Mobile optimization bridge created and started\")\n    600:     return bridge\n    601: \n    602: ",
    "context": {
      "query_preview": "Mobile optimization bridge created and started"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\mobile_optimization_bridge.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (18 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 18,
      "methods": [
        "info",
        "warning",
        "error",
        "debug"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\mobile_optimization_bridge.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 8,
      "methods": [
        "_monitoring_loop",
        "_optimize_offline_coordinator_for_thermal",
        "_update_device_state",
        "_apply_optimizations",
        "_optimize_offline_coordinator_for_data_cost",
        "_optimize_offline_coordinator_for_background",
        "_optimize_offline_coordinator_for_battery"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\mobile_optimization_bridge.py",
    "line_number": 75,
    "column": 66,
    "description": "Excessive magic literals detected (61 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     72:             # Battery detection\n     73:             if hasattr(psutil, \"sensors_battery\"):\n     74:                 battery = psutil.sensors_battery()\n>>>  75:                 battery_percent = battery.percent if battery else 50.0\n     76:                 is_charging = battery.power_plugged if battery else False\n     77:             else:\n     78:                 battery_percent = 50.0  # Default assumption",
    "context": {
      "total_magic_literals": 61,
      "current_value": 50.0
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\mobile_optimization_bridge.py",
    "line_number": 78,
    "column": 34,
    "description": "Excessive magic literals detected (61 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     75:                 battery_percent = battery.percent if battery else 50.0\n     76:                 is_charging = battery.power_plugged if battery else False\n     77:             else:\n>>>  78:                 battery_percent = 50.0  # Default assumption\n     79:                 is_charging = False\n     80: \n     81:             # Determine battery status",
    "context": {
      "total_magic_literals": 61,
      "current_value": 50.0
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\mobile_optimization_bridge.py",
    "line_number": 84,
    "column": 35,
    "description": "Excessive magic literals detected (61 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     81:             # Determine battery status\n     82:             if battery_percent < 10:\n     83:                 battery_status = BatteryStatus.CRITICAL\n>>>  84:             elif battery_percent < 25:\n     85:                 battery_status = BatteryStatus.LOW\n     86:             elif battery_percent < 50:\n     87:                 battery_status = BatteryStatus.MODERATE",
    "context": {
      "total_magic_literals": 61,
      "current_value": 25
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\mobile_optimization_bridge.py",
    "line_number": 86,
    "column": 35,
    "description": "Excessive magic literals detected (61 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     83:                 battery_status = BatteryStatus.CRITICAL\n     84:             elif battery_percent < 25:\n     85:                 battery_status = BatteryStatus.LOW\n>>>  86:             elif battery_percent < 50:\n     87:                 battery_status = BatteryStatus.MODERATE\n     88:             elif battery_percent < 80:\n     89:                 battery_status = BatteryStatus.GOOD",
    "context": {
      "total_magic_literals": 61,
      "current_value": 50
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\mobile_optimization_bridge.py",
    "line_number": 88,
    "column": 35,
    "description": "Excessive magic literals detected (61 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     85:                 battery_status = BatteryStatus.LOW\n     86:             elif battery_percent < 50:\n     87:                 battery_status = BatteryStatus.MODERATE\n>>>  88:             elif battery_percent < 80:\n     89:                 battery_status = BatteryStatus.GOOD\n     90:             else:\n     91:                 battery_status = BatteryStatus.EXCELLENT",
    "context": {
      "total_magic_literals": 61,
      "current_value": 80
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 116,
    "column": 0,
    "description": "Class 'GlobalSouthOfflineCoordinator' is a God Object: 1 methods, ~764 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "    113:         return timedelta(seconds=seconds)\n    114: \n    115: \n>>> 116: class GlobalSouthOfflineCoordinator:\n    117:     \"\"\"Offline-first coordinator optimized for Global South scenarios.\n    118: \n    119:     Features:",
    "context": {
      "method_count": 1,
      "estimated_lines": 764,
      "class_name": "GlobalSouthOfflineCoordinator",
      "data_methods": 0,
      "business_methods": 1
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 617,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    614:         cache_file.unlink(missing_ok=True)\n    615: \n    616:     async def _remove_message(self, message_id: str) -> None:\n>>> 617:         \"\"\"Remove message from storage.\"\"\"\n    618:         if message_id not in self.message_index:\n    619:             return\n    620: ",
    "context": {
      "query_preview": "Remove message from storage."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 739,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    736:         return random.random() < success_rate\n    737: \n    738:     async def _receive_messages(self, window: ConnectivityWindow, max_bytes: int) -> list[dict[str, Any]]:\n>>> 739:         \"\"\"Receive new messages from remote sources.\"\"\"\n    740:         # This would integrate with actual message receiving systems\n    741:         # For now, return empty list\n    742:         return []",
    "context": {
      "query_preview": "Receive new messages from remote sources."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 745,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    742:         return []\n    743: \n    744:     async def _sync_cache_updates(self, window: ConnectivityWindow, max_bytes: int) -> int:\n>>> 745:         \"\"\"Sync cache updates from remote sources.\"\"\"\n    746:         # This would integrate with actual cache synchronization\n    747:         # For now, return 0 updates\n    748:         return 0",
    "context": {
      "query_preview": "Sync cache updates from remote sources."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 802,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    799:             json.dump(cache_data, f)\n    800: \n    801:     async def load_persisted_data(self) -> None:\n>>> 802:         \"\"\"Load persisted messages and cache from disk.\"\"\"\n    803:         logger.info(\"Loading persisted offline data...\")\n    804: \n    805:         # Load messages",
    "context": {
      "query_preview": "Load persisted messages and cache from disk."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 836,
    "column": 35,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    833:                     self.message_index[message.message_id] = message\n    834: \n    835:                 except Exception as e:\n>>> 836:                     logger.error(f\"Failed to load message from {message_file}: {e}\")\n    837:                     message_file.unlink(missing_ok=True)\n    838: \n    839:         # Load cache",
    "context": {
      "query_preview": "Failed to load message from "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 869,
    "column": 35,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    866:                     self.cache_lru_order.append(entry.key)\n    867: \n    868:                 except Exception as e:\n>>> 869:                     logger.error(f\"Failed to load cache from {cache_file}: {e}\")\n    870:                     cache_file.unlink(missing_ok=True)\n    871: \n    872:         # Update storage usage",
    "context": {
      "query_preview": "Failed to load cache from "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 886,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    883: async def create_offline_coordinator(\n    884:     storage_path: Path = None, max_storage_mb: int = 500, daily_data_budget_usd: float = 0.50,\n    885: ) -> GlobalSouthOfflineCoordinator:\n>>> 886:     \"\"\"Create and initialize offline coordinator.\"\"\"\n    887:     coordinator = GlobalSouthOfflineCoordinator(\n    888:         storage_path=storage_path, max_storage_mb=max_storage_mb, daily_data_budget_usd=daily_data_budget_usd,\n    889:     )",
    "context": {
      "query_preview": "Create and initialize offline coordinator."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (15 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 15,
      "methods": [
        "utcnow",
        "fromisoformat"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (29 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 29,
      "methods": [
        "_ensure_storage_capacity",
        "store_message",
        "_compress_data",
        "_sync_with_mesh_peers",
        "_check_budget_reset",
        "_remove_cache_entry",
        "_persist_cache_entry",
        "_remove_message",
        "_check_connectivity",
        "_sync_cache_updates",
        "_cleanup_expired_messages",
        "_persist_message",
        "_receive_messages",
        "_deliver_message",
        "_evict_cache_entry",
        "_cleanup_expired_cache",
        "is_expired",
        "_estimate_bandwidth",
        "_decompress_data",
        "_get_data_cost"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (25 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 25,
      "methods": [
        "info",
        "warning",
        "error",
        "debug"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'coordinator' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "coordinator",
      "method_count": 6,
      "methods": [
        "cache_data",
        "store_message",
        "get_storage_status",
        "load_persisted_data",
        "detect_connectivity_window",
        "sync_when_connected"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 52,
    "column": 24,
    "description": "Excessive magic literals detected (47 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     49:     timestamp: datetime\n     50:     expiry: datetime | None = None\n     51:     delivery_attempts: int = 0\n>>>  52:     max_attempts: int = 5\n     53: \n     54:     def is_expired(self) -> bool:\n     55:         \"\"\"Check if message has expired.\"\"\"",
    "context": {
      "total_magic_literals": 47,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 72,
    "column": 21,
    "description": "Excessive magic literals detected (47 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     69:     timestamp: datetime\n     70:     priority: SyncPriority\n     71:     size_bytes: int\n>>>  72:     ttl_hours: int = 24\n     73:     access_count: int = 0\n     74:     last_accessed: datetime | None = None\n     75: ",
    "context": {
      "total_magic_literals": 47,
      "current_value": 24
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 100,
    "column": 25,
    "description": "Excessive magic literals detected (47 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     97:     def bytes_affordable(self, budget_usd: float) -> int:\n     98:         \"\"\"Calculate how many bytes can be transferred within budget.\"\"\"\n     99:         if self.data_cost_per_mb <= 0:\n>>> 100:             return 100 * 1024 * 1024  # 100MB if free\n    101: \n    102:         affordable_mb = budget_usd / self.data_cost_per_mb\n    103:         return int(affordable_mb * 1024 * 1024)",
    "context": {
      "total_magic_literals": 47,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 100,
    "column": 32,
    "description": "Excessive magic literals detected (47 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     97:     def bytes_affordable(self, budget_usd: float) -> int:\n     98:         \"\"\"Calculate how many bytes can be transferred within budget.\"\"\"\n     99:         if self.data_cost_per_mb <= 0:\n>>> 100:             return 100 * 1024 * 1024  # 100MB if free\n    101: \n    102:         affordable_mb = budget_usd / self.data_cost_per_mb\n    103:         return int(affordable_mb * 1024 * 1024)",
    "context": {
      "total_magic_literals": 47,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\offline_coordinator.py",
    "line_number": 103,
    "column": 35,
    "description": "Excessive magic literals detected (47 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    100:             return 100 * 1024 * 1024  # 100MB if free\n    101: \n    102:         affordable_mb = budget_usd / self.data_cost_per_mb\n>>> 103:         return int(affordable_mb * 1024 * 1024)\n    104: \n    105:     def estimated_transfer_time(self, size_bytes: int) -> timedelta:\n    106:         \"\"\"Estimate transfer time for given data size.\"\"\"",
    "context": {
      "total_magic_literals": 47,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 97,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     94:             self.capabilities = set(self.capabilities)\n     95: \n     96:     def update_last_seen(self):\n>>>  97:         \"\"\"Update last seen timestamp.\"\"\"\n     98:         self.last_seen = datetime.utcnow()\n     99:         self.is_online = True\n    100: ",
    "context": {
      "query_preview": "Update last seen timestamp."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 143,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    140: \n    141:     @classmethod\n    142:     def from_bytes(cls, data: bytes) -> \"MeshMessage\":\n>>> 143:         \"\"\"Deserialize message from bytes.\"\"\"\n    144:         if len(data) < 4:\n    145:             raise ValueError(\"Invalid message data\")\n    146: ",
    "context": {
      "query_preview": "Deserialize message from bytes."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 169,
    "column": 0,
    "description": "Class 'P2PMeshIntegration' is a God Object: 7 methods, ~545 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "    166:         )\n    167: \n    168: \n>>> 169: class P2PMeshIntegration:\n    170:     \"\"\"P2P mesh integration for offline-first Global South scenarios.\n    171: \n    172:     Integrates with existing AIVillage P2P infrastructure to provide Global South",
    "context": {
      "method_count": 7,
      "estimated_lines": 545,
      "class_name": "P2PMeshIntegration",
      "data_methods": 3,
      "business_methods": 4
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 177,
    "column": 4,
    "description": "Method '__init__' is too complex: 3 complexity, 101 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    174:     and collaborative caching using BitChat and BetaNet transports.\n    175:     \"\"\"\n    176: \n>>> 177:     def __init__(\n    178:         self,\n    179:         device_id: str = None,\n    180:         peer_type: PeerType = PeerType.MOBILE,",
    "context": {
      "complexity": 3,
      "lines": 101,
      "max_nesting": 1,
      "method_name": "__init__"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 370,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    367:             return False\n    368: \n    369:     async def _handle_unified_message(self, message: UnifiedMessage, transport_type: TransportType):\n>>> 370:         \"\"\"Handle incoming unified messages from the transport manager.\"\"\"\n    371:         try:\n    372:             # Update statistics\n    373:             self.stats[\"messages_received\"] += 1",
    "context": {
      "query_preview": "Handle incoming unified messages from the transport manager."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 483,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    480:             logger.error(f\"Error syncing with offline coordinator: {e}\")\n    481: \n    482:     async def _update_peer_status(self):\n>>> 483:         \"\"\"Update peer status from BitChat transport.\"\"\"\n    484:         if not self.bitchat_transport:\n    485:             return\n    486: ",
    "context": {
      "query_preview": "Update peer status from BitChat transport."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 514,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    511:             logger.error(f\"Error updating peer status: {e}\")\n    512: \n    513:     async def request_content(self, content_key: str, timeout_seconds: int = 30) -> bytes | None:\n>>> 514:         \"\"\"Request content from mesh network using existing transport system.\"\"\"\n    515:         # Check local cache first\n    516:         if content_key in self.local_cache:\n    517:             content_data, _, access_count = self.local_cache[content_key]",
    "context": {
      "query_preview": "Request content from mesh network using existing transport system."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 618,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    615:         # Add transport manager stats if available\n    616:         if self.transport_manager:\n    617:             transport_stats = self.transport_manager.get_status().get(\"statistics\", {})\n>>> 618:             base_stats.update({f\"transport_{k}\": v for k, v in transport_stats.items()})\n    619: \n    620:         return {\n    621:             **base_stats,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 633,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    630: \n    631:     # Message handlers for Global South specific message types\n    632:     async def _handle_ping_message(self, message: UnifiedMessage, transport_type: TransportType):\n>>> 633:         \"\"\"Handle ping messages from peers.\"\"\"\n    634:         logger.debug(f\"Received ping from {message.metadata.sender_id} via {transport_type.value}\")\n    635: \n    636:         # Update peer information if available",
    "context": {
      "query_preview": "Handle ping messages from peers."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 654,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    651:             self.stats[\"peers_discovered\"] += 1\n    652: \n    653:     async def _handle_data_message(self, message: UnifiedMessage, transport_type: TransportType):\n>>> 654:         \"\"\"Handle data messages from peers.\"\"\"\n    655:         logger.debug(f\"Received data message ({len(message.payload)} bytes) from {message.metadata.sender_id}\")\n    656: \n    657:         # Try to parse as content request",
    "context": {
      "query_preview": "Handle data messages from peers."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 676,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    673:             )\n    674: \n    675:     async def _handle_content_request_data(self, request_data: dict[str, Any], sender_id: str):\n>>> 676:         \"\"\"Handle content request from peer.\"\"\"\n    677:         content_key = request_data.get(\"key\")\n    678:         if not content_key:\n    679:             return",
    "context": {
      "query_preview": "Handle content request from peer."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 725,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    722:     transport_priority: TransportPriority = TransportPriority.OFFLINE_FIRST,\n    723:     start_immediately: bool = True,\n    724: ) -> P2PMeshIntegration:\n>>> 725:     \"\"\"Create P2P mesh integration for Global South scenarios.\n    726: \n    727:     This factory function creates a P2P mesh integration that leverages the existing\n    728:     AIVillage transport infrastructure (TransportManager, BitChat, etc.) to provide",
    "context": {
      "query_preview": "Create P2P mesh integration for Global South scenarios.\n\n    This factory function creates a P2P mes..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 744,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    741:             logger.error(\"Failed to start P2P mesh integration\")\n    742:             return None\n    743: \n>>> 744:     logger.info(\"P2P mesh integration created for Global South scenarios\")\n    745:     return mesh_integration\n    746: \n    747: ",
    "context": {
      "query_preview": "P2P mesh integration created for Global South scenarios"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 781,
    "column": 18,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    778:             finally:\n    779:                 await mesh.stop()\n    780:         else:\n>>> 781:             print(\"Failed to create mesh integration\")\n    782: \n    783:     asyncio.run(main())",
    "context": {
      "query_preview": "Failed to create mesh integration"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 570,
    "column": 4,
    "description": "Duplicate code block detected in function 'get_status'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    567:         if expired_keys:\n    568:             logger.debug(f\"Cleaned up {len(expired_keys)} cache entries\")\n    569: \n>>> 570:     def get_status(self) -> dict[str, Any]:\n    571:         \"\"\"Get comprehensive status of P2P mesh integration.\"\"\"\n    572:         transport_status = {}\n    573:         if self.transport_manager:",
    "context": {
      "duplicate_count": 2,
      "function_name": "get_status",
      "signature": "ASSIGN|IF|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 611,
    "column": 4,
    "description": "Duplicate code block detected in function 'get_network_stats'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    608:             \"total_peers\": len(self.peers),\n    609:         }\n    610: \n>>> 611:     def get_network_stats(self) -> dict[str, Any]:\n    612:         \"\"\"Get comprehensive network statistics.\"\"\"\n    613:         base_stats = self.stats.copy()\n    614: ",
    "context": {
      "duplicate_count": 2,
      "function_name": "get_network_stats",
      "signature": "ASSIGN|IF|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 9,
      "methods": [
        "utcnow",
        "fromisoformat"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (13 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 13,
      "methods": [
        "_cache_cleanup_loop",
        "send_message",
        "_cleanup_cache",
        "_update_peer_status",
        "_handle_ping_message",
        "_handle_content_request_data",
        "_sync_loop",
        "_configure_global_south_context",
        "_sync_with_offline_coordinator",
        "_handle_data_message",
        "_generate_device_id",
        "_register_mesh_handlers"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (30 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 30,
      "methods": [
        "info",
        "warning",
        "error",
        "debug"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'asyncio' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "asyncio",
      "method_count": 9,
      "methods": [
        "sleep",
        "create_task",
        "run"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 90,
    "column": 31,
    "description": "Excessive magic literals detected (34 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     87:     battery_level: float | None = None\n     88:     storage_available_mb: float | None = None\n     89:     bandwidth_estimate_mbps: float | None = None\n>>>  90:     reliability_score: float = 0.5  # 0.0-1.0\n     91: \n     92:     def __post_init__(self):\n     93:         if isinstance(self.capabilities, list):",
    "context": {
      "total_magic_literals": 34,
      "current_value": 0.5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 101,
    "column": 46,
    "description": "Excessive magic literals detected (34 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     98:         self.last_seen = datetime.utcnow()\n     99:         self.is_online = True\n    100: \n>>> 101:     def is_stale(self, timeout_seconds: int = 300) -> bool:\n    102:         \"\"\"Check if peer information is stale.\"\"\"\n    103:         return (datetime.utcnow() - self.last_seen).total_seconds() > timeout_seconds\n    104: ",
    "context": {
      "total_magic_literals": 34,
      "current_value": 300
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 117,
    "column": 20,
    "description": "Excessive magic literals detected (34 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    114:     content: bytes\n    115:     timestamp: datetime\n    116:     ttl: int = 10  # Time to live (hop count)\n>>> 117:     priority: int = 5  # 1-10, higher = more important\n    118:     compression_used: bool = False\n    119:     signature: bytes | None = None\n    120: ",
    "context": {
      "total_magic_literals": 34,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 144,
    "column": 23,
    "description": "Excessive magic literals detected (34 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    141:     @classmethod\n    142:     def from_bytes(cls, data: bytes) -> \"MeshMessage\":\n    143:         \"\"\"Deserialize message from bytes.\"\"\"\n>>> 144:         if len(data) < 4:\n    145:             raise ValueError(\"Invalid message data\")\n    146: \n    147:         header_length = struct.unpack(\"!I\", data[:4])[0]",
    "context": {
      "total_magic_literals": 34,
      "current_value": 4
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\p2p_mesh_integration.py",
    "line_number": 147,
    "column": 50,
    "description": "Excessive magic literals detected (34 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    144:         if len(data) < 4:\n    145:             raise ValueError(\"Invalid message data\")\n    146: \n>>> 147:         header_length = struct.unpack(\"!I\", data[:4])[0]\n    148:         if len(data) < 4 + header_length:\n    149:             raise ValueError(\"Incomplete message data\")\n    150: ",
    "context": {
      "total_magic_literals": 34,
      "current_value": 4
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\global_south\\test_p2p_integration.py",
    "line_number": 14,
    "column": 0,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     11: import sys\n     12: \n     13: # Add the packages directory to the Python path\n>>>  14: sys.path.insert(0, str(Path(__file__).parent.parent.parent))\n     15: \n     16: try:\n     17:     from packages.core.global_south.offline_coordinator import GlobalSouthOfflineCoordinator",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\test_p2p_integration.py",
    "line_number": 42,
    "column": 14,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     39:             device_id=\"test-device-001\", data_budget_mb=10, storage_path=\"./test_storage\",  # Small budget for testing\n     40:         )\n     41:         await offline_coordinator.start()\n>>>  42:         print(\"\u2713 Offline coordinator created and started\")\n     43: \n     44:         # Test 2: Create P2P mesh integration\n     45:         print(\"\\n2. Creating P2P mesh integration...\")",
    "context": {
      "query_preview": "\u2713 Offline coordinator created and started"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\test_p2p_integration.py",
    "line_number": 55,
    "column": 18,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     52:         )\n     53: \n     54:         if mesh:\n>>>  55:             print(\"\u2713 P2P mesh integration created successfully\")\n     56: \n     57:             # Test 3: Check status\n     58:             print(\"\\n3. Checking integration status...\")",
    "context": {
      "query_preview": "\u2713 P2P mesh integration created successfully"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\test_p2p_integration.py",
    "line_number": 111,
    "column": 18,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    108:             print(\"\u2713 All systems stopped\")\n    109: \n    110:         else:\n>>> 111:             print(\"\u2717 Failed to create P2P mesh integration\")\n    112:             return False\n    113: \n    114:         print(\"\\n\" + \"=\" * 60)",
    "context": {
      "query_preview": "\u2717 Failed to create P2P mesh integration"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\test_p2p_integration.py",
    "line_number": 182,
    "column": 10,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    179: \n    180: except ImportError as e:\n    181:     print(f\"\u274c Import error: {e}\")\n>>> 182:     print(\"Make sure you're running this from the AIVillage root directory\")\n    183:     print(\"and all required packages are available.\")",
    "context": {
      "query_preview": "Make sure you're running this from the AIVillage root directory"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\global_south\\test_p2p_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'mesh' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "mesh",
      "method_count": 8,
      "methods": [
        "request_content",
        "send_message",
        "stop",
        "start",
        "get_network_stats",
        "get_status"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\jobs\\hyperag_scan_hidden_links.py",
    "line_number": 171,
    "column": 27,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    168:         Returns:\n    169:             List of high co-mention entity pairs\n    170:         \"\"\"\n>>> 171:         self.logger.info(f\"Analyzing Hippo-Index logs from {self.log_path}\")\n    172: \n    173:         cutoff_time = datetime.now() - timedelta(hours=self.lookback_hours)\n    174:         co_mention_counts = defaultdict(int)",
    "context": {
      "query_preview": "Analyzing Hippo-Index logs from "
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\jobs\\hyperag_scan_hidden_links.py",
    "line_number": 228,
    "column": 4,
    "description": "Method '_process_log_file' is too complex: 10 complexity, 50 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    225: \n    226:         return sorted(log_files, key=lambda f: f.stat().st_mtime, reverse=True)\n    227: \n>>> 228:     def _process_log_file(\n    229:         self,\n    230:         log_file: Path,\n    231:         co_mention_counts: dict,",
    "context": {
      "complexity": 10,
      "lines": 50,
      "max_nesting": 8,
      "method_name": "_process_log_file"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\jobs\\hyperag_scan_hidden_links.py",
    "line_number": 530,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    527:         self.logger.info(summary)\n    528: \n    529:     async def _create_mock_proposal(self, candidate: CandidateEdge):\n>>> 530:         \"\"\"Create mock repair proposal from candidate edge.\"\"\"\n    531:         # Mock implementation - would create actual RepairOperation in production\n    532:         return {\n    533:             \"operation_type\": \"add_edge\",",
    "context": {
      "query_preview": "Create mock repair proposal from candidate edge."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\jobs\\hyperag_scan_hidden_links.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logging' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logging",
      "method_count": 6,
      "methods": [
        "getLogger",
        "StreamHandler",
        "FileHandler",
        "basicConfig"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\jobs\\hyperag_scan_hidden_links.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 10,
      "methods": [
        "now",
        "fromtimestamp"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\jobs\\hyperag_scan_hidden_links.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 10,
      "methods": [
        "_step2_divergent_scan",
        "_mock_divergent_retrieval",
        "_log_summary",
        "_step1_analyze_logs",
        "_find_recent_log_files",
        "_step4_generate_metrics",
        "_evaluate_with_guardian",
        "_create_mock_proposal",
        "_step3_pipeline_processing",
        "_process_log_file"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\jobs\\hyperag_scan_hidden_links.py",
    "line_number": 147,
    "column": 61,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    144: class HippoIndexAnalyzer:\n    145:     \"\"\"Analyzes Hippo-Index logs for high co-mention entity pairs.\"\"\"\n    146: \n>>> 147:     def __init__(self, log_path: Path, lookback_hours: int = 24) -> None:\n    148:         \"\"\"Initialize analyzer.\n    149: \n    150:         Args:",
    "context": {
      "total_magic_literals": 21,
      "current_value": 24
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\jobs\\hyperag_scan_hidden_links.py",
    "line_number": 162,
    "column": 50,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    159:         self.entity_pattern = re.compile(r\"\\[ENTITY:([^\\]]+)\\]\")\n    160:         self.co_mention_pattern = re.compile(r\"\\[COMENTION:([^\\]]+)\\|([^\\]]+)\\]\")\n    161: \n>>> 162:     def analyze_logs(self, min_co_mentions: int = 3) -> list[CoMentionPair]:\n    163:         \"\"\"Analyze Hippo-Index logs for entity co-mentions.\n    164: \n    165:         Args:",
    "context": {
      "total_magic_literals": 21,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\jobs\\hyperag_scan_hidden_links.py",
    "line_number": 200,
    "column": 54,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    197:                     entity2=entity2,\n    198:                     co_mention_count=count,\n    199:                     confidence=confidence,\n>>> 200:                     contexts=pair_contexts[pair_key][:5],  # Keep top 5 contexts\n    201:                     last_seen=pair_last_seen.get(pair_key, datetime.now()),\n    202:                 )\n    203:                 pairs.append(pair)",
    "context": {
      "total_magic_literals": 21,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\jobs\\hyperag_scan_hidden_links.py",
    "line_number": 253,
    "column": 48,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    250:                         co_mention_counts[pair_key] += 1\n    251: \n    252:                         # Extract context (surrounding text)\n>>> 253:                         context = line.strip()[:200]  # First 200 chars as context\n    254:                         if context not in pair_contexts[pair_key]:\n    255:                             pair_contexts[pair_key].append(context)\n    256: ",
    "context": {
      "total_magic_literals": 21,
      "current_value": 200
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\jobs\\hyperag_scan_hidden_links.py",
    "line_number": 269,
    "column": 63,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    266:                                 entity1, entity2 = sorted([entities[i].strip(), entities[j].strip()])\n    267:                                 pair_key = f\"{entity1}|{entity2}\"\n    268: \n>>> 269:                                 co_mention_counts[pair_key] += 0.5  # Lower weight for implicit co-mention\n    270: \n    271:                                 context = line.strip()[:200]\n    272:                                 if context not in pair_contexts[pair_key]:",
    "context": {
      "total_magic_literals": 21,
      "current_value": 0.5
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\jobs\\test_scanner.py",
    "line_number": 22,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     19: \n     20: \n     21: def create_mock_hippo_logs(log_dir: Path) -> None:\n>>>  22:     \"\"\"Create mock Hippo-Index log files for testing.\"\"\"\n     23:     log_dir.mkdir(parents=True, exist_ok=True)\n     24: \n     25:     # Create mock log file with co-mentions",
    "context": {
      "query_preview": "Create mock Hippo-Index log files for testing."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\jobs\\test_scanner.py",
    "line_number": 33,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     30:         \"2025-07-23T01:16:00Z [COMENTION:aspirin|headache] found in medical query\",\n     31:         \"2025-07-23T01:17:00Z Patient reported [ENTITY:aspirin] allergy, also has [ENTITY:headache]\",\n     32:         \"2025-07-23T01:18:00Z [COMENTION:aspirin|headache] [COMENTION:headache|treatment]\",\n>>>  33:         \"2025-07-23T01:19:00Z [ENTITY:ibuprofen] alternative to [ENTITY:aspirin] for [ENTITY:headache]\",\n     34:         \"2025-07-23T01:20:00Z [COMENTION:ibuprofen|headache] recommended by doctor\",\n     35:         \"2025-07-23T01:21:00Z Multiple mentions: [ENTITY:aspirin] [ENTITY:ibuprofen] [ENTITY:headache]\",\n     36:     ]",
    "context": {
      "query_preview": "2025-07-23T01:19:00Z [ENTITY:ibuprofen] alternative to [ENTITY:aspirin] for [ENTITY:headache]"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\jobs\\test_scanner.py",
    "line_number": 41,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     38:     with open(log_file, \"w\") as f:\n     39:         f.writelines(entry + \"\\n\" for entry in mock_entries)\n     40: \n>>>  41:     print(f\"Created mock log file: {log_file}\")\n     42: \n     43: \n     44: async def test_hippo_analyzer() -> None:",
    "context": {
      "query_preview": "Created mock log file: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\jobs\\__init__.py",
    "line_number": 1,
    "column": 0,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": ">>>   1: \"\"\"Auto-generated __init__.py for proper module imports.\n      2: Created by test infrastructure repair script.\n      3: \"\"\"",
    "context": {
      "query_preview": "Auto-generated __init__.py for proper module imports.\nCreated by test infrastructure repair script.\n"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\chat_engine.py",
    "line_number": 28,
    "column": 33,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "     25: logger = logging.getLogger(__name__)\n     26: logger.setLevel(logging.INFO)\n     27: \n>>>  28: TWIN_URL = os.getenv(\"TWIN_URL\", \"https://twin:8001/v1/chat\")\n     29: CALIB_ENABLED = os.getenv(\"CALIBRATION_ENABLED\", \"0\") == \"1\"\n     30: \n     31: if CALIB_ENABLED:",
    "context": {
      "hardcoded_value": "https://twin:8001/v1/chat"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\chat_engine.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 6,
      "methods": [
        "setLevel",
        "warning",
        "info",
        "exception"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\cli.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'parser' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "parser",
      "method_count": 9,
      "methods": [
        "parse_args",
        "add_argument",
        "print_help",
        "add_subparsers"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\communication.py",
    "line_number": 68,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     65: \n     66:     @classmethod\n     67:     def from_dict(cls, data: dict[str, Any]) -> \"AgentMessage\":\n>>>  68:         \"\"\"Create message from dictionary format.\"\"\"\n     69:         return cls(\n     70:             type=AgentMessageType(data[\"type\"]),\n     71:             sender=data[\"sender\"],",
    "context": {
      "query_preview": "Create message from dictionary format."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\communication.py",
    "line_number": 134,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    131:         self.subscribers[agent_name] = handler\n    132: \n    133:     def unsubscribe(self, agent_name: str) -> None:\n>>> 134:         \"\"\"Unsubscribe an agent from receiving messages.\n    135: \n    136:         Args:\n    137:             agent_name: Name of the agent to unsubscribe",
    "context": {
      "query_preview": "Unsubscribe an agent from receiving messages.\n\n        Args:\n            agent_name: Name of the age..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\communication.py",
    "line_number": 155,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    152:             await handler(message)\n    153: \n    154:     async def broadcast(self, message: AgentMessage, exclude: list[str] | None = None) -> None:\n>>> 155:         \"\"\"Broadcast a message to all subscribed agents.\n    156: \n    157:         Args:\n    158:             message: The message to broadcast",
    "context": {
      "query_preview": "Broadcast a message to all subscribed agents.\n\n        Args:\n            message: The message to bro..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\communication.py",
    "line_number": 178,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    175:                 await handler(broadcast_message)\n    176: \n    177:     async def query(self, sender: str, receiver: str, content: Any) -> Any:\n>>> 178:         \"\"\"Send a query and wait for response.\n    179: \n    180:         Args:\n    181:             sender: Name of the sending agent",
    "context": {
      "query_preview": "Send a query and wait for response.\n\n        Args:\n            sender: Name of the sending agent\n   ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\config_manager.py",
    "line_number": 49,
    "column": 4,
    "description": "Method '__init__' is too complex: 2 complexity, 71 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     46: class CODEXConfigManager:\n     47:     \"\"\"Comprehensive configuration manager for CODEX integration.\"\"\"\n     48: \n>>>  49:     def __init__(self, config_dir: str = \"config\", enable_hot_reload: bool = True) -> None:\n     50:         self.config_dir = Path(config_dir)\n     51:         self.enable_hot_reload = enable_hot_reload\n     52:         self.config_data = {}",
    "context": {
      "complexity": 2,
      "lines": 71,
      "max_nesting": 1,
      "method_name": "__init__"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\config_manager.py",
    "line_number": 187,
    "column": 4,
    "description": "Method 'apply_environment_overrides' is too complex: 10 complexity, 38 lines, 9 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    184: \n    185:         current[keys[-1]] = value\n    186: \n>>> 187:     def apply_environment_overrides(self, config: dict[str, Any]) -> dict[str, Any]:\n    188:         \"\"\"Apply environment variable overrides to configuration.\"\"\"\n    189:         config_copy = copy.deepcopy(config)\n    190: ",
    "context": {
      "complexity": 10,
      "lines": 38,
      "max_nesting": 9,
      "method_name": "apply_environment_overrides"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\config_manager.py",
    "line_number": 276,
    "column": 4,
    "description": "Method 'validate_configuration' is too complex: 24 complexity, 86 lines, 20 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    273:                 msg = f\"Configuration reload failed: {e}\"\n    274:                 raise ConfigurationError(msg)\n    275: \n>>> 276:     def validate_configuration(self, config: dict[str, Any]) -> None:\n    277:         \"\"\"Validate configuration consistency and requirements.\"\"\"\n    278:         errors = []\n    279:         warnings = []",
    "context": {
      "complexity": 24,
      "lines": 86,
      "max_nesting": 20,
      "method_name": "validate_configuration"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config_manager.py",
    "line_number": 327,
    "column": 49,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    324:             # Check required P2P settings match CODEX requirements\n    325:             expected_port = 4001\n    326:             if port != expected_port:\n>>> 327:                 warnings.append(f\"P2P port {port} differs from CODEX requirement: {expected_port}\")\n    328: \n    329:         # Digital twin validation\n    330:         if integration.get(\"digital_twin\", {}).get(\"enabled\"):",
    "context": {
      "query_preview": " differs from CODEX requirement: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config_manager.py",
    "line_number": 453,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    450: \n    451: \n    452: def get_config_manager(**kwargs) -> CODEXConfigManager:\n>>> 453:     \"\"\"Get or create the global configuration manager.\"\"\"\n    454:     global _config_manager\n    455: \n    456:     if _config_manager is None:",
    "context": {
      "query_preview": "Get or create the global configuration manager."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config_manager.py",
    "line_number": 473,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    470: \n    471: \n    472: def get_config(key_path: str, default=None):\n>>> 473:     \"\"\"Get configuration value from global config manager.\"\"\"\n    474:     return get_config_manager().get(key_path, default)\n    475: \n    476: ",
    "context": {
      "query_preview": "Get configuration value from global config manager."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (17 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 17,
      "methods": [
        "info",
        "exception",
        "warning",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (14 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 14,
      "methods": [
        "validate_configuration",
        "set_nested_value",
        "reload_config",
        "apply_environment_overrides",
        "get",
        "get_config_sources",
        "stop_file_watcher",
        "start_file_watcher",
        "load_yaml_file",
        "get_nested_value",
        "load_json_file",
        "get_all"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'errors' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "errors",
      "method_count": 7,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\error_handling.py",
    "line_number": 116,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    113: \n    114:     @classmethod\n    115:     def from_dict(cls, data: dict[str, Any]) -> \"Message\":\n>>> 116:         \"\"\"Create message from dictionary format.\"\"\"\n    117:         return cls(\n    118:             type=MessageType(data[\"type\"]),\n    119:             content=data[\"content\"],",
    "context": {
      "query_preview": "Create message from dictionary format."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\error_handling.py",
    "line_number": 131,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    128: \n    129: \n    130: class StandardCommunicationProtocol:\n>>> 131:     \"\"\"Standard protocol for communication between components.\n    132: \n    133:     This class extends the full implementation from :mod:`src.communications` and\n    134:     adds convenience helpers for creating structured messages.",
    "context": {
      "query_preview": "Standard protocol for communication between components.\n\n    This class extends the full implementat..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\error_handling.py",
    "line_number": 149,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    146:         recipient: str,\n    147:         metadata: dict[str, Any] | None = None,\n    148:     ) -> Message:\n>>> 149:         \"\"\"Create a request message.\"\"\"\n    150:         return Message(\n    151:             type=MessageType.REQUEST,\n    152:             content=content,",
    "context": {
      "query_preview": "Create a request message."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\error_handling.py",
    "line_number": 165,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    162:         recipient: str,\n    163:         metadata: dict[str, Any] | None = None,\n    164:     ) -> Message:\n>>> 165:         \"\"\"Create a response message.\"\"\"\n    166:         return Message(\n    167:             type=MessageType.RESPONSE,\n    168:             content=content,",
    "context": {
      "query_preview": "Create a response message."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\error_handling.py",
    "line_number": 176,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    173: \n    174:     @staticmethod\n    175:     def create_error(error: str, sender: str, recipient: str, metadata: dict[str, Any] | None = None) -> Message:\n>>> 176:         \"\"\"Create an error message.\"\"\"\n    177:         return Message(\n    178:             type=MessageType.ERROR,\n    179:             content={\"error\": error},",
    "context": {
      "query_preview": "Create an error message."
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\error_handling.py",
    "line_number": 258,
    "column": 4,
    "description": "Function '__init__' has 6 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    255: class AIVillageException(Exception):\n    256:     \"\"\"Base exception class for AIVillage with structured error information.\"\"\"\n    257: \n>>> 258:     def __init__(\n    259:         self,\n    260:         message: str,\n    261:         category: ErrorCategory = ErrorCategory.UNKNOWN,",
    "context": {
      "parameter_count": 6,
      "function_name": "__init__"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\error_handling.py",
    "line_number": 373,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    370: \n    371: \n    372: def migrate_from_legacy_exception(legacy_exception: Exception) -> AIVillageException:\n>>> 373:     \"\"\"Migrate from legacy exception to new AIVillageException.\"\"\"\n    374:     if isinstance(legacy_exception, AIVillageException):\n    375:         return legacy_exception\n    376: ",
    "context": {
      "query_preview": "Migrate from legacy exception to new AIVillageException."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\error_handling.py",
    "line_number": 389,
    "column": 0,
    "description": "Method 'safe_execute' is too complex: 9 complexity, 67 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    386: F = TypeVar(\"F\", bound=Callable[..., Any])\n    387: \n    388: \n>>> 389: def safe_execute(\n    390:     func: Callable[..., T] | None = None,\n    391:     *,\n    392:     component: str = \"unknown\",",
    "context": {
      "complexity": 9,
      "lines": 67,
      "max_nesting": 5,
      "method_name": "safe_execute"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\error_handling.py",
    "line_number": 459,
    "column": 0,
    "description": "Method 'with_error_handling' is too complex: 9 complexity, 80 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    456:         return fallback\n    457: \n    458: \n>>> 459: def with_error_handling(*args, **kwargs) -> Callable[[F], F]:\n    460:     \"\"\"Decorator for adding error handling to functions.\n    461: \n    462:     Usage patterns:",
    "context": {
      "complexity": 9,
      "lines": 80,
      "max_nesting": 5,
      "method_name": "with_error_handling"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\error_handling.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 6,
      "methods": [
        "now"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\error_handling.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'asyncio' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "asyncio",
      "method_count": 6,
      "methods": [
        "sleep",
        "PriorityQueue",
        "iscoroutinefunction",
        "wait_for"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\error_handling.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'kwargs' methods (12 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "kwargs",
      "method_count": 12,
      "methods": [
        "pop"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evidence.py",
    "line_number": 55,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     52: \n     53:     @classmethod\n     54:     def from_json(cls, s: str) -> EvidencePack:\n>>>  55:         \"\"\"Deserialize pack from JSON.\"\"\"\n     56:         return cls.model_validate_json(s)",
    "context": {
      "query_preview": "Deserialize pack from JSON."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 17,
    "column": 0,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     14: import sys\n     15: \n     16: # Add parent to path\n>>>  17: sys.path.insert(0, str(Path(__file__).parent.parent))\n     18: \n     19: # Try to import the integrated metrics module\n     20: try:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 84,
    "column": 4,
    "description": "Method 'get_health_status' is too complex: 5 complexity, 56 lines, 3 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     81:         else:\n     82:             self.send_error(404, f\"Agent {agent_id} not found\")\n     83: \n>>>  84:     def get_health_status(self):\n     85:         \"\"\"Get health status data.\"\"\"\n     86:         if INTEGRATED_AVAILABLE:\n     87:             return get_health_status()",
    "context": {
      "complexity": 5,
      "lines": 56,
      "max_nesting": 3,
      "method_name": "get_health_status"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 120,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    117:                 cursor = conn.cursor()\n    118: \n    119:                 # Check WAL mode\n>>> 120:                 cursor.execute(\"PRAGMA journal_mode\")\n    121:                 mode = cursor.fetchone()[0]\n    122:                 health[\"database\"][\"wal_mode\"] = mode.lower() == \"wal\"\n    123: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 125,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    122:                 health[\"database\"][\"wal_mode\"] = mode.lower() == \"wal\"\n    123: \n    124:                 # Get metrics count\n>>> 125:                 cursor.execute(\"SELECT COUNT(*) FROM fitness_metrics\")\n    126:                 health[\"metrics\"][\"total_collected\"] = cursor.fetchone()[0]\n    127: \n    128:                 # Get current round",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 125,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    122:                 health[\"database\"][\"wal_mode\"] = mode.lower() == \"wal\"\n    123: \n    124:                 # Get metrics count\n>>> 125:                 cursor.execute(\"SELECT COUNT(*) FROM fitness_metrics\")\n    126:                 health[\"metrics\"][\"total_collected\"] = cursor.fetchone()[0]\n    127: \n    128:                 # Get current round",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM fitness_metrics"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 129,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    126:                 health[\"metrics\"][\"total_collected\"] = cursor.fetchone()[0]\n    127: \n    128:                 # Get current round\n>>> 129:                 cursor.execute(\"SELECT id, status FROM evolution_rounds ORDER BY id DESC LIMIT 1\")\n    130:                 row = cursor.fetchone()\n    131:                 if row:\n    132:                     health[\"database\"][\"current_round\"] = row[0]",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 129,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    126:                 health[\"metrics\"][\"total_collected\"] = cursor.fetchone()[0]\n    127: \n    128:                 # Get current round\n>>> 129:                 cursor.execute(\"SELECT id, status FROM evolution_rounds ORDER BY id DESC LIMIT 1\")\n    130:                 row = cursor.fetchone()\n    131:                 if row:\n    132:                     health[\"database\"][\"current_round\"] = row[0]",
    "context": {
      "query_preview": "SELECT id, status FROM evolution_rounds ORDER BY id DESC LIMIT 1"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 142,
    "column": 4,
    "description": "Method 'get_current_metrics' is too complex: 9 complexity, 57 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    139: \n    140:         return health\n    141: \n>>> 142:     def get_current_metrics(self):\n    143:         \"\"\"Get current metrics summary.\"\"\"\n    144:         db_path = os.getenv(\"AIVILLAGE_DB_PATH\", \"./data/evolution_metrics.db\")\n    145: ",
    "context": {
      "complexity": 9,
      "lines": 57,
      "max_nesting": 1,
      "method_name": "get_current_metrics"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 154,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    151:             cursor = conn.cursor()\n    152: \n    153:             # Get latest round metrics\n>>> 154:             cursor.execute(\n    155:                 \"\"\"\n    156:                 SELECT\n    157:                     COUNT(DISTINCT agent_id) as agent_count,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 155,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    152: \n    153:             # Get latest round metrics\n    154:             cursor.execute(\n>>> 155:                 \"\"\"\n    156:                 SELECT\n    157:                     COUNT(DISTINCT agent_id) as agent_count,\n    158:                     AVG(fitness_score) as avg_fitness,",
    "context": {
      "query_preview": "\n                SELECT\n                    COUNT(DISTINCT agent_id) as agent_count,\n               ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 179,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    176:             }\n    177: \n    178:             # Get resource usage\n>>> 179:             cursor.execute(\n    180:                 \"\"\"\n    181:                 SELECT\n    182:                     AVG(cpu_usage) as avg_cpu,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 180,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    177: \n    178:             # Get resource usage\n    179:             cursor.execute(\n>>> 180:                 \"\"\"\n    181:                 SELECT\n    182:                     AVG(cpu_usage) as avg_cpu,\n    183:                     AVG(memory_usage_mb) as avg_memory",
    "context": {
      "query_preview": "\n                SELECT\n                    AVG(cpu_usage) as avg_cpu,\n                    AVG(memor..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 212,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    209:             conn = sqlite3.connect(db_path)\n    210:             cursor = conn.cursor()\n    211: \n>>> 212:             cursor.execute(\n    213:                 \"\"\"\n    214:                 SELECT\n    215:                     agent_id,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 213,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    210:             cursor = conn.cursor()\n    211: \n    212:             cursor.execute(\n>>> 213:                 \"\"\"\n    214:                 SELECT\n    215:                     agent_id,\n    216:                     AVG(fitness_score) as avg_fitness,",
    "context": {
      "query_preview": "\n                SELECT\n                    agent_id,\n                    AVG(fitness_score) as avg_..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 254,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    251:             conn = sqlite3.connect(db_path)\n    252:             cursor = conn.cursor()\n    253: \n>>> 254:             cursor.execute(\n    255:                 \"\"\"\n    256:                 SELECT\n    257:                     fitness_score,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 255,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    252:             cursor = conn.cursor()\n    253: \n    254:             cursor.execute(\n>>> 255:                 \"\"\"\n    256:                 SELECT\n    257:                     fitness_score,\n    258:                     performance_metrics,",
    "context": {
      "query_preview": "\n                SELECT\n                    fitness_score,\n                    performance_metrics,\n..."
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 44,
    "column": 4,
    "description": "Duplicate code block detected in function 'handle_health_check'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "     41:         else:\n     42:             self.send_error(404, \"Not Found\")\n     43: \n>>>  44:     def handle_health_check(self) -> None:\n     45:         \"\"\"Handle health check endpoint.\"\"\"\n     46:         health_data = self.get_health_status()\n     47: ",
    "context": {
      "duplicate_count": 3,
      "function_name": "handle_health_check",
      "signature": "ASSIGN|CALL_send_response|CALL_send_header|CALL_end_headers|CALL_write"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 53,
    "column": 4,
    "description": "Duplicate code block detected in function 'handle_current_metrics'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "     50:         self.end_headers()\n     51:         self.wfile.write(json.dumps(health_data, indent=2).encode())\n     52: \n>>>  53:     def handle_current_metrics(self) -> None:\n     54:         \"\"\"Handle current metrics endpoint.\"\"\"\n     55:         metrics_data = self.get_current_metrics()\n     56: ",
    "context": {
      "duplicate_count": 3,
      "function_name": "handle_current_metrics",
      "signature": "ASSIGN|CALL_send_response|CALL_send_header|CALL_end_headers|CALL_write"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 62,
    "column": 4,
    "description": "Duplicate code block detected in function 'handle_leaderboard'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "     59:         self.end_headers()\n     60:         self.wfile.write(json.dumps(metrics_data, indent=2).encode())\n     61: \n>>>  62:     def handle_leaderboard(self) -> None:\n     63:         \"\"\"Handle leaderboard endpoint.\"\"\"\n     64:         leaderboard = self.get_leaderboard()\n     65: ",
    "context": {
      "duplicate_count": 3,
      "function_name": "handle_leaderboard",
      "signature": "ASSIGN|CALL_send_response|CALL_send_header|CALL_end_headers|CALL_write"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 142,
    "column": 4,
    "description": "Duplicate code block detected in function 'get_current_metrics'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    139: \n    140:         return health\n    141: \n>>> 142:     def get_current_metrics(self):\n    143:         \"\"\"Get current metrics summary.\"\"\"\n    144:         db_path = os.getenv(\"AIVILLAGE_DB_PATH\", \"./data/evolution_metrics.db\")\n    145: ",
    "context": {
      "duplicate_count": 3,
      "function_name": "get_current_metrics",
      "signature": "ASSIGN|IF|TRY"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 201,
    "column": 4,
    "description": "Duplicate code block detected in function 'get_leaderboard'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    198:         except Exception as e:\n    199:             return {\"error\": str(e)}\n    200: \n>>> 201:     def get_leaderboard(self):\n    202:         \"\"\"Get agent leaderboard.\"\"\"\n    203:         db_path = os.getenv(\"AIVILLAGE_DB_PATH\", \"./data/evolution_metrics.db\")\n    204: ",
    "context": {
      "duplicate_count": 3,
      "function_name": "get_leaderboard",
      "signature": "ASSIGN|IF|TRY"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 243,
    "column": 4,
    "description": "Duplicate code block detected in function 'get_agent_metrics'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    240:         except Exception as e:\n    241:             return {\"error\": str(e)}\n    242: \n>>> 243:     def get_agent_metrics(self, agent_id):\n    244:         \"\"\"Get metrics for specific agent.\"\"\"\n    245:         db_path = os.getenv(\"AIVILLAGE_DB_PATH\", \"./data/evolution_metrics.db\")\n    246: ",
    "context": {
      "duplicate_count": 3,
      "function_name": "get_agent_metrics",
      "signature": "ASSIGN|IF|TRY"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (22 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 22,
      "methods": [
        "send_header",
        "get_current_metrics",
        "get_agent_metrics",
        "end_headers",
        "get_health_status",
        "get_leaderboard",
        "send_response",
        "handle_current_metrics",
        "handle_health_check",
        "handle_agent_metrics",
        "handle_leaderboard",
        "send_error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'os' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "os",
      "method_count": 7,
      "methods": [
        "getenv",
        "chdir"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'conn' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "conn",
      "method_count": 9,
      "methods": [
        "close",
        "cursor"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_api.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'cursor' methods (14 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "cursor",
      "method_count": 14,
      "methods": [
        "execute",
        "fetchone",
        "fetchall"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 122,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    119: \n    120:     @classmethod\n    121:     def from_dict(cls, data: dict[str, Any]) -> \"EvolutionMetricsData\":\n>>> 122:         \"\"\"Create from dictionary.\"\"\"\n    123:         return cls(**data)\n    124: \n    125: ",
    "context": {
      "query_preview": "Create from dictionary."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 126,
    "column": 0,
    "description": "Class 'IntegratedEvolutionMetrics' is a God Object: 19 methods, ~508 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "    123:         return cls(**data)\n    124: \n    125: \n>>> 126: class IntegratedEvolutionMetrics:\n    127:     \"\"\"Integrated Evolution Metrics system with CODEX requirements.\n    128: \n    129:     Features:",
    "context": {
      "method_count": 19,
      "estimated_lines": 508,
      "class_name": "IntegratedEvolutionMetrics",
      "data_methods": 3,
      "business_methods": 16
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 186,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    183:         \"\"\"Initialize SQLite database with WAL mode.\"\"\"\n    184:         try:\n    185:             self.db_conn = sqlite3.connect(self.db_path, check_same_thread=False)\n>>> 186:             self.db_conn.execute(\"PRAGMA journal_mode=WAL\")\n    187:             self.db_conn.execute(\"PRAGMA synchronous=NORMAL\")\n    188:             self.db_conn.execute(\"PRAGMA cache_size=10000\")\n    189:             self.db_conn.execute(\"PRAGMA temp_store=MEMORY\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 187,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    184:         try:\n    185:             self.db_conn = sqlite3.connect(self.db_path, check_same_thread=False)\n    186:             self.db_conn.execute(\"PRAGMA journal_mode=WAL\")\n>>> 187:             self.db_conn.execute(\"PRAGMA synchronous=NORMAL\")\n    188:             self.db_conn.execute(\"PRAGMA cache_size=10000\")\n    189:             self.db_conn.execute(\"PRAGMA temp_store=MEMORY\")\n    190:             self.db_conn.execute(\"PRAGMA mmap_size=268435456\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 188,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    185:             self.db_conn = sqlite3.connect(self.db_path, check_same_thread=False)\n    186:             self.db_conn.execute(\"PRAGMA journal_mode=WAL\")\n    187:             self.db_conn.execute(\"PRAGMA synchronous=NORMAL\")\n>>> 188:             self.db_conn.execute(\"PRAGMA cache_size=10000\")\n    189:             self.db_conn.execute(\"PRAGMA temp_store=MEMORY\")\n    190:             self.db_conn.execute(\"PRAGMA mmap_size=268435456\")\n    191: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 189,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    186:             self.db_conn.execute(\"PRAGMA journal_mode=WAL\")\n    187:             self.db_conn.execute(\"PRAGMA synchronous=NORMAL\")\n    188:             self.db_conn.execute(\"PRAGMA cache_size=10000\")\n>>> 189:             self.db_conn.execute(\"PRAGMA temp_store=MEMORY\")\n    190:             self.db_conn.execute(\"PRAGMA mmap_size=268435456\")\n    191: \n    192:             logger.info(f\"SQLite database initialized at {self.db_path} with WAL mode\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 190,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    187:             self.db_conn.execute(\"PRAGMA synchronous=NORMAL\")\n    188:             self.db_conn.execute(\"PRAGMA cache_size=10000\")\n    189:             self.db_conn.execute(\"PRAGMA temp_store=MEMORY\")\n>>> 190:             self.db_conn.execute(\"PRAGMA mmap_size=268435456\")\n    191: \n    192:             logger.info(f\"SQLite database initialized at {self.db_path} with WAL mode\")\n    193:         except Exception as e:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 268,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    265: \n    266:         try:\n    267:             cursor = self.db_conn.cursor()\n>>> 268:             cursor.execute(\n    269:                 \"\"\"\n    270:                 INSERT INTO evolution_rounds (round_number, generation, status, timestamp)\n    271:                 VALUES (?, ?, ?, ?)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 269,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    266:         try:\n    267:             cursor = self.db_conn.cursor()\n    268:             cursor.execute(\n>>> 269:                 \"\"\"\n    270:                 INSERT INTO evolution_rounds (round_number, generation, status, timestamp)\n    271:                 VALUES (?, ?, ?, ?)\n    272:             \"\"\",",
    "context": {
      "query_preview": "\n                INSERT INTO evolution_rounds (round_number, generation, status, timestamp)\n        ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 281,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    278:                 ),\n    279:             )\n    280:             self.current_round_id = cursor.lastrowid\n>>> 281:             self.db_conn.commit()\n    282:             logger.info(f\"Started evolution round {self.current_round_id}\")\n    283:         except Exception as e:\n    284:             logger.exception(f\"Failed to start evolution round: {e}\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 293,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    290: \n    291:         try:\n    292:             cursor = self.db_conn.cursor()\n>>> 293:             cursor.execute(\n    294:                 \"\"\"\n    295:                 UPDATE evolution_rounds\n    296:                 SET status = 'completed'",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 294,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    291:         try:\n    292:             cursor = self.db_conn.cursor()\n    293:             cursor.execute(\n>>> 294:                 \"\"\"\n    295:                 UPDATE evolution_rounds\n    296:                 SET status = 'completed'\n    297:                 WHERE id = ?",
    "context": {
      "query_preview": "\n                UPDATE evolution_rounds\n                SET status = 'completed'\n                WH..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 301,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    298:             \"\"\",\n    299:                 (self.current_round_id,),\n    300:             )\n>>> 301:             self.db_conn.commit()\n    302:             logger.info(f\"Completed evolution round {self.current_round_id}\")\n    303:         except Exception as e:\n    304:             logger.exception(f\"Failed to complete evolution round: {e}\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 331,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    328:         value: float,\n    329:         metadata: dict | None = None,\n    330:     ) -> None:\n>>> 331:         \"\"\"Record a single KPI value.\n    332: \n    333:         Args:\n    334:             agent_id: Agent identifier",
    "context": {
      "query_preview": "Record a single KPI value.\n\n        Args:\n            agent_id: Agent identifier\n            kpi_typ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 382,
    "column": 4,
    "description": "Method '_persist_metrics' is too complex: 6 complexity, 83 lines, 3 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    379:             except Exception as e:\n    380:                 logger.exception(f\"Worker error: {e}\")\n    381: \n>>> 382:     def _persist_metrics(self, metrics_list: list[EvolutionMetricsData]) -> None:\n    383:         \"\"\"Persist metrics to database.\"\"\"\n    384:         if not self.db_conn or not self.current_round_id:\n    385:             return",
    "context": {
      "complexity": 6,
      "lines": 83,
      "max_nesting": 3,
      "method_name": "_persist_metrics"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 392,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    389: \n    390:             for metrics in metrics_list:\n    391:                 # Insert fitness metrics\n>>> 392:                 cursor.execute(\n    393:                     \"\"\"\n    394:                     INSERT INTO fitness_metrics\n    395:                     (round_id, agent_id, fitness_score, performance_metrics, timestamp)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 393,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    390:             for metrics in metrics_list:\n    391:                 # Insert fitness metrics\n    392:                 cursor.execute(\n>>> 393:                     \"\"\"\n    394:                     INSERT INTO fitness_metrics\n    395:                     (round_id, agent_id, fitness_score, performance_metrics, timestamp)\n    396:                     VALUES (?, ?, ?, ?, ?)",
    "context": {
      "query_preview": "\n                    INSERT INTO fitness_metrics\n                    (round_id, agent_id, fitness_sc..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 425,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    422:                 )\n    423: \n    424:                 # Insert resource metrics\n>>> 425:                 cursor.execute(\n    426:                     \"\"\"\n    427:                     INSERT INTO resource_metrics\n    428:                     (round_id, cpu_usage, memory_usage_mb, network_io_kb, disk_io_kb, gpu_usage, timestamp)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 426,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    423: \n    424:                 # Insert resource metrics\n    425:                 cursor.execute(\n>>> 426:                     \"\"\"\n    427:                     INSERT INTO resource_metrics\n    428:                     (round_id, cpu_usage, memory_usage_mb, network_io_kb, disk_io_kb, gpu_usage, timestamp)\n    429:                     VALUES (?, ?, ?, ?, ?, ?, ?)",
    "context": {
      "query_preview": "\n                    INSERT INTO resource_metrics\n                    (round_id, cpu_usage, memory_u..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 444,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    441: \n    442:                 # Insert selection outcomes if applicable\n    443:                 if metrics.selection_method:\n>>> 444:                     cursor.execute(\n    445:                         \"\"\"\n    446:                         INSERT INTO selection_outcomes\n    447:                         (round_id, parent_agent_id, selection_method, mutation_applied, survival_reason, timestamp)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 445,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    442:                 # Insert selection outcomes if applicable\n    443:                 if metrics.selection_method:\n    444:                     cursor.execute(\n>>> 445:                         \"\"\"\n    446:                         INSERT INTO selection_outcomes\n    447:                         (round_id, parent_agent_id, selection_method, mutation_applied, survival_reason, timestamp)\n    448:                         VALUES (?, ?, ?, ?, ?, ?)",
    "context": {
      "query_preview": "\n                        INSERT INTO selection_outcomes\n                        (round_id, parent_ag..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 460,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    457:                         ),\n    458:                     )\n    459: \n>>> 460:             self.db_conn.commit()\n    461:             logger.debug(f\"Persisted {len(metrics_list)} metrics to database\")\n    462: \n    463:         except Exception as e:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 527,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    524: \n    525:         try:\n    526:             cursor = self.db_conn.cursor()\n>>> 527:             cursor.execute(\n    528:                 \"\"\"\n    529:                 SELECT\n    530:                     fm.fitness_score,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 528,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    525:         try:\n    526:             cursor = self.db_conn.cursor()\n    527:             cursor.execute(\n>>> 528:                 \"\"\"\n    529:                 SELECT\n    530:                     fm.fitness_score,\n    531:                     fm.performance_metrics,",
    "context": {
      "query_preview": "\n                SELECT\n                    fm.fitness_score,\n                    fm.performance_met..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 594,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    591:         if self.db_conn:\n    592:             try:\n    593:                 cursor = self.db_conn.cursor()\n>>> 594:                 cursor.execute(\"SELECT COUNT(*) FROM fitness_metrics\")\n    595:                 count = cursor.fetchone()[0]\n    596:                 status[\"database\"][\"total_records\"] = count\n    597:             except Exception as e:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 594,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    591:         if self.db_conn:\n    592:             try:\n    593:                 cursor = self.db_conn.cursor()\n>>> 594:                 cursor.execute(\"SELECT COUNT(*) FROM fitness_metrics\")\n    595:                 count = cursor.fetchone()[0]\n    596:                 status[\"database\"][\"total_records\"] = count\n    597:             except Exception as e:",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM fitness_metrics"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 642,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    639: \n    640: \n    641: def get_metrics_instance() -> IntegratedEvolutionMetrics:\n>>> 642:     \"\"\"Get or create the singleton metrics instance.\"\"\"\n    643:     global _metrics_instance\n    644:     if _metrics_instance is None:\n    645:         _metrics_instance = IntegratedEvolutionMetrics()",
    "context": {
      "query_preview": "Get or create the singleton metrics instance."
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 498,
    "column": 4,
    "description": "Duplicate code block detected in function 'get_current_metrics'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    495:         except Exception as e:\n    496:             logger.debug(f\"Redis operation failed (non-critical): {e}\")\n    497: \n>>> 498:     def get_current_metrics(self) -> dict[str, Any]:\n    499:         \"\"\"Get current metrics summary.\"\"\"\n    500:         summary = {\n    501:             \"total_metrics_collected\": self.total_metrics_collected,",
    "context": {
      "duplicate_count": 2,
      "function_name": "get_current_metrics",
      "signature": "ASSIGN|IF|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 604,
    "column": 4,
    "description": "Duplicate code block detected in function 'collect_system_metrics'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    601: \n    602:         return status\n    603: \n>>> 604:     def collect_system_metrics(self) -> EvolutionMetricsData:\n    605:         \"\"\"Collect current system resource metrics.\"\"\"\n    606:         metrics = EvolutionMetricsData(agent_id=\"system\", timestamp=time.time())\n    607: ",
    "context": {
      "duplicate_count": 2,
      "function_name": "collect_system_metrics",
      "signature": "ASSIGN|IF|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'os' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "os",
      "method_count": 8,
      "methods": [
        "getenv"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 11,
      "methods": [
        "_init_redis",
        "_start_evolution_round",
        "_complete_evolution_round",
        "_init_sqlite",
        "_flush_internal",
        "_persist_metrics",
        "_init_storage",
        "flush",
        "_send_to_redis",
        "record_metric"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (20 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 20,
      "methods": [
        "info",
        "warning",
        "exception",
        "debug"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'cursor' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "cursor",
      "method_count": 9,
      "methods": [
        "execute",
        "fetchone",
        "fetchall"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 137,
    "column": 4,
    "description": "Sequential coupling detected: Function '__init__' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    134:     - Real-time metrics collection\n    135:     \"\"\"\n    136: \n>>> 137:     def __init__(self) -> None:\n    138:         \"\"\"Initialize the integrated metrics system.\"\"\"\n    139:         # Load configuration from environment\n    140:         self.db_path = os.getenv(\"AIVILLAGE_DB_PATH\", \"./data/evolution_metrics.db\")",
    "context": {
      "function_name": "__init__",
      "sequential_functions": [
        "__init__",
        "_init_storage",
        "_init_sqlite",
        "_init_redis"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 170,
    "column": 4,
    "description": "Sequential coupling detected: Function '_init_storage' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    167:         # Initialize storage\n    168:         self._init_storage()\n    169: \n>>> 170:     def _init_storage(self) -> None:\n    171:         \"\"\"Initialize storage backends.\"\"\"\n    172:         # Initialize SQLite\n    173:         self._init_sqlite()",
    "context": {
      "function_name": "_init_storage",
      "sequential_functions": [
        "__init__",
        "_init_storage",
        "_init_sqlite",
        "_init_redis"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 182,
    "column": 4,
    "description": "Sequential coupling detected: Function '_init_sqlite' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    179:         # Create log directory\n    180:         Path(self.log_dir).mkdir(parents=True, exist_ok=True)\n    181: \n>>> 182:     def _init_sqlite(self) -> None:\n    183:         \"\"\"Initialize SQLite database with WAL mode.\"\"\"\n    184:         try:\n    185:             self.db_conn = sqlite3.connect(self.db_path, check_same_thread=False)",
    "context": {
      "function_name": "_init_sqlite",
      "sequential_functions": [
        "__init__",
        "_init_storage",
        "_init_sqlite",
        "_init_redis"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 197,
    "column": 4,
    "description": "Sequential coupling detected: Function '_init_redis' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    194:             logger.exception(f\"Failed to initialize SQLite: {e}\")\n    195:             raise\n    196: \n>>> 197:     def _init_redis(self) -> None:\n    198:         \"\"\"Initialize Redis connection with fallback.\"\"\"\n    199:         if not REDIS_AVAILABLE:\n    200:             logger.warning(\"Redis module not available, using SQLite only\")",
    "context": {
      "function_name": "_init_redis",
      "sequential_functions": [
        "__init__",
        "_init_storage",
        "_init_sqlite",
        "_init_redis"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 209,
    "column": 39,
    "description": "Excessive magic literals detected (13 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    206:                 port=self.redis_port,\n    207:                 db=self.redis_db,\n    208:                 decode_responses=True,\n>>> 209:                 socket_connect_timeout=5,\n    210:                 socket_timeout=5,\n    211:             )\n    212:             # Test connection",
    "context": {
      "total_magic_literals": 13,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 210,
    "column": 31,
    "description": "Excessive magic literals detected (13 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    207:                 db=self.redis_db,\n    208:                 decode_responses=True,\n    209:                 socket_connect_timeout=5,\n>>> 210:                 socket_timeout=5,\n    211:             )\n    212:             # Test connection\n    213:             self.redis_client.ping()",
    "context": {
      "total_magic_literals": 13,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 251,
    "column": 44,
    "description": "Excessive magic literals detected (13 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    248:         # Wait for worker to finish\n    249:         if self.worker_thread:\n    250:             self.worker_queue.put(None)  # Signal to stop\n>>> 251:             self.worker_thread.join(timeout=5)\n    252: \n    253:         # Close connections\n    254:         if self.db_conn:",
    "context": {
      "total_magic_literals": 13,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 478,
    "column": 42,
    "description": "Excessive magic literals detected (13 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    475:             self.redis_client.zadd(key, {json.dumps(metrics.to_dict()): metrics.timestamp})\n    476: \n    477:             # Set expiry (1 hour)\n>>> 478:             self.redis_client.expire(key, 3600)\n    479: \n    480:             # Update real-time leaderboard\n    481:             self.redis_client.zadd(\"evolution:leaderboard\", {metrics.agent_id: metrics.fitness_score})",
    "context": {
      "total_magic_literals": 13,
      "current_value": 3600
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\evolution_metrics_integrated.py",
    "line_number": 512,
    "column": 85,
    "description": "Excessive magic literals detected (13 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    509:         # Add leaderboard from Redis if available\n    510:         if self.redis_client:\n    511:             try:\n>>> 512:                 top_agents = self.redis_client.zrevrange(\"evolution:leaderboard\", 0, 9, withscores=True)\n    513:                 summary[\"top_agents\"] = [{\"agent_id\": agent, \"fitness_score\": score} for agent, score in top_agents]\n    514:             except Exception as e:\n    515:                 logger.warning(f\"Failed to get top agents: {e}\")",
    "context": {
      "total_magic_literals": 13,
      "current_value": 9
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\logging_config.py",
    "line_number": 76,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     73:         \"\"\"Process log message with additional context.\"\"\"\n     74:         # Merge extra context\n     75:         if \"extra\" in kwargs:\n>>>  76:             kwargs[\"extra\"].update(self.extra)\n     77:         else:\n     78:             kwargs[\"extra\"] = self.extra.copy()\n     79: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\logging_config.py",
    "line_number": 83,
    "column": 0,
    "description": "Method 'create_logging_config' is too complex: 7 complexity, 116 lines, 4 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     80:         return msg, kwargs\n     81: \n     82: \n>>>  83: def create_logging_config(\n     84:     log_level: str = \"INFO\",\n     85:     log_dir: str | None = None,\n     86:     structured_logging: bool = True,",
    "context": {
      "complexity": 7,
      "lines": 116,
      "max_nesting": 4,
      "method_name": "create_logging_config"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\logging_config.py",
    "line_number": 83,
    "column": 0,
    "description": "Function 'create_logging_config' has 7 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "     80:         return msg, kwargs\n     81: \n     82: \n>>>  83: def create_logging_config(\n     84:     log_level: str = \"INFO\",\n     85:     log_dir: str | None = None,\n     86:     structured_logging: bool = True,",
    "context": {
      "parameter_count": 7,
      "function_name": "create_logging_config"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\logging_config.py",
    "line_number": 92,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     89:     max_file_size: int = 10 * 1024 * 1024,  # 10MB\n     90:     backup_count: int = 5,\n     91: ) -> dict[str, Any]:\n>>>  92:     \"\"\"Create logging configuration dictionary.\n     93: \n     94:     Args:\n     95:         log_level: Default logging level",
    "context": {
      "query_preview": "Create logging configuration dictionary.\n\n    Args:\n        log_level: Default logging level\n       ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\logging_config.py",
    "line_number": 208,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    205:     structured_logging: bool = True,\n    206:     **kwargs,\n    207: ) -> logging.Logger:\n>>> 208:     \"\"\"Setup AIVillage logging with standardized configuration.\n    209: \n    210:     Args:\n    211:         log_level: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)",
    "context": {
      "query_preview": "Setup AIVillage logging with standardized configuration.\n\n    Args:\n        log_level: Logging level..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\logging_config.py",
    "line_number": 264,
    "column": 0,
    "description": "Method 'log_function_call' is too complex: 8 complexity, 94 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    261:     return AIVillageLoggerAdapter(base_logger, extra_context)\n    262: \n    263: \n>>> 264: def log_function_call(\n    265:     logger: logging.Logger,\n    266:     level: int = logging.DEBUG,\n    267:     include_args: bool = False,",
    "context": {
      "complexity": 8,
      "lines": 94,
      "max_nesting": 5,
      "method_name": "log_function_call"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\logging_config.py",
    "line_number": 279,
    "column": 4,
    "description": "Method 'decorator' is too complex: 8 complexity, 77 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    276:         include_result: Whether to include function result\n    277:     \"\"\"\n    278: \n>>> 279:     def decorator(func):\n    280:         import functools\n    281: \n    282:         @functools.wraps(func)",
    "context": {
      "complexity": 8,
      "lines": 77,
      "max_nesting": 5,
      "method_name": "decorator"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\logging_config.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 7,
      "methods": [
        "info",
        "log",
        "exception"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\__init__.py",
    "line_number": 52,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     49:     \"ValidationException\",\n     50:     \"error_handler\",\n     51:     \"get_component_logger\",\n>>>  52:     \"migrate_from_legacy_exception\",\n     53:     \"safe_execute\",\n     54:     \"with_error_handling\",\n     55: ]",
    "context": {
      "query_preview": "migrate_from_legacy_exception"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 1,
    "column": 0,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": ">>>   1: \"\"\"AIVillage Operational Artifacts Collection System\n      2: \n      3: Collects, validates, and manages operational artifacts from CI/CD pipeline\n      4: including coverage reports, security scans, SBOM files, performance metrics,",
    "context": {
      "query_preview": "AIVillage Operational Artifacts Collection System\n\nCollects, validates, and manages operational arti..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 95,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     92: \n     93: \n     94: class OperationalArtifactCollector:\n>>>  95:     \"\"\"Main artifact collection system for AIVillage operational visibility.\n     96: \n     97:     Collects artifacts from CI/CD pipeline and local builds, validates them,\n     98:     and creates searchable indexes for operational monitoring and compliance.",
    "context": {
      "query_preview": "Main artifact collection system for AIVillage operational visibility.\n\n    Collects artifacts from C..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 115,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    112:         logger.info(\"Operational artifact collector initialized\")\n    113: \n    114:     def _setup_directories(self):\n>>> 115:         \"\"\"Create required artifact directories.\"\"\"\n    116:         for dir_path in [\n    117:             self.config.artifacts_base_dir,\n    118:             self.config.archive_base_dir,",
    "context": {
      "query_preview": "Create required artifact directories."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 173,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    170:     async def collect_ci_artifacts(\n    171:         self, pipeline_id: str, commit_sha: str, branch: str, artifact_sources: dict[ArtifactType, str],\n    172:     ) -> list[ArtifactMetadata]:\n>>> 173:         \"\"\"Collect artifacts from CI/CD pipeline.\n    174: \n    175:         Args:\n    176:             pipeline_id: Unique identifier for pipeline run",
    "context": {
      "query_preview": "Collect artifacts from CI/CD pipeline.\n\n        Args:\n            pipeline_id: Unique identifier for..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 285,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    282:             return None\n    283: \n    284:     async def _download_artifact(self, url: str, destination: Path):\n>>> 285:         \"\"\"Download artifact from URL using async HTTP client.\"\"\"\n    286:         try:\n    287:             import aiofiles\n    288:             import aiohttp",
    "context": {
      "query_preview": "Download artifact from URL using async HTTP client."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 336,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    333: \n    334:             # Validate content based on artifact type\n    335:             content_validation = await self._validate_artifact_content(artifact_type, file_path, rules)\n>>> 336:             validation_result[\"metadata\"].update(content_validation)\n    337: \n    338:             validation_result[\"valid\"] = True\n    339:             return validation_result",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 398,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    395:         return metadata\n    396: \n    397:     async def _update_artifacts_index(self):\n>>> 398:         \"\"\"Update the artifacts index file.\"\"\"\n    399:         index_file = Path(self.config.artifacts_base_dir) / \"index.json\"\n    400: \n    401:         # Create index data",
    "context": {
      "query_preview": "Update the artifacts index file."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 438,
    "column": 22,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    435:         with open(index_file, \"w\") as f:\n    436:             json.dump(index_data, f, indent=2)\n    437: \n>>> 438:         logger.info(f\"Updated artifacts index: {len(self.artifacts)} artifacts\")\n    439: \n    440:     def search_artifacts(\n    441:         self,",
    "context": {
      "query_preview": "Updated artifacts index: "
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 440,
    "column": 4,
    "description": "Method 'search_artifacts' is too complex: 6 complexity, 27 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    437: \n    438:         logger.info(f\"Updated artifacts index: {len(self.artifacts)} artifacts\")\n    439: \n>>> 440:     def search_artifacts(\n    441:         self,\n    442:         artifact_type: ArtifactType | None = None,\n    443:         pipeline_id: str | None = None,",
    "context": {
      "complexity": 6,
      "lines": 27,
      "max_nesting": 5,
      "method_name": "search_artifacts"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 440,
    "column": 4,
    "description": "Function 'search_artifacts' has 6 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    437: \n    438:         logger.info(f\"Updated artifacts index: {len(self.artifacts)} artifacts\")\n    439: \n>>> 440:     def search_artifacts(\n    441:         self,\n    442:         artifact_type: ArtifactType | None = None,\n    443:         pipeline_id: str | None = None,",
    "context": {
      "parameter_count": 6,
      "function_name": "search_artifacts"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 470,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    467:         return sorted(results, key=lambda x: x.collected_at, reverse=True)\n    468: \n    469:     async def generate_operational_report(self, days_back: int = 7) -> dict[str, Any]:\n>>> 470:         \"\"\"Generate operational report from collected artifacts.\"\"\"\n    471:         cutoff_time = time.time() - (days_back * 24 * 3600)\n    472:         recent_artifacts = [a for a in self.artifacts if a.collected_at > cutoff_time]\n    473: ",
    "context": {
      "query_preview": "Generate operational report from collected artifacts."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 565,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    562:     commit_sha: str,\n    563:     branch: str,\n    564: ) -> list[ArtifactMetadata]:\n>>> 565:     \"\"\"Collect artifacts from GitHub Actions workflow run.\"\"\"\n    566:     # Map of expected GitHub Actions artifacts to their types\n    567:     github_artifact_mapping = {\n    568:         \"coverage-report\": ArtifactType.COVERAGE,",
    "context": {
      "query_preview": "Collect artifacts from GitHub Actions workflow run."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 8,
      "methods": [
        "_update_artifacts_index",
        "_collect_single_artifact",
        "_validate_artifact_content",
        "_download_artifact",
        "_load_validation_rules",
        "_setup_directories",
        "_validate_artifact"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 10,
      "methods": [
        "info",
        "warning",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'time' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "time",
      "method_count": 7,
      "methods": [
        "time"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'data' methods (12 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "data",
      "method_count": 12,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 74,
    "column": 38,
    "description": "Excessive magic literals detected (22 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     71: \n     72:     # Collection settings\n     73:     enabled_types: list[ArtifactType] = field(default_factory=lambda: list(ArtifactType))\n>>>  74:     collection_timeout_seconds: int = 300\n     75:     max_artifact_size_mb: int = 100\n     76:     retention_days: int = 90\n     77: ",
    "context": {
      "total_magic_literals": 22,
      "current_value": 300
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 76,
    "column": 26,
    "description": "Excessive magic literals detected (22 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     73:     enabled_types: list[ArtifactType] = field(default_factory=lambda: list(ArtifactType))\n     74:     collection_timeout_seconds: int = 300\n     75:     max_artifact_size_mb: int = 100\n>>>  76:     retention_days: int = 90\n     77: \n     78:     # Storage settings\n     79:     artifacts_base_dir: str = \"artifacts\"",
    "context": {
      "total_magic_literals": 22,
      "current_value": 90
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 128,
    "column": 31,
    "description": "Excessive magic literals detected (22 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    125:         return {\n    126:             ArtifactType.COVERAGE: {\n    127:                 \"required_extensions\": [\".xml\", \".json\", \".html\"],\n>>> 128:                 \"max_size_mb\": 50,\n    129:                 \"required_fields\": [\"coverage_percent\", \"lines_covered\"],\n    130:                 \"schema_validation\": True,\n    131:             },",
    "context": {
      "total_magic_literals": 22,
      "current_value": 50
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 134,
    "column": 31,
    "description": "Excessive magic literals detected (22 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    131:             },\n    132:             ArtifactType.SECURITY: {\n    133:                 \"required_extensions\": [\".json\", \".sarif\", \".xml\"],\n>>> 134:                 \"max_size_mb\": 25,\n    135:                 \"required_fields\": [\"scan_date\", \"vulnerabilities\"],\n    136:                 \"schema_validation\": True,\n    137:             },",
    "context": {
      "total_magic_literals": 22,
      "current_value": 25
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\artifact_collector.py",
    "line_number": 146,
    "column": 31,
    "description": "Excessive magic literals detected (22 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    143:             },\n    144:             ArtifactType.PERFORMANCE: {\n    145:                 \"required_extensions\": [\".json\", \".csv\", \".html\"],\n>>> 146:                 \"max_size_mb\": 20,\n    147:                 \"required_fields\": [\"benchmarks\", \"metrics\"],\n    148:                 \"schema_validation\": True,\n    149:             },",
    "context": {
      "total_magic_literals": 22,
      "current_value": 20
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\github_workflow_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": ">>>   1: \"\"\"GitHub Actions Workflow Integration for AIVillage Operational Artifacts\n      2: \n      3: Provides integration with GitHub Actions workflows to automatically collect\n      4: operational artifacts including coverage, security scans, SBOM, performance",
    "context": {
      "query_preview": "GitHub Actions Workflow Integration for AIVillage Operational Artifacts\n\nProvides integration with G..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\operations\\github_workflow_integration.py",
    "line_number": 58,
    "column": 4,
    "description": "Method 'generate_workflow_yaml' is too complex: 4 complexity, 318 lines, 3 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     55:         if not self.github_token:\n     56:             logger.warning(\"No GitHub token provided - GitHub API features disabled\")\n     57: \n>>>  58:     def generate_workflow_yaml(self) -> str:\n     59:         \"\"\"Generate GitHub Actions workflow YAML for artifact collection.\"\"\"\n     60:         workflow_yaml = f\"\"\"name: {self.config.workflow_name}\n     61: ",
    "context": {
      "complexity": 4,
      "lines": 318,
      "max_nesting": 3,
      "method_name": "generate_workflow_yaml"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\github_workflow_integration.py",
    "line_number": 80,
    "column": 25,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     77:   schedule:\n     78:     - cron: '{self.config.schedule_cron}'\"\"\"\n     79: \n>>>  80:         workflow_yaml += \"\"\"\n     81:   workflow_dispatch:\n     82: \n     83: jobs:",
    "context": {
      "query_preview": "\n  workflow_dispatch:\n\njobs:\n  collect-artifacts:\n    runs-on: ubuntu-latest\n    timeout-minutes: 30..."
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\github_workflow_integration.py",
    "line_number": 80,
    "column": 25,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "     77:   schedule:\n     78:     - cron: '{self.config.schedule_cron}'\"\"\"\n     79: \n>>>  80:         workflow_yaml += \"\"\"\n     81:   workflow_dispatch:\n     82: \n     83: jobs:",
    "context": {
      "hardcoded_value": "\n  workflow_dispatch:\n\njobs:\n  collect-artifacts:\n    runs-on: ubuntu-latest\n    timeout-minutes: 30\n\n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v4\n      with:\n        fetch-depth: 0\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.11'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r config/requirements/requirements.txt\n        pip install -r config/requirements/requirements-dev.txt\n\n    - name: Run pre-commit checks\n      run: |\n        pre-commit run --all-files --show-diff-on-failure\n      continue-on-error: true\n\n    # Code Coverage Collection\n    - name: Run tests with coverage\n      run: |\n        pytest tests/ --cov=packages --cov-report=json --cov-report=html --cov-report=xml\n        mkdir -p artifacts/coverage\n        cp coverage.json artifacts/coverage/\n        cp coverage.xml artifacts/coverage/\n        tar -czf artifacts/coverage-report.tar.gz htmlcov/\n\n    # Security Scanning\n    - name: Run Bandit security scan\n      run: |\n        mkdir -p artifacts/security\n        bandit -r packages/ -f json -o artifacts/security/bandit-report.json || true\n        bandit -r packages/ -f txt -o artifacts/security/bandit-report.txt || true\n\n    - name: Run Safety dependency check\n      run: |\n        safety check --json --output artifacts/security/safety-report.json || true\n\n    # SBOM Generation\n    - name: Generate Software Bill of Materials\n      run: |\n        mkdir -p artifacts/sbom\n        # Generate Python SBOM\n        pip freeze > artifacts/sbom/requirements-freeze.txt\n        # Generate SPDX SBOM (if cyclonedx-python is available)\n        pip install cyclonedx-bom\n        cyclonedx-py -o artifacts/sbom/sbom.json || true\n\n    # Performance Benchmarks\n    - name: Run performance benchmarks\n      run: |\n        mkdir -p artifacts/performance\n        # Run basic performance tests\n        python -m pytest tests/benchmarks/ --benchmark-json=artifacts/performance/benchmarks.json || true\n        # Run Agent Forge performance tests if available\n        python -c \"\nimport json\nimport time\nbenchmarks = {\n    'timestamp': time.time(),\n    'benchmarks': [\n        {'name': 'agent_forge_pipeline', 'avg_time_ms': 1200, 'iterations': 10},\n        {'name': 'p2p_message_routing', 'avg_time_ms': 45, 'iterations': 100},\n        {'name': 'rag_query_processing', 'avg_time_ms': 120, 'iterations': 50}\n    ],\n    'system_info': {'cpu_count': 4, 'memory_gb': 16}\n}\nwith open('artifacts/performance/benchmarks.json', 'w') as f:\n    json.dump(benchmarks, f, indent=2)\n\"\n\n    # Code Quality Analysis\n    - name: Run code quality analysis\n      run: |\n        mkdir -p artifacts/quality\n        # Ruff linting with JSON output\n        ruff check packages/ --format=json --output-file=artifacts/quality/ruff-report.json || true\n        # MyPy type checking\n        mypy packages/ --txt-report artifacts/quality/mypy-report || true\n        # Generate quality summary\n        python -c \"\nimport json\nimport time\nquality_report = {\n    'timestamp': time.time(),\n    'quality_score': 85,\n    'issues': [\n        {'type': 'style', 'count': 12, 'severity': 'low'},\n        {'type': 'complexity', 'count': 3, 'severity': 'medium'},\n        {'type': 'security', 'count': 0, 'severity': 'high'}\n    ],\n    'code_smell_count': 5,\n    'technical_debt_minutes': 45\n}\nwith open('artifacts/quality/quality-summary.json', 'w') as f:\n    json.dump(quality_report, f, indent=2)\n\"\n\n    # Container Security Scanning (if Docker is used)\n    - name: Build and scan container images\n      if: hashFiles('Dockerfile*') != ''\n      run: |\n        mkdir -p artifacts/container\n        # Build images\n        docker build -t aivillage:latest .\n        # Scan with Trivy (if available)\n        docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \\\n          -v ${{ github.workspace }}/artifacts/container:/output \\\n          aquasec/trivy image --format json --output /output/trivy-report.json \\\n          aivillage:latest || true\n\n    # Compliance Validation\n    - name: Generate compliance report\n      run: |\n        mkdir -p artifacts/compliance\n        python -c \"\nimport json\nimport time\ncompliance_report = {\n    'timestamp': time.time(),\n    'compliance_checks': [\n        {'name': 'security_scanning', 'status': 'pass', 'details': 'All security scans completed'},\n        {'name': 'code_coverage', 'status': 'pass', 'details': 'Coverage >= 60%'},\n        {'name': 'dependency_check', 'status': 'pass', 'details': 'No high-risk dependencies'},\n        {'name': 'license_compliance', 'status': 'pass', 'details': 'All dependencies have compatible licenses'}\n    ],\n    'overall_status': 'compliant',\n    'recommendations': [\n        'Consider increasing code coverage to 70%',\n        'Update dependencies with known vulnerabilities'\n    ]\n}\nwith open('artifacts/compliance/compliance-report.json', 'w') as f:\n    json.dump(compliance_report, f, indent=2)\n\"\n\n    # Upload artifacts to GitHub\n    - name: Upload coverage reports\n      uses: actions/upload-artifact@v4\n      with:\n        name: coverage-report\n        path: artifacts/coverage/\n        retention-days: ${{ github.event_name == 'push' && 30 || 7 }}\n\n    - name: Upload security scan results\n      uses: actions/upload-artifact@v4\n      with:\n        name: security-scan\n        path: artifacts/security/\n        retention-days: 30\n\n    - name: Upload SBOM\n      uses: actions/upload-artifact@v4\n      with:\n        name: sbom-report\n        path: artifacts/sbom/\n        retention-days: 30\n\n    - name: Upload performance benchmarks\n      uses: actions/upload-artifact@v4\n      with:\n        name: performance-benchmarks\n        path: artifacts/performance/\n        retention-days: 15\n\n    - name: Upload quality report\n      uses: actions/upload-artifact@v4\n      with:\n        name: quality-report\n        path: artifacts/quality/\n        retention-days: 15\n\n    - name: Upload container scan results\n      if: hashFiles('Dockerfile*') != ''\n      uses: actions/upload-artifact@v4\n      with:\n        name: container-scan\n        path: artifacts/container/\n        retention-days: 30\n\n    - name: Upload compliance report\n      uses: actions/upload-artifact@v4\n      with:\n        name: compliance-report\n        path: artifacts/compliance/\n        retention-days: 30\n\n    # Collect artifacts with AIVillage collector\n    - name: Process artifacts with collector\n      run: |\n        python -c \"\nimport asyncio\nimport os\nimport sys\nsys.path.insert(0, 'packages')\n\nfrom core.operations.artifact_collector import (\n    OperationalArtifactCollector, CollectionConfig, ArtifactType\n)\n\nasync def main():\n    config = CollectionConfig(\n        enabled_types=[\n            ArtifactType.COVERAGE,\n            ArtifactType.SECURITY,\n            ArtifactType.SBOM,\n            ArtifactType.PERFORMANCE,\n            ArtifactType.QUALITY,\n            ArtifactType.COMPLIANCE,\n        ]\n    )\n\n    collector = OperationalArtifactCollector(config)\n\n    artifact_sources = {\n        ArtifactType.COVERAGE: 'artifacts/coverage/coverage.json',\n        ArtifactType.SECURITY: 'artifacts/security/bandit-report.json',\n        ArtifactType.SBOM: 'artifacts/sbom/sbom.json',\n        ArtifactType.PERFORMANCE: 'artifacts/performance/benchmarks.json',\n        ArtifactType.QUALITY: 'artifacts/quality/quality-summary.json',\n        ArtifactType.COMPLIANCE: 'artifacts/compliance/compliance-report.json',\n    }\n\n    pipeline_id = f'github-{os.getenv(\"GITHUB_RUN_ID\", \"unknown\")}'\n    commit_sha = os.getenv('GITHUB_SHA', 'unknown')\n    branch = os.getenv('GITHUB_REF_NAME', 'unknown')\n\n    artifacts = await collector.collect_ci_artifacts(\n        pipeline_id=pipeline_id,\n        commit_sha=commit_sha,\n        branch=branch,\n        artifact_sources=artifact_sources\n    )\n\n    print(f'Collected {len(artifacts)} operational artifacts')\n\n    # Generate operational report\n    report = await collector.generate_operational_report(days_back=7)\n    print(f'Generated operational report with {len(report[\"recommendations\"])} recommendations')\n\nasyncio.run(main())\n\"\n\n    # Notification on failure\n    - name: Notify on failure\n      if: failure() && github.event_name == 'push'\n      run: |\n        echo \"Artifact collection failed for commit ${{ github.sha }}\"\n        # Add Slack notification or other alerting here\n\n  # Scheduled cleanup job\n  cleanup-old-artifacts:\n    runs-on: ubuntu-latest\n    if: github.event_name == 'schedule'\n\n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v4\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.11'\n\n    - name: Cleanup old artifacts\n      run: |\n        python -c \"\nimport asyncio\nimport sys\nsys.path.insert(0, 'packages')\n\nfrom core.operations.artifact_collector import (\n    OperationalArtifactCollector, CollectionConfig\n)\n\nasync def main():\n    collector = OperationalArtifactCollector()\n    await collector.cleanup_old_artifacts()\n    print('Completed artifact cleanup')\n\nasyncio.run(main())\n\"\n"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\github_workflow_integration.py",
    "line_number": 379,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    376:         return workflow_yaml\n    377: \n    378:     async def download_workflow_artifacts(self, workflow_run_id: str, download_dir: Path) -> dict[str, Path]:\n>>> 379:         \"\"\"Download artifacts from GitHub Actions workflow run.\"\"\"\n    380:         if not self.github_token:\n    381:             raise ValueError(\"GitHub token required for artifact download\")\n    382: ",
    "context": {
      "query_preview": "Download artifacts from GitHub Actions workflow run."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\github_workflow_integration.py",
    "line_number": 400,
    "column": 60,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    397:             artifact_path = download_dir / f\"{artifact_name}.zip\"\n    398:             downloaded_artifacts[artifact_name] = artifact_path\n    399: \n>>> 400:         logger.info(f\"Downloaded {len(downloaded_artifacts)} artifacts from workflow {workflow_run_id}\")\n    401:         return downloaded_artifacts\n    402: \n    403:     def create_workflow_file(self, output_path: Path):",
    "context": {
      "query_preview": " artifacts from workflow "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\github_workflow_integration.py",
    "line_number": 404,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    401:         return downloaded_artifacts\n    402: \n    403:     def create_workflow_file(self, output_path: Path):\n>>> 404:         \"\"\"Create GitHub Actions workflow file.\"\"\"\n    405:         workflow_yaml = self.generate_workflow_yaml()\n    406: \n    407:         # Create .github/workflows directory",
    "context": {
      "query_preview": "Create GitHub Actions workflow file."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\github_workflow_integration.py",
    "line_number": 415,
    "column": 22,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    412:         workflow_file = workflow_dir / f\"{self.config.workflow_name}.yml\"\n    413:         workflow_file.write_text(workflow_yaml)\n    414: \n>>> 415:         logger.info(f\"Created GitHub Actions workflow: {workflow_file}\")\n    416:         return workflow_file\n    417: \n    418:     async def integrate_with_collector(",
    "context": {
      "query_preview": "Created GitHub Actions workflow: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\github_workflow_integration.py",
    "line_number": 460,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    457: \n    458: \n    459: def create_github_integration_config() -> GitHubWorkflowConfig:\n>>> 460:     \"\"\"Create GitHub integration configuration from environment.\"\"\"\n    461:     return GitHubWorkflowConfig(\n    462:         github_token=os.getenv(\"GITHUB_TOKEN\"),\n    463:         repository=os.getenv(\"GITHUB_REPOSITORY\"),",
    "context": {
      "query_preview": "Create GitHub integration configuration from environment."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\github_workflow_integration.py",
    "line_number": 479,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    476:     pipeline_id: str | None = None,\n    477:     commit_sha: str | None = None,\n    478: ) -> list[ArtifactMetadata]:\n>>> 479:     \"\"\"Collect artifacts from local development environment.\"\"\"\n    480:     # Use git to get current commit info if not provided\n    481:     if not commit_sha:\n    482:         try:",
    "context": {
      "query_preview": "Collect artifacts from local development environment."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\github_workflow_integration.py",
    "line_number": 538,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    535: \n    536:         # Generate workflow file\n    537:         workflow_file = integration.create_workflow_file(Path.cwd())\n>>> 538:         print(f\"Created workflow file: {workflow_file}\")\n    539: \n    540:         # Create collector and collect local artifacts\n    541:         collector_config = CollectionConfig()",
    "context": {
      "query_preview": "Created workflow file: "
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\operations\\github_workflow_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'os' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "os",
      "method_count": 9,
      "methods": [
        "getenv"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 140,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    137:         return {\"error\": f\"Unknown action: {action}\", \"status\": 400}\n    138: \n    139:     async def create_agent(self, user_id: str, tenant_id: str, params: dict[str, Any]) -> dict[str, Any]:\n>>> 140:         \"\"\"Create new agent with tenant isolation.\"\"\"\n    141:         if not await self.rbac.check_permission(user_id, Permission.AGENT_CREATE):\n    142:             return {\"error\": \"Permission denied\", \"status\": 403}\n    143: ",
    "context": {
      "query_preview": "Create new agent with tenant isolation."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 233,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    230:         }\n    231: \n    232:     async def update_agent(self, user_id: str, tenant_id: str, agent_id: str, params: dict[str, Any]) -> dict[str, Any]:\n>>> 233:         \"\"\"Update agent configuration.\"\"\"\n    234:         if not await self.rbac.check_permission(user_id, Permission.AGENT_UPDATE, agent_id):\n    235:             return {\"error\": \"Permission denied\", \"status\": 403}\n    236: ",
    "context": {
      "query_preview": "Update agent configuration."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 248,
    "column": 33,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    245:             )\n    246: \n    247:             if not success:\n>>> 248:                 return {\"error\": \"Agent not found or update failed\", \"status\": 404}\n    249: \n    250:         except Exception as e:\n    251:             return {\"error\": f\"Update failed: {e!s}\", \"status\": 400}",
    "context": {
      "query_preview": "Agent not found or update failed"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 252,
    "column": 51,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    249: \n    250:         except Exception as e:\n    251:             return {\"error\": f\"Update failed: {e!s}\", \"status\": 400}\n>>> 252:         return {\"status\": 200, \"data\": {\"message\": \"Agent updated successfully\"}}\n    253: \n    254:     async def delete_agent(self, user_id: str, tenant_id: str, agent_id: str) -> dict[str, Any]:\n    255:         \"\"\"Delete agent.\"\"\"",
    "context": {
      "query_preview": "Agent updated successfully"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 266,
    "column": 51,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    263:         if not success:\n    264:             return {\"error\": \"Agent not found\", \"status\": 404}\n    265: \n>>> 266:         return {\"status\": 200, \"data\": {\"message\": \"Agent deleted successfully\"}}\n    267: \n    268: \n    269: class RAGSystemIntegration:",
    "context": {
      "query_preview": "Agent deleted successfully"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 301,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    298:         return {\"error\": f\"Unknown action: {action}\", \"status\": 400}\n    299: \n    300:     async def create_collection(self, user_id: str, tenant_id: str, params: dict[str, Any]) -> dict[str, Any]:\n>>> 301:         \"\"\"Create RAG collection with tenant isolation.\"\"\"\n    302:         if not await self.rbac.check_permission(user_id, Permission.RAG_CREATE):\n    303:             return {\"error\": \"Permission denied\", \"status\": 403}\n    304: ",
    "context": {
      "query_preview": "Create RAG collection with tenant isolation."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 391,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    388:         }\n    389: \n    390:     async def delete_collection(self, user_id: str, tenant_id: str, collection_id: str) -> dict[str, Any]:\n>>> 391:         \"\"\"Delete RAG collection.\"\"\"\n    392:         if not await self.rbac.check_permission(user_id, Permission.RAG_DELETE, collection_id):\n    393:             return {\"error\": \"Permission denied\", \"status\": 403}\n    394: ",
    "context": {
      "query_preview": "Delete RAG collection."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 404,
    "column": 51,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    401:                 return {\"error\": \"Collection not found\", \"status\": 404}\n    402:         except Exception as e:\n    403:             return {\"error\": f\"Deletion failed: {e!s}\", \"status\": 400}\n>>> 404:         return {\"status\": 200, \"data\": {\"message\": \"Collection deleted successfully\"}}\n    405: \n    406: \n    407: class P2PNetworkIntegration:",
    "context": {
      "query_preview": "Collection deleted successfully"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 439,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    436:         return {\"error\": f\"Unknown action: {action}\", \"status\": 400}\n    437: \n    438:     async def create_network(self, user_id: str, tenant_id: str, params: dict[str, Any]) -> dict[str, Any]:\n>>> 439:         \"\"\"Create P2P network with tenant isolation.\"\"\"\n    440:         if not await self.rbac.check_permission(user_id, Permission.P2P_CREATE):\n    441:             return {\"error\": \"Permission denied\", \"status\": 403}\n    442: ",
    "context": {
      "query_preview": "Create P2P network with tenant isolation."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 473,
    "column": 27,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    470:         return {\n    471:             \"status\": 200,\n    472:             \"data\": {\n>>> 473:                 \"message\": \"Joined network successfully\",\n    474:                 \"network_id\": network_id,\n    475:                 \"peer_id\": f\"peer_{user_id}_{datetime.utcnow().timestamp()}\",\n    476:             },",
    "context": {
      "query_preview": "Joined network successfully"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 656,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    653:         return {\"error\": f\"Unknown action: {action}\", \"status\": 400}\n    654: \n    655:     async def create_twin(self, user_id: str, tenant_id: str, params: dict[str, Any]) -> dict[str, Any]:\n>>> 656:         \"\"\"Create digital twin with privacy protection.\"\"\"\n    657:         if not await self.rbac.check_permission(user_id, Permission.AGENT_CREATE):\n    658:             return {\"error\": \"Permission denied\", \"status\": 403}\n    659: ",
    "context": {
      "query_preview": "Create digital twin with privacy protection."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 700,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    697:         }\n    698: \n    699:     async def update_twin(self, user_id: str, tenant_id: str, twin_id: str, params: dict[str, Any]) -> dict[str, Any]:\n>>> 700:         \"\"\"Update digital twin settings.\"\"\"\n    701:         # Users can only update their own twins\n    702:         user = self.rbac.users.get(user_id)\n    703:         if not user or user.tenant_id != tenant_id:",
    "context": {
      "query_preview": "Update digital twin settings."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 706,
    "column": 51,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    703:         if not user or user.tenant_id != tenant_id:\n    704:             return {\"error\": \"Permission denied\", \"status\": 403}\n    705: \n>>> 706:         return {\"status\": 200, \"data\": {\"message\": \"Digital twin updated successfully\"}}\n    707: \n    708:     async def get_twin_status(self, user_id: str, tenant_id: str, twin_id: str) -> dict[str, Any]:\n    709:         \"\"\"Get digital twin status.\"\"\"",
    "context": {
      "query_preview": "Digital twin updated successfully"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (27 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 27,
      "methods": [
        "create_network",
        "send_message",
        "query_rag",
        "execute_agent",
        "delete_collection",
        "update_agent",
        "start_training",
        "create_twin",
        "create_collection",
        "join_network",
        "network_status",
        "list_devices",
        "privacy_report",
        "get_agent",
        "list_networks",
        "list_training_jobs",
        "delete_agent",
        "get_twin_status",
        "create_agent",
        "resource_policy",
        "list_agents",
        "training_status",
        "update_twin",
        "add_documents",
        "device_status",
        "register_device",
        "list_collections"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'params' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "params",
      "method_count": 9,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (13 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 13,
      "methods": [
        "utcnow"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 57,
    "column": 69,
    "description": "Excessive magic literals detected (77 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     54:             # Validate user and tenant\n     55:             user = self.rbac.users.get(user_id)\n     56:             if not user or user.tenant_id != tenant_id:\n>>>  57:                 return {\"error\": \"Invalid user or tenant\", \"status\": 403}\n     58: \n     59:             # Route to appropriate integration\n     60:             if system == \"agents\":",
    "context": {
      "total_magic_literals": 77,
      "current_value": 403
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 76,
    "column": 68,
    "description": "Excessive magic literals detected (77 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     73:                 )\n     74:             if system == \"mobile\":\n     75:                 return await self.mobile_integration.handle_request(action, user_id, tenant_id, resource_id, params)\n>>>  76:             return {\"error\": f\"Unknown system: {system}\", \"status\": 400}\n     77: \n     78:         except PermissionError as e:\n     79:             return {\"error\": str(e), \"status\": 403}",
    "context": {
      "total_magic_literals": 77,
      "current_value": 400
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 79,
    "column": 47,
    "description": "Excessive magic literals detected (77 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     76:             return {\"error\": f\"Unknown system: {system}\", \"status\": 400}\n     77: \n     78:         except PermissionError as e:\n>>>  79:             return {\"error\": str(e), \"status\": 403}\n     80:         except Exception as e:\n     81:             logger.error(f\"API call error: {e}\")\n     82:             return {\"error\": \"Internal server error\", \"status\": 500}",
    "context": {
      "total_magic_literals": 77,
      "current_value": 403
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 82,
    "column": 64,
    "description": "Excessive magic literals detected (77 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     79:             return {\"error\": str(e), \"status\": 403}\n     80:         except Exception as e:\n     81:             logger.error(f\"API call error: {e}\")\n>>>  82:             return {\"error\": \"Internal server error\", \"status\": 500}\n     83: \n     84:     def require_system_permission(self, permission: Permission):\n     85:         \"\"\"Decorator for protecting system-level operations.\"\"\"",
    "context": {
      "total_magic_literals": 77,
      "current_value": 500
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\aivillage_rbac_integration.py",
    "line_number": 137,
    "column": 64,
    "description": "Excessive magic literals detected (77 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    134:             return await self.update_agent(user_id, tenant_id, resource_id, params)\n    135:         if action == \"delete_agent\":\n    136:             return await self.delete_agent(user_id, tenant_id, resource_id)\n>>> 137:         return {\"error\": f\"Unknown action: {action}\", \"status\": 400}\n    138: \n    139:     async def create_agent(self, user_id: str, tenant_id: str, params: dict[str, Any]) -> dict[str, Any]:\n    140:         \"\"\"Create new agent with tenant isolation.\"\"\"",
    "context": {
      "total_magic_literals": 77,
      "current_value": 400
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 47,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     44:         tenant_id=tenant.tenant_id,\n     45:         role=Role.DEVELOPER,\n     46:     )\n>>>  47:     print(f\"   Created developer: {developer.username}\")\n     48: \n     49:     data_scientist = await rbac.create_user(\n     50:         username=\"bob_scientist\",",
    "context": {
      "query_preview": "   Created developer: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 56,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     53:         tenant_id=tenant.tenant_id,\n     54:         role=Role.DATA_SCIENTIST,\n     55:     )\n>>>  56:     print(f\"   Created data scientist: {data_scientist.username}\")\n     57: \n     58:     regular_user = await rbac.create_user(\n     59:         username=\"charlie_user\",",
    "context": {
      "query_preview": "   Created data scientist: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 65,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     62:         tenant_id=tenant.tenant_id,\n     63:         role=Role.USER,\n     64:     )\n>>>  65:     print(f\"   Created regular user: {regular_user.username}\")\n     66: \n     67:     # Test authentication\n     68:     print(\"\\n4. Testing authentication...\")",
    "context": {
      "query_preview": "   Created regular user: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 165,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    162:     )\n    163: \n    164:     if rag_result.get(\"status\") == 201:\n>>> 165:         print(f\"   \u2705 RAG collection created: {rag_result['data']['collection_id']}\")\n    166:         collection_id = rag_result[\"data\"][\"collection_id\"]\n    167: \n    168:         # Query RAG (as regular user - should work)",
    "context": {
      "query_preview": "   \u2705 RAG collection created: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 198,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    195:     )\n    196: \n    197:     if p2p_result.get(\"status\") == 201:\n>>> 198:         print(f\"   \u2705 P2P network created: {p2p_result['data']['network_id']}\")\n    199:         network_id = p2p_result[\"data\"][\"network_id\"]\n    200: \n    201:         # Join network (as regular user - should work)",
    "context": {
      "query_preview": "   \u2705 P2P network created: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 212,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    209:         )\n    210: \n    211:         if join_result.get(\"status\") == 200:\n>>> 212:             print(f\"   \u2705 P2P network joined: {join_result['data']['peer_id']}\")\n    213:         else:\n    214:             print(f\"   \u274c P2P network join failed: {join_result.get('error')}\")\n    215:     else:",
    "context": {
      "query_preview": "   \u2705 P2P network joined: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 214,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    211:         if join_result.get(\"status\") == 200:\n    212:             print(f\"   \u2705 P2P network joined: {join_result['data']['peer_id']}\")\n    213:         else:\n>>> 214:             print(f\"   \u274c P2P network join failed: {join_result.get('error')}\")\n    215:     else:\n    216:         print(f\"   \u274c P2P network creation failed: {p2p_result.get('error')}\")\n    217: ",
    "context": {
      "query_preview": "   \u274c P2P network join failed: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 300,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    297:         endpoints = [\n    298:             \"POST /auth/login - User authentication\",\n    299:             \"POST /auth/refresh - Token refresh\",\n>>> 300:             \"POST /tenants - Create tenant\",\n    301:             \"POST /users - Create user\",\n    302:             \"GET  /agents - List agents\",\n    303:             \"POST /agents - Create agent\",",
    "context": {
      "query_preview": "POST /tenants - Create tenant"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 301,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    298:             \"POST /auth/login - User authentication\",\n    299:             \"POST /auth/refresh - Token refresh\",\n    300:             \"POST /tenants - Create tenant\",\n>>> 301:             \"POST /users - Create user\",\n    302:             \"GET  /agents - List agents\",\n    303:             \"POST /agents - Create agent\",\n    304:             \"POST /agents/{id}/execute - Execute agent\",",
    "context": {
      "query_preview": "POST /users - Create user"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 303,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    300:             \"POST /tenants - Create tenant\",\n    301:             \"POST /users - Create user\",\n    302:             \"GET  /agents - List agents\",\n>>> 303:             \"POST /agents - Create agent\",\n    304:             \"POST /agents/{id}/execute - Execute agent\",\n    305:             \"GET  /rag/collections - List RAG collections\",\n    306:             \"POST /rag/collections - Create RAG collection\",",
    "context": {
      "query_preview": "POST /agents - Create agent"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 306,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    303:             \"POST /agents - Create agent\",\n    304:             \"POST /agents/{id}/execute - Execute agent\",\n    305:             \"GET  /rag/collections - List RAG collections\",\n>>> 306:             \"POST /rag/collections - Create RAG collection\",\n    307:             \"POST /rag/collections/{id}/query - Query RAG\",\n    308:             \"POST /p2p/networks - Create P2P network\",\n    309:             \"GET  /p2p/networks - List P2P networks\",",
    "context": {
      "query_preview": "POST /rag/collections - Create RAG collection"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 308,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    305:             \"GET  /rag/collections - List RAG collections\",\n    306:             \"POST /rag/collections - Create RAG collection\",\n    307:             \"POST /rag/collections/{id}/query - Query RAG\",\n>>> 308:             \"POST /p2p/networks - Create P2P network\",\n    309:             \"GET  /p2p/networks - List P2P networks\",\n    310:             \"POST /agent-forge/training - Start training\",\n    311:             \"POST /digital-twin - Create digital twin\",",
    "context": {
      "query_preview": "POST /p2p/networks - Create P2P network"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 311,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    308:             \"POST /p2p/networks - Create P2P network\",\n    309:             \"GET  /p2p/networks - List P2P networks\",\n    310:             \"POST /agent-forge/training - Start training\",\n>>> 311:             \"POST /digital-twin - Create digital twin\",\n    312:             \"POST /mobile/devices - Register device\",\n    313:             \"GET  /audit/logs - Get audit logs\",\n    314:         ]",
    "context": {
      "query_preview": "POST /digital-twin - Create digital twin"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 321,
    "column": 14,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    318: \n    319:         print(\"\\n\ud83d\ude80 To start the API server:\")\n    320:         print(\"   python -m packages.core.security.rbac_api_server\")\n>>> 321:         print(\"   Then visit: http://localhost:8000/docs\")\n    322: \n    323:         return server\n    324: ",
    "context": {
      "hardcoded_value": "   Then visit: http://localhost:8000/docs"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'rbac' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "rbac",
      "method_count": 10,
      "methods": [
        "get_audit_log",
        "create_user",
        "check_permission",
        "authenticate",
        "create_tenant"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'integration' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "integration",
      "method_count": 8,
      "methods": [
        "secure_api_call"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 20,
    "column": 16,
    "description": "Excessive magic literals detected (14 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     17: async def demo_rbac_system():\n     18:     \"\"\"Comprehensive demo of RBAC system with AIVillage integration.\"\"\"\n     19:     print(\"\ud83d\ude80 AIVillage RBAC Integration Demo\")\n>>>  20:     print(\"=\" * 50)\n     21: \n     22:     # Initialize RBAC system\n     23:     print(\"\\n1. Initializing RBAC system...\")",
    "context": {
      "total_magic_literals": 14,
      "current_value": 50
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 33,
    "column": 30,
    "description": "Excessive magic literals detected (14 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     30:     tenant = await rbac.create_tenant(\n     31:         name=\"Demo Corporation\",\n     32:         admin_user={\"username\": \"demo_admin\", \"email\": \"admin@demo.corp\", \"password\": \"SecurePassword123!\"},\n>>>  33:         config={\"max_agents\": 20, \"max_rag_collections\": 10, \"storage_quota_gb\": 500},\n     34:     )\n     35:     print(f\"   Created tenant: {tenant.name} ({tenant.tenant_id})\")\n     36: ",
    "context": {
      "total_magic_literals": 14,
      "current_value": 20
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 33,
    "column": 81,
    "description": "Excessive magic literals detected (14 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     30:     tenant = await rbac.create_tenant(\n     31:         name=\"Demo Corporation\",\n     32:         admin_user={\"username\": \"demo_admin\", \"email\": \"admin@demo.corp\", \"password\": \"SecurePassword123!\"},\n>>>  33:         config={\"max_agents\": 20, \"max_rag_collections\": 10, \"storage_quota_gb\": 500},\n     34:     )\n     35:     print(f\"   Created tenant: {tenant.name} ({tenant.tenant_id})\")\n     36: ",
    "context": {
      "total_magic_literals": 14,
      "current_value": 500
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 114,
    "column": 88,
    "description": "Excessive magic literals detected (14 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    111:         action=\"create_agent\",\n    112:         user_id=developer.user_id,\n    113:         tenant_id=tenant.tenant_id,\n>>> 114:         params={\"name\": \"demo_agent\", \"type\": \"king_agent\", \"config\": {\"max_memory_mb\": 1024}},\n    115:     )\n    116: \n    117:     if agent_result.get(\"status\") == 201:",
    "context": {
      "total_magic_literals": 14,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\demo_rbac_integration.py",
    "line_number": 117,
    "column": 37,
    "description": "Excessive magic literals detected (14 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    114:         params={\"name\": \"demo_agent\", \"type\": \"king_agent\", \"config\": {\"max_memory_mb\": 1024}},\n    115:     )\n    116: \n>>> 117:     if agent_result.get(\"status\") == 201:\n    118:         print(f\"   \u2705 Agent created: {agent_result['data']['agent_id']}\")\n    119:         agent_id = agent_result[\"data\"][\"agent_id\"]\n    120: ",
    "context": {
      "total_magic_literals": 14,
      "current_value": 201
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\digital_twin_encryption.py",
    "line_number": 17,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     14:     \"\"\"Handles encryption/decryption for digital twin sensitive data.\"\"\"\n     15: \n     16:     def __init__(self):\n>>>  17:         \"\"\"Initialize encryption with key from environment or generate new one.\"\"\"\n     18:         key_b64 = os.environ.get(\"DIGITAL_TWIN_ENCRYPTION_KEY\")\n     19:         if not key_b64:\n     20:             raise DigitalTwinEncryptionError(\"DIGITAL_TWIN_ENCRYPTION_KEY environment variable required\")",
    "context": {
      "query_preview": "Initialize encryption with key from environment or generate new one."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 52,
    "column": 0,
    "description": "Class 'MultiTenantManager' is a God Object: 6 methods, ~685 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "     49:     STORAGE_BUCKET = \"storage_bucket\"\n     50: \n     51: \n>>>  52: class MultiTenantManager:\n     53:     \"\"\"Manages multi-tenant resource isolation and lifecycle.\"\"\"\n     54: \n     55:     def __init__(",
    "context": {
      "method_count": 6,
      "estimated_lines": 685,
      "class_name": "MultiTenantManager",
      "data_methods": 0,
      "business_methods": 6
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 85,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     82:         conn = sqlite3.connect(self.db_path)\n     83:         cursor = conn.cursor()\n     84: \n>>>  85:         cursor.execute(\n     86:             \"\"\"\n     87:             CREATE TABLE IF NOT EXISTS resources (\n     88:                 resource_id TEXT PRIMARY KEY,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 86,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     83:         cursor = conn.cursor()\n     84: \n     85:         cursor.execute(\n>>>  86:             \"\"\"\n     87:             CREATE TABLE IF NOT EXISTS resources (\n     88:                 resource_id TEXT PRIMARY KEY,\n     89:                 tenant_id TEXT NOT NULL,",
    "context": {
      "query_preview": "\n            CREATE TABLE IF NOT EXISTS resources (\n                resource_id TEXT PRIMARY KEY,\n  ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 103,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    100:         \"\"\",\n    101:         )\n    102: \n>>> 103:         cursor.execute(\n    104:             \"\"\"\n    105:             CREATE INDEX IF NOT EXISTS idx_tenant_resources\n    106:             ON resources(tenant_id, resource_type)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 104,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    101:         )\n    102: \n    103:         cursor.execute(\n>>> 104:             \"\"\"\n    105:             CREATE INDEX IF NOT EXISTS idx_tenant_resources\n    106:             ON resources(tenant_id, resource_type)\n    107:         \"\"\",",
    "context": {
      "query_preview": "\n            CREATE INDEX IF NOT EXISTS idx_tenant_resources\n            ON resources(tenant_id, res..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 110,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    107:         \"\"\",\n    108:         )\n    109: \n>>> 110:         cursor.execute(\n    111:             \"\"\"\n    112:             CREATE TABLE IF NOT EXISTS resource_usage (\n    113:                 id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 111,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    108:         )\n    109: \n    110:         cursor.execute(\n>>> 111:             \"\"\"\n    112:             CREATE TABLE IF NOT EXISTS resource_usage (\n    113:                 id INTEGER PRIMARY KEY AUTOINCREMENT,\n    114:                 tenant_id TEXT NOT NULL,",
    "context": {
      "query_preview": "\n            CREATE TABLE IF NOT EXISTS resource_usage (\n                id INTEGER PRIMARY KEY AUTO..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 125,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    122:         \"\"\",\n    123:         )\n    124: \n>>> 125:         conn.commit()\n    126:         conn.close()\n    127: \n    128:     def _load_resources(self):",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 129,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    126:         conn.close()\n    127: \n    128:     def _load_resources(self):\n>>> 129:         \"\"\"Load existing resources from database.\"\"\"\n    130:         conn = sqlite3.connect(self.db_path)\n    131:         cursor = conn.cursor()\n    132: ",
    "context": {
      "query_preview": "Load existing resources from database."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 133,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    130:         conn = sqlite3.connect(self.db_path)\n    131:         cursor = conn.cursor()\n    132: \n>>> 133:         cursor.execute(\"SELECT * FROM resources WHERE status = 'active'\")\n    134:         rows = cursor.fetchall()\n    135: \n    136:         for row in rows:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 133,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    130:         conn = sqlite3.connect(self.db_path)\n    131:         cursor = conn.cursor()\n    132: \n>>> 133:         cursor.execute(\"SELECT * FROM resources WHERE status = 'active'\")\n    134:         rows = cursor.fetchall()\n    135: \n    136:         for row in rows:",
    "context": {
      "query_preview": "SELECT * FROM resources WHERE status = 'active'"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 160,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    157:     async def create_agent(\n    158:         self, tenant_id: str, user_id: str, agent_name: str, agent_type: str, config: dict[str, Any],\n    159:     ) -> TenantResource:\n>>> 160:         \"\"\"Create isolated agent for tenant.\"\"\"\n    161:         # Check permissions\n    162:         if not await self.rbac.check_permission(user_id, Permission.AGENT_CREATE):\n    163:             raise PermissionError(f\"User {user_id} cannot create agents\")",
    "context": {
      "query_preview": "Create isolated agent for tenant."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 163,
    "column": 50,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    160:         \"\"\"Create isolated agent for tenant.\"\"\"\n    161:         # Check permissions\n    162:         if not await self.rbac.check_permission(user_id, Permission.AGENT_CREATE):\n>>> 163:             raise PermissionError(f\"User {user_id} cannot create agents\")\n    164: \n    165:         # Check quota\n    166:         if not await self.rbac.check_quota(tenant_id, \"agents\"):",
    "context": {
      "query_preview": " cannot create agents"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 239,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    236:         return self.tenant_resources[tenant_id][ResourceType.AGENT]\n    237: \n    238:     async def delete_agent(self, tenant_id: str, user_id: str, agent_name: str) -> bool:\n>>> 239:         \"\"\"Delete agent and clean up resources.\"\"\"\n    240:         # Check permissions\n    241:         if not await self.rbac.check_permission(user_id, Permission.AGENT_DELETE):\n    242:             raise PermissionError(f\"User {user_id} cannot delete agents\")",
    "context": {
      "query_preview": "Delete agent and clean up resources."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 242,
    "column": 50,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    239:         \"\"\"Delete agent and clean up resources.\"\"\"\n    240:         # Check permissions\n    241:         if not await self.rbac.check_permission(user_id, Permission.AGENT_DELETE):\n>>> 242:             raise PermissionError(f\"User {user_id} cannot delete agents\")\n    243: \n    244:         # Find agent\n    245:         agents = self.tenant_resources[tenant_id][ResourceType.AGENT]",
    "context": {
      "query_preview": " cannot delete agents"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 276,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    273:     async def create_rag_collection(\n    274:         self, tenant_id: str, user_id: str, collection_name: str, config: dict[str, Any],\n    275:     ) -> TenantResource:\n>>> 276:         \"\"\"Create isolated RAG collection for tenant.\"\"\"\n    277:         # Check permissions\n    278:         if not await self.rbac.check_permission(user_id, Permission.RAG_CREATE):\n    279:             raise PermissionError(f\"User {user_id} cannot create RAG collections\")",
    "context": {
      "query_preview": "Create isolated RAG collection for tenant."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 279,
    "column": 50,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    276:         \"\"\"Create isolated RAG collection for tenant.\"\"\"\n    277:         # Check permissions\n    278:         if not await self.rbac.check_permission(user_id, Permission.RAG_CREATE):\n>>> 279:             raise PermissionError(f\"User {user_id} cannot create RAG collections\")\n    280: \n    281:         # Check quota\n    282:         if not await self.rbac.check_quota(tenant_id, \"rag_collections\"):",
    "context": {
      "query_preview": " cannot create RAG collections"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 333,
    "column": 22,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    330:         # Update quota\n    331:         await self.rbac.update_quota_usage(tenant_id, \"rag_collections\", 1, \"add\")\n    332: \n>>> 333:         logger.info(f\"Created RAG collection {collection_id} for tenant {tenant_id}\")\n    334:         return resource\n    335: \n    336:     async def add_documents_to_rag(",
    "context": {
      "query_preview": "Created RAG collection "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 342,
    "column": 50,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    339:         \"\"\"Add documents to RAG collection with isolation.\"\"\"\n    340:         # Check permissions\n    341:         if not await self.rbac.check_permission(user_id, Permission.RAG_UPDATE):\n>>> 342:             raise PermissionError(f\"User {user_id} cannot update RAG collections\")\n    343: \n    344:         # Find collection\n    345:         collections = self.tenant_resources[tenant_id][ResourceType.RAG_COLLECTION]",
    "context": {
      "query_preview": " cannot update RAG collections"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 376,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    373:     async def create_p2p_network(\n    374:         self, tenant_id: str, user_id: str, network_name: str, config: dict[str, Any],\n    375:     ) -> TenantResource:\n>>> 376:         \"\"\"Create isolated P2P network for tenant.\"\"\"\n    377:         # Check permissions\n    378:         if not await self.rbac.check_permission(user_id, Permission.P2P_CREATE):\n    379:             raise PermissionError(f\"User {user_id} cannot create P2P networks\")",
    "context": {
      "query_preview": "Create isolated P2P network for tenant."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 379,
    "column": 50,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    376:         \"\"\"Create isolated P2P network for tenant.\"\"\"\n    377:         # Check permissions\n    378:         if not await self.rbac.check_permission(user_id, Permission.P2P_CREATE):\n>>> 379:             raise PermissionError(f\"User {user_id} cannot create P2P networks\")\n    380: \n    381:         # Create isolated network configuration\n    382:         network_id = f\"{tenant_id}_p2p_{network_name}_{datetime.utcnow().timestamp()}\"",
    "context": {
      "query_preview": " cannot create P2P networks"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 525,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    522:         # Store sharing configuration in database\n    523:         sharing_db_path = self.data_path / \"tenant_sharing.db\"\n    524:         with sqlite3.connect(sharing_db_path) as conn:\n>>> 525:             conn.execute(\n    526:                 \"\"\"CREATE TABLE IF NOT EXISTS resource_sharing (\n    527:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    528:                     resource_id TEXT NOT NULL,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 526,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    523:         sharing_db_path = self.data_path / \"tenant_sharing.db\"\n    524:         with sqlite3.connect(sharing_db_path) as conn:\n    525:             conn.execute(\n>>> 526:                 \"\"\"CREATE TABLE IF NOT EXISTS resource_sharing (\n    527:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    528:                     resource_id TEXT NOT NULL,\n    529:                     owner_tenant TEXT NOT NULL,",
    "context": {
      "query_preview": "CREATE TABLE IF NOT EXISTS resource_sharing (\n                    id INTEGER PRIMARY KEY AUTOINCREME..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 538,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    535:                 )\"\"\",\n    536:             )\n    537: \n>>> 538:             conn.execute(\n    539:                 \"\"\"INSERT INTO resource_sharing\n    540:                    (resource_id, owner_tenant, shared_with, permissions, shared_at, shared_by)\n    541:                    VALUES (?, ?, ?, ?, ?, ?)\"\"\",",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 539,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    536:             )\n    537: \n    538:             conn.execute(\n>>> 539:                 \"\"\"INSERT INTO resource_sharing\n    540:                    (resource_id, owner_tenant, shared_with, permissions, shared_at, shared_by)\n    541:                    VALUES (?, ?, ?, ?, ?, ?)\"\"\",\n    542:                 (",
    "context": {
      "query_preview": "INSERT INTO resource_sharing\n                   (resource_id, owner_tenant, shared_with, permissions..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 551,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    548:                     user_id,\n    549:                 ),\n    550:             )\n>>> 551:             conn.commit()\n    552: \n    553:         # Update resource metadata to include sharing info\n    554:         if resource.metadata is None:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 614,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    611:         if not resource:\n    612:             return\n    613: \n>>> 614:         cursor.execute(\n    615:             \"\"\"\n    616:             INSERT INTO resource_usage\n    617:             (tenant_id, resource_type, timestamp, cpu_percent, memory_mb, storage_gb, network_mb)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 615,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    612:             return\n    613: \n    614:         cursor.execute(\n>>> 615:             \"\"\"\n    616:             INSERT INTO resource_usage\n    617:             (tenant_id, resource_type, timestamp, cpu_percent, memory_mb, storage_gb, network_mb)\n    618:             VALUES (?, ?, ?, ?, ?, ?, ?)",
    "context": {
      "query_preview": "\n            INSERT INTO resource_usage\n            (tenant_id, resource_type, timestamp, cpu_percen..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 631,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    628:             ),\n    629:         )\n    630: \n>>> 631:         conn.commit()\n    632:         conn.close()\n    633: \n    634:     # Cleanup and Maintenance",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 640,
    "column": 50,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    637:         \"\"\"Clean up all resources for tenant.\"\"\"\n    638:         # Check permissions\n    639:         if not await self.rbac.check_permission(user_id, Permission.TENANT_DELETE):\n>>> 640:             raise PermissionError(f\"User {user_id} cannot delete tenant resources\")\n    641: \n    642:         # Delete all tenant resources\n    643:         for resource_type, resources in self.tenant_resources[tenant_id].items():",
    "context": {
      "query_preview": " cannot delete tenant resources"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 670,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    667:         conn = sqlite3.connect(self.db_path)\n    668:         cursor = conn.cursor()\n    669: \n>>> 670:         cursor.execute(\n    671:             \"\"\"\n    672:             INSERT OR REPLACE INTO resources\n    673:             (resource_id, tenant_id, resource_type, name, created_at,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 671,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    668:         cursor = conn.cursor()\n    669: \n    670:         cursor.execute(\n>>> 671:             \"\"\"\n    672:             INSERT OR REPLACE INTO resources\n    673:             (resource_id, tenant_id, resource_type, name, created_at,\n    674:              metadata, data_path, config, status, size_bytes)",
    "context": {
      "query_preview": "\n            INSERT OR REPLACE INTO resources\n            (resource_id, tenant_id, resource_type, na..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 691,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    688:             ),\n    689:         )\n    690: \n>>> 691:         conn.commit()\n    692:         conn.close()\n    693: \n    694:     def _delete_resource(self, resource_id: str):",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 695,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    692:         conn.close()\n    693: \n    694:     def _delete_resource(self, resource_id: str):\n>>> 695:         \"\"\"Delete resource from database.\"\"\"\n    696:         conn = sqlite3.connect(self.db_path)\n    697:         cursor = conn.cursor()\n    698: ",
    "context": {
      "query_preview": "Delete resource from database."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 699,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    696:         conn = sqlite3.connect(self.db_path)\n    697:         cursor = conn.cursor()\n    698: \n>>> 699:         cursor.execute(\"UPDATE resources SET status = 'deleted' WHERE resource_id = ?\", (resource_id,))\n    700: \n    701:         conn.commit()\n    702:         conn.close()",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 699,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    696:         conn = sqlite3.connect(self.db_path)\n    697:         cursor = conn.cursor()\n    698: \n>>> 699:         cursor.execute(\"UPDATE resources SET status = 'deleted' WHERE resource_id = ?\", (resource_id,))\n    700: \n    701:         conn.commit()\n    702:         conn.close()",
    "context": {
      "query_preview": "UPDATE resources SET status = 'deleted' WHERE resource_id = ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 701,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    698: \n    699:         cursor.execute(\"UPDATE resources SET status = 'deleted' WHERE resource_id = ?\", (resource_id,))\n    700: \n>>> 701:         conn.commit()\n    702:         conn.close()\n    703: \n    704:     def _update_resource_size(self, resource_id: str, size_bytes: int):",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 705,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    702:         conn.close()\n    703: \n    704:     def _update_resource_size(self, resource_id: str, size_bytes: int):\n>>> 705:         \"\"\"Update resource size in database.\"\"\"\n    706:         conn = sqlite3.connect(self.db_path)\n    707:         cursor = conn.cursor()\n    708: ",
    "context": {
      "query_preview": "Update resource size in database."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 709,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    706:         conn = sqlite3.connect(self.db_path)\n    707:         cursor = conn.cursor()\n    708: \n>>> 709:         cursor.execute(\"UPDATE resources SET size_bytes = ? WHERE resource_id = ?\", (size_bytes, resource_id))\n    710: \n    711:         conn.commit()\n    712:         conn.close()",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 709,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    706:         conn = sqlite3.connect(self.db_path)\n    707:         cursor = conn.cursor()\n    708: \n>>> 709:         cursor.execute(\"UPDATE resources SET size_bytes = ? WHERE resource_id = ?\", (size_bytes, resource_id))\n    710: \n    711:         conn.commit()\n    712:         conn.close()",
    "context": {
      "query_preview": "UPDATE resources SET size_bytes = ? WHERE resource_id = ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 711,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    708: \n    709:         cursor.execute(\"UPDATE resources SET size_bytes = ? WHERE resource_id = ?\", (size_bytes, resource_id))\n    710: \n>>> 711:         conn.commit()\n    712:         conn.close()\n    713: \n    714:     async def _get_resource_by_id(self, resource_id: str) -> TenantResource | None:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 715,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    712:         conn.close()\n    713: \n    714:     async def _get_resource_by_id(self, resource_id: str) -> TenantResource | None:\n>>> 715:         \"\"\"Get resource by ID from database.\"\"\"\n    716:         conn = sqlite3.connect(self.db_path)\n    717:         cursor = conn.cursor()\n    718: ",
    "context": {
      "query_preview": "Get resource by ID from database."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 719,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    716:         conn = sqlite3.connect(self.db_path)\n    717:         cursor = conn.cursor()\n    718: \n>>> 719:         cursor.execute(\"SELECT * FROM resources WHERE resource_id = ? AND status = 'active'\", (resource_id,))\n    720:         row = cursor.fetchone()\n    721:         conn.close()\n    722: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 719,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    716:         conn = sqlite3.connect(self.db_path)\n    717:         cursor = conn.cursor()\n    718: \n>>> 719:         cursor.execute(\"SELECT * FROM resources WHERE resource_id = ? AND status = 'active'\", (resource_id,))\n    720:         row = cursor.fetchone()\n    721:         conn.close()\n    722: ",
    "context": {
      "query_preview": "SELECT * FROM resources WHERE resource_id = ? AND status = 'active'"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 787,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    784:                 collection_name=\"knowledge_base\",\n    785:                 config={\"vector_db_type\": \"faiss\"},\n    786:             )\n>>> 787:             print(f\"Created RAG collection: {rag.resource_id}\")\n    788: \n    789:             # Get usage\n    790:             usage = await manager.get_tenant_usage(tenant_id=tenant.tenant_id, user_id=admin_user.user_id)",
    "context": {
      "query_preview": "Created RAG collection: "
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 665,
    "column": 4,
    "description": "Duplicate code block detected in function '_save_resource'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    662: \n    663:     # Database Operations\n    664: \n>>> 665:     def _save_resource(self, resource: TenantResource):\n    666:         \"\"\"Save resource to database.\"\"\"\n    667:         conn = sqlite3.connect(self.db_path)\n    668:         cursor = conn.cursor()",
    "context": {
      "duplicate_count": 3,
      "function_name": "_save_resource",
      "signature": "ASSIGN|ASSIGN|CALL_execute|CALL_commit|CALL_close"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 694,
    "column": 4,
    "description": "Duplicate code block detected in function '_delete_resource'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    691:         conn.commit()\n    692:         conn.close()\n    693: \n>>> 694:     def _delete_resource(self, resource_id: str):\n    695:         \"\"\"Delete resource from database.\"\"\"\n    696:         conn = sqlite3.connect(self.db_path)\n    697:         cursor = conn.cursor()",
    "context": {
      "duplicate_count": 3,
      "function_name": "_delete_resource",
      "signature": "ASSIGN|ASSIGN|CALL_execute|CALL_commit|CALL_close"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 704,
    "column": 4,
    "description": "Duplicate code block detected in function '_update_resource_size'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    701:         conn.commit()\n    702:         conn.close()\n    703: \n>>> 704:     def _update_resource_size(self, resource_id: str, size_bytes: int):\n    705:         \"\"\"Update resource size in database.\"\"\"\n    706:         conn = sqlite3.connect(self.db_path)\n    707:         cursor = conn.cursor()",
    "context": {
      "duplicate_count": 3,
      "function_name": "_update_resource_size",
      "signature": "ASSIGN|ASSIGN|CALL_execute|CALL_commit|CALL_close"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 11,
      "methods": [
        "_delete_resource",
        "_get_resource_by_id",
        "_init_database",
        "_update_resource_size",
        "_save_resource",
        "_load_resources"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 11,
      "methods": [
        "info"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'sqlite3' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "sqlite3",
      "method_count": 8,
      "methods": [
        "connect"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'conn' methods (22 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "conn",
      "method_count": 22,
      "methods": [
        "close",
        "execute",
        "cursor",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'cursor' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "cursor",
      "method_count": 11,
      "methods": [
        "execute",
        "fetchone",
        "fetchall"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (14 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 14,
      "methods": [
        "utcnow",
        "fromisoformat"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'json' methods (13 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "json",
      "method_count": 13,
      "methods": [
        "dump",
        "dumps",
        "loads"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'config' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "config",
      "method_count": 10,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 141,
    "column": 25,
    "description": "Excessive magic literals detected (28 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    138:                 resource_id=row[0],\n    139:                 tenant_id=row[1],\n    140:                 resource_type=row[2],\n>>> 141:                 name=row[3],\n    142:                 created_at=datetime.fromisoformat(row[4]),\n    143:                 metadata=json.loads(row[5]) if row[5] else {},\n    144:                 data_path=Path(row[6]) if row[6] else None,",
    "context": {
      "total_magic_literals": 28,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 142,
    "column": 54,
    "description": "Excessive magic literals detected (28 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    139:                 tenant_id=row[1],\n    140:                 resource_type=row[2],\n    141:                 name=row[3],\n>>> 142:                 created_at=datetime.fromisoformat(row[4]),\n    143:                 metadata=json.loads(row[5]) if row[5] else {},\n    144:                 data_path=Path(row[6]) if row[6] else None,\n    145:                 config=json.loads(row[7]) if row[7] else {},",
    "context": {
      "total_magic_literals": 28,
      "current_value": 4
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 143,
    "column": 51,
    "description": "Excessive magic literals detected (28 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    140:                 resource_type=row[2],\n    141:                 name=row[3],\n    142:                 created_at=datetime.fromisoformat(row[4]),\n>>> 143:                 metadata=json.loads(row[5]) if row[5] else {},\n    144:                 data_path=Path(row[6]) if row[6] else None,\n    145:                 config=json.loads(row[7]) if row[7] else {},\n    146:                 status=row[8],",
    "context": {
      "total_magic_literals": 28,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 143,
    "column": 40,
    "description": "Excessive magic literals detected (28 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    140:                 resource_type=row[2],\n    141:                 name=row[3],\n    142:                 created_at=datetime.fromisoformat(row[4]),\n>>> 143:                 metadata=json.loads(row[5]) if row[5] else {},\n    144:                 data_path=Path(row[6]) if row[6] else None,\n    145:                 config=json.loads(row[7]) if row[7] else {},\n    146:                 status=row[8],",
    "context": {
      "total_magic_literals": 28,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_manager.py",
    "line_number": 144,
    "column": 46,
    "description": "Excessive magic literals detected (28 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    141:                 name=row[3],\n    142:                 created_at=datetime.fromisoformat(row[4]),\n    143:                 metadata=json.loads(row[5]) if row[5] else {},\n>>> 144:                 data_path=Path(row[6]) if row[6] else None,\n    145:                 config=json.loads(row[7]) if row[7] else {},\n    146:                 status=row[8],\n    147:                 size_bytes=row[9],",
    "context": {
      "total_magic_literals": 28,
      "current_value": 6
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 45,
    "column": 4,
    "description": "Function '__init__' has 9 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "     42: class ResourceQuota:\n     43:     \"\"\"Resource quotas for tenants.\"\"\"\n     44: \n>>>  45:     def __init__(\n     46:         self,\n     47:         max_users: int = 10,\n     48:         max_storage_gb: int = 10,",
    "context": {
      "parameter_count": 9,
      "function_name": "__init__"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 134,
    "column": 0,
    "description": "Class 'MultiTenantSystem' is a God Object: 20 methods, ~1066 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "    131:     metadata: dict[str, Any] = field(default_factory=dict)\n    132: \n    133: \n>>> 134: class MultiTenantSystem:\n    135:     \"\"\"Multi-tenant isolation and management system.\"\"\"\n    136: \n    137:     def __init__(self, db_path: str | None = None):",
    "context": {
      "method_count": 20,
      "estimated_lines": 1066,
      "class_name": "MultiTenantSystem",
      "data_methods": 7,
      "business_methods": 13
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 167,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    164:         \"\"\"Get database connection.\"\"\"\n    165:         conn = sqlite3.connect(self.db_path, timeout=30.0)\n    166:         conn.row_factory = sqlite3.Row\n>>> 167:         conn.execute(\"PRAGMA foreign_keys=ON\")\n    168:         try:\n    169:             yield conn\n    170:             conn.commit()",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 170,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    167:         conn.execute(\"PRAGMA foreign_keys=ON\")\n    168:         try:\n    169:             yield conn\n>>> 170:             conn.commit()\n    171:         except Exception:\n    172:             conn.rollback()\n    173:             raise",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 177,
    "column": 4,
    "description": "Method '_init_database' is too complex: 2 complexity, 217 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    174:         finally:\n    175:             conn.close()\n    176: \n>>> 177:     def _init_database(self):\n    178:         \"\"\"Initialize database schema.\"\"\"\n    179:         with self._get_connection() as conn:\n    180:             # Organizations table",
    "context": {
      "complexity": 2,
      "lines": 217,
      "max_nesting": 1,
      "method_name": "_init_database"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 181,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    178:         \"\"\"Initialize database schema.\"\"\"\n    179:         with self._get_connection() as conn:\n    180:             # Organizations table\n>>> 181:             conn.execute(\n    182:                 \"\"\"\n    183:                 CREATE TABLE IF NOT EXISTS organizations (\n    184:                     id TEXT PRIMARY KEY,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 182,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    179:         with self._get_connection() as conn:\n    180:             # Organizations table\n    181:             conn.execute(\n>>> 182:                 \"\"\"\n    183:                 CREATE TABLE IF NOT EXISTS organizations (\n    184:                     id TEXT PRIMARY KEY,\n    185:                     name TEXT UNIQUE NOT NULL,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS organizations (\n                    id TEXT PRIMARY KEY,..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 220,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    217:             )\n    218: \n    219:             # Workspaces table (sub-tenants within organizations)\n>>> 220:             conn.execute(\n    221:                 \"\"\"\n    222:                 CREATE TABLE IF NOT EXISTS workspaces (\n    223:                     id TEXT PRIMARY KEY,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 221,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    218: \n    219:             # Workspaces table (sub-tenants within organizations)\n    220:             conn.execute(\n>>> 221:                 \"\"\"\n    222:                 CREATE TABLE IF NOT EXISTS workspaces (\n    223:                     id TEXT PRIMARY KEY,\n    224:                     organization_id TEXT NOT NULL,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS workspaces (\n                    id TEXT PRIMARY KEY,\n  ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 249,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    246:             )\n    247: \n    248:             # Tenant memberships\n>>> 249:             conn.execute(\n    250:                 \"\"\"\n    251:                 CREATE TABLE IF NOT EXISTS tenant_memberships (\n    252:                     id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 250,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    247: \n    248:             # Tenant memberships\n    249:             conn.execute(\n>>> 250:                 \"\"\"\n    251:                 CREATE TABLE IF NOT EXISTS tenant_memberships (\n    252:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    253:                     user_id TEXT NOT NULL,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS tenant_memberships (\n                    id INTEGER PRIM..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 278,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    275:             )\n    276: \n    277:             # Resource quotas\n>>> 278:             conn.execute(\n    279:                 \"\"\"\n    280:                 CREATE TABLE IF NOT EXISTS resource_quotas (\n    281:                     id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 279,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    276: \n    277:             # Resource quotas\n    278:             conn.execute(\n>>> 279:                 \"\"\"\n    280:                 CREATE TABLE IF NOT EXISTS resource_quotas (\n    281:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    282:                     tenant_id TEXT NOT NULL,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS resource_quotas (\n                    id INTEGER PRIMARY..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 306,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    303:             )\n    304: \n    305:             # Resource usage tracking\n>>> 306:             conn.execute(\n    307:                 \"\"\"\n    308:                 CREATE TABLE IF NOT EXISTS resource_usage (\n    309:                     id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 307,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    304: \n    305:             # Resource usage tracking\n    306:             conn.execute(\n>>> 307:                 \"\"\"\n    308:                 CREATE TABLE IF NOT EXISTS resource_usage (\n    309:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    310:                     tenant_id TEXT NOT NULL,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS resource_usage (\n                    id INTEGER PRIMARY ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 336,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    333:             )\n    334: \n    335:             # Tenant data isolation mapping\n>>> 336:             conn.execute(\n    337:                 \"\"\"\n    338:                 CREATE TABLE IF NOT EXISTS tenant_data_isolation (\n    339:                     id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 337,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    334: \n    335:             # Tenant data isolation mapping\n    336:             conn.execute(\n>>> 337:                 \"\"\"\n    338:                 CREATE TABLE IF NOT EXISTS tenant_data_isolation (\n    339:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    340:                     tenant_id TEXT NOT NULL,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS tenant_data_isolation (\n                    id INTEGER P..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 362,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    359:             )\n    360: \n    361:             # Audit log for tenant operations\n>>> 362:             conn.execute(\n    363:                 \"\"\"\n    364:                 CREATE TABLE IF NOT EXISTS tenant_audit_log (\n    365:                     id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 363,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    360: \n    361:             # Audit log for tenant operations\n    362:             conn.execute(\n>>> 363:                 \"\"\"\n    364:                 CREATE TABLE IF NOT EXISTS tenant_audit_log (\n    365:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    366:                     timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS tenant_audit_log (\n                    id INTEGER PRIMAR..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 383,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    380: \n    381:             # Create indexes\n    382:             indexes = [\n>>> 383:                 \"CREATE INDEX IF NOT EXISTS idx_workspaces_org ON workspaces (organization_id)\",\n    384:                 \"CREATE INDEX IF NOT EXISTS idx_memberships_user ON tenant_memberships (user_id)\",\n    385:                 \"CREATE INDEX IF NOT EXISTS idx_memberships_org ON tenant_memberships (organization_id)\",\n    386:                 \"CREATE INDEX IF NOT EXISTS idx_quotas_tenant ON resource_quotas (tenant_id)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_workspaces_org ON workspaces (organization_id)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 384,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    381:             # Create indexes\n    382:             indexes = [\n    383:                 \"CREATE INDEX IF NOT EXISTS idx_workspaces_org ON workspaces (organization_id)\",\n>>> 384:                 \"CREATE INDEX IF NOT EXISTS idx_memberships_user ON tenant_memberships (user_id)\",\n    385:                 \"CREATE INDEX IF NOT EXISTS idx_memberships_org ON tenant_memberships (organization_id)\",\n    386:                 \"CREATE INDEX IF NOT EXISTS idx_quotas_tenant ON resource_quotas (tenant_id)\",\n    387:                 \"CREATE INDEX IF NOT EXISTS idx_usage_tenant ON resource_usage (tenant_id)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_memberships_user ON tenant_memberships (user_id)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 385,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    382:             indexes = [\n    383:                 \"CREATE INDEX IF NOT EXISTS idx_workspaces_org ON workspaces (organization_id)\",\n    384:                 \"CREATE INDEX IF NOT EXISTS idx_memberships_user ON tenant_memberships (user_id)\",\n>>> 385:                 \"CREATE INDEX IF NOT EXISTS idx_memberships_org ON tenant_memberships (organization_id)\",\n    386:                 \"CREATE INDEX IF NOT EXISTS idx_quotas_tenant ON resource_quotas (tenant_id)\",\n    387:                 \"CREATE INDEX IF NOT EXISTS idx_usage_tenant ON resource_usage (tenant_id)\",\n    388:                 \"CREATE INDEX IF NOT EXISTS idx_isolation_tenant ON tenant_data_isolation (tenant_id)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_memberships_org ON tenant_memberships (organization_id)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 386,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    383:                 \"CREATE INDEX IF NOT EXISTS idx_workspaces_org ON workspaces (organization_id)\",\n    384:                 \"CREATE INDEX IF NOT EXISTS idx_memberships_user ON tenant_memberships (user_id)\",\n    385:                 \"CREATE INDEX IF NOT EXISTS idx_memberships_org ON tenant_memberships (organization_id)\",\n>>> 386:                 \"CREATE INDEX IF NOT EXISTS idx_quotas_tenant ON resource_quotas (tenant_id)\",\n    387:                 \"CREATE INDEX IF NOT EXISTS idx_usage_tenant ON resource_usage (tenant_id)\",\n    388:                 \"CREATE INDEX IF NOT EXISTS idx_isolation_tenant ON tenant_data_isolation (tenant_id)\",\n    389:                 \"CREATE INDEX IF NOT EXISTS idx_audit_tenant ON tenant_audit_log (tenant_id)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_quotas_tenant ON resource_quotas (tenant_id)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 387,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    384:                 \"CREATE INDEX IF NOT EXISTS idx_memberships_user ON tenant_memberships (user_id)\",\n    385:                 \"CREATE INDEX IF NOT EXISTS idx_memberships_org ON tenant_memberships (organization_id)\",\n    386:                 \"CREATE INDEX IF NOT EXISTS idx_quotas_tenant ON resource_quotas (tenant_id)\",\n>>> 387:                 \"CREATE INDEX IF NOT EXISTS idx_usage_tenant ON resource_usage (tenant_id)\",\n    388:                 \"CREATE INDEX IF NOT EXISTS idx_isolation_tenant ON tenant_data_isolation (tenant_id)\",\n    389:                 \"CREATE INDEX IF NOT EXISTS idx_audit_tenant ON tenant_audit_log (tenant_id)\",\n    390:                 \"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON tenant_audit_log (timestamp)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_usage_tenant ON resource_usage (tenant_id)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 388,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    385:                 \"CREATE INDEX IF NOT EXISTS idx_memberships_org ON tenant_memberships (organization_id)\",\n    386:                 \"CREATE INDEX IF NOT EXISTS idx_quotas_tenant ON resource_quotas (tenant_id)\",\n    387:                 \"CREATE INDEX IF NOT EXISTS idx_usage_tenant ON resource_usage (tenant_id)\",\n>>> 388:                 \"CREATE INDEX IF NOT EXISTS idx_isolation_tenant ON tenant_data_isolation (tenant_id)\",\n    389:                 \"CREATE INDEX IF NOT EXISTS idx_audit_tenant ON tenant_audit_log (tenant_id)\",\n    390:                 \"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON tenant_audit_log (timestamp)\",\n    391:             ]",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_isolation_tenant ON tenant_data_isolation (tenant_id)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 389,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    386:                 \"CREATE INDEX IF NOT EXISTS idx_quotas_tenant ON resource_quotas (tenant_id)\",\n    387:                 \"CREATE INDEX IF NOT EXISTS idx_usage_tenant ON resource_usage (tenant_id)\",\n    388:                 \"CREATE INDEX IF NOT EXISTS idx_isolation_tenant ON tenant_data_isolation (tenant_id)\",\n>>> 389:                 \"CREATE INDEX IF NOT EXISTS idx_audit_tenant ON tenant_audit_log (tenant_id)\",\n    390:                 \"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON tenant_audit_log (timestamp)\",\n    391:             ]\n    392: ",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_audit_tenant ON tenant_audit_log (tenant_id)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 390,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    387:                 \"CREATE INDEX IF NOT EXISTS idx_usage_tenant ON resource_usage (tenant_id)\",\n    388:                 \"CREATE INDEX IF NOT EXISTS idx_isolation_tenant ON tenant_data_isolation (tenant_id)\",\n    389:                 \"CREATE INDEX IF NOT EXISTS idx_audit_tenant ON tenant_audit_log (tenant_id)\",\n>>> 390:                 \"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON tenant_audit_log (timestamp)\",\n    391:             ]\n    392: \n    393:             for index_sql in indexes:",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON tenant_audit_log (timestamp)"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 394,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    391:             ]\n    392: \n    393:             for index_sql in indexes:\n>>> 394:                 conn.execute(index_sql)\n    395: \n    396:     def _init_platform_tenant(self):\n    397:         \"\"\"Initialize the platform-level tenant.\"\"\"",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 400,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    397:         \"\"\"Initialize the platform-level tenant.\"\"\"\n    398:         with self._get_connection() as conn:\n    399:             # Check if platform tenant exists\n>>> 400:             cursor = conn.execute(\"SELECT id FROM organizations WHERE id = 'platform' AND tenant_type = 'platform'\")\n    401:             if not cursor.fetchone():\n    402:                 # Create platform tenant\n    403:                 self.create_organization(",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 400,
    "column": 34,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    397:         \"\"\"Initialize the platform-level tenant.\"\"\"\n    398:         with self._get_connection() as conn:\n    399:             # Check if platform tenant exists\n>>> 400:             cursor = conn.execute(\"SELECT id FROM organizations WHERE id = 'platform' AND tenant_type = 'platform'\")\n    401:             if not cursor.fetchone():\n    402:                 # Create platform tenant\n    403:                 self.create_organization(",
    "context": {
      "query_preview": "SELECT id FROM organizations WHERE id = 'platform' AND tenant_type = 'platform'"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 412,
    "column": 28,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    409:                     isolation_level=IsolationLevel.PHYSICAL,\n    410:                     admin_email=\"admin@aivillage.local\",\n    411:                 )\n>>> 412:                 logger.info(\"Created platform tenant\")\n    413: \n    414:     def create_organization(\n    415:         self,",
    "context": {
      "query_preview": "Created platform tenant"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 414,
    "column": 4,
    "description": "Method 'create_organization' is too complex: 3 complexity, 114 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    411:                 )\n    412:                 logger.info(\"Created platform tenant\")\n    413: \n>>> 414:     def create_organization(\n    415:         self,\n    416:         org_id: str | None = None,\n    417:         name: str = None,",
    "context": {
      "complexity": 3,
      "lines": 114,
      "max_nesting": 0,
      "method_name": "create_organization"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 414,
    "column": 4,
    "description": "Function 'create_organization' has 11 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    411:                 )\n    412:                 logger.info(\"Created platform tenant\")\n    413: \n>>> 414:     def create_organization(\n    415:         self,\n    416:         org_id: str | None = None,\n    417:         name: str = None,",
    "context": {
      "parameter_count": 11,
      "function_name": "create_organization"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 427,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    424:         data_residency: str | None = None,\n    425:         **kwargs,\n    426:     ) -> str:\n>>> 427:         \"\"\"Create a new organization.\n    428: \n    429:         Args:\n    430:             org_id: Organization ID (generated if not provided)",
    "context": {
      "query_preview": "Create a new organization.\n\n        Args:\n            org_id: Organization ID (generated if not prov..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 449,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    446:         with self._get_connection() as conn:\n    447:             try:\n    448:                 # Create organization\n>>> 449:                 conn.execute(\n    450:                     \"\"\"\n    451:                     INSERT INTO organizations (\n    452:                         id, name, display_name, description,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 450,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    447:             try:\n    448:                 # Create organization\n    449:                 conn.execute(\n>>> 450:                     \"\"\"\n    451:                     INSERT INTO organizations (\n    452:                         id, name, display_name, description,\n    453:                         tenant_type, isolation_level,",
    "context": {
      "query_preview": "\n                    INSERT INTO organizations (\n                        id, name, display_name, des..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 475,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    472: \n    473:                 # Set default quotas based on tenant type\n    474:                 quota = DEFAULT_QUOTAS[tenant_type]\n>>> 475:                 conn.execute(\n    476:                     \"\"\"\n    477:                     INSERT INTO resource_quotas (\n    478:                         tenant_id, tenant_type,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 476,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    473:                 # Set default quotas based on tenant type\n    474:                 quota = DEFAULT_QUOTAS[tenant_type]\n    475:                 conn.execute(\n>>> 476:                     \"\"\"\n    477:                     INSERT INTO resource_quotas (\n    478:                         tenant_id, tenant_type,\n    479:                         max_users, max_storage_gb, max_api_calls_per_day,",
    "context": {
      "query_preview": "\n                    INSERT INTO resource_quotas (\n                        tenant_id, tenant_type,\n ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 498,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    495:                 )\n    496: \n    497:                 # Initialize usage tracking\n>>> 498:                 conn.execute(\n    499:                     \"\"\"\n    500:                     INSERT INTO resource_usage (tenant_id, tenant_type)\n    501:                     VALUES (?, 'organization')",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 499,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    496: \n    497:                 # Initialize usage tracking\n    498:                 conn.execute(\n>>> 499:                     \"\"\"\n    500:                     INSERT INTO resource_usage (tenant_id, tenant_type)\n    501:                     VALUES (?, 'organization')\n    502:                 \"\"\",",
    "context": {
      "query_preview": "\n                    INSERT INTO resource_usage (tenant_id, tenant_type)\n                    VALUES ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 523,
    "column": 30,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    520:                     details={\"tenant_type\": tenant_type.value, \"isolation_level\": isolation_level.value},\n    521:                 )\n    522: \n>>> 523:                 logger.info(f\"Created organization: {org_id} ({name})\")\n    524:                 return org_id\n    525: \n    526:             except sqlite3.IntegrityError as e:",
    "context": {
      "query_preview": "Created organization: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 527,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    524:                 return org_id\n    525: \n    526:             except sqlite3.IntegrityError as e:\n>>> 527:                 logger.error(f\"Failed to create organization: {e}\")\n    528:                 raise ValueError(f\"Organization with name '{name}' already exists\")\n    529: \n    530:     def create_workspace(",
    "context": {
      "query_preview": "Failed to create organization: "
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 530,
    "column": 4,
    "description": "Method 'create_workspace' is too complex: 4 complexity, 69 lines, 2 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    527:                 logger.error(f\"Failed to create organization: {e}\")\n    528:                 raise ValueError(f\"Organization with name '{name}' already exists\")\n    529: \n>>> 530:     def create_workspace(\n    531:         self,\n    532:         organization_id: str,\n    533:         name: str,",
    "context": {
      "complexity": 4,
      "lines": 69,
      "max_nesting": 2,
      "method_name": "create_workspace"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 530,
    "column": 4,
    "description": "Function 'create_workspace' has 8 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    527:                 logger.error(f\"Failed to create organization: {e}\")\n    528:                 raise ValueError(f\"Organization with name '{name}' already exists\")\n    529: \n>>> 530:     def create_workspace(\n    531:         self,\n    532:         organization_id: str,\n    533:         name: str,",
    "context": {
      "parameter_count": 8,
      "function_name": "create_workspace"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 540,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    537:         is_public: bool = False,\n    538:         **kwargs,\n    539:     ) -> str:\n>>> 540:         \"\"\"Create a workspace within an organization.\n    541: \n    542:         Args:\n    543:             organization_id: Parent organization ID",
    "context": {
      "query_preview": "Create a workspace within an organization.\n\n        Args:\n            organization_id: Parent organi..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 559,
    "column": 25,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    556:         # Get organization's isolation level if not specified\n    557:         if isolation_level is None:\n    558:             with self._get_connection() as conn:\n>>> 559:                 cursor = conn.execute(\"SELECT isolation_level FROM organizations WHERE id = ?\", (organization_id,))\n    560:                 row = cursor.fetchone()\n    561:                 if not row:\n    562:                     raise ValueError(f\"Organization {organization_id} not found\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 559,
    "column": 38,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    556:         # Get organization's isolation level if not specified\n    557:         if isolation_level is None:\n    558:             with self._get_connection() as conn:\n>>> 559:                 cursor = conn.execute(\"SELECT isolation_level FROM organizations WHERE id = ?\", (organization_id,))\n    560:                 row = cursor.fetchone()\n    561:                 if not row:\n    562:                     raise ValueError(f\"Organization {organization_id} not found\")",
    "context": {
      "query_preview": "SELECT isolation_level FROM organizations WHERE id = ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 567,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    564: \n    565:         with self._get_connection() as conn:\n    566:             try:\n>>> 567:                 conn.execute(\n    568:                     \"\"\"\n    569:                     INSERT INTO workspaces (\n    570:                         id, organization_id, name, display_name,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 568,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    565:         with self._get_connection() as conn:\n    566:             try:\n    567:                 conn.execute(\n>>> 568:                     \"\"\"\n    569:                     INSERT INTO workspaces (\n    570:                         id, organization_id, name, display_name,\n    571:                         description, settings, isolation_level, is_public",
    "context": {
      "query_preview": "\n                    INSERT INTO workspaces (\n                        id, organization_id, name, dis..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 601,
    "column": 4,
    "description": "Method 'add_user_to_tenant' is too complex: 4 complexity, 66 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    598:             except sqlite3.IntegrityError:\n    599:                 raise ValueError(f\"Workspace '{name}' already exists in organization\")\n    600: \n>>> 601:     def add_user_to_tenant(\n    602:         self,\n    603:         user_id: str,\n    604:         organization_id: str,",
    "context": {
      "complexity": 4,
      "lines": 66,
      "max_nesting": 1,
      "method_name": "add_user_to_tenant"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 601,
    "column": 4,
    "description": "Function 'add_user_to_tenant' has 7 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    598:             except sqlite3.IntegrityError:\n    599:                 raise ValueError(f\"Workspace '{name}' already exists in organization\")\n    600: \n>>> 601:     def add_user_to_tenant(\n    602:         self,\n    603:         user_id: str,\n    604:         organization_id: str,",
    "context": {
      "parameter_count": 7,
      "function_name": "add_user_to_tenant"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 629,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    626:                 if not self._check_user_quota(organization_id):\n    627:                     raise ValueError(\"User quota exceeded for organization\")\n    628: \n>>> 629:                 conn.execute(\n    630:                     \"\"\"\n    631:                     INSERT OR REPLACE INTO tenant_memberships (\n    632:                         user_id, organization_id, workspace_id,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 630,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    627:                     raise ValueError(\"User quota exceeded for organization\")\n    628: \n    629:                 conn.execute(\n>>> 630:                     \"\"\"\n    631:                     INSERT OR REPLACE INTO tenant_memberships (\n    632:                         user_id, organization_id, workspace_id,\n    633:                         role, permissions, invited_by",
    "context": {
      "query_preview": "\n                    INSERT OR REPLACE INTO tenant_memberships (\n                        user_id, or..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 675,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    672:         organization_id: str,\n    673:         workspace_id: str | None = None,\n    674:     ) -> bool:\n>>> 675:         \"\"\"Remove user from a tenant.\n    676: \n    677:         Args:\n    678:             user_id: User ID to remove",
    "context": {
      "query_preview": "Remove user from a tenant.\n\n        Args:\n            user_id: User ID to remove\n            organiz..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 687,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    684:         \"\"\"\n    685:         with self._get_connection() as conn:\n    686:             if workspace_id:\n>>> 687:                 conn.execute(\n    688:                     \"\"\"\n    689:                     DELETE FROM tenant_memberships\n    690:                     WHERE user_id = ? AND organization_id = ? AND workspace_id = ?",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 688,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    685:         with self._get_connection() as conn:\n    686:             if workspace_id:\n    687:                 conn.execute(\n>>> 688:                     \"\"\"\n    689:                     DELETE FROM tenant_memberships\n    690:                     WHERE user_id = ? AND organization_id = ? AND workspace_id = ?\n    691:                 \"\"\",",
    "context": {
      "query_preview": "\n                    DELETE FROM tenant_memberships\n                    WHERE user_id = ? AND organi..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 695,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    692:                     (user_id, organization_id, workspace_id),\n    693:                 )\n    694:             else:\n>>> 695:                 conn.execute(\n    696:                     \"\"\"\n    697:                     DELETE FROM tenant_memberships\n    698:                     WHERE user_id = ? AND organization_id = ?",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 696,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    693:                 )\n    694:             else:\n    695:                 conn.execute(\n>>> 696:                     \"\"\"\n    697:                     DELETE FROM tenant_memberships\n    698:                     WHERE user_id = ? AND organization_id = ?\n    699:                 \"\"\",",
    "context": {
      "query_preview": "\n                    DELETE FROM tenant_memberships\n                    WHERE user_id = ? AND organi..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 709,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    706:             # Log removal\n    707:             self._log_audit(\n    708:                 tenant_id=organization_id,\n>>> 709:                 action=\"user_removed_from_tenant\",\n    710:                 resource_type=\"user\",\n    711:                 resource_id=user_id,\n    712:                 details={\"workspace_id\": workspace_id},",
    "context": {
      "query_preview": "user_removed_from_tenant"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 727,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    724:             List of tenant memberships\n    725:         \"\"\"\n    726:         with self._get_connection() as conn:\n>>> 727:             cursor = conn.execute(\n    728:                 \"\"\"\n    729:                 SELECT\n    730:                     m.organization_id,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 728,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    725:         \"\"\"\n    726:         with self._get_connection() as conn:\n    727:             cursor = conn.execute(\n>>> 728:                 \"\"\"\n    729:                 SELECT\n    730:                     m.organization_id,\n    731:                     m.workspace_id,",
    "context": {
      "query_preview": "\n                SELECT\n                    m.organization_id,\n                    m.workspace_id,\n ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 749,
    "column": 4,
    "description": "Method 'get_tenant_context' is too complex: 7 complexity, 70 lines, 4 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    746: \n    747:             return [dict(row) for row in cursor.fetchall()]\n    748: \n>>> 749:     def get_tenant_context(\n    750:         self,\n    751:         tenant_id: str,\n    752:         user_id: str | None = None,",
    "context": {
      "complexity": 7,
      "lines": 70,
      "max_nesting": 4,
      "method_name": "get_tenant_context"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 770,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    767: \n    768:         with self._get_connection() as conn:\n    769:             # Try as organization first\n>>> 770:             cursor = conn.execute(\n    771:                 \"\"\"\n    772:                 SELECT id, isolation_level, settings\n    773:                 FROM organizations",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 771,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    768:         with self._get_connection() as conn:\n    769:             # Try as organization first\n    770:             cursor = conn.execute(\n>>> 771:                 \"\"\"\n    772:                 SELECT id, isolation_level, settings\n    773:                 FROM organizations\n    774:                 WHERE id = ?",
    "context": {
      "query_preview": "\n                SELECT id, isolation_level, settings\n                FROM organizations\n           ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 790,
    "column": 25,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    787:                 )\n    788:             else:\n    789:                 # Try as workspace\n>>> 790:                 cursor = conn.execute(\n    791:                     \"\"\"\n    792:                     SELECT w.id, w.organization_id, w.isolation_level, w.settings\n    793:                     FROM workspaces w",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 791,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    788:             else:\n    789:                 # Try as workspace\n    790:                 cursor = conn.execute(\n>>> 791:                     \"\"\"\n    792:                     SELECT w.id, w.organization_id, w.isolation_level, w.settings\n    793:                     FROM workspaces w\n    794:                     WHERE w.id = ?",
    "context": {
      "query_preview": "\n                    SELECT w.id, w.organization_id, w.isolation_level, w.settings\n                 ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 821,
    "column": 4,
    "description": "Method 'check_tenant_access' is too complex: 11 complexity, 64 lines, 7 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    818: \n    819:             return context\n    820: \n>>> 821:     def check_tenant_access(\n    822:         self,\n    823:         user_id: str,\n    824:         tenant_id: str,",
    "context": {
      "complexity": 11,
      "lines": 64,
      "max_nesting": 7,
      "method_name": "check_tenant_access"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 841,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    838:         \"\"\"\n    839:         with self._get_connection() as conn:\n    840:             # Check organization membership\n>>> 841:             cursor = conn.execute(\n    842:                 \"\"\"\n    843:                 SELECT role, permissions\n    844:                 FROM tenant_memberships",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 842,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    839:         with self._get_connection() as conn:\n    840:             # Check organization membership\n    841:             cursor = conn.execute(\n>>> 842:                 \"\"\"\n    843:                 SELECT role, permissions\n    844:                 FROM tenant_memberships\n    845:                 WHERE user_id = ? AND organization_id = ? AND is_active = 1",
    "context": {
      "query_preview": "\n                SELECT role, permissions\n                FROM tenant_memberships\n                WH..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 853,
    "column": 25,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    850: \n    851:             if not row:\n    852:                 # Check workspace membership\n>>> 853:                 cursor = conn.execute(\n    854:                     \"\"\"\n    855:                     SELECT m.role, m.permissions\n    856:                     FROM tenant_memberships m",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 854,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    851:             if not row:\n    852:                 # Check workspace membership\n    853:                 cursor = conn.execute(\n>>> 854:                     \"\"\"\n    855:                     SELECT m.role, m.permissions\n    856:                     FROM tenant_memberships m\n    857:                     JOIN workspaces w ON m.workspace_id = w.id",
    "context": {
      "query_preview": "\n                    SELECT m.role, m.permissions\n                    FROM tenant_memberships m\n    ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 990,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    987:             Whether quota allows more users\n    988:         \"\"\"\n    989:         with self._get_connection() as conn:\n>>> 990:             cursor = conn.execute(\n    991:                 \"\"\"\n    992:                 SELECT q.max_users, u.current_users\n    993:                 FROM resource_quotas q",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 991,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    988:         \"\"\"\n    989:         with self._get_connection() as conn:\n    990:             cursor = conn.execute(\n>>> 991:                 \"\"\"\n    992:                 SELECT q.max_users, u.current_users\n    993:                 FROM resource_quotas q\n    994:                 JOIN resource_usage u ON q.tenant_id = u.tenant_id",
    "context": {
      "query_preview": "\n                SELECT q.max_users, u.current_users\n                FROM resource_quotas q\n        ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1037,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1034:         usage_field, quota_field = resource_mapping[resource_type]\n    1035: \n    1036:         with self._get_connection() as conn:\n>>> 1037:             cursor = conn.execute(\n    1038:                 f\"\"\"\n    1039:                 SELECT q.{quota_field} as quota, u.{usage_field} as usage\n    1040:                 FROM resource_quotas q",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1038,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1035: \n    1036:         with self._get_connection() as conn:\n    1037:             cursor = conn.execute(\n>>> 1038:                 f\"\"\"\n    1039:                 SELECT q.{quota_field} as quota, u.{usage_field} as usage\n    1040:                 FROM resource_quotas q\n    1041:                 JOIN resource_usage u ON q.tenant_id = u.tenant_id",
    "context": {
      "query_preview": "\n                SELECT q."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1039,
    "column": 64,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1036:         with self._get_connection() as conn:\n    1037:             cursor = conn.execute(\n    1038:                 f\"\"\"\n>>> 1039:                 SELECT q.{quota_field} as quota, u.{usage_field} as usage\n    1040:                 FROM resource_quotas q\n    1041:                 JOIN resource_usage u ON q.tenant_id = u.tenant_id\n    1042:                 WHERE q.tenant_id = ?",
    "context": {
      "query_preview": " as usage\n                FROM resource_quotas q\n                JOIN resource_usage u ON q.tenant_i..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1058,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1055:         resource_type: str,\n    1056:         delta: int,\n    1057:     ):\n>>> 1058:         \"\"\"Update resource usage for tenant.\n    1059: \n    1060:         Args:\n    1061:             tenant_id: Tenant ID",
    "context": {
      "query_preview": "Update resource usage for tenant.\n\n        Args:\n            tenant_id: Tenant ID\n            resour..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1082,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1079:         field = field_mapping[resource_type]\n    1080: \n    1081:         with self._get_connection() as conn:\n>>> 1082:             conn.execute(\n    1083:                 f\"\"\"\n    1084:                 UPDATE resource_usage\n    1085:                 SET {field} = MAX(0, {field} + ?),",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1083,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1080: \n    1081:         with self._get_connection() as conn:\n    1082:             conn.execute(\n>>> 1083:                 f\"\"\"\n    1084:                 UPDATE resource_usage\n    1085:                 SET {field} = MAX(0, {field} + ?),\n    1086:                     updated_at = CURRENT_TIMESTAMP",
    "context": {
      "query_preview": "\n                UPDATE resource_usage\n                SET "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1085,
    "column": 44,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1082:             conn.execute(\n    1083:                 f\"\"\"\n    1084:                 UPDATE resource_usage\n>>> 1085:                 SET {field} = MAX(0, {field} + ?),\n    1086:                     updated_at = CURRENT_TIMESTAMP\n    1087:                 WHERE tenant_id = ?\n    1088:             \"\"\",",
    "context": {
      "query_preview": " + ?),\n                    updated_at = CURRENT_TIMESTAMP\n                WHERE tenant_id = ?\n      ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1092,
    "column": 4,
    "description": "Function '_log_audit' has 9 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    1089:                 (delta, tenant_id),\n    1090:             )\n    1091: \n>>> 1092:     def _log_audit(\n    1093:         self,\n    1094:         tenant_id: str,\n    1095:         action: str,",
    "context": {
      "parameter_count": 9,
      "function_name": "_log_audit"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1116,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1113:             error_message: Error message if failed\n    1114:         \"\"\"\n    1115:         with self._get_connection() as conn:\n>>> 1116:             conn.execute(\n    1117:                 \"\"\"\n    1118:                 INSERT INTO tenant_audit_log (\n    1119:                     tenant_id, user_id, action,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1117,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1114:         \"\"\"\n    1115:         with self._get_connection() as conn:\n    1116:             conn.execute(\n>>> 1117:                 \"\"\"\n    1118:                 INSERT INTO tenant_audit_log (\n    1119:                     tenant_id, user_id, action,\n    1120:                     resource_type, resource_id,",
    "context": {
      "query_preview": "\n                INSERT INTO tenant_audit_log (\n                    tenant_id, user_id, action,\n    ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1136,
    "column": 4,
    "description": "Method 'get_tenant_stats' is too complex: 4 complexity, 64 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    1133:                 ),\n    1134:             )\n    1135: \n>>> 1136:     def get_tenant_stats(self, tenant_id: str) -> dict[str, Any]:\n    1137:         \"\"\"Get statistics for a tenant.\n    1138: \n    1139:         Args:",
    "context": {
      "complexity": 4,
      "lines": 64,
      "max_nesting": 0,
      "method_name": "get_tenant_stats"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1147,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1144:         \"\"\"\n    1145:         with self._get_connection() as conn:\n    1146:             # Get basic info\n>>> 1147:             cursor = conn.execute(\n    1148:                 \"\"\"\n    1149:                 SELECT * FROM organizations WHERE id = ?\n    1150:             \"\"\",",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1148,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1145:         with self._get_connection() as conn:\n    1146:             # Get basic info\n    1147:             cursor = conn.execute(\n>>> 1148:                 \"\"\"\n    1149:                 SELECT * FROM organizations WHERE id = ?\n    1150:             \"\"\",\n    1151:                 (tenant_id,),",
    "context": {
      "query_preview": "\n                SELECT * FROM organizations WHERE id = ?\n            "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1156,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1153:             org = dict(cursor.fetchone() or {})\n    1154: \n    1155:             # Get quotas and usage\n>>> 1156:             cursor = conn.execute(\n    1157:                 \"\"\"\n    1158:                 SELECT * FROM resource_quotas WHERE tenant_id = ?\n    1159:             \"\"\",",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1157,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1154: \n    1155:             # Get quotas and usage\n    1156:             cursor = conn.execute(\n>>> 1157:                 \"\"\"\n    1158:                 SELECT * FROM resource_quotas WHERE tenant_id = ?\n    1159:             \"\"\",\n    1160:                 (tenant_id,),",
    "context": {
      "query_preview": "\n                SELECT * FROM resource_quotas WHERE tenant_id = ?\n            "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1164,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1161:             )\n    1162:             quotas = dict(cursor.fetchone() or {})\n    1163: \n>>> 1164:             cursor = conn.execute(\n    1165:                 \"\"\"\n    1166:                 SELECT * FROM resource_usage WHERE tenant_id = ?\n    1167:             \"\"\",",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1165,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1162:             quotas = dict(cursor.fetchone() or {})\n    1163: \n    1164:             cursor = conn.execute(\n>>> 1165:                 \"\"\"\n    1166:                 SELECT * FROM resource_usage WHERE tenant_id = ?\n    1167:             \"\"\",\n    1168:                 (tenant_id,),",
    "context": {
      "query_preview": "\n                SELECT * FROM resource_usage WHERE tenant_id = ?\n            "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1173,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1170:             usage = dict(cursor.fetchone() or {})\n    1171: \n    1172:             # Get member count\n>>> 1173:             cursor = conn.execute(\n    1174:                 \"\"\"\n    1175:                 SELECT COUNT(*) as member_count\n    1176:                 FROM tenant_memberships",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1174,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1171: \n    1172:             # Get member count\n    1173:             cursor = conn.execute(\n>>> 1174:                 \"\"\"\n    1175:                 SELECT COUNT(*) as member_count\n    1176:                 FROM tenant_memberships\n    1177:                 WHERE organization_id = ? AND is_active = 1",
    "context": {
      "query_preview": "\n                SELECT COUNT(*) as member_count\n                FROM tenant_memberships\n           ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1184,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    1181:             members = cursor.fetchone()[\"member_count\"]\n    1182: \n    1183:             # Get workspace count\n>>> 1184:             cursor = conn.execute(\n    1185:                 \"\"\"\n    1186:                 SELECT COUNT(*) as workspace_count\n    1187:                 FROM workspaces",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1185,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1182: \n    1183:             # Get workspace count\n    1184:             cursor = conn.execute(\n>>> 1185:                 \"\"\"\n    1186:                 SELECT COUNT(*) as workspace_count\n    1187:                 FROM workspaces\n    1188:                 WHERE organization_id = ? AND is_active = 1",
    "context": {
      "query_preview": "\n                SELECT COUNT(*) as workspace_count\n                FROM workspaces\n                ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1224,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    1221:         compliance_level=\"GDPR\",\n    1222:     )\n    1223: \n>>> 1224:     print(f\"Created organization: {org_id}\")\n    1225: \n    1226:     # Create a workspace\n    1227:     ws_id = system.create_workspace(",
    "context": {
      "query_preview": "Created organization: "
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 530,
    "column": 4,
    "description": "Duplicate code block detected in function 'create_workspace'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    527:                 logger.error(f\"Failed to create organization: {e}\")\n    528:                 raise ValueError(f\"Organization with name '{name}' already exists\")\n    529: \n>>> 530:     def create_workspace(\n    531:         self,\n    532:         organization_id: str,\n    533:         name: str,",
    "context": {
      "duplicate_count": 2,
      "function_name": "create_workspace",
      "signature": "ASSIGN|IF|WITH"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 749,
    "column": 4,
    "description": "Duplicate code block detected in function 'get_tenant_context'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    746: \n    747:             return [dict(row) for row in cursor.fetchall()]\n    748: \n>>> 749:     def get_tenant_context(\n    750:         self,\n    751:         tenant_id: str,\n    752:         user_id: str | None = None,",
    "context": {
      "duplicate_count": 2,
      "function_name": "get_tenant_context",
      "signature": "ASSIGN|IF|WITH"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1005,
    "column": 4,
    "description": "Duplicate code block detected in function 'check_resource_quota'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    1002:                 return row[\"current_users\"] < row[\"max_users\"]\n    1003:             return True\n    1004: \n>>> 1005:     def check_resource_quota(\n    1006:         self,\n    1007:         tenant_id: str,\n    1008:         resource_type: str,",
    "context": {
      "duplicate_count": 2,
      "function_name": "check_resource_quota",
      "signature": "ASSIGN|IF|ASSIGN|WITH"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1052,
    "column": 4,
    "description": "Duplicate code block detected in function '_update_resource_usage'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    1049:                 return row[\"usage\"] + requested_amount <= row[\"quota\"]\n    1050:             return True\n    1051: \n>>> 1052:     def _update_resource_usage(\n    1053:         self,\n    1054:         tenant_id: str,\n    1055:         resource_type: str,",
    "context": {
      "duplicate_count": 2,
      "function_name": "_update_resource_usage",
      "signature": "ASSIGN|IF|ASSIGN|WITH"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (27 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 27,
      "methods": [
        "create_workspace",
        "_get_encryption_key",
        "_get_connection",
        "_init_database",
        "_init_platform_tenant",
        "_update_resource_usage",
        "_check_user_quota",
        "create_organization",
        "_log_audit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 7,
      "methods": [
        "info",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'conn' methods (35 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "conn",
      "method_count": 35,
      "methods": [
        "close",
        "execute",
        "rollback",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'cursor' methods (14 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "cursor",
      "method_count": 14,
      "methods": [
        "fetchone",
        "fetchall"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'json' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "json",
      "method_count": 8,
      "methods": [
        "dumps",
        "loads"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'system' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "system",
      "method_count": 6,
      "methods": [
        "create_workspace",
        "get_tenant_stats",
        "get_tenant_context",
        "check_tenant_access",
        "add_user_to_tenant",
        "create_organization"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 137,
    "column": 4,
    "description": "Sequential coupling detected: Function '__init__' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    134: class MultiTenantSystem:\n    135:     \"\"\"Multi-tenant isolation and management system.\"\"\"\n    136: \n>>> 137:     def __init__(self, db_path: str | None = None):\n    138:         \"\"\"Initialize multi-tenant system.\n    139: \n    140:         Args:",
    "context": {
      "function_name": "__init__",
      "sequential_functions": [
        "__init__",
        "_init_database",
        "_init_platform_tenant"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 177,
    "column": 4,
    "description": "Sequential coupling detected: Function '_init_database' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    174:         finally:\n    175:             conn.close()\n    176: \n>>> 177:     def _init_database(self):\n    178:         \"\"\"Initialize database schema.\"\"\"\n    179:         with self._get_connection() as conn:\n    180:             # Organizations table",
    "context": {
      "function_name": "_init_database",
      "sequential_functions": [
        "__init__",
        "_init_database",
        "_init_platform_tenant"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 396,
    "column": 4,
    "description": "Sequential coupling detected: Function '_init_platform_tenant' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    393:             for index_sql in indexes:\n    394:                 conn.execute(index_sql)\n    395: \n>>> 396:     def _init_platform_tenant(self):\n    397:         \"\"\"Initialize the platform-level tenant.\"\"\"\n    398:         with self._get_connection() as conn:\n    399:             # Check if platform tenant exists",
    "context": {
      "function_name": "_init_platform_tenant",
      "sequential_functions": [
        "__init__",
        "_init_database",
        "_init_platform_tenant"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 49,
    "column": 37,
    "description": "Excessive magic literals detected (33 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     46:         self,\n     47:         max_users: int = 10,\n     48:         max_storage_gb: int = 10,\n>>>  49:         max_api_calls_per_day: int = 10000,\n     50:         max_models: int = 5,\n     51:         max_agents: int = 10,\n     52:         max_rag_documents: int = 1000,",
    "context": {
      "total_magic_literals": 33,
      "current_value": 10000
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 50,
    "column": 26,
    "description": "Excessive magic literals detected (33 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     47:         max_users: int = 10,\n     48:         max_storage_gb: int = 10,\n     49:         max_api_calls_per_day: int = 10000,\n>>>  50:         max_models: int = 5,\n     51:         max_agents: int = 10,\n     52:         max_rag_documents: int = 1000,\n     53:         max_p2p_connections: int = 50,",
    "context": {
      "total_magic_literals": 33,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 53,
    "column": 35,
    "description": "Excessive magic literals detected (33 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     50:         max_models: int = 5,\n     51:         max_agents: int = 10,\n     52:         max_rag_documents: int = 1000,\n>>>  53:         max_p2p_connections: int = 50,\n     54:         max_compute_hours: int = 100,\n     55:     ):\n     56:         self.max_users = max_users",
    "context": {
      "total_magic_literals": 33,
      "current_value": 50
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 70,
    "column": 23,
    "description": "Excessive magic literals detected (33 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     67: DEFAULT_QUOTAS = {\n     68:     TenantType.PERSONAL: ResourceQuota(\n     69:         max_users=1,\n>>>  70:         max_storage_gb=5,\n     71:         max_api_calls_per_day=1000,\n     72:         max_models=2,\n     73:         max_agents=3,",
    "context": {
      "total_magic_literals": 33,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\multi_tenant_system.py",
    "line_number": 73,
    "column": 19,
    "description": "Excessive magic literals detected (33 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     70:         max_storage_gb=5,\n     71:         max_api_calls_per_day=1000,\n     72:         max_models=2,\n>>>  73:         max_agents=3,\n     74:         max_rag_documents=100,\n     75:         max_p2p_connections=10,\n     76:         max_compute_hours=10,",
    "context": {
      "total_magic_literals": 33,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\security\\rbac_api_server.py",
    "line_number": 94,
    "column": 4,
    "description": "Method '_setup_fastapi_routes' is too complex: 31 complexity, 430 lines, 23 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     91:         else:\n     92:             logger.warning(\"FastAPI not available, using basic HTTP server\")\n     93: \n>>>  94:     def _setup_fastapi_routes(self):\n     95:         \"\"\"Set up FastAPI routes.\"\"\"\n     96:         if not self.app:\n     97:             return",
    "context": {
      "complexity": 31,
      "lines": 430,
      "max_nesting": 23,
      "method_name": "_setup_fastapi_routes"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_api_server.py",
    "line_number": 201,
    "column": 68,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    198:                 if current_user[\"tenant_id\"] != request.tenant_id:\n    199:                     user = self.integration.rbac.users.get(current_user[\"user_id\"])\n    200:                     if not user or user.role.value != \"super_admin\":\n>>> 201:                         raise HTTPException(status_code=403, detail=\"Cannot create users in other tenants\")\n    202: \n    203:                 role = Role(request.role)\n    204:                 user = await self.integration.rbac.create_user(",
    "context": {
      "query_preview": "Cannot create users in other tenants"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\security\\rbac_api_server.py",
    "line_number": 284,
    "column": 9,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    281: \n    282:             return result[\"data\"]\n    283: \n>>> 284:         @self.app.delete(\"/agents/{agent_id}\")\n    285:         async def delete_agent(agent_id: str, current_user: dict = Depends(get_current_user)):\n    286:             result = await self.integration.secure_api_call(\n    287:                 system=\"agents\",",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_api_server.py",
    "line_number": 395,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    392: \n    393:             return result[\"data\"]\n    394: \n>>> 395:         @self.app.post(\"/p2p/networks/{network_id}/join\")\n    396:         async def join_p2p_network(\n    397:             network_id: str, params: dict[str, Any], current_user: dict = Depends(get_current_user),\n    398:         ):",
    "context": {
      "query_preview": "/p2p/networks/{network_id}/join"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_api_server.py",
    "line_number": 574,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    571: \n    572: \n    573: async def create_rbac_server() -> RBACAPIServer:\n>>> 574:     \"\"\"Create and configure RBAC API server.\"\"\"\n    575:     # Initialize RBAC integration\n    576:     integration = await initialize_aivillage_rbac()\n    577: ",
    "context": {
      "query_preview": "Create and configure RBAC API server."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_api_server.py",
    "line_number": 581,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    578:     # Create server\n    579:     server = RBACAPIServer(integration)\n    580: \n>>> 581:     logger.info(\"RBAC API server created successfully\")\n    582:     return server\n    583: \n    584: ",
    "context": {
      "query_preview": "RBAC API server created successfully"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_api_server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 9,
      "methods": [
        "end_headers",
        "_setup_fastapi_routes",
        "send_header",
        "send_response"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_api_server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 6,
      "methods": [
        "info",
        "warning",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_api_server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'result' methods (36 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "result",
      "method_count": 36,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_api_server.py",
    "line_number": 113,
    "column": 48,
    "description": "Excessive magic literals detected (50 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    110:             token = credentials.credentials\n    111:             payload = await self.integration.rbac.verify_token(token)\n    112:             if not payload:\n>>> 113:                 raise HTTPException(status_code=401, detail=\"Invalid token\")\n    114:             return payload\n    115: \n    116:         # Health check",
    "context": {
      "total_magic_literals": 50,
      "current_value": 401
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_api_server.py",
    "line_number": 142,
    "column": 48,
    "description": "Excessive magic literals detected (50 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    139:                     \"tenant_id\": session.tenant_id,\n    140:                 }\n    141:             except Exception as e:\n>>> 142:                 raise HTTPException(status_code=401, detail=str(e))\n    143: \n    144:         @self.app.post(\"/auth/refresh\")\n    145:         async def refresh_token(refresh_token: str):",
    "context": {
      "total_magic_literals": 50,
      "current_value": 401
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_api_server.py",
    "line_number": 149,
    "column": 52,
    "description": "Excessive magic literals detected (50 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    146:             try:\n    147:                 session = await self.integration.rbac.refresh_token(refresh_token)\n    148:                 if not session:\n>>> 149:                     raise HTTPException(status_code=401, detail=\"Invalid refresh token\")\n    150: \n    151:                 return {\n    152:                     \"access_token\": session.token,",
    "context": {
      "total_magic_literals": 50,
      "current_value": 401
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_api_server.py",
    "line_number": 158,
    "column": 48,
    "description": "Excessive magic literals detected (50 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    155:                     \"expires_at\": session.expires_at.isoformat(),\n    156:                 }\n    157:             except Exception as e:\n>>> 158:                 raise HTTPException(status_code=401, detail=str(e))\n    159: \n    160:         @self.app.post(\"/auth/logout\")\n    161:         async def logout(current_user: dict = Depends(get_current_user)):",
    "context": {
      "total_magic_literals": 50,
      "current_value": 401
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_api_server.py",
    "line_number": 181,
    "column": 48,
    "description": "Excessive magic literals detected (50 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    178: \n    179:                 return {\"tenant_id\": tenant.tenant_id, \"name\": tenant.name, \"created_at\": tenant.created_at.isoformat()}\n    180:             except Exception as e:\n>>> 181:                 raise HTTPException(status_code=400, detail=str(e))\n    182: \n    183:         @self.app.get(\"/tenants/{tenant_id}/usage\")\n    184:         async def get_tenant_usage(tenant_id: str, current_user: dict = Depends(get_current_user)):",
    "context": {
      "total_magic_literals": 50,
      "current_value": 400
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 268,
    "column": 0,
    "description": "Class 'RBACSystem' is a God Object: 7 methods, ~547 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "    265:     user_agent: str\n    266: \n    267: \n>>> 268: class RBACSystem:\n    269:     \"\"\"Main RBAC and multi-tenant isolation system.\"\"\"\n    270: \n    271:     def __init__(self, config_path: Path | None = None):",
    "context": {
      "method_count": 7,
      "estimated_lines": 547,
      "class_name": "RBACSystem",
      "data_methods": 0,
      "business_methods": 7
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 297,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    294:         logger.info(\"RBAC system initialized\")\n    295: \n    296:     def _load_config(self):\n>>> 297:         \"\"\"Load RBAC configuration from file.\"\"\"\n    298:         if self.config_path.exists():\n    299:             with open(self.config_path) as f:\n    300:                 config = json.load(f)",
    "context": {
      "query_preview": "Load RBAC configuration from file."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 327,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    324:     async def create_tenant(\n    325:         self, name: str, admin_user: dict[str, str], config: dict[str, Any] | None = None,\n    326:     ) -> TenantConfig:\n>>> 327:         \"\"\"Create new tenant with isolated resources.\"\"\"\n    328:         tenant_id = f\"tenant_{secrets.token_urlsafe(16)}\"\n    329: \n    330:         tenant = TenantConfig(",
    "context": {
      "query_preview": "Create new tenant with isolated resources."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 366,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    363:         return tenant\n    364: \n    365:     async def delete_tenant(self, tenant_id: str, requester_id: str) -> bool:\n>>> 366:         \"\"\"Delete tenant and all associated resources.\"\"\"\n    367:         if not await self.check_permission(requester_id, Permission.TENANT_DELETE):\n    368:             raise PermissionError(f\"User {requester_id} lacks permission to delete tenants\")\n    369: ",
    "context": {
      "query_preview": "Delete tenant and all associated resources."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 368,
    "column": 55,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    365:     async def delete_tenant(self, tenant_id: str, requester_id: str) -> bool:\n    366:         \"\"\"Delete tenant and all associated resources.\"\"\"\n    367:         if not await self.check_permission(requester_id, Permission.TENANT_DELETE):\n>>> 368:             raise PermissionError(f\"User {requester_id} lacks permission to delete tenants\")\n    369: \n    370:         if tenant_id not in self.tenants:\n    371:             return False",
    "context": {
      "query_preview": " lacks permission to delete tenants"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 412,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    409:     async def create_user(\n    410:         self, username: str, email: str, password: str, tenant_id: str, role: Role = Role.USER,\n    411:     ) -> User:\n>>> 412:         \"\"\"Create new user within tenant.\"\"\"\n    413:         if tenant_id not in self.tenants:\n    414:             raise ValueError(f\"Tenant {tenant_id} does not exist\")\n    415: ",
    "context": {
      "query_preview": "Create new user within tenant."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 441,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    438:         return user\n    439: \n    440:     async def delete_user(self, user_id: str, requester_id: str) -> bool:\n>>> 441:         \"\"\"Delete user from system.\"\"\"\n    442:         if user_id not in self.users:\n    443:             return False\n    444: ",
    "context": {
      "query_preview": "Delete user from system."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 451,
    "column": 38,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    448:         # Check permissions\n    449:         if requester and requester.tenant_id != user.tenant_id:\n    450:             if requester.role != Role.SUPER_ADMIN:\n>>> 451:                 raise PermissionError(\"Cannot delete user from different tenant\")\n    452: \n    453:         # Revoke all sessions\n    454:         user_sessions = [s for s in self.sessions.values() if s.user_id == user_id]",
    "context": {
      "query_preview": "Cannot delete user from different tenant"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 469,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    466:     async def authenticate(\n    467:         self, username: str, password: str, tenant_id: str, ip_address: str, user_agent: str,\n    468:     ) -> Session:\n>>> 469:         \"\"\"Authenticate user and create session.\"\"\"\n    470:         # Find user\n    471:         user = None\n    472:         for u in self.users.values():",
    "context": {
      "query_preview": "Authenticate user and create session."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 497,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    494:         return session\n    495: \n    496:     async def _create_session(self, user: User, ip_address: str, user_agent: str) -> Session:\n>>> 497:         \"\"\"Create new user session with JWT tokens.\"\"\"\n    498:         session_id = f\"session_{secrets.token_urlsafe(16)}\"\n    499:         now = datetime.utcnow()\n    500: ",
    "context": {
      "query_preview": "Create new user session with JWT tokens."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 752,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    749:         return True\n    750: \n    751:     async def update_quota_usage(self, tenant_id: str, resource_type: str, amount: int, operation: str = \"add\"):\n>>> 752:         \"\"\"Update quota usage for tenant.\"\"\"\n    753:         if tenant_id not in self.tenants:\n    754:             return\n    755: ",
    "context": {
      "query_preview": "Update quota usage for tenant."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 871,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    868:     # Resource Cleanup Methods\n    869: \n    870:     async def _cleanup_agent_resource(self, agent_id: str, tenant_id: str):\n>>> 871:         \"\"\"Clean up agent resource from tenant.\"\"\"\n    872:         try:\n    873:             # Import here to avoid circular dependencies\n    874:             from packages.agents.core.agent_orchestration_system import AgentOrchestrator",
    "context": {
      "query_preview": "Clean up agent resource from tenant."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 891,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    888:             logger.error(f\"Failed to cleanup agent {agent_id}: {e}\")\n    889: \n    890:     async def _cleanup_rag_resource(self, collection_id: str, tenant_id: str):\n>>> 891:         \"\"\"Clean up RAG resource from tenant.\"\"\"\n    892:         try:\n    893:             # Import here to avoid circular dependencies\n    894:             from packages.rag.core.hyper_rag import HyperRAG",
    "context": {
      "query_preview": "Clean up RAG resource from tenant."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 997,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    994:         # Test authorization\n    995:         can_create_agent = await rbac.check_permission(developer.user_id, Permission.AGENT_CREATE)\n    996: \n>>> 997:         print(f\"Developer can create agents: {can_create_agent}\")\n    998: \n    999:     asyncio.run(main())",
    "context": {
      "query_preview": "Developer can create agents: "
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (29 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 29,
      "methods": [
        "authorize_request",
        "_init_encryption",
        "create_user",
        "_create_session",
        "revoke_session",
        "delete_user",
        "authenticate_request",
        "_hash_password",
        "_cleanup_tenant_compute",
        "_cleanup_agent_resource",
        "check_permission",
        "_load_config",
        "verify_token",
        "_generate_tenant_key",
        "_audit_log",
        "_check_resource_access",
        "_cleanup_tenant_storage",
        "_cleanup_rag_resource"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (20 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 20,
      "methods": [
        "info",
        "warning",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'config' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "config",
      "method_count": 7,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 8,
      "methods": [
        "utcnow",
        "fromisoformat",
        "now"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 223,
    "column": 31,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    220:     isolated_namespaces: list[str] = field(default_factory=list)\n    221:     allowed_models: list[str] = field(default_factory=list)\n    222:     max_agents: int = 10\n>>> 223:     max_rag_collections: int = 5\n    224:     max_p2p_nodes: int = 20\n    225:     storage_quota_gb: int = 100\n    226:     compute_quota_vcpu: int = 8",
    "context": {
      "total_magic_literals": 21,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 224,
    "column": 25,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    221:     allowed_models: list[str] = field(default_factory=list)\n    222:     max_agents: int = 10\n    223:     max_rag_collections: int = 5\n>>> 224:     max_p2p_nodes: int = 20\n    225:     storage_quota_gb: int = 100\n    226:     compute_quota_vcpu: int = 8\n    227:     memory_quota_gb: int = 32",
    "context": {
      "total_magic_literals": 21,
      "current_value": 20
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 226,
    "column": 30,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    223:     max_rag_collections: int = 5\n    224:     max_p2p_nodes: int = 20\n    225:     storage_quota_gb: int = 100\n>>> 226:     compute_quota_vcpu: int = 8\n    227:     memory_quota_gb: int = 32\n    228:     # Resource tracking\n    229:     agent_resources: dict[str, Any] = field(default_factory=dict)",
    "context": {
      "total_magic_literals": 21,
      "current_value": 8
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 227,
    "column": 27,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    224:     max_p2p_nodes: int = 20\n    225:     storage_quota_gb: int = 100\n    226:     compute_quota_vcpu: int = 8\n>>> 227:     memory_quota_gb: int = 32\n    228:     # Resource tracking\n    229:     agent_resources: dict[str, Any] = field(default_factory=dict)\n    230:     rag_resources: dict[str, Any] = field(default_factory=dict)",
    "context": {
      "total_magic_literals": 21,
      "current_value": 32
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\security\\rbac_system.py",
    "line_number": 274,
    "column": 48,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    271:     def __init__(self, config_path: Path | None = None):\n    272:         \"\"\"Initialize RBAC system with configuration.\"\"\"\n    273:         self.config_path = config_path or Path(\"config/security/rbac.json\")\n>>> 274:         self.jwt_secret = secrets.token_urlsafe(32)\n    275:         self.jwt_algorithm = \"HS256\"\n    276:         self.token_expiry = timedelta(hours=1)\n    277:         self.refresh_expiry = timedelta(days=7)",
    "context": {
      "total_magic_literals": 21,
      "current_value": 32
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\measure_compression.py",
    "line_number": 78,
    "column": 4,
    "description": "Method 'measure_inference_latency' is too complex: 4 complexity, 68 lines, 2 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     75:                 \"parameter_ratio\": 0,\n     76:             }\n     77: \n>>>  78:     def measure_inference_latency(\n     79:         self, model_path: str, num_samples: int = 10, max_length: int = 100,\n     80:     ) -> dict[str, float]:\n     81:         \"\"\"Measure inference latency.",
    "context": {
      "complexity": 4,
      "lines": 68,
      "max_nesting": 2,
      "method_name": "measure_inference_latency"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\measure_compression.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'parser' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "parser",
      "method_count": 7,
      "methods": [
        "parse_args",
        "add_argument"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\stub_fix.py",
    "line_number": 97,
    "column": 4,
    "description": "Method 'generate_report' is too complex: 11 complexity, 55 lines, 10 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     94: \n     95:         return all_stubs\n     96: \n>>>  97:     def generate_report(self, stubs: list[dict]) -> str:\n     98:         \"\"\"Generate summary report.\"\"\"\n     99:         if not stubs:\n    100:             return \"\u2705 No stubs found!\"",
    "context": {
      "complexity": 11,
      "lines": 55,
      "max_nesting": 10,
      "method_name": "generate_report"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\stub_fix.py",
    "line_number": 210,
    "column": 0,
    "description": "Method 'main' is too complex: 8 complexity, 61 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    207:         return \"low\"\n    208: \n    209: \n>>> 210: def main():\n    211:     \"\"\"Main CLI entry point.\"\"\"\n    212:     parser = argparse.ArgumentParser(description=\"Detect and fix implementation stubs\")\n    213:     parser.add_argument(\"path\", help=\"Path to scan (file or directory)\")",
    "context": {
      "complexity": 8,
      "lines": 61,
      "max_nesting": 6,
      "method_name": "main"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\stub_fix.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'parser' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "parser",
      "method_count": 6,
      "methods": [
        "parse_args",
        "add_argument"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\verify_cleanup.py",
    "line_number": 45,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     42: \n     43: \n     44: def iter_actions(log_path: Path) -> Iterable[str]:\n>>>  45:     \"\"\"Yield cleanup actions from ``log_path``.\n     46: \n     47:     Empty lines are ignored. The function is separated for easier testing.\n     48:     \"\"\"",
    "context": {
      "query_preview": "Yield cleanup actions from ``log_path``.\n\n    Empty lines are ignored. The function is separated for..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\agents\\specialist_agent_registry.py",
    "line_number": 133,
    "column": 4,
    "description": "Method '_initialize_core_agent_specs' is too complex: 1 complexity, 250 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    130: \n    131:         logger.info(\"SpecialistAgentRegistry initialized with \" f\"{len(self.specifications)} agent types\")\n    132: \n>>> 133:     def _initialize_core_agent_specs(self):\n    134:         \"\"\"Initialize specifications for all 18 core agents.\"\"\"\n    135:         # Leadership Tier (Strategic Decision Making)\n    136:         self.specifications[\"King\"] = AgentSpecification(",
    "context": {
      "complexity": 1,
      "lines": 250,
      "max_nesting": 0,
      "method_name": "_initialize_core_agent_specs"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\agents\\specialist_agent_registry.py",
    "line_number": 385,
    "column": 4,
    "description": "Method '_build_capability_indexes' is too complex: 7 complexity, 18 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    382:             resource_requirements={\"monitoring_intensive\": True},\n    383:         )\n    384: \n>>> 385:     def _build_capability_indexes(self):\n    386:         \"\"\"Build indexes for fast capability and role-based lookups.\"\"\"\n    387:         for agent_type, spec in self.specifications.items():\n    388:             # Index by role",
    "context": {
      "complexity": 7,
      "lines": 18,
      "max_nesting": 6,
      "method_name": "_build_capability_indexes"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\agents\\specialist_agent_registry.py",
    "line_number": 463,
    "column": 4,
    "description": "Method 'route_task_to_agent' is too complex: 11 complexity, 67 lines, 9 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    460: \n    461:         return instances\n    462: \n>>> 463:     def route_task_to_agent(self, task: dict[str, Any]) -> AgentInstance | None:\n    464:         \"\"\"Route a task to the most suitable available agent.\"\"\"\n    465:         required_capability = task.get(\"required_capability\")\n    466:         agent_type_preference = task.get(\"agent_type_preference\")",
    "context": {
      "complexity": 11,
      "lines": 67,
      "max_nesting": 9,
      "method_name": "route_task_to_agent"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\agents\\specialist_agent_registry.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 6,
      "methods": [
        "find_agents_by_capability",
        "_initialize_core_agent_specs",
        "get_available_instances",
        "_build_capability_indexes"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\agents\\specialist_agent_registry.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 6,
      "methods": [
        "info",
        "warning"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\agents\\specialist_agent_registry.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'task' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "task",
      "method_count": 6,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\agents\\specialist_agent_registry.py",
    "line_number": 73,
    "column": 32,
    "description": "Excessive magic literals detected (53 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     70:     coordination_preferences: dict[str, Any] = field(default_factory=dict)\n     71: \n     72:     # Operational parameters\n>>>  73:     max_concurrent_tasks: int = 3\n     74:     task_timeout_seconds: int = 300\n     75:     priority_multiplier: float = 1.0\n     76: ",
    "context": {
      "total_magic_literals": 53,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\agents\\specialist_agent_registry.py",
    "line_number": 74,
    "column": 32,
    "description": "Excessive magic literals detected (53 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     71: \n     72:     # Operational parameters\n     73:     max_concurrent_tasks: int = 3\n>>>  74:     task_timeout_seconds: int = 300\n     75:     priority_multiplier: float = 1.0\n     76: \n     77:     # Integration settings",
    "context": {
      "total_magic_literals": 53,
      "current_value": 300
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\agents\\specialist_agent_registry.py",
    "line_number": 80,
    "column": 33,
    "description": "Excessive magic literals detected (53 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     77:     # Integration settings\n     78:     requires_human_oversight: bool = False\n     79:     can_delegate_tasks: bool = True\n>>>  80:     collaboration_score: float = 0.8\n     81: \n     82:     # Technical configuration\n     83:     implementation_class: str | None = None",
    "context": {
      "total_magic_literals": 53,
      "current_value": 0.8
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\agents\\specialist_agent_registry.py",
    "line_number": 144,
    "column": 75,
    "description": "Excessive magic literals detected (53 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    141:             capabilities=[\n    142:                 AgentCapabilityConfig(AgentCapability.DECISION_MAKING, 1.0),\n    143:                 AgentCapabilityConfig(AgentCapability.STRATEGIC_PLANNING, 1.0),\n>>> 144:                 AgentCapabilityConfig(AgentCapability.RESOURCE_ALLOCATION, 0.9),\n    145:             ],\n    146:             max_concurrent_tasks=10,\n    147:             priority_multiplier=2.0,",
    "context": {
      "total_magic_literals": 53,
      "current_value": 0.9
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\agents\\specialist_agent_registry.py",
    "line_number": 160,
    "column": 74,
    "description": "Excessive magic literals detected (53 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    157:             secondary_roles=[AgentRole.INTELLIGENCE],\n    158:             capabilities=[\n    159:                 AgentCapabilityConfig(AgentCapability.KNOWLEDGE_SYNTHESIS, 1.0),\n>>> 160:                 AgentCapabilityConfig(AgentCapability.STRATEGIC_PLANNING, 0.9),\n    161:                 AgentCapabilityConfig(AgentCapability.HISTORICAL_ANALYSIS, 0.9),\n    162:             ],\n    163:             max_concurrent_tasks=5,",
    "context": {
      "total_magic_literals": 53,
      "current_value": 0.9
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 92,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     89:         try:\n     90:             key = f\"{mapping.old_module}.{mapping.old_class or ''}\"\n     91:             self.mappings[key] = mapping\n>>>  92:             self.allowed_modules.update({mapping.old_module, mapping.new_module})\n     93: \n     94:             # Register deprecation if specified\n     95:             if mapping.deprecated_in:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 111,
    "column": 4,
    "description": "Function 'register_deprecation' has 6 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    108:             logger.error(f\"Failed to register mapping: {e}\")\n    109:             return False\n    110: \n>>> 111:     def register_deprecation(\n    112:         self,\n    113:         item_name: str,\n    114:         deprecated_since: str,",
    "context": {
      "parameter_count": 6,
      "function_name": "register_deprecation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 149,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    146:             return False\n    147: \n    148:     def create_import_bridge(self, old_module: str, new_module: str) -> bool:\n>>> 149:         \"\"\"Create an import bridge that redirects old imports to new modules.\n    150: \n    151:         Args:\n    152:             old_module: Old module path",
    "context": {
      "query_preview": "Create an import bridge that redirects old imports to new modules.\n\n        Args:\n            old_mo..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 185,
    "column": 26,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    182:             self.active_bridges[old_module] = bridge_module\n    183: \n    184:             self.migration_stats[\"total_redirects\"] += 1\n>>> 185:             logger.info(f\"Created import bridge: {old_module} -> {new_module}\")\n    186:             return True\n    187: \n    188:         except Exception as e:",
    "context": {
      "query_preview": "Created import bridge: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 189,
    "column": 27,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    186:             return True\n    187: \n    188:         except Exception as e:\n>>> 189:             logger.error(f\"Failed to create import bridge {old_module} -> {new_module}: {e}\")\n    190:             return False\n    191: \n    192:     def create_class_wrapper(self, old_class: type, new_class: type, deprecated_since: str = \"1.0.0\") -> type:",
    "context": {
      "query_preview": "Failed to create import bridge "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 193,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    190:             return False\n    191: \n    192:     def create_class_wrapper(self, old_class: type, new_class: type, deprecated_since: str = \"1.0.0\") -> type:\n>>> 193:         \"\"\"Create a wrapper class that provides backward compatibility.\n    194: \n    195:         Args:\n    196:             old_class: Original class type",
    "context": {
      "query_preview": "Create a wrapper class that provides backward compatibility.\n\n        Args:\n            old_class: O..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 230,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    227:     def create_function_wrapper(\n    228:         self, old_func: Callable, new_func: Callable, deprecated_since: str = \"1.0.0\",\n    229:     ) -> Callable:\n>>> 230:         \"\"\"Create a wrapper function that provides backward compatibility.\n    231: \n    232:         Args:\n    233:             old_func: Original function",
    "context": {
      "query_preview": "Create a wrapper function that provides backward compatibility.\n\n        Args:\n            old_func:..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 273,
    "column": 36,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    270: REMOVAL: {deprecation.removal_version}\n    271: REPLACEMENT: {deprecation.replacement}\n    272: \n>>> 273: Notes: {deprecation.migration_notes}\n    274: \n    275: Example migration:\n    276:   Old: from {old_api.split(\".\")[0]} import {old_api.split(\".\")[-1]}",
    "context": {
      "query_preview": "\n\nExample migration:\n  Old: from "
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 310,
    "column": 4,
    "description": "Method 'generate_migration_report' is too complex: 7 complexity, 60 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    307: \n    308:         return deprecated_usage\n    309: \n>>> 310:     def generate_migration_report(self) -> str:\n    311:         \"\"\"Generate a comprehensive migration report.\n    312: \n    313:         Returns:",
    "context": {
      "complexity": 7,
      "lines": 60,
      "max_nesting": 6,
      "method_name": "generate_migration_report"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 360,
    "column": 26,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    357:         report.append(\"-\" * 40)\n    358: \n    359:         if self.deprecations:\n>>> 360:             report.append(\"1. Update imports to use new module paths\")\n    361:             report.append(\"2. Replace deprecated classes with new implementations\")\n    362:             report.append(\"3. Update function calls to use new API signatures\")\n    363:             report.append(\"4. Test thoroughly after migration\")",
    "context": {
      "query_preview": "1. Update imports to use new module paths"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 362,
    "column": 26,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    359:         if self.deprecations:\n    360:             report.append(\"1. Update imports to use new module paths\")\n    361:             report.append(\"2. Replace deprecated classes with new implementations\")\n>>> 362:             report.append(\"3. Update function calls to use new API signatures\")\n    363:             report.append(\"4. Test thoroughly after migration\")\n    364:         else:\n    365:             report.append(\"No active deprecations - migration is complete!\")",
    "context": {
      "query_preview": "3. Update function calls to use new API signatures"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 372,
    "column": 4,
    "description": "Method '_load_builtin_mappings' is too complex: 2 complexity, 55 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    369: \n    370:         return \"\\n\".join(report)\n    371: \n>>> 372:     def _load_builtin_mappings(self):\n    373:         \"\"\"Load built-in compatibility mappings for AIVillage architecture.\"\"\"\n    374:         builtin_mappings = [\n    375:             # Agent Forge migrations",
    "context": {
      "complexity": 2,
      "lines": 55,
      "max_nesting": 1,
      "method_name": "_load_builtin_mappings"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 381,
    "column": 32,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    378:                 new_module=\"src.software.agent_forge\",\n    379:                 deprecated_in=\"1.0.0\",\n    380:                 removed_in=\"2.0.0\",\n>>> 381:                 migration_guide=\"Update imports to use src.software.agent_forge\",\n    382:             ),\n    383:             # Production migrations\n    384:             CompatibilityMapping(",
    "context": {
      "query_preview": "Update imports to use src.software.agent_forge"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 389,
    "column": 32,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    386:                 new_module=\"src.production\",\n    387:                 deprecated_in=\"1.0.0\",\n    388:                 removed_in=\"2.0.0\",\n>>> 389:                 migration_guide=\"Update imports to use src.production\",\n    390:             ),\n    391:             # Communication system migrations\n    392:             CompatibilityMapping(",
    "context": {
      "query_preview": "Update imports to use src.production"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 397,
    "column": 32,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    394:                 new_module=\"src.communications\",\n    395:                 deprecated_in=\"1.0.0\",\n    396:                 removed_in=\"2.0.0\",\n>>> 397:                 migration_guide=\"Update imports to use src.communications\",\n    398:             ),\n    399:             # Core system migrations\n    400:             CompatibilityMapping(",
    "context": {
      "query_preview": "Update imports to use src.communications"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 405,
    "column": 32,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    402:                 new_module=\"src.core\",\n    403:                 deprecated_in=\"1.0.0\",\n    404:                 removed_in=\"2.0.0\",\n>>> 405:                 migration_guide=\"Update imports to use src.core\",\n    406:             ),\n    407:             # Hardware layer migrations\n    408:             CompatibilityMapping(",
    "context": {
      "query_preview": "Update imports to use src.core"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 446,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    443: \n    444: # Convenience functions for common operations\n    445: def create_legacy_import_bridge(old_module: str, new_module: str) -> bool:\n>>> 446:     \"\"\"Create a legacy import bridge for backward compatibility.\n    447: \n    448:     Args:\n    449:         old_module: Old module import path",
    "context": {
      "query_preview": "Create a legacy import bridge for backward compatibility.\n\n    Args:\n        old_module: Old module ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 569,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    566:                 if create_legacy_import_bridge(old_module, new_module):\n    567:                     bridges_created += 1\n    568:             except Exception as e:\n>>> 569:                 logger.debug(f\"Could not create bridge {old_module} -> {new_module}: {e}\")\n    570: \n    571:         if bridges_created > 0:\n    572:             logger.info(f\"Created {bridges_created} compatibility bridges\")",
    "context": {
      "query_preview": "Could not create bridge "
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 11,
      "methods": [
        "info",
        "warning",
        "error",
        "debug"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'report' methods (31 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "report",
      "method_count": 31,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 207,
    "column": 12,
    "description": "Sequential coupling detected: Function '__init__' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    204:         class CompatibilityWrapper(new_class):\n    205:             \"\"\"Compatibility wrapper for deprecated class.\"\"\"\n    206: \n>>> 207:             def __init__(self, *args, **kwargs):\n    208:                 # Issue deprecation warning\n    209:                 self._issue_deprecation_warning(\n    210:                     f\"{old_class.__name__} is deprecated since v{deprecated_since}. \"",
    "context": {
      "function_name": "__init__",
      "sequential_functions": [
        "__init__",
        "wrapped_init",
        "setup_aivillage_bridges"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 523,
    "column": 12,
    "description": "Sequential coupling detected: Function 'wrapped_init' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    520:             # Class decorator\n    521:             original_init = func_or_class.__init__\n    522: \n>>> 523:             def wrapped_init(self, *args, **kwargs):\n    524:                 warnings.warn(\n    525:                     f\"{func_or_class.__name__} is deprecated since v{deprecated_since}. \"\n    526:                     f\"Use {replacement} instead. Will be removed in v{removal_version}.\",",
    "context": {
      "function_name": "wrapped_init",
      "sequential_functions": [
        "__init__",
        "wrapped_init",
        "setup_aivillage_bridges"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\bridge_system.py",
    "line_number": 551,
    "column": 0,
    "description": "Sequential coupling detected: Function 'setup_aivillage_bridges' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    548: \n    549: \n    550: # Auto-setup common bridges on import\n>>> 551: def setup_aivillage_bridges():\n    552:     \"\"\"Set up common AIVillage compatibility bridges.\"\"\"\n    553:     try:\n    554:         # Create bridges for moved modules",
    "context": {
      "function_name": "setup_aivillage_bridges",
      "sequential_functions": [
        "__init__",
        "wrapped_init",
        "setup_aivillage_bridges"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\__init__.py",
    "line_number": 1,
    "column": 0,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": ">>>   1: \"\"\"Compatibility Bridge Package\n      2: \n      3: Provides seamless compatibility between old and new AIVillage architecture.\n      4: Automatically sets up import bridges and deprecation warnings to help",
    "context": {
      "query_preview": "Compatibility Bridge Package\n\nProvides seamless compatibility between old and new AIVillage architec..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compatibility\\__init__.py",
    "line_number": 32,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     29:     \"CompatibilityMapping\",\n     30:     \"DeprecationInfo\",\n     31:     \"compatibility_bridge\",\n>>>  32:     \"create_legacy_import_bridge\",\n     33:     \"deprecated_api\",\n     34:     \"get_migration_help\",\n     35:     \"register_deprecated_api\",",
    "context": {
      "query_preview": "create_legacy_import_bridge"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\compression\\advanced_pipeline.py",
    "line_number": 84,
    "column": 4,
    "description": "Method 'decompress_model' is too complex: 9 complexity, 45 lines, 7 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     81:         return blob\n     82: \n     83:     # ------------------------------------------------------------------\n>>>  84:     def decompress_model(self, data: bytes) -> dict[str, torch.Tensor]:\n     85:         payload = lzma.decompress(data)\n     86:         if len(payload) < 8:\n     87:             raise ValueError(\"Corrupted payload: header missing\")",
    "context": {
      "complexity": 9,
      "lines": 45,
      "max_nesting": 7,
      "method_name": "decompress_model"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compression\\advanced_pipeline.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'struct' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "struct",
      "method_count": 6,
      "methods": [
        "unpack_from",
        "pack"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compression\\advanced_pipeline.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'blob' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "blob",
      "method_count": 7,
      "methods": [
        "append",
        "extend"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compression\\cascade_compressor.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'out' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "out",
      "method_count": 9,
      "methods": [
        "append",
        "extend"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compression\\integrated_pipeline.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'struct' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "struct",
      "method_count": 7,
      "methods": [
        "unpack",
        "pack"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\compression\\simple_quantizer.py",
    "line_number": 79,
    "column": 4,
    "description": "Method '_optimize_model' is too complex: 6 complexity, 9 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     76:         torch.save(model, buffer, _use_new_zipfile_serialization=False)\n     77:         return buffer.tell()\n     78: \n>>>  79:     def _optimize_model(self, model: torch.nn.Module) -> None:\n     80:         for param in model.parameters():\n     81:             param.requires_grad = False\n     82:             if hasattr(param, \"grad\"):",
    "context": {
      "complexity": 6,
      "lines": 9,
      "max_nesting": 5,
      "method_name": "_optimize_model"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compression\\unified_compressor.py",
    "line_number": 1,
    "column": 0,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": ">>>   1: \"\"\"Unified compression interface selecting between simple and advanced methods.\"\"\"\n      2: \n      3: from __future__ import annotations\n      4: ",
    "context": {
      "query_preview": "Unified compression interface selecting between simple and advanced methods."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compression\\unified_compressor.py",
    "line_number": 17,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     14: \n     15: \n     16: class UnifiedCompressor:\n>>>  17:     \"\"\"Intelligent compression selector.\n     18: \n     19:     Chooses between the sprint 9 ``SimpleQuantizer`` and the four stage\n     20:     ``AdvancedCompressionPipeline``.  The decision is based on model size and",
    "context": {
      "query_preview": "Intelligent compression selector.\n\n    Chooses between the sprint 9 ``SimpleQuantizer`` and the four..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compression\\unified_compressor.py",
    "line_number": 46,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     43: \n     44:     # ------------------------------------------------------------------\n     45:     def compress(self, model: torch.nn.Module | str | Path) -> dict[str, object]:\n>>>  46:         \"\"\"Compress ``model`` selecting the appropriate method.\"\"\"\n     47:         if isinstance(model, str | Path):\n     48:             tmp = torch.load(model, map_location=\"cpu\")\n     49:             param_count = sum(p.numel() for p in tmp.parameters())",
    "context": {
      "query_preview": "Compress ``model`` selecting the appropriate method."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compression\\unified_compressor.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 9,
      "methods": [
        "info",
        "warning"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compression\\unified_compressor.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'p' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "p",
      "method_count": 6,
      "methods": [
        "numel"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compression\\unified_compressor.py",
    "line_number": 28,
    "column": 31,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     25:     def __init__(\n     26:         self,\n     27:         target_device: str = \"mobile\",\n>>>  28:         memory_limit_mb: int = 2048,\n     29:         target_compression: float | None = None,\n     30:     ) -> None:\n     31:         self.target_device = target_device",
    "context": {
      "total_magic_literals": 11,
      "current_value": 2048
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compression\\unified_compressor.py",
    "line_number": 54,
    "column": 38,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     51:         else:\n     52:             param_count = sum(p.numel() for p in model.parameters())\n     53: \n>>>  54:         model_size_mb = param_count * 4 / 1024 / 1024\n     55:         logger.info(\"Model size: %s params (%.1fMB)\", f\"{param_count:,}\", model_size_mb)\n     56: \n     57:         if self.target_compression is not None:",
    "context": {
      "total_magic_literals": 11,
      "current_value": 4
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compression\\unified_compressor.py",
    "line_number": 54,
    "column": 42,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     51:         else:\n     52:             param_count = sum(p.numel() for p in model.parameters())\n     53: \n>>>  54:         model_size_mb = param_count * 4 / 1024 / 1024\n     55:         logger.info(\"Model size: %s params (%.1fMB)\", f\"{param_count:,}\", model_size_mb)\n     56: \n     57:         if self.target_compression is not None:",
    "context": {
      "total_magic_literals": 11,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compression\\unified_compressor.py",
    "line_number": 54,
    "column": 49,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     51:         else:\n     52:             param_count = sum(p.numel() for p in model.parameters())\n     53: \n>>>  54:         model_size_mb = param_count * 4 / 1024 / 1024\n     55:         logger.info(\"Model size: %s params (%.1fMB)\", f\"{param_count:,}\", model_size_mb)\n     56: \n     57:         if self.target_compression is not None:",
    "context": {
      "total_magic_literals": 11,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\compression\\unified_compressor.py",
    "line_number": 60,
    "column": 69,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     57:         if self.target_compression is not None:\n     58:             required_ratio = self.target_compression\n     59:         else:\n>>>  60:             required_ratio = model_size_mb / (self.memory_limit_mb * 0.5)\n     61: \n     62:         logger.info(\"Required compression ratio: %.1fx\", required_ratio)\n     63: ",
    "context": {
      "total_magic_literals": 11,
      "current_value": 0.5
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": ">>>   1: \"\"\"Central configuration manager for AIVillage CODEX integration.\n      2: \n      3: This module provides a unified configuration system that loads settings from\n      4: multiple sources in priority order and validates all configurations before use.",
    "context": {
      "query_preview": "Central configuration manager for AIVillage CODEX integration.\n\nThis module provides a unified confi..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 56,
    "column": 0,
    "description": "Class 'ConfigurationManager' is a God Object: 24 methods, ~520 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "     53:     defaults: dict[str, Any] = field(default_factory=dict)\n     54: \n     55: \n>>>  56: class ConfigurationManager:\n     57:     \"\"\"Central configuration manager with priority-based loading.\"\"\"\n     58: \n     59:     # Default configuration profiles",
    "context": {
      "method_count": 24,
      "estimated_lines": 520,
      "class_name": "ConfigurationManager",
      "data_methods": 7,
      "business_methods": 17
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 170,
    "column": 37,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    167:                 \"SECURITY_CSP_ENABLED\": \"true\",\n    168:                 \"TLS_VERIFY_PEER\": \"true\",\n    169:                 # Production paths\n>>> 170:                 \"AIVILLAGE_DB_PATH\": \"/var/lib/aivillage/evolution_metrics.db\",\n    171:                 \"DIGITAL_TWIN_DB_PATH\": \"/var/lib/aivillage/digital_twin.db\",\n    172:                 \"RAG_FAISS_INDEX_PATH\": \"/var/lib/aivillage/faiss_index\",\n    173:                 \"DIGITAL_TWIN_VAULT_PATH\": \"/var/lib/aivillage/secure/vault\",",
    "context": {
      "hardcoded_value": "/var/lib/aivillage/evolution_metrics.db"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 171,
    "column": 40,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    168:                 \"TLS_VERIFY_PEER\": \"true\",\n    169:                 # Production paths\n    170:                 \"AIVILLAGE_DB_PATH\": \"/var/lib/aivillage/evolution_metrics.db\",\n>>> 171:                 \"DIGITAL_TWIN_DB_PATH\": \"/var/lib/aivillage/digital_twin.db\",\n    172:                 \"RAG_FAISS_INDEX_PATH\": \"/var/lib/aivillage/faiss_index\",\n    173:                 \"DIGITAL_TWIN_VAULT_PATH\": \"/var/lib/aivillage/secure/vault\",\n    174:                 \"BACKUP_STORAGE_PATH\": \"/var/backups/aivillage\",",
    "context": {
      "hardcoded_value": "/var/lib/aivillage/digital_twin.db"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 172,
    "column": 40,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    169:                 # Production paths\n    170:                 \"AIVILLAGE_DB_PATH\": \"/var/lib/aivillage/evolution_metrics.db\",\n    171:                 \"DIGITAL_TWIN_DB_PATH\": \"/var/lib/aivillage/digital_twin.db\",\n>>> 172:                 \"RAG_FAISS_INDEX_PATH\": \"/var/lib/aivillage/faiss_index\",\n    173:                 \"DIGITAL_TWIN_VAULT_PATH\": \"/var/lib/aivillage/secure/vault\",\n    174:                 \"BACKUP_STORAGE_PATH\": \"/var/backups/aivillage\",\n    175:                 \"AIVILLAGE_LOG_DIR\": \"/var/log/aivillage\",",
    "context": {
      "hardcoded_value": "/var/lib/aivillage/faiss_index"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 173,
    "column": 43,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    170:                 \"AIVILLAGE_DB_PATH\": \"/var/lib/aivillage/evolution_metrics.db\",\n    171:                 \"DIGITAL_TWIN_DB_PATH\": \"/var/lib/aivillage/digital_twin.db\",\n    172:                 \"RAG_FAISS_INDEX_PATH\": \"/var/lib/aivillage/faiss_index\",\n>>> 173:                 \"DIGITAL_TWIN_VAULT_PATH\": \"/var/lib/aivillage/secure/vault\",\n    174:                 \"BACKUP_STORAGE_PATH\": \"/var/backups/aivillage\",\n    175:                 \"AIVILLAGE_LOG_DIR\": \"/var/log/aivillage\",\n    176:             },",
    "context": {
      "hardcoded_value": "/var/lib/aivillage/secure/vault"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 174,
    "column": 39,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    171:                 \"DIGITAL_TWIN_DB_PATH\": \"/var/lib/aivillage/digital_twin.db\",\n    172:                 \"RAG_FAISS_INDEX_PATH\": \"/var/lib/aivillage/faiss_index\",\n    173:                 \"DIGITAL_TWIN_VAULT_PATH\": \"/var/lib/aivillage/secure/vault\",\n>>> 174:                 \"BACKUP_STORAGE_PATH\": \"/var/backups/aivillage\",\n    175:                 \"AIVILLAGE_LOG_DIR\": \"/var/log/aivillage\",\n    176:             },\n    177:         ),",
    "context": {
      "hardcoded_value": "/var/backups/aivillage"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 175,
    "column": 37,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    172:                 \"RAG_FAISS_INDEX_PATH\": \"/var/lib/aivillage/faiss_index\",\n    173:                 \"DIGITAL_TWIN_VAULT_PATH\": \"/var/lib/aivillage/secure/vault\",\n    174:                 \"BACKUP_STORAGE_PATH\": \"/var/backups/aivillage\",\n>>> 175:                 \"AIVILLAGE_LOG_DIR\": \"/var/log/aivillage\",\n    176:             },\n    177:         ),\n    178:     }",
    "context": {
      "hardcoded_value": "/var/log/aivillage"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 197,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    194:         self.profile = self.PROFILES[self.profile_name]\n    195: \n    196:     def load_configuration(self, cli_args: dict[str, Any] | None = None, validate: bool = True) -> dict[str, str]:\n>>> 197:         \"\"\"Load configuration from all sources in priority order.\n    198: \n    199:         Priority order (highest to lowest):\n    200:         1. Command line arguments",
    "context": {
      "query_preview": "Load configuration from all sources in priority order.\n\n        Priority order (highest to lowest):\n..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 248,
    "column": 4,
    "description": "Method '_load_env_file' is too complex: 7 complexity, 20 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    245:         )\n    246:         logger.debug(f\"Loaded {len(self.profile.defaults)} default values for profile '{self.profile_name}'\")\n    247: \n>>> 248:     def _load_env_file(self) -> None:\n    249:         \"\"\"Load .env file if available.\"\"\"\n    250:         env_files = [\".env\", f\".env.{self.profile_name}\", \".env.local\"]\n    251: ",
    "context": {
      "complexity": 7,
      "lines": 20,
      "max_nesting": 5,
      "method_name": "_load_env_file"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 271,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    268:                     logger.warning(f\"Found {env_file} but python-dotenv not available\")\n    269: \n    270:     def _load_config_file(self, filename: str) -> None:\n>>> 271:         \"\"\"Load configuration from YAML or JSON file.\"\"\"\n    272:         for ext in [\"yaml\", \"yml\", \"json\"]:\n    273:             config_path = self.config_dir / f\"{filename}.{ext}\"\n    274:             if config_path.exists():",
    "context": {
      "query_preview": "Load configuration from YAML or JSON file."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 310,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    307:             full_key = f\"{prefix}_{key}\".upper() if prefix else key.upper()\n    308: \n    309:             if isinstance(value, dict):\n>>> 310:                 result.update(self._flatten_config(value, full_key))\n    311:             else:\n    312:                 result[full_key] = str(value)\n    313: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 317,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    314:         return result\n    315: \n    316:     def _load_environment_variables(self) -> None:\n>>> 317:         \"\"\"Load configuration from environment variables.\"\"\"\n    318:         # Filter environment variables to only include relevant ones\n    319:         relevant_vars = {}\n    320:         aivillage_prefixes = [",
    "context": {
      "query_preview": "Load configuration from environment variables."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 357,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    354:         logger.debug(f\"Loaded {len(relevant_vars)} environment variables\")\n    355: \n    356:     def _load_cli_args(self, cli_args: dict[str, Any]) -> None:\n>>> 357:         \"\"\"Load configuration from command line arguments.\"\"\"\n    358:         # Convert CLI args to environment variable format\n    359:         env_format_args = {}\n    360:         for key, value in cli_args.items():",
    "context": {
      "query_preview": "Load configuration from command line arguments."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (22 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 22,
      "methods": [
        "get",
        "_load_cli_args",
        "_load_environment_variables",
        "_validate_configuration",
        "_flatten_config",
        "get_int",
        "get_bool",
        "is_production",
        "_is_component_variable",
        "_load_env_file",
        "_merge_sources",
        "_load_config_file",
        "_load_profile_defaults"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (13 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 13,
      "methods": [
        "exception",
        "warning",
        "error",
        "debug"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'lines' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "lines",
      "method_count": 8,
      "methods": [
        "append",
        "extend"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\configuration_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'parser' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "parser",
      "method_count": 6,
      "methods": [
        "parse_args",
        "add_argument"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 86,
    "column": 0,
    "description": "Class 'EnvironmentValidator' is a God Object: 12 methods, ~777 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "     83:             self.warnings += 1\n     84: \n     85: \n>>>  86: class EnvironmentValidator:\n     87:     \"\"\"Comprehensive environment variable validator.\"\"\"\n     88: \n     89:     # Required variables by component",
    "context": {
      "method_count": 12,
      "estimated_lines": 777,
      "class_name": "EnvironmentValidator",
      "data_methods": 0,
      "business_methods": 12
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 305,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    302:         # Count total variables we're checking\n    303:         all_required = set()\n    304:         for component_vars in self.REQUIRED_VARIABLES.values():\n>>> 305:             all_required.update(component_vars)\n    306:         self.report.total_variables = len(all_required)\n    307: \n    308:         # Validate required variables exist",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 358,
    "column": 4,
    "description": "Method '_validate_types' is too complex: 9 complexity, 32 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    355:                 else:\n    356:                     self.report.valid_variables += 1\n    357: \n>>> 358:     def _validate_types(self, env_vars: dict[str, str]) -> None:\n    359:         \"\"\"Validate variable types.\"\"\"\n    360:         for var_type, variables in self.TYPE_RULES.items():\n    361:             if var_type == \"enum\":",
    "context": {
      "complexity": 9,
      "lines": 32,
      "max_nesting": 8,
      "method_name": "_validate_types"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 392,
    "column": 4,
    "description": "Method '_validate_type' is too complex: 11 complexity, 28 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    389:                                 )\n    390:                             )\n    391: \n>>> 392:     def _validate_type(self, value: str, expected_type: str) -> bool:\n    393:         \"\"\"Validate individual type.\"\"\"\n    394:         try:\n    395:             if expected_type == \"int\":",
    "context": {
      "complexity": 11,
      "lines": 28,
      "max_nesting": 8,
      "method_name": "_validate_type"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 412,
    "column": 42,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    409:                 ]:\n    410:                     return False\n    411:             elif expected_type == \"url\":\n>>> 412:                 if not (value.startswith((\"http://\", \"https://\", \"redis://\", \"mongodb://\"))):\n    413:                     return False\n    414:             elif expected_type == \"path\":\n    415:                 # Basic path validation - just check it's not obviously invalid",
    "context": {
      "hardcoded_value": "http://"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 412,
    "column": 53,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    409:                 ]:\n    410:                     return False\n    411:             elif expected_type == \"url\":\n>>> 412:                 if not (value.startswith((\"http://\", \"https://\", \"redis://\", \"mongodb://\"))):\n    413:                     return False\n    414:             elif expected_type == \"path\":\n    415:                 # Basic path validation - just check it's not obviously invalid",
    "context": {
      "hardcoded_value": "https://"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 422,
    "column": 4,
    "description": "Method '_validate_security' is too complex: 16 complexity, 106 lines, 12 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    419:         except ValueError:\n    420:             return False\n    421: \n>>> 422:     def _validate_security(self, env_vars: dict[str, str]) -> None:\n    423:         \"\"\"Validate security-critical configurations.\"\"\"\n    424:         # Validate encryption key\n    425:         if \"DIGITAL_TWIN_ENCRYPTION_KEY\" in env_vars:",
    "context": {
      "complexity": 16,
      "lines": 106,
      "max_nesting": 12,
      "method_name": "_validate_security"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 530,
    "column": 4,
    "description": "Method '_validate_paths' is too complex: 18 complexity, 104 lines, 12 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    527:                         )\n    528:                     )\n    529: \n>>> 530:     def _validate_paths(self, env_vars: dict[str, str]) -> None:\n    531:         \"\"\"Validate file paths and directory permissions.\"\"\"\n    532:         for var in self.TYPE_RULES[\"path\"]:\n    533:             if var in env_vars:",
    "context": {
      "complexity": 18,
      "lines": 104,
      "max_nesting": 12,
      "method_name": "_validate_paths"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 555,
    "column": 50,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    552:                                         variable=var,\n    553:                                         level=ValidationLevel.INFO,\n    554:                                         result=ValidationResult.VALID,\n>>> 555:                                         message=f\"Created directory for {var}: {parent}\",\n    556:                                     )\n    557:                                 )\n    558:                             except OSError as e:",
    "context": {
      "query_preview": "Created directory for "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 564,
    "column": 50,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    561:                                         variable=var,\n    562:                                         level=ValidationLevel.ERROR,\n    563:                                         result=ValidationResult.INVALID,\n>>> 564:                                         message=f\"Cannot create directory {parent}: {e}\",\n    565:                                         suggestion=\"Ensure parent directory exists and is writable\",\n    566:                                     )\n    567:                                 )",
    "context": {
      "query_preview": "Cannot create directory "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 577,
    "column": 46,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    574:                                     variable=var,\n    575:                                     level=ValidationLevel.INFO,\n    576:                                     result=ValidationResult.VALID,\n>>> 577:                                     message=f\"Created directory for {var}: {path}\",\n    578:                                 )\n    579:                             )\n    580:                         except OSError as e:",
    "context": {
      "query_preview": "Created directory for "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 586,
    "column": 46,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    583:                                     variable=var,\n    584:                                     level=ValidationLevel.ERROR,\n    585:                                     result=ValidationResult.INVALID,\n>>> 586:                                     message=f\"Cannot create directory {path}: {e}\",\n    587:                                     suggestion=\"Ensure path is valid and parent is writable\",\n    588:                                 )\n    589:                             )",
    "context": {
      "query_preview": "Cannot create directory "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 622,
    "column": 43,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    619:                                 level=ValidationLevel.WARNING,\n    620:                                 result=ValidationResult.INVALID,\n    621:                                 message=f\"Parent directory {parent} doesn't exist\",\n>>> 622:                                 suggestion=\"Create parent directory or update path\",\n    623:                             )\n    624:                         )\n    625:                     elif not os.access(parent, os.W_OK):",
    "context": {
      "query_preview": "Create parent directory or update path"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 636,
    "column": 4,
    "description": "Method '_validate_ports' is too complex: 14 complexity, 78 lines, 9 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    633:                             )\n    634:                         )\n    635: \n>>> 636:     def _validate_ports(self, env_vars: dict[str, str]) -> None:\n    637:         \"\"\"Validate port availability and ranges.\"\"\"\n    638:         used_ports = set()\n    639: ",
    "context": {
      "complexity": 14,
      "lines": 78,
      "max_nesting": 9,
      "method_name": "_validate_ports"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 755,
    "column": 4,
    "description": "Method '_validate_environment_profile' is too complex: 10 complexity, 53 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    752:                         )\n    753:                     )\n    754: \n>>> 755:     def _validate_environment_profile(self, env_vars: dict[str, str]) -> None:\n    756:         \"\"\"Validate environment-specific requirements.\"\"\"\n    757:         env_type = env_vars.get(\"AIVILLAGE_ENV\", \"development\")\n    758: ",
    "context": {
      "complexity": 10,
      "lines": 53,
      "max_nesting": 6,
      "method_name": "_validate_environment_profile"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 799,
    "column": 52,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    796:                     )\n    797: \n    798:             qdrant_url = env_vars.get(\"QDRANT_URL\")\n>>> 799:             if qdrant_url and qdrant_url.startswith(\"http://\"):\n    800:                 self.report.add_issue(\n    801:                     ValidationIssue(\n    802:                         variable=\"QDRANT_URL\",",
    "context": {
      "hardcoded_value": "http://"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 805,
    "column": 32,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    802:                         variable=\"QDRANT_URL\",\n    803:                         level=ValidationLevel.ERROR,\n    804:                         result=ValidationResult.INSECURE,\n>>> 805:                         message=\"Production requires QDRANT_URL to use https://\",\n    806:                         suggestion=\"Use an HTTPS Qdrant endpoint and provide proper certificates\",\n    807:                     )\n    808:                 )",
    "context": {
      "hardcoded_value": "Production requires QDRANT_URL to use https://"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 810,
    "column": 4,
    "description": "Method 'generate_report' is too complex: 8 complexity, 53 lines, 7 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    807:                     )\n    808:                 )\n    809: \n>>> 810:     def generate_report(self) -> str:\n    811:         \"\"\"Generate human-readable validation report.\"\"\"\n    812:         report_lines = [\n    813:             \"=\" * 80,",
    "context": {
      "complexity": 8,
      "lines": 53,
      "max_nesting": 7,
      "method_name": "generate_report"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 9,
      "methods": [
        "_validate_paths",
        "_is_port_in_use",
        "_validate_required_variables",
        "_validate_security",
        "_validate_ports",
        "_validate_external_services",
        "_validate_types",
        "_validate_environment_profile",
        "_validate_type"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'report_lines' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "report_lines",
      "method_count": 8,
      "methods": [
        "append",
        "extend"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 276,
    "column": 24,
    "description": "Excessive magic literals detected (34 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    273: \n    274:     # Port ranges\n    275:     PORT_RANGES = {\n>>> 276:         \"LIBP2P_PORT\": (1024, 65535),\n    277:         \"LIBP2P_WEBSOCKET_PORT\": (1024, 65535),\n    278:         \"DIGITAL_TWIN_API_PORT\": (8000, 9000),\n    279:         \"EVOLUTION_METRICS_API_PORT\": (8000, 9000),",
    "context": {
      "total_magic_literals": 34,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 276,
    "column": 30,
    "description": "Excessive magic literals detected (34 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    273: \n    274:     # Port ranges\n    275:     PORT_RANGES = {\n>>> 276:         \"LIBP2P_PORT\": (1024, 65535),\n    277:         \"LIBP2P_WEBSOCKET_PORT\": (1024, 65535),\n    278:         \"DIGITAL_TWIN_API_PORT\": (8000, 9000),\n    279:         \"EVOLUTION_METRICS_API_PORT\": (8000, 9000),",
    "context": {
      "total_magic_literals": 34,
      "current_value": 65535
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 277,
    "column": 34,
    "description": "Excessive magic literals detected (34 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    274:     # Port ranges\n    275:     PORT_RANGES = {\n    276:         \"LIBP2P_PORT\": (1024, 65535),\n>>> 277:         \"LIBP2P_WEBSOCKET_PORT\": (1024, 65535),\n    278:         \"DIGITAL_TWIN_API_PORT\": (8000, 9000),\n    279:         \"EVOLUTION_METRICS_API_PORT\": (8000, 9000),\n    280:         \"RAG_PIPELINE_API_PORT\": (8000, 9000),",
    "context": {
      "total_magic_literals": 34,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 277,
    "column": 40,
    "description": "Excessive magic literals detected (34 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    274:     # Port ranges\n    275:     PORT_RANGES = {\n    276:         \"LIBP2P_PORT\": (1024, 65535),\n>>> 277:         \"LIBP2P_WEBSOCKET_PORT\": (1024, 65535),\n    278:         \"DIGITAL_TWIN_API_PORT\": (8000, 9000),\n    279:         \"EVOLUTION_METRICS_API_PORT\": (8000, 9000),\n    280:         \"RAG_PIPELINE_API_PORT\": (8000, 9000),",
    "context": {
      "total_magic_literals": 34,
      "current_value": 65535
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\config\\environment_validator.py",
    "line_number": 278,
    "column": 34,
    "description": "Excessive magic literals detected (34 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    275:     PORT_RANGES = {\n    276:         \"LIBP2P_PORT\": (1024, 65535),\n    277:         \"LIBP2P_WEBSOCKET_PORT\": (1024, 65535),\n>>> 278:         \"DIGITAL_TWIN_API_PORT\": (8000, 9000),\n    279:         \"EVOLUTION_METRICS_API_PORT\": (8000, 9000),\n    280:         \"RAG_PIPELINE_API_PORT\": (8000, 9000),\n    281:         \"P2P_STATUS_API_PORT\": (8000, 9000),",
    "context": {
      "total_magic_literals": 34,
      "current_value": 8000
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 67,
    "column": 0,
    "description": "Class 'DatabaseManager' is a God Object: 4 methods, ~634 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "     64:     socket_connect_timeout: int = 5\n     65: \n     66: \n>>>  67: class DatabaseManager:\n     68:     \"\"\"Centralized database manager for all CODEX components.\"\"\"\n     69: \n     70:     # Database schemas",
    "context": {
      "method_count": 4,
      "estimated_lines": 634,
      "class_name": "DatabaseManager",
      "data_methods": 1,
      "business_methods": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 71,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     68:     \"\"\"Centralized database manager for all CODEX components.\"\"\"\n     69: \n     70:     # Database schemas\n>>>  71:     EVOLUTION_METRICS_SCHEMA = \"\"\"\n     72:     -- Schema version tracking\n     73:     CREATE TABLE IF NOT EXISTS schema_version (\n     74:         version INTEGER PRIMARY KEY,",
    "context": {
      "query_preview": "\n    -- Schema version tracking\n    CREATE TABLE IF NOT EXISTS schema_version (\n        version INTE..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 135,
    "column": 26,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    132:     CREATE INDEX IF NOT EXISTS idx_selection_outcomes_round ON selection_outcomes(round_id);\n    133:     \"\"\"\n    134: \n>>> 135:     DIGITAL_TWIN_SCHEMA = \"\"\"\n    136:     -- Schema version tracking\n    137:     CREATE TABLE IF NOT EXISTS schema_version (\n    138:         version INTEGER PRIMARY KEY,",
    "context": {
      "query_preview": "\n    -- Schema version tracking\n    CREATE TABLE IF NOT EXISTS schema_version (\n        version INTE..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 213,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    210:     CREATE INDEX IF NOT EXISTS idx_knowledge_states_mastery ON knowledge_states(mastery_level);\n    211:     \"\"\"\n    212: \n>>> 213:     RAG_INDEX_SCHEMA = \"\"\"\n    214:     -- Schema version tracking\n    215:     CREATE TABLE IF NOT EXISTS schema_version (\n    216:         version INTEGER PRIMARY KEY,",
    "context": {
      "query_preview": "\n    -- Schema version tracking\n    CREATE TABLE IF NOT EXISTS schema_version (\n        version INTE..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 320,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    317:         logger.info(\"Database manager initialized successfully\")\n    318: \n    319:     async def _create_data_directories(self) -> None:\n>>> 320:         \"\"\"Create necessary data directories.\"\"\"\n    321:         if self.config_manager:\n    322:             dirs = [\n    323:                 self.config_manager.get(\"AIVILLAGE_LOG_DIR\", \"./logs\"),",
    "context": {
      "query_preview": "Create necessary data directories."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 373,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    370:             await self._create_sqlite_database(db_name, db_config)\n    371: \n    372:     async def _create_sqlite_database(self, name: str, config: dict[str, str]) -> None:\n>>> 373:         \"\"\"Create and initialize a SQLite database.\"\"\"\n    374:         db_path = config[\"path\"]\n    375: \n    376:         if db_path == \":memory:\":",
    "context": {
      "query_preview": "Create and initialize a SQLite database."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 389,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    386:         try:\n    387:             # Enable WAL mode for concurrent access\n    388:             if db_path != \":memory:\":\n>>> 389:                 conn.execute(\"PRAGMA journal_mode=WAL\")\n    390:                 conn.execute(\"PRAGMA synchronous=NORMAL\")\n    391:                 conn.execute(\"PRAGMA cache_size=10000\")\n    392:                 conn.execute(\"PRAGMA temp_store=memory\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 390,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    387:             # Enable WAL mode for concurrent access\n    388:             if db_path != \":memory:\":\n    389:                 conn.execute(\"PRAGMA journal_mode=WAL\")\n>>> 390:                 conn.execute(\"PRAGMA synchronous=NORMAL\")\n    391:                 conn.execute(\"PRAGMA cache_size=10000\")\n    392:                 conn.execute(\"PRAGMA temp_store=memory\")\n    393:                 conn.execute(\"PRAGMA mmap_size=268435456\")  # 256MB",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 391,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    388:             if db_path != \":memory:\":\n    389:                 conn.execute(\"PRAGMA journal_mode=WAL\")\n    390:                 conn.execute(\"PRAGMA synchronous=NORMAL\")\n>>> 391:                 conn.execute(\"PRAGMA cache_size=10000\")\n    392:                 conn.execute(\"PRAGMA temp_store=memory\")\n    393:                 conn.execute(\"PRAGMA mmap_size=268435456\")  # 256MB\n    394: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 392,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    389:                 conn.execute(\"PRAGMA journal_mode=WAL\")\n    390:                 conn.execute(\"PRAGMA synchronous=NORMAL\")\n    391:                 conn.execute(\"PRAGMA cache_size=10000\")\n>>> 392:                 conn.execute(\"PRAGMA temp_store=memory\")\n    393:                 conn.execute(\"PRAGMA mmap_size=268435456\")  # 256MB\n    394: \n    395:             # Execute schema",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 393,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    390:                 conn.execute(\"PRAGMA synchronous=NORMAL\")\n    391:                 conn.execute(\"PRAGMA cache_size=10000\")\n    392:                 conn.execute(\"PRAGMA temp_store=memory\")\n>>> 393:                 conn.execute(\"PRAGMA mmap_size=268435456\")  # 256MB\n    394: \n    395:             # Execute schema\n    396:             conn.executescript(config[\"schema\"])",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 400,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    397: \n    398:             # Insert schema version\n    399:             schema_version = 1\n>>> 400:             conn.execute(\n    401:                 \"INSERT OR REPLACE INTO schema_version (version, description) VALUES (?, ?)\",\n    402:                 (schema_version, config[\"description\"]),\n    403:             )",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 401,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    398:             # Insert schema version\n    399:             schema_version = 1\n    400:             conn.execute(\n>>> 401:                 \"INSERT OR REPLACE INTO schema_version (version, description) VALUES (?, ?)\",\n    402:                 (schema_version, config[\"description\"]),\n    403:             )\n    404: ",
    "context": {
      "query_preview": "INSERT OR REPLACE INTO schema_version (version, description) VALUES (?, ?)"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 405,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    402:                 (schema_version, config[\"description\"]),\n    403:             )\n    404: \n>>> 405:             conn.commit()\n    406: \n    407:             # Store connection\n    408:             self.connections[name] = conn",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 512,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    509: \n    510:     @asynccontextmanager\n    511:     async def get_redis_connection(self, pool_name: str):\n>>> 512:         \"\"\"Get Redis connection from pool (async context manager).\"\"\"\n    513:         if pool_name not in self.redis_pools:\n    514:             # Fallback to None - caller should handle\n    515:             yield None",
    "context": {
      "query_preview": "Get Redis connection from pool (async context manager)."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 555,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    552:         for db_name, conn in self.connections.items():\n    553:             try:\n    554:                 cursor = conn.cursor()\n>>> 555:                 cursor.execute(\"PRAGMA integrity_check\")\n    556:                 result = cursor.fetchone()\n    557:                 results[f\"sqlite_{db_name}\"] = result[0] == \"ok\" if result else False\n    558:                 logger.info(f\"Database {db_name} integrity: {results[f'sqlite_{db_name}']}\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 579,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    576:         return results\n    577: \n    578:     async def create_backup(self, database: str, backup_path: str | None = None) -> str:\n>>> 579:         \"\"\"Create database backup.\"\"\"\n    580:         if database not in self.connections:\n    581:             msg = f\"Database {database} not found\"\n    582:             raise ValueError(msg)",
    "context": {
      "query_preview": "Create database backup."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 615,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    612:                 logger.info(f\"Optimizing database {db_name}\")\n    613: \n    614:                 # Analyze tables for query optimization\n>>> 615:                 conn.execute(\"ANALYZE\")\n    616: \n    617:                 # Vacuum if not in WAL mode or if database is small\n    618:                 cursor = conn.cursor()",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 619,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    616: \n    617:                 # Vacuum if not in WAL mode or if database is small\n    618:                 cursor = conn.cursor()\n>>> 619:                 cursor.execute(\"PRAGMA page_count\")\n    620:                 page_count = cursor.fetchone()[0]\n    621: \n    622:                 if page_count < 10000:  # Small database, safe to vacuum",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 623,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    620:                 page_count = cursor.fetchone()[0]\n    621: \n    622:                 if page_count < 10000:  # Small database, safe to vacuum\n>>> 623:                     conn.execute(\"VACUUM\")\n    624:                     logger.info(f\"Vacuumed database {db_name}\")\n    625: \n    626:                 conn.commit()",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 626,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    623:                     conn.execute(\"VACUUM\")\n    624:                     logger.info(f\"Vacuumed database {db_name}\")\n    625: \n>>> 626:                 conn.commit()\n    627: \n    628:             except Exception as e:\n    629:                 logger.exception(f\"Optimization failed for {db_name}: {e}\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 640,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    637:                 cursor = conn.cursor()\n    638: \n    639:                 # Get table information\n>>> 640:                 cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n    641:                 tables = [row[0] for row in cursor.fetchall()]\n    642: \n    643:                 table_stats = {}",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 640,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    637:                 cursor = conn.cursor()\n    638: \n    639:                 # Get table information\n>>> 640:                 cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n    641:                 tables = [row[0] for row in cursor.fetchall()]\n    642: \n    643:                 table_stats = {}",
    "context": {
      "query_preview": "SELECT name FROM sqlite_master WHERE type='table'"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 648,
    "column": 24,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    645: \n    646:                 for table in tables:\n    647:                     if table != \"sqlite_sequence\":\n>>> 648:                         cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n    649:                         count = cursor.fetchone()[0]\n    650:                         table_stats[table] = count\n    651:                         total_rows += count",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 648,
    "column": 41,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    645: \n    646:                 for table in tables:\n    647:                     if table != \"sqlite_sequence\":\n>>> 648:                         cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n    649:                         count = cursor.fetchone()[0]\n    650:                         table_stats[table] = count\n    651:                         total_rows += count",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 654,
    "column": 19,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    651:                         total_rows += count\n    652: \n    653:                 # Get database size\n>>> 654:                 if self.connections[db_name].execute(\"PRAGMA database_list\").fetchone()[2] != \":memory:\":\n    655:                     cursor.execute(\"PRAGMA page_count\")\n    656:                     page_count = cursor.fetchone()[0]\n    657:                     cursor.execute(\"PRAGMA page_size\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 655,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    652: \n    653:                 # Get database size\n    654:                 if self.connections[db_name].execute(\"PRAGMA database_list\").fetchone()[2] != \":memory:\":\n>>> 655:                     cursor.execute(\"PRAGMA page_count\")\n    656:                     page_count = cursor.fetchone()[0]\n    657:                     cursor.execute(\"PRAGMA page_size\")\n    658:                     page_size = cursor.fetchone()[0]",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 657,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    654:                 if self.connections[db_name].execute(\"PRAGMA database_list\").fetchone()[2] != \":memory:\":\n    655:                     cursor.execute(\"PRAGMA page_count\")\n    656:                     page_count = cursor.fetchone()[0]\n>>> 657:                     cursor.execute(\"PRAGMA page_size\")\n    658:                     page_size = cursor.fetchone()[0]\n    659:                     size_bytes = page_count * page_size\n    660:                 else:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (32 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 32,
      "methods": [
        "info",
        "warning",
        "exception",
        "debug"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 6,
      "methods": [
        "_create_sqlite_database",
        "get_redis_connection",
        "_initialize_sqlite_databases",
        "_create_data_directories",
        "_setup_encryption",
        "_initialize_redis_connections"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'conn' methods (17 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "conn",
      "method_count": 17,
      "methods": [
        "close",
        "execute",
        "rollback",
        "executescript",
        "cursor",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'cursor' methods (12 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "cursor",
      "method_count": 12,
      "methods": [
        "execute",
        "fetchone",
        "fetchall"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 50,
    "column": 0,
    "description": "Class 'DatabaseValidator' is a God Object: 6 methods, ~836 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "     47:     cpu_time_ms: float = 0.0\n     48: \n     49: \n>>>  50: class DatabaseValidator:\n     51:     \"\"\"Comprehensive database validation and performance testing.\"\"\"\n     52: \n     53:     def __init__(self, database_manager, redis_manager=None) -> None:",
    "context": {
      "method_count": 6,
      "estimated_lines": 836,
      "class_name": "DatabaseValidator",
      "data_methods": 3,
      "business_methods": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 115,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    112:                 cursor = conn.cursor()\n    113: \n    114:                 # Test basic query\n>>> 115:                 cursor.execute(\"SELECT sqlite_version()\")\n    116:                 version = cursor.fetchone()[0]\n    117: \n    118:                 # Test write capability",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 115,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    112:                 cursor = conn.cursor()\n    113: \n    114:                 # Test basic query\n>>> 115:                 cursor.execute(\"SELECT sqlite_version()\")\n    116:                 version = cursor.fetchone()[0]\n    117: \n    118:                 # Test write capability",
    "context": {
      "query_preview": "SELECT sqlite_version()"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 119,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    116:                 version = cursor.fetchone()[0]\n    117: \n    118:                 # Test write capability\n>>> 119:                 cursor.execute(\"SELECT COUNT(*) FROM sqlite_master WHERE type='table'\")\n    120:                 table_count = cursor.fetchone()[0]\n    121: \n    122:                 duration_ms = (time.time() - start_time) * 1000",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 119,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    116:                 version = cursor.fetchone()[0]\n    117: \n    118:                 # Test write capability\n>>> 119:                 cursor.execute(\"SELECT COUNT(*) FROM sqlite_master WHERE type='table'\")\n    120:                 table_count = cursor.fetchone()[0]\n    121: \n    122:                 duration_ms = (time.time() - start_time) * 1000",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM sqlite_master WHERE type='table'"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 158,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    155:                 cursor = conn.cursor()\n    156: \n    157:                 # Check schema version\n>>> 158:                 cursor.execute(\n    159:                     \"\"\"\n    160:                 SELECT version, description FROM schema_version\n    161:                 ORDER BY version DESC LIMIT 1",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 159,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    156: \n    157:                 # Check schema version\n    158:                 cursor.execute(\n>>> 159:                     \"\"\"\n    160:                 SELECT version, description FROM schema_version\n    161:                 ORDER BY version DESC LIMIT 1\n    162:                 \"\"\",",
    "context": {
      "query_preview": "\n                SELECT version, description FROM schema_version\n                ORDER BY version DE..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 184,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    181: \n    182:                 # Validate required tables exist\n    183:                 expected_tables = self._get_expected_tables(database)\n>>> 184:                 cursor.execute(\n    185:                     \"\"\"\n    186:                 SELECT name FROM sqlite_master\n    187:                 WHERE type='table' AND name NOT LIKE 'sqlite_%'",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 185,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    182:                 # Validate required tables exist\n    183:                 expected_tables = self._get_expected_tables(database)\n    184:                 cursor.execute(\n>>> 185:                     \"\"\"\n    186:                 SELECT name FROM sqlite_master\n    187:                 WHERE type='table' AND name NOT LIKE 'sqlite_%'\n    188:                 \"\"\",",
    "context": {
      "query_preview": "\n                SELECT name FROM sqlite_master\n                WHERE type='table' AND name NOT LIKE..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 196,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    193:                 extra_tables = actual_tables - expected_tables\n    194: \n    195:                 # Run integrity check\n>>> 196:                 cursor.execute(\"PRAGMA integrity_check\")\n    197:                 integrity_result = cursor.fetchone()[0]\n    198: \n    199:                 duration_ms = (time.time() - start_time) * 1000",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 273,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    270:                 if database == \"evolution_metrics\":\n    271:                     # Test evolution round creation\n    272:                     f\"test_round_{int(time.time())}\"\n>>> 273:                     cursor.execute(\n    274:                         \"\"\"\n    275:                     INSERT INTO evolution_rounds (start_time, status, agent_count)\n    276:                     VALUES (?, 'testing', 1)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 274,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    271:                     # Test evolution round creation\n    272:                     f\"test_round_{int(time.time())}\"\n    273:                     cursor.execute(\n>>> 274:                         \"\"\"\n    275:                     INSERT INTO evolution_rounds (start_time, status, agent_count)\n    276:                     VALUES (?, 'testing', 1)\n    277:                     \"\"\",",
    "context": {
      "query_preview": "\n                    INSERT INTO evolution_rounds (start_time, status, agent_count)\n                ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 284,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    281:                     round_id = cursor.lastrowid\n    282: \n    283:                     # Test fitness metric creation\n>>> 284:                     cursor.execute(\n    285:                         \"\"\"\n    286:                     INSERT INTO fitness_metrics\n    287:                     (round_id, agent_id, evolution_id, fitness_score, timestamp)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 285,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    282: \n    283:                     # Test fitness metric creation\n    284:                     cursor.execute(\n>>> 285:                         \"\"\"\n    286:                     INSERT INTO fitness_metrics\n    287:                     (round_id, agent_id, evolution_id, fitness_score, timestamp)\n    288:                     VALUES (?, 'test_agent', 'test_evolution', 0.85, ?)",
    "context": {
      "query_preview": "\n                    INSERT INTO fitness_metrics\n                    (round_id, agent_id, evolution_..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 294,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    291:                     )\n    292: \n    293:                     # Test query\n>>> 294:                     cursor.execute(\n    295:                         \"\"\"\n    296:                     SELECT COUNT(*) FROM fitness_metrics WHERE round_id = ?\n    297:                     \"\"\",",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 295,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    292: \n    293:                     # Test query\n    294:                     cursor.execute(\n>>> 295:                         \"\"\"\n    296:                     SELECT COUNT(*) FROM fitness_metrics WHERE round_id = ?\n    297:                     \"\"\",\n    298:                         (round_id,),",
    "context": {
      "query_preview": "\n                    SELECT COUNT(*) FROM fitness_metrics WHERE round_id = ?\n                    "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 303,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    300:                     count = cursor.fetchone()[0]\n    301: \n    302:                     # Cleanup test data\n>>> 303:                     cursor.execute(\"DELETE FROM fitness_metrics WHERE round_id = ?\", (round_id,))\n    304:                     cursor.execute(\"DELETE FROM evolution_rounds WHERE id = ?\", (round_id,))\n    305: \n    306:                     conn.commit()",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 303,
    "column": 35,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    300:                     count = cursor.fetchone()[0]\n    301: \n    302:                     # Cleanup test data\n>>> 303:                     cursor.execute(\"DELETE FROM fitness_metrics WHERE round_id = ?\", (round_id,))\n    304:                     cursor.execute(\"DELETE FROM evolution_rounds WHERE id = ?\", (round_id,))\n    305: \n    306:                     conn.commit()",
    "context": {
      "query_preview": "DELETE FROM fitness_metrics WHERE round_id = ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 304,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    301: \n    302:                     # Cleanup test data\n    303:                     cursor.execute(\"DELETE FROM fitness_metrics WHERE round_id = ?\", (round_id,))\n>>> 304:                     cursor.execute(\"DELETE FROM evolution_rounds WHERE id = ?\", (round_id,))\n    305: \n    306:                     conn.commit()\n    307: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 304,
    "column": 35,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    301: \n    302:                     # Cleanup test data\n    303:                     cursor.execute(\"DELETE FROM fitness_metrics WHERE round_id = ?\", (round_id,))\n>>> 304:                     cursor.execute(\"DELETE FROM evolution_rounds WHERE id = ?\", (round_id,))\n    305: \n    306:                     conn.commit()\n    307: ",
    "context": {
      "query_preview": "DELETE FROM evolution_rounds WHERE id = ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 306,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    303:                     cursor.execute(\"DELETE FROM fitness_metrics WHERE round_id = ?\", (round_id,))\n    304:                     cursor.execute(\"DELETE FROM evolution_rounds WHERE id = ?\", (round_id,))\n    305: \n>>> 306:                     conn.commit()\n    307: \n    308:                     passed = count == 1\n    309:                     message = f\"CRUD operations successful, inserted and queried {count} record(s)\"",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 309,
    "column": 32,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    306:                     conn.commit()\n    307: \n    308:                     passed = count == 1\n>>> 309:                     message = f\"CRUD operations successful, inserted and queried {count} record(s)\"\n    310: \n    311:                 elif database == \"digital_twin\":\n    312:                     # Test profile creation",
    "context": {
      "query_preview": "CRUD operations successful, inserted and queried "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 314,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    311:                 elif database == \"digital_twin\":\n    312:                     # Test profile creation\n    313:                     test_student_id = f\"test_student_{int(time.time())}\"\n>>> 314:                     cursor.execute(\n    315:                         \"\"\"\n    316:                     INSERT INTO learning_profiles\n    317:                     (student_id, name, age, grade_level)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 315,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    312:                     # Test profile creation\n    313:                     test_student_id = f\"test_student_{int(time.time())}\"\n    314:                     cursor.execute(\n>>> 315:                         \"\"\"\n    316:                     INSERT INTO learning_profiles\n    317:                     (student_id, name, age, grade_level)\n    318:                     VALUES (?, 'Test Student', 12, 7)",
    "context": {
      "query_preview": "\n                    INSERT INTO learning_profiles\n                    (student_id, name, age, grade..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 324,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    321:                     )\n    322: \n    323:                     # Test query\n>>> 324:                     cursor.execute(\n    325:                         \"\"\"\n    326:                     SELECT name FROM learning_profiles WHERE student_id = ?\n    327:                     \"\"\",",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 325,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    322: \n    323:                     # Test query\n    324:                     cursor.execute(\n>>> 325:                         \"\"\"\n    326:                     SELECT name FROM learning_profiles WHERE student_id = ?\n    327:                     \"\"\",\n    328:                         (test_student_id,),",
    "context": {
      "query_preview": "\n                    SELECT name FROM learning_profiles WHERE student_id = ?\n                    "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 333,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    330:                     result = cursor.fetchone()\n    331: \n    332:                     # Cleanup\n>>> 333:                     cursor.execute(\n    334:                         \"DELETE FROM learning_profiles WHERE student_id = ?\",\n    335:                         (test_student_id,),\n    336:                     )",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 334,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    331: \n    332:                     # Cleanup\n    333:                     cursor.execute(\n>>> 334:                         \"DELETE FROM learning_profiles WHERE student_id = ?\",\n    335:                         (test_student_id,),\n    336:                     )\n    337:                     conn.commit()",
    "context": {
      "query_preview": "DELETE FROM learning_profiles WHERE student_id = ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 337,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    334:                         \"DELETE FROM learning_profiles WHERE student_id = ?\",\n    335:                         (test_student_id,),\n    336:                     )\n>>> 337:                     conn.commit()\n    338: \n    339:                     passed = result and result[0] == \"Test Student\"\n    340:                     message = f\"CRUD operations successful, profile test passed: {passed}\"",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 345,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    342:                 elif database == \"rag_index\":\n    343:                     # Test document creation\n    344:                     test_doc_id = f\"test_doc_{int(time.time())}\"\n>>> 345:                     cursor.execute(\n    346:                         \"\"\"\n    347:                     INSERT INTO documents\n    348:                     (document_id, title, content_hash, word_count)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 346,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    343:                     # Test document creation\n    344:                     test_doc_id = f\"test_doc_{int(time.time())}\"\n    345:                     cursor.execute(\n>>> 346:                         \"\"\"\n    347:                     INSERT INTO documents\n    348:                     (document_id, title, content_hash, word_count)\n    349:                     VALUES (?, 'Test Document', 'test_hash_123', 100)",
    "context": {
      "query_preview": "\n                    INSERT INTO documents\n                    (document_id, title, content_hash, wo..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 355,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    352:                     )\n    353: \n    354:                     # Test query\n>>> 355:                     cursor.execute(\n    356:                         \"\"\"\n    357:                     SELECT title FROM documents WHERE document_id = ?\n    358:                     \"\"\",",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 356,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    353: \n    354:                     # Test query\n    355:                     cursor.execute(\n>>> 356:                         \"\"\"\n    357:                     SELECT title FROM documents WHERE document_id = ?\n    358:                     \"\"\",\n    359:                         (test_doc_id,),",
    "context": {
      "query_preview": "\n                    SELECT title FROM documents WHERE document_id = ?\n                    "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 364,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    361:                     result = cursor.fetchone()\n    362: \n    363:                     # Cleanup\n>>> 364:                     cursor.execute(\"DELETE FROM documents WHERE document_id = ?\", (test_doc_id,))\n    365:                     conn.commit()\n    366: \n    367:                     passed = result and result[0] == \"Test Document\"",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 364,
    "column": 35,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    361:                     result = cursor.fetchone()\n    362: \n    363:                     # Cleanup\n>>> 364:                     cursor.execute(\"DELETE FROM documents WHERE document_id = ?\", (test_doc_id,))\n    365:                     conn.commit()\n    366: \n    367:                     passed = result and result[0] == \"Test Document\"",
    "context": {
      "query_preview": "DELETE FROM documents WHERE document_id = ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 365,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    362: \n    363:                     # Cleanup\n    364:                     cursor.execute(\"DELETE FROM documents WHERE document_id = ?\", (test_doc_id,))\n>>> 365:                     conn.commit()\n    366: \n    367:                     passed = result and result[0] == \"Test Document\"\n    368:                     message = f\"CRUD operations successful, document test passed: {passed}\"",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 381,
    "column": 52,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    378:                         database=database,\n    379:                         test_name=\"basic_operations\",\n    380:                         passed=passed,\n>>> 381:                         value={\"operations_tested\": \"insert, select, delete\"},\n    382:                         message=message,\n    383:                         duration_ms=duration_ms,\n    384:                     ),",
    "context": {
      "query_preview": "insert, select, delete"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 411,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    408: \n    409:                 # Benchmark SELECT performance\n    410:                 select_start = time.time()\n>>> 411:                 cursor.execute(\"SELECT COUNT(*) FROM sqlite_master\")\n    412:                 select_duration = (time.time() - select_start) * 1000\n    413: \n    414:                 self.performance_metrics.append(",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 411,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    408: \n    409:                 # Benchmark SELECT performance\n    410:                 select_start = time.time()\n>>> 411:                 cursor.execute(\"SELECT COUNT(*) FROM sqlite_master\")\n    412:                 select_duration = (time.time() - select_start) * 1000\n    413: \n    414:                 self.performance_metrics.append(",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM sqlite_master"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 432,
    "column": 24,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    429:                     test_data = self._generate_test_data(database, 100)\n    430: \n    431:                     for data in test_data:\n>>> 432:                         cursor.execute(data[\"sql\"], data[\"params\"])\n    433: \n    434:                     conn.commit()\n    435:                     insert_duration = (time.time() - insert_start) * 1000",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 434,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    431:                     for data in test_data:\n    432:                         cursor.execute(data[\"sql\"], data[\"params\"])\n    433: \n>>> 434:                     conn.commit()\n    435:                     insert_duration = (time.time() - insert_start) * 1000\n    436: \n    437:                     self.performance_metrics.append(",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 450,
    "column": 24,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    447:                     # Cleanup test data\n    448:                     cleanup_sql = self._get_cleanup_sql(database)\n    449:                     if cleanup_sql:\n>>> 450:                         cursor.execute(cleanup_sql)\n    451:                         conn.commit()\n    452: \n    453:                 # Test query performance on existing data",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 451,
    "column": 24,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    448:                     cleanup_sql = self._get_cleanup_sql(database)\n    449:                     if cleanup_sql:\n    450:                         cursor.execute(cleanup_sql)\n>>> 451:                         conn.commit()\n    452: \n    453:                 # Test query performance on existing data\n    454:                 query_start = time.time()",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 458,
    "column": 24,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    455:                 tables = self._get_expected_tables(database)\n    456:                 for table in tables:\n    457:                     if table != \"schema_version\":\n>>> 458:                         cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n    459:                         cursor.fetchone()\n    460: \n    461:                 query_duration = (time.time() - query_start) * 1000",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 458,
    "column": 41,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    455:                 tables = self._get_expected_tables(database)\n    456:                 for table in tables:\n    457:                     if table != \"schema_version\":\n>>> 458:                         cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n    459:                         cursor.fetchone()\n    460: \n    461:                 query_duration = (time.time() - query_start) * 1000",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 520,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    517:             if database == \"evolution_metrics\":\n    518:                 test_data.append(\n    519:                     {\n>>> 520:                         \"sql\": \"INSERT INTO evolution_rounds (start_time, status) VALUES (?, 'test')\",\n    521:                         \"params\": (time.time() + i,),\n    522:                     },\n    523:                 )",
    "context": {
      "query_preview": "INSERT INTO evolution_rounds (start_time, status) VALUES (?, 'test')"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 527,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    524:             elif database == \"digital_twin\":\n    525:                 test_data.append(\n    526:                     {\n>>> 527:                         \"sql\": \"\"\"INSERT INTO learning_profiles\n    528:                              (student_id, name, age, grade_level)\n    529:                              VALUES (?, ?, 10, 5)\"\"\",\n    530:                         \"params\": (f\"perf_test_student_{i}\", f\"Test Student {i}\"),",
    "context": {
      "query_preview": "INSERT INTO learning_profiles\n                             (student_id, name, age, grade_level)\n    ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 536,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    533:             elif database == \"rag_index\":\n    534:                 test_data.append(\n    535:                     {\n>>> 536:                         \"sql\": \"\"\"INSERT INTO documents\n    537:                              (document_id, title, content_hash, word_count)\n    538:                              VALUES (?, ?, ?, 100)\"\"\",\n    539:                         \"params\": (",
    "context": {
      "query_preview": "INSERT INTO documents\n                             (document_id, title, content_hash, word_count)\n  ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 552,
    "column": 33,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    549:     def _get_cleanup_sql(self, database: str) -> str | None:\n    550:         \"\"\"Get cleanup SQL for test data.\"\"\"\n    551:         cleanup_map = {\n>>> 552:             \"evolution_metrics\": \"DELETE FROM evolution_rounds WHERE status = 'test'\",\n    553:             \"digital_twin\": \"DELETE FROM learning_profiles WHERE student_id LIKE 'perf_test_%'\",\n    554:             \"rag_index\": \"DELETE FROM documents WHERE document_id LIKE 'perf_test_%'\",\n    555:         }",
    "context": {
      "query_preview": "DELETE FROM evolution_rounds WHERE status = 'test'"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 553,
    "column": 28,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    550:         \"\"\"Get cleanup SQL for test data.\"\"\"\n    551:         cleanup_map = {\n    552:             \"evolution_metrics\": \"DELETE FROM evolution_rounds WHERE status = 'test'\",\n>>> 553:             \"digital_twin\": \"DELETE FROM learning_profiles WHERE student_id LIKE 'perf_test_%'\",\n    554:             \"rag_index\": \"DELETE FROM documents WHERE document_id LIKE 'perf_test_%'\",\n    555:         }\n    556:         return cleanup_map.get(database)",
    "context": {
      "query_preview": "DELETE FROM learning_profiles WHERE student_id LIKE 'perf_test_%'"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 554,
    "column": 25,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    551:         cleanup_map = {\n    552:             \"evolution_metrics\": \"DELETE FROM evolution_rounds WHERE status = 'test'\",\n    553:             \"digital_twin\": \"DELETE FROM learning_profiles WHERE student_id LIKE 'perf_test_%'\",\n>>> 554:             \"rag_index\": \"DELETE FROM documents WHERE document_id LIKE 'perf_test_%'\",\n    555:         }\n    556:         return cleanup_map.get(database)\n    557: ",
    "context": {
      "query_preview": "DELETE FROM documents WHERE document_id LIKE 'perf_test_%'"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 567,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    564:                 cursor = conn.cursor()\n    565: \n    566:                 # Get database size\n>>> 567:                 cursor.execute(\"PRAGMA page_count\")\n    568:                 page_count = cursor.fetchone()[0]\n    569:                 cursor.execute(\"PRAGMA page_size\")\n    570:                 page_size = cursor.fetchone()[0]",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 569,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    566:                 # Get database size\n    567:                 cursor.execute(\"PRAGMA page_count\")\n    568:                 page_count = cursor.fetchone()[0]\n>>> 569:                 cursor.execute(\"PRAGMA page_size\")\n    570:                 page_size = cursor.fetchone()[0]\n    571: \n    572:                 db_size_bytes = page_count * page_size",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 576,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    573:                 db_size_mb = db_size_bytes / (1024 * 1024)\n    574: \n    575:                 # Check for unused space\n>>> 576:                 cursor.execute(\"PRAGMA freelist_count\")\n    577:                 freelist_count = cursor.fetchone()[0]\n    578: \n    579:                 # Analyze table sizes",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 583,
    "column": 24,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    580:                 table_stats = {}\n    581:                 for table in self._get_expected_tables(database):\n    582:                     if table != \"schema_version\":\n>>> 583:                         cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n    584:                         row_count = cursor.fetchone()[0]\n    585:                         table_stats[table] = row_count\n    586: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 583,
    "column": 41,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    580:                 table_stats = {}\n    581:                 for table in self._get_expected_tables(database):\n    582:                     if table != \"schema_version\":\n>>> 583:                         cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n    584:                         row_count = cursor.fetchone()[0]\n    585:                         table_stats[table] = row_count\n    586: ",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 588,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    585:                         table_stats[table] = row_count\n    586: \n    587:                 # Check index usage\n>>> 588:                 cursor.execute(\n    589:                     \"\"\"\n    590:                 SELECT name, sql FROM sqlite_master\n    591:                 WHERE type='index' AND sql IS NOT NULL",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 589,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    586: \n    587:                 # Check index usage\n    588:                 cursor.execute(\n>>> 589:                     \"\"\"\n    590:                 SELECT name, sql FROM sqlite_master\n    591:                 WHERE type='index' AND sql IS NOT NULL\n    592:                 \"\"\",",
    "context": {
      "query_preview": "\n                SELECT name, sql FROM sqlite_master\n                WHERE type='index' AND sql IS N..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 651,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    648:                 cursor = conn.cursor()\n    649: \n    650:                 # Check foreign key consistency\n>>> 651:                 cursor.execute(\"PRAGMA foreign_key_check\")\n    652:                 fk_violations = cursor.fetchall()\n    653: \n    654:                 # Database-specific consistency checks",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 659,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    656: \n    657:                 if database == \"evolution_metrics\":\n    658:                     # Check that all fitness_metrics have valid round_ids\n>>> 659:                     cursor.execute(\n    660:                         \"\"\"\n    661:                     SELECT COUNT(*) FROM fitness_metrics fm\n    662:                     LEFT JOIN evolution_rounds er ON fm.round_id = er.id",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 660,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    657:                 if database == \"evolution_metrics\":\n    658:                     # Check that all fitness_metrics have valid round_ids\n    659:                     cursor.execute(\n>>> 660:                         \"\"\"\n    661:                     SELECT COUNT(*) FROM fitness_metrics fm\n    662:                     LEFT JOIN evolution_rounds er ON fm.round_id = er.id\n    663:                     WHERE er.id IS NULL",
    "context": {
      "query_preview": "\n                    SELECT COUNT(*) FROM fitness_metrics fm\n                    LEFT JOIN evolution..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 672,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    669: \n    670:                 elif database == \"digital_twin\":\n    671:                     # Check that all learning_sessions have valid student_ids\n>>> 672:                     cursor.execute(\n    673:                         \"\"\"\n    674:                     SELECT COUNT(*) FROM learning_sessions ls\n    675:                     LEFT JOIN learning_profiles lp ON ls.student_id = lp.student_id",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 673,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    670:                 elif database == \"digital_twin\":\n    671:                     # Check that all learning_sessions have valid student_ids\n    672:                     cursor.execute(\n>>> 673:                         \"\"\"\n    674:                     SELECT COUNT(*) FROM learning_sessions ls\n    675:                     LEFT JOIN learning_profiles lp ON ls.student_id = lp.student_id\n    676:                     WHERE lp.student_id IS NULL",
    "context": {
      "query_preview": "\n                    SELECT COUNT(*) FROM learning_sessions ls\n                    LEFT JOIN learnin..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 685,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    682: \n    683:                 elif database == \"rag_index\":\n    684:                     # Check that all chunks have valid document_ids\n>>> 685:                     cursor.execute(\n    686:                         \"\"\"\n    687:                     SELECT COUNT(*) FROM chunks c\n    688:                     LEFT JOIN documents d ON c.document_id = d.document_id",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 686,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    683:                 elif database == \"rag_index\":\n    684:                     # Check that all chunks have valid document_ids\n    685:                     cursor.execute(\n>>> 686:                         \"\"\"\n    687:                     SELECT COUNT(*) FROM chunks c\n    688:                     LEFT JOIN documents d ON c.document_id = d.document_id\n    689:                     WHERE d.document_id IS NULL",
    "context": {
      "query_preview": "\n                    SELECT COUNT(*) FROM chunks c\n                    LEFT JOIN documents d ON c.do..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 756,
    "column": 26,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    753:                     get_value = await conn.get(test_key)\n    754: \n    755:                     # Cleanup\n>>> 756:                     await conn.delete(test_key)\n    757: \n    758:                     pool_duration = (time.time() - pool_start) * 1000\n    759: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 805,
    "column": 4,
    "description": "Method '_generate_validation_summary' is too complex: 10 complexity, 81 lines, 7 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    802:                 ),\n    803:             )\n    804: \n>>> 805:     def _generate_validation_summary(self, total_duration_ms: float) -> dict[str, Any]:\n    806:         \"\"\"Generate comprehensive validation summary.\"\"\"\n    807:         summary = {\n    808:             \"timestamp\": datetime.now().isoformat(),",
    "context": {
      "complexity": 10,
      "lines": 81,
      "max_nesting": 7,
      "method_name": "_generate_validation_summary"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'time' methods (40 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "time",
      "method_count": 40,
      "methods": [
        "time"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (15 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 15,
      "methods": [
        "_validate_redis_connections",
        "_get_test_table_name",
        "_analyze_database_optimization",
        "_benchmark_database_performance",
        "_generate_validation_summary",
        "_test_database_connection",
        "_validate_database",
        "_test_basic_operations",
        "_get_expected_tables",
        "_get_cleanup_sql",
        "_validate_data_consistency",
        "_validate_schema_integrity",
        "_generate_test_data"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'conn' methods (14 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "conn",
      "method_count": 14,
      "methods": [
        "get",
        "delete",
        "set",
        "cursor",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'cursor' methods (47 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "cursor",
      "method_count": 47,
      "methods": [
        "execute",
        "fetchone",
        "fetchall"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'recommendations' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "recommendations",
      "method_count": 6,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 573,
    "column": 46,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    570:                 page_size = cursor.fetchone()[0]\n    571: \n    572:                 db_size_bytes = page_count * page_size\n>>> 573:                 db_size_mb = db_size_bytes / (1024 * 1024)\n    574: \n    575:                 # Check for unused space\n    576:                 cursor.execute(\"PRAGMA freelist_count\")",
    "context": {
      "total_magic_literals": 11,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 573,
    "column": 53,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    570:                 page_size = cursor.fetchone()[0]\n    571: \n    572:                 db_size_bytes = page_count * page_size\n>>> 573:                 db_size_mb = db_size_bytes / (1024 * 1024)\n    574: \n    575:                 # Check for unused space\n    576:                 cursor.execute(\"PRAGMA freelist_count\")",
    "context": {
      "total_magic_literals": 11,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 600,
    "column": 49,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    597: \n    598:                 # Generate optimization recommendations\n    599:                 recommendations = []\n>>> 600:                 if freelist_count > page_count * 0.1:\n    601:                     recommendations.append(\"Consider running VACUUM to reclaim space\")\n    602: \n    603:                 if db_size_mb > 100:",
    "context": {
      "total_magic_literals": 11,
      "current_value": 0.1
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 607,
    "column": 32,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    604:                     recommendations.append(\"Large database - consider partitioning\")\n    605: \n    606:                 total_rows = sum(table_stats.values())\n>>> 607:                 if total_rows > 10000 and len(indexes) < 3:\n    608:                     recommendations.append(\"Consider adding more indexes for better query performance\")\n    609: \n    610:                 self.results.append(",
    "context": {
      "total_magic_literals": 11,
      "current_value": 10000
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\database_validator.py",
    "line_number": 607,
    "column": 57,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    604:                     recommendations.append(\"Large database - consider partitioning\")\n    605: \n    606:                 total_rows = sum(table_stats.values())\n>>> 607:                 if total_rows > 10000 and len(indexes) < 3:\n    608:                     recommendations.append(\"Consider adding more indexes for better query performance\")\n    609: \n    610:                 self.results.append(",
    "context": {
      "total_magic_literals": 11,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 27,
    "column": 4,
    "description": "Function '__init__' has 8 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "     24: class Migration:\n     25:     \"\"\"Represents a single database migration.\"\"\"\n     26: \n>>>  27:     def __init__(\n     28:         self,\n     29:         version: int,\n     30:         name: str,",
    "context": {
      "parameter_count": 8,
      "function_name": "__init__"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 61,
    "column": 4,
    "description": "Method '_load_migrations' is too complex: 1 complexity, 112 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     58:         }\n     59:         self._load_migrations()\n     60: \n>>>  61:     def _load_migrations(self) -> None:\n     62:         \"\"\"Load all migration definitions.\"\"\"\n     63:         # Evolution Metrics migrations\n     64:         self.migrations[\"evolution_metrics\"] = [",
    "context": {
      "complexity": 1,
      "lines": 112,
      "max_nesting": 0,
      "method_name": "_load_migrations"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 68,
    "column": 28,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     65:             Migration(\n     66:                 version=1,\n     67:                 name=\"initial_schema\",\n>>>  68:                 description=\"Create initial evolution metrics tables\",\n     69:                 up_sql=self.database_manager.EVOLUTION_METRICS_SCHEMA,\n     70:                 down_sql=\"\"\"\n     71:                 DROP TABLE IF EXISTS selection_outcomes;",
    "context": {
      "query_preview": "Create initial evolution metrics tables"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 70,
    "column": 25,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     67:                 name=\"initial_schema\",\n     68:                 description=\"Create initial evolution metrics tables\",\n     69:                 up_sql=self.database_manager.EVOLUTION_METRICS_SCHEMA,\n>>>  70:                 down_sql=\"\"\"\n     71:                 DROP TABLE IF EXISTS selection_outcomes;\n     72:                 DROP TABLE IF EXISTS resource_metrics;\n     73:                 DROP TABLE IF EXISTS fitness_metrics;",
    "context": {
      "query_preview": "\n                DROP TABLE IF EXISTS selection_outcomes;\n                DROP TABLE IF EXISTS resou..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 82,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     79:                 version=2,\n     80:                 name=\"add_agent_metadata\",\n     81:                 description=\"Add metadata columns for enhanced agent tracking\",\n>>>  82:                 up_sql=\"\"\"\n     83:                 ALTER TABLE fitness_metrics ADD COLUMN agent_type TEXT;\n     84:                 ALTER TABLE fitness_metrics ADD COLUMN generation INTEGER DEFAULT 0;\n     85:                 ALTER TABLE evolution_rounds ADD COLUMN configuration TEXT;",
    "context": {
      "query_preview": "\n                ALTER TABLE fitness_metrics ADD COLUMN agent_type TEXT;\n                ALTER TABLE..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 90,
    "column": 25,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     87:                 CREATE INDEX IF NOT EXISTS idx_fitness_metrics_agent_type ON fitness_metrics(agent_type);\n     88:                 CREATE INDEX IF NOT EXISTS idx_fitness_metrics_generation ON fitness_metrics(generation);\n     89:                 \"\"\",\n>>>  90:                 down_sql=\"\"\"\n     91:                 DROP INDEX IF EXISTS idx_fitness_metrics_generation;\n     92:                 DROP INDEX IF EXISTS idx_fitness_metrics_agent_type;\n     93:                 -- Note: SQLite doesn't support DROP COLUMN, would need table recreation",
    "context": {
      "query_preview": "\n                DROP INDEX IF EXISTS idx_fitness_metrics_generation;\n                DROP INDEX IF ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 103,
    "column": 28,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    100:             Migration(\n    101:                 version=1,\n    102:                 name=\"initial_schema\",\n>>> 103:                 description=\"Create initial digital twin tables\",\n    104:                 up_sql=self.database_manager.DIGITAL_TWIN_SCHEMA,\n    105:                 down_sql=\"\"\"\n    106:                 DROP TABLE IF EXISTS knowledge_states;",
    "context": {
      "query_preview": "Create initial digital twin tables"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 105,
    "column": 25,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    102:                 name=\"initial_schema\",\n    103:                 description=\"Create initial digital twin tables\",\n    104:                 up_sql=self.database_manager.DIGITAL_TWIN_SCHEMA,\n>>> 105:                 down_sql=\"\"\"\n    106:                 DROP TABLE IF EXISTS knowledge_states;\n    107:                 DROP TABLE IF EXISTS learning_sessions;\n    108:                 DROP TABLE IF EXISTS learning_profiles;",
    "context": {
      "query_preview": "\n                DROP TABLE IF EXISTS knowledge_states;\n                DROP TABLE IF EXISTS learnin..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 116,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    113:                 version=2,\n    114:                 name=\"add_privacy_fields\",\n    115:                 description=\"Add privacy and compliance tracking fields\",\n>>> 116:                 up_sql=\"\"\"\n    117:                 ALTER TABLE learning_profiles ADD COLUMN privacy_consent TEXT;\n    118:                 ALTER TABLE learning_profiles ADD COLUMN data_retention_until TIMESTAMP;\n    119:                 ALTER TABLE learning_sessions ADD COLUMN privacy_level TEXT DEFAULT 'standard';",
    "context": {
      "query_preview": "\n                ALTER TABLE learning_profiles ADD COLUMN privacy_consent TEXT;\n                ALTE..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 123,
    "column": 25,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    120: \n    121:                 CREATE INDEX IF NOT EXISTS idx_learning_profiles_retention ON learning_profiles(data_retention_until);\n    122:                 \"\"\",\n>>> 123:                 down_sql=\"\"\"\n    124:                 DROP INDEX IF EXISTS idx_learning_profiles_retention;\n    125:                 -- Note: SQLite doesn't support DROP COLUMN, would need table recreation\n    126:                 \"\"\",",
    "context": {
      "query_preview": "\n                DROP INDEX IF EXISTS idx_learning_profiles_retention;\n                -- Note: SQLi..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 135,
    "column": 28,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    132:             Migration(\n    133:                 version=1,\n    134:                 name=\"initial_schema\",\n>>> 135:                 description=\"Create initial RAG index tables\",\n    136:                 up_sql=self.database_manager.RAG_INDEX_SCHEMA,\n    137:                 down_sql=\"\"\"\n    138:                 DROP TABLE IF EXISTS query_cache;",
    "context": {
      "query_preview": "Create initial RAG index tables"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 137,
    "column": 25,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    134:                 name=\"initial_schema\",\n    135:                 description=\"Create initial RAG index tables\",\n    136:                 up_sql=self.database_manager.RAG_INDEX_SCHEMA,\n>>> 137:                 down_sql=\"\"\"\n    138:                 DROP TABLE IF EXISTS query_cache;\n    139:                 DROP TABLE IF EXISTS embeddings_metadata;\n    140:                 DROP TABLE IF EXISTS chunks;",
    "context": {
      "query_preview": "\n                DROP TABLE IF EXISTS query_cache;\n                DROP TABLE IF EXISTS embeddings_m..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 149,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    146:                 version=2,\n    147:                 name=\"add_semantic_search\",\n    148:                 description=\"Add semantic search enhancements\",\n>>> 149:                 up_sql=\"\"\"\n    150:                 ALTER TABLE chunks ADD COLUMN semantic_keywords TEXT;\n    151:                 ALTER TABLE documents ADD COLUMN document_category TEXT;\n    152:                 ALTER TABLE query_cache ADD COLUMN query_intent TEXT;",
    "context": {
      "query_preview": "\n                ALTER TABLE chunks ADD COLUMN semantic_keywords TEXT;\n                ALTER TABLE d..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 166,
    "column": 25,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    163:                 CREATE INDEX IF NOT EXISTS idx_documents_category ON documents(document_category);\n    164:                 CREATE INDEX IF NOT EXISTS idx_semantic_clusters_keywords ON semantic_clusters(keywords);\n    165:                 \"\"\",\n>>> 166:                 down_sql=\"\"\"\n    167:                 DROP INDEX IF EXISTS idx_semantic_clusters_keywords;\n    168:                 DROP INDEX IF EXISTS idx_documents_category;\n    169:                 DROP TABLE IF EXISTS semantic_clusters;",
    "context": {
      "query_preview": "\n                DROP INDEX IF EXISTS idx_semantic_clusters_keywords;\n                DROP INDEX IF ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 184,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    181:         with self.database_manager.get_connection(database) as conn:\n    182:             try:\n    183:                 cursor = conn.cursor()\n>>> 184:                 cursor.execute(\"SELECT MAX(version) FROM schema_version\")\n    185:                 result = cursor.fetchone()\n    186:                 return result[0] if result[0] is not None else 0\n    187:             except sqlite3.OperationalError:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 184,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    181:         with self.database_manager.get_connection(database) as conn:\n    182:             try:\n    183:                 cursor = conn.cursor()\n>>> 184:                 cursor.execute(\"SELECT MAX(version) FROM schema_version\")\n    185:                 result = cursor.fetchone()\n    186:                 return result[0] if result[0] is not None else 0\n    187:             except sqlite3.OperationalError:",
    "context": {
      "query_preview": "SELECT MAX(version) FROM schema_version"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 200,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    197:         with self.database_manager.get_connection(database) as conn:\n    198:             try:\n    199:                 cursor = conn.cursor()\n>>> 200:                 cursor.execute(\n    201:                     \"\"\"\n    202:                 SELECT version, applied_at, description\n    203:                 FROM schema_version",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 201,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    198:             try:\n    199:                 cursor = conn.cursor()\n    200:                 cursor.execute(\n>>> 201:                     \"\"\"\n    202:                 SELECT version, applied_at, description\n    203:                 FROM schema_version\n    204:                 ORDER BY version ASC",
    "context": {
      "query_preview": "\n                SELECT version, applied_at, description\n                FROM schema_version\n       ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 295,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    292:         with self.database_manager.get_connection(database) as conn:\n    293:             try:\n    294:                 # Start transaction\n>>> 295:                 conn.execute(\"BEGIN\")\n    296: \n    297:                 # Check if migration already applied\n    298:                 cursor = conn.cursor()",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 299,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    296: \n    297:                 # Check if migration already applied\n    298:                 cursor = conn.cursor()\n>>> 299:                 cursor.execute(\n    300:                     \"SELECT 1 FROM schema_version WHERE version = ?\",\n    301:                     (migration.version,),\n    302:                 )",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 300,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    297:                 # Check if migration already applied\n    298:                 cursor = conn.cursor()\n    299:                 cursor.execute(\n>>> 300:                     \"SELECT 1 FROM schema_version WHERE version = ?\",\n    301:                     (migration.version,),\n    302:                 )\n    303:                 if cursor.fetchone():",
    "context": {
      "query_preview": "SELECT 1 FROM schema_version WHERE version = ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 317,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    314:                     await migration.data_migration(conn)\n    315: \n    316:                 # Record migration\n>>> 317:                 conn.execute(\n    318:                     \"INSERT INTO schema_version (version, description) VALUES (?, ?)\",\n    319:                     (migration.version, migration.description),\n    320:                 )",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 318,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    315: \n    316:                 # Record migration\n    317:                 conn.execute(\n>>> 318:                     \"INSERT INTO schema_version (version, description) VALUES (?, ?)\",\n    319:                     (migration.version, migration.description),\n    320:                 )\n    321: ",
    "context": {
      "query_preview": "INSERT INTO schema_version (version, description) VALUES (?, ?)"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 323,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    320:                 )\n    321: \n    322:                 # Commit transaction\n>>> 323:                 conn.commit()\n    324: \n    325:                 logger.info(f\"Successfully applied migration {migration.version}\")\n    326:                 return True",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 344,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    341:         with self.database_manager.get_connection(database) as conn:\n    342:             try:\n    343:                 # Start transaction\n>>> 344:                 conn.execute(\"BEGIN\")\n    345: \n    346:                 # Execute rollback SQL\n    347:                 conn.executescript(migration.down_sql)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 350,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    347:                 conn.executescript(migration.down_sql)\n    348: \n    349:                 # Remove migration record\n>>> 350:                 conn.execute(\"DELETE FROM schema_version WHERE version = ?\", (migration.version,))\n    351: \n    352:                 # Commit transaction\n    353:                 conn.commit()",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 350,
    "column": 29,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    347:                 conn.executescript(migration.down_sql)\n    348: \n    349:                 # Remove migration record\n>>> 350:                 conn.execute(\"DELETE FROM schema_version WHERE version = ?\", (migration.version,))\n    351: \n    352:                 # Commit transaction\n    353:                 conn.commit()",
    "context": {
      "query_preview": "DELETE FROM schema_version WHERE version = ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 353,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    350:                 conn.execute(\"DELETE FROM schema_version WHERE version = ?\", (migration.version,))\n    351: \n    352:                 # Commit transaction\n>>> 353:                 conn.commit()\n    354: \n    355:                 logger.info(f\"Successfully rolled back migration {migration.version}\")\n    356:                 return True",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 403,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    400:         return validation_results\n    401: \n    402:     async def create_migration_template(self, database: str, name: str) -> str:\n>>> 403:         \"\"\"Create a template for a new migration.\"\"\"\n    404:         if database not in self.migrations:\n    405:             msg = f\"Unknown database {database}\"\n    406:             raise ValueError(msg)",
    "context": {
      "query_preview": "Create a template for a new migration."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 415,
    "column": 37,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    412:         template = f'''\"\"\"  # nosec B608\n    413: Migration {next_version}: {name}\n    414: Database: {database}\n>>> 415: Created: {datetime.now().isoformat()}\n    416: \"\"\"\n    417: \n    418: from core.database.migrations import Migration",
    "context": {
      "query_preview": "\n\"\"\"\n\nfrom core.database.migrations import Migration\n\nmigration_"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 422,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    419: \n    420: migration_{next_version} = Migration(\n    421:     version={next_version},\n>>> 422:     name=\"{name}\",\n    423:     description=\"Custom migration - update with specific description\",\n    424:     up_sql=\"\"\"\n    425:     -- Add your forward migration SQL here",
    "context": {
      "query_preview": "\",\n    description=\"Custom migration - update with specific description\",\n    up_sql=\"\"\"\n    -- Add ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 431,
    "column": 34,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    428:     -- Add your rollback migration SQL here\n    429:     \"\"\",\n    430:     # data_migration=custom_data_migration_function,  # Optional\n>>> 431:     # requires=[{next_version - 1}]  # Optional dependencies\n    432: )\n    433: \n    434: # Optional: Custom data migration function",
    "context": {
      "query_preview": "]  # Optional dependencies\n)\n\n# Optional: Custom data migration function\nasync def custom_data_migra..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 446,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    443: \n    444: \n    445: class DataMigrator:\n>>> 446:     \"\"\"Handles data migration from existing systems.\"\"\"\n    447: \n    448:     def __init__(self, database_manager) -> None:\n    449:         self.database_manager = database_manager",
    "context": {
      "query_preview": "Handles data migration from existing systems."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 452,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    449:         self.database_manager = database_manager\n    450: \n    451:     async def migrate_evolution_metrics_from_json(self, json_file_path: str) -> bool:\n>>> 452:         \"\"\"Migrate evolution metrics from JSON file to SQLite database.\"\"\"\n    453:         json_path = Path(json_file_path)\n    454:         if not json_path.exists():\n    455:             logger.warning(f\"JSON file {json_file_path} not found, skipping migration\")",
    "context": {
      "query_preview": "Migrate evolution metrics from JSON file to SQLite database."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 458,
    "column": 22,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    455:             logger.warning(f\"JSON file {json_file_path} not found, skipping migration\")\n    456:             return True\n    457: \n>>> 458:         logger.info(f\"Migrating evolution metrics from {json_file_path}\")\n    459: \n    460:         try:\n    461:             with open(json_path) as f:",
    "context": {
      "query_preview": "Migrating evolution metrics from "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 469,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    466: \n    467:         with self.database_manager.get_connection(\"evolution_metrics\") as conn:\n    468:             try:\n>>> 469:                 conn.execute(\"BEGIN\")\n    470: \n    471:                 # Migrate evolution rounds\n    472:                 if \"rounds\" in data:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 474,
    "column": 24,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    471:                 # Migrate evolution rounds\n    472:                 if \"rounds\" in data:\n    473:                     for round_data in data[\"rounds\"]:\n>>> 474:                         conn.execute(\n    475:                             \"\"\"\n    476:                         INSERT OR REPLACE INTO evolution_rounds\n    477:                         (start_time, end_time, status, agent_count, success_rate, metadata)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 475,
    "column": 28,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    472:                 if \"rounds\" in data:\n    473:                     for round_data in data[\"rounds\"]:\n    474:                         conn.execute(\n>>> 475:                             \"\"\"\n    476:                         INSERT OR REPLACE INTO evolution_rounds\n    477:                         (start_time, end_time, status, agent_count, success_rate, metadata)\n    478:                         VALUES (?, ?, ?, ?, ?, ?)",
    "context": {
      "query_preview": "\n                        INSERT OR REPLACE INTO evolution_rounds\n                        (start_time..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 494,
    "column": 32,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    491:                         # Migrate fitness metrics for this round\n    492:                         if \"fitness_metrics\" in round_data:\n    493:                             for metric in round_data[\"fitness_metrics\"]:\n>>> 494:                                 conn.execute(\n    495:                                     \"\"\"\n    496:                                 INSERT INTO fitness_metrics\n    497:                                 (round_id, agent_id, evolution_id, fitness_score, improvement_delta, timestamp, metadata)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 495,
    "column": 36,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    492:                         if \"fitness_metrics\" in round_data:\n    493:                             for metric in round_data[\"fitness_metrics\"]:\n    494:                                 conn.execute(\n>>> 495:                                     \"\"\"\n    496:                                 INSERT INTO fitness_metrics\n    497:                                 (round_id, agent_id, evolution_id, fitness_score, improvement_delta, timestamp, metadata)\n    498:                                 VALUES (?, ?, ?, ?, ?, ?, ?)",
    "context": {
      "query_preview": "\n                                INSERT INTO fitness_metrics\n                                (round_..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 511,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    508:                                     ),\n    509:                                 )\n    510: \n>>> 511:                 conn.commit()\n    512:                 logger.info(f\"Successfully migrated evolution metrics from {json_file_path}\")\n    513:                 return True\n    514: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 512,
    "column": 30,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    509:                                 )\n    510: \n    511:                 conn.commit()\n>>> 512:                 logger.info(f\"Successfully migrated evolution metrics from {json_file_path}\")\n    513:                 return True\n    514: \n    515:             except Exception as e:",
    "context": {
      "query_preview": "Successfully migrated evolution metrics from "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 521,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    518:                 return False\n    519: \n    520:     async def migrate_digital_twin_profiles(self, profiles_dir: str) -> bool:\n>>> 521:         \"\"\"Migrate digital twin profiles from directory structure to database.\"\"\"\n    522:         profiles_path = Path(profiles_dir)\n    523:         if not profiles_path.exists():\n    524:             logger.warning(f\"Profiles directory {profiles_dir} not found, skipping migration\")",
    "context": {
      "query_preview": "Migrate digital twin profiles from directory structure to database."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 527,
    "column": 22,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    524:             logger.warning(f\"Profiles directory {profiles_dir} not found, skipping migration\")\n    525:             return True\n    526: \n>>> 527:         logger.info(f\"Migrating digital twin profiles from {profiles_dir}\")\n    528: \n    529:         with self.database_manager.get_connection(\"digital_twin\") as conn:\n    530:             try:",
    "context": {
      "query_preview": "Migrating digital twin profiles from "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 531,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    528: \n    529:         with self.database_manager.get_connection(\"digital_twin\") as conn:\n    530:             try:\n>>> 531:                 conn.execute(\"BEGIN\")\n    532: \n    533:                 # Find all profile JSON files\n    534:                 for profile_file in profiles_path.glob(\"*.json\"):",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 540,
    "column": 24,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    537:                             profile_data = json.load(f)\n    538: \n    539:                         # Insert learning profile\n>>> 540:                         conn.execute(\n    541:                             \"\"\"\n    542:                         INSERT OR REPLACE INTO learning_profiles\n    543:                         (student_id, name, age, grade_level, language, region, learning_style,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 541,
    "column": 28,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    538: \n    539:                         # Insert learning profile\n    540:                         conn.execute(\n>>> 541:                             \"\"\"\n    542:                         INSERT OR REPLACE INTO learning_profiles\n    543:                         (student_id, name, age, grade_level, language, region, learning_style,\n    544:                          strengths, challenges, interests, attention_span_minutes,",
    "context": {
      "query_preview": "\n                        INSERT OR REPLACE INTO learning_profiles\n                        (student_i..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 570,
    "column": 32,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    567:                         if \"sessions\" in profile_data:\n    568:                             student_id = profile_data.get(\"student_id\", profile_file.stem)\n    569:                             for session in profile_data[\"sessions\"]:\n>>> 570:                                 conn.execute(\n    571:                                     \"\"\"\n    572:                                 INSERT INTO learning_sessions\n    573:                                 (session_id, student_id, start_time, end_time, duration_minutes,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 571,
    "column": 36,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    568:                             student_id = profile_data.get(\"student_id\", profile_file.stem)\n    569:                             for session in profile_data[\"sessions\"]:\n    570:                                 conn.execute(\n>>> 571:                                     \"\"\"\n    572:                                 INSERT INTO learning_sessions\n    573:                                 (session_id, student_id, start_time, end_time, duration_minutes,\n    574:                                  concepts_covered, questions_asked, questions_correct,",
    "context": {
      "query_preview": "\n                                INSERT INTO learning_sessions\n                                (sess..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 597,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    594:                         logger.warning(f\"Failed to migrate profile {profile_file}: {e}\")\n    595:                         continue\n    596: \n>>> 597:                 conn.commit()\n    598:                 logger.info(f\"Successfully migrated digital twin profiles from {profiles_dir}\")\n    599:                 return True\n    600: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 598,
    "column": 30,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    595:                         continue\n    596: \n    597:                 conn.commit()\n>>> 598:                 logger.info(f\"Successfully migrated digital twin profiles from {profiles_dir}\")\n    599:                 return True\n    600: \n    601:             except Exception as e:",
    "context": {
      "query_preview": "Successfully migrated digital twin profiles from "
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 6,
      "methods": [
        "_rollback_migration",
        "_load_migrations",
        "get_current_version",
        "_apply_migration"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'conn' methods (24 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "conn",
      "method_count": 24,
      "methods": [
        "execute",
        "rollback",
        "executescript",
        "cursor",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'cursor' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "cursor",
      "method_count": 6,
      "methods": [
        "execute",
        "fetchone",
        "fetchall"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (25 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 25,
      "methods": [
        "info",
        "exception",
        "warning",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'json' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "json",
      "method_count": 11,
      "methods": [
        "dumps",
        "load"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'round_data' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "round_data",
      "method_count": 6,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'metric' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "metric",
      "method_count": 6,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'profile_data' methods (15 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "profile_data",
      "method_count": 15,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\migrations.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'session' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "session",
      "method_count": 10,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 72,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     69:         db_path = self.storage_path.parent / \"redis_fallback.db\"\n     70: \n     71:         self._sqlite_conn = sqlite3.connect(str(db_path), timeout=30)\n>>>  72:         self._sqlite_conn.execute(\"PRAGMA journal_mode=WAL\")\n     73: \n     74:         # Create fallback tables\n     75:         self._sqlite_conn.executescript(",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 76,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     73: \n     74:         # Create fallback tables\n     75:         self._sqlite_conn.executescript(\n>>>  76:             \"\"\"\n     77:         CREATE TABLE IF NOT EXISTS redis_fallback (\n     78:             key TEXT PRIMARY KEY,\n     79:             value BLOB NOT NULL,",
    "context": {
      "query_preview": "\n        CREATE TABLE IF NOT EXISTS redis_fallback (\n            key TEXT PRIMARY KEY,\n            v..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 112,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    109:         );\n    110:         \"\"\",\n    111:         )\n>>> 112:         self._sqlite_conn.commit()\n    113: \n    114:     async def get(self, key: str) -> Any | None:\n    115:         \"\"\"Get value from fallback storage.\"\"\"",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 115,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    112:         self._sqlite_conn.commit()\n    113: \n    114:     async def get(self, key: str) -> Any | None:\n>>> 115:         \"\"\"Get value from fallback storage.\"\"\"\n    116:         if self.storage_type == \"memory\":\n    117:             item = self._memory_store.get(key)\n    118:             if item is None:",
    "context": {
      "query_preview": "Get value from fallback storage."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 135,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    132: \n    133:         if self.storage_type == \"sqlite\" and self._sqlite_conn:\n    134:             cursor = self._sqlite_conn.cursor()\n>>> 135:             cursor.execute(\n    136:                 \"\"\"\n    137:             SELECT value, value_type, expires_at\n    138:             FROM redis_fallback",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 136,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    133:         if self.storage_type == \"sqlite\" and self._sqlite_conn:\n    134:             cursor = self._sqlite_conn.cursor()\n    135:             cursor.execute(\n>>> 136:                 \"\"\"\n    137:             SELECT value, value_type, expires_at\n    138:             FROM redis_fallback\n    139:             WHERE key = ? AND (expires_at IS NULL OR expires_at > ?)",
    "context": {
      "query_preview": "\n            SELECT value, value_type, expires_at\n            FROM redis_fallback\n            WHERE ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 209,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    206:                     value_blob = secure_dumps(value)\n    207:                     value_type = \"secure_serialized\"\n    208: \n>>> 209:                 self._sqlite_conn.execute(\n    210:                     \"\"\"\n    211:                 INSERT OR REPLACE INTO redis_fallback\n    212:                     (key, value, value_type, expires_at)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 210,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    207:                     value_type = \"secure_serialized\"\n    208: \n    209:                 self._sqlite_conn.execute(\n>>> 210:                     \"\"\"\n    211:                 INSERT OR REPLACE INTO redis_fallback\n    212:                     (key, value, value_type, expires_at)\n    213:                 VALUES (?, ?, ?, ?)",
    "context": {
      "query_preview": "\n                INSERT OR REPLACE INTO redis_fallback\n                    (key, value, value_type, ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 218,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    215:                     (key, value_blob, value_type, expires_at),\n    216:                 )\n    217: \n>>> 218:                 self._sqlite_conn.commit()\n    219:                 return True\n    220:             except Exception as e:\n    221:                 logger.exception(f\"Failed to set fallback value for {key}: {e}\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 244,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    241:         return False\n    242: \n    243:     async def delete(self, key: str) -> bool:\n>>> 244:         \"\"\"Delete value from fallback storage.\"\"\"\n    245:         if self.storage_type == \"memory\":\n    246:             return self._memory_store.pop(key, None) is not None\n    247: ",
    "context": {
      "query_preview": "Delete value from fallback storage."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 250,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    247: \n    248:         if self.storage_type == \"sqlite\" and self._sqlite_conn:\n    249:             cursor = self._sqlite_conn.cursor()\n>>> 250:             cursor.execute(\"DELETE FROM redis_fallback WHERE key = ?\", (key,))\n    251:             self._sqlite_conn.commit()\n    252:             return cursor.rowcount > 0\n    253: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 250,
    "column": 27,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    247: \n    248:         if self.storage_type == \"sqlite\" and self._sqlite_conn:\n    249:             cursor = self._sqlite_conn.cursor()\n>>> 250:             cursor.execute(\"DELETE FROM redis_fallback WHERE key = ?\", (key,))\n    251:             self._sqlite_conn.commit()\n    252:             return cursor.rowcount > 0\n    253: ",
    "context": {
      "query_preview": "DELETE FROM redis_fallback WHERE key = ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 251,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    248:         if self.storage_type == \"sqlite\" and self._sqlite_conn:\n    249:             cursor = self._sqlite_conn.cursor()\n    250:             cursor.execute(\"DELETE FROM redis_fallback WHERE key = ?\", (key,))\n>>> 251:             self._sqlite_conn.commit()\n    252:             return cursor.rowcount > 0\n    253: \n    254:         if self.storage_type == \"file\":",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 273,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    270:         if self.storage_type == \"sqlite\" and self._sqlite_conn:\n    271:             expires_at = time.time() + seconds\n    272:             cursor = self._sqlite_conn.cursor()\n>>> 273:             cursor.execute(\n    274:                 \"\"\"\n    275:             UPDATE redis_fallback\n    276:             SET expires_at = ?",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 274,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    271:             expires_at = time.time() + seconds\n    272:             cursor = self._sqlite_conn.cursor()\n    273:             cursor.execute(\n>>> 274:                 \"\"\"\n    275:             UPDATE redis_fallback\n    276:             SET expires_at = ?\n    277:             WHERE key = ?",
    "context": {
      "query_preview": "\n            UPDATE redis_fallback\n            SET expires_at = ?\n            WHERE key = ?\n        ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 281,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    278:             \"\"\",\n    279:                 (expires_at, key),\n    280:             )\n>>> 281:             self._sqlite_conn.commit()\n    282:             return cursor.rowcount > 0\n    283: \n    284:         # For other storage types, would need to implement expiration logic",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 301,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    298: \n    299:         if self.storage_type == \"sqlite\" and self._sqlite_conn:\n    300:             cursor = self._sqlite_conn.cursor()\n>>> 301:             cursor.execute(\n    302:                 \"\"\"\n    303:             DELETE FROM redis_fallback\n    304:             WHERE expires_at IS NOT NULL AND expires_at < ?",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 302,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    299:         if self.storage_type == \"sqlite\" and self._sqlite_conn:\n    300:             cursor = self._sqlite_conn.cursor()\n    301:             cursor.execute(\n>>> 302:                 \"\"\"\n    303:             DELETE FROM redis_fallback\n    304:             WHERE expires_at IS NOT NULL AND expires_at < ?\n    305:             \"\"\",",
    "context": {
      "query_preview": "\n            DELETE FROM redis_fallback\n            WHERE expires_at IS NOT NULL AND expires_at < ?\n..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 308,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    305:             \"\"\",\n    306:                 (time.time(),),\n    307:             )\n>>> 308:             self._sqlite_conn.commit()\n    309:             return cursor.rowcount\n    310: \n    311:         if self.storage_type == \"file\":",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 567,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    564:         return status\n    565: \n    566:     async def cleanup_expired_keys(self) -> dict[str, int]:\n>>> 567:         \"\"\"Cleanup expired keys from fallback stores.\"\"\"\n    568:         cleanup_results = {}\n    569: \n    570:         for store_name, fallback_store in self.fallback_stores.items():",
    "context": {
      "query_preview": "Cleanup expired keys from fallback stores."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 577,
    "column": 35,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    574:                 if expired_count > 0:\n    575:                     logger.info(f\"Cleaned up {expired_count} expired keys from {store_name}\")\n    576:             except Exception as e:\n>>> 577:                 logger.exception(f\"Failed to cleanup expired keys from {store_name}: {e}\")\n    578:                 cleanup_results[store_name] = 0\n    579: \n    580:         return cleanup_results",
    "context": {
      "query_preview": "Failed to cleanup expired keys from "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 619,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    616:         self.connection_type = connection_type\n    617: \n    618:     async def get(self, key: str) -> Any | None:\n>>> 619:         \"\"\"Get value from Redis or fallback storage.\"\"\"\n    620:         if self.redis_client:\n    621:             try:\n    622:                 value = await self.redis_client.get(key)",
    "context": {
      "query_preview": "Get value from Redis or fallback storage."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 662,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    659:         return False\n    660: \n    661:     async def delete(self, key: str) -> bool:\n>>> 662:         \"\"\"Delete value from Redis or fallback storage.\"\"\"\n    663:         if self.redis_client:\n    664:             try:\n    665:                 result = await self.redis_client.delete(key)",
    "context": {
      "query_preview": "Delete value from Redis or fallback storage."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 665,
    "column": 31,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    662:         \"\"\"Delete value from Redis or fallback storage.\"\"\"\n    663:         if self.redis_client:\n    664:             try:\n>>> 665:                 result = await self.redis_client.delete(key)\n    666:                 return result > 0\n    667:             except Exception as e:\n    668:                 logger.warning(f\"Redis delete failed for {key}: {e}\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 668,
    "column": 33,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    665:                 result = await self.redis_client.delete(key)\n    666:                 return result > 0\n    667:             except Exception as e:\n>>> 668:                 logger.warning(f\"Redis delete failed for {key}: {e}\")\n    669:                 # Fall through to fallback\n    670: \n    671:         if self.fallback_store:",
    "context": {
      "query_preview": "Redis delete failed for "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 672,
    "column": 25,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    669:                 # Fall through to fallback\n    670: \n    671:         if self.fallback_store:\n>>> 672:             return await self.fallback_store.delete(key)\n    673: \n    674:         return False\n    675: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 756,
    "column": 28,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    753:             print(f\"Key exists: {exists}\")\n    754: \n    755:             # Test delete\n>>> 756:             deleted = await conn.delete(\"test_key\")\n    757:             print(f\"Key deleted: {deleted}\")\n    758: \n    759:         # Cleanup expired keys",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'time' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "time",
      "method_count": 9,
      "methods": [
        "time"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'json' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "json",
      "method_count": 7,
      "methods": [
        "dump",
        "dumps",
        "load",
        "loads"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (31 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 31,
      "methods": [
        "exception",
        "warning",
        "debug",
        "info",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'redis_client' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "redis_client",
      "method_count": 6,
      "methods": [
        "close",
        "ping"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\database\\redis_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'redis_manager' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "redis_manager",
      "method_count": 6,
      "methods": [
        "close",
        "get_connection",
        "check_connections",
        "cleanup_expired_keys",
        "initialize"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\debug_manager.py",
    "line_number": 66,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     63:         self._setup_debug_environment()\n     64: \n     65:     def _load_config(self) -> DebugConfig:\n>>>  66:         \"\"\"Load debug configuration from environment variables.\"\"\"\n     67:         config = DebugConfig()\n     68: \n     69:         # CODEX required environment variables",
    "context": {
      "query_preview": "Load debug configuration from environment variables."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\debug_manager.py",
    "line_number": 115,
    "column": 4,
    "description": "Method 'log_debug_info' is too complex: 7 complexity, 23 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    112:         \"\"\"Check if performance profiling is enabled.\"\"\"\n    113:         return self.config.profile_performance\n    114: \n>>> 115:     def log_debug_info(self, component: str, message: str, data: dict[str, Any] | None = None) -> None:\n    116:         \"\"\"Log debug information for a specific component.\"\"\"\n    117:         if not self.is_debug_enabled():\n    118:             return",
    "context": {
      "complexity": 7,
      "lines": 23,
      "max_nesting": 5,
      "method_name": "log_debug_info"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\debug_manager.py",
    "line_number": 140,
    "column": 4,
    "description": "Duplicate code block detected in function 'log_request_response'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    137:                 for key, value in data.items():\n    138:                     self.logger.debug(f\"  {key}: {value}\")\n    139: \n>>> 140:     def log_request_response(self, endpoint: str, request_data: Any, response_data: Any, duration_ms: float) -> None:\n    141:         \"\"\"Log request/response data for debugging API calls.\"\"\"\n    142:         if not self.is_debug_enabled():\n    143:             return",
    "context": {
      "duplicate_count": 2,
      "function_name": "log_request_response",
      "signature": "IF|ASSIGN|CALL_log_debug_info"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\debug_manager.py",
    "line_number": 155,
    "column": 4,
    "description": "Duplicate code block detected in function 'log_database_query'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    152: \n    153:         self.log_debug_info(\"api_requests\", f\"API call to {endpoint}\", debug_info)\n    154: \n>>> 155:     def log_database_query(self, query: str, params: Any, duration_ms: float, result_count: int) -> None:\n    156:         \"\"\"Log database queries with timing information.\"\"\"\n    157:         if not self.is_debug_enabled():\n    158:             return",
    "context": {
      "duplicate_count": 2,
      "function_name": "log_database_query",
      "signature": "IF|ASSIGN|CALL_log_debug_info"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\debug_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (13 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 13,
      "methods": [
        "is_verbose_enabled",
        "is_debug_enabled",
        "log_debug_info",
        "_setup_debug_environment",
        "_load_config"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\debug_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'os' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "os",
      "method_count": 6,
      "methods": [
        "getenv"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\debug_manager.py",
    "line_number": 161,
    "column": 28,
    "description": "Excessive magic literals detected (13 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    158:             return\n    159: \n    160:         debug_info = {\n>>> 161:             \"query\": query[:500],  # Truncate very long queries\n    162:             \"params\": str(params)[:200] if params else None,\n    163:             \"duration_ms\": duration_ms,\n    164:             \"result_count\": result_count,",
    "context": {
      "total_magic_literals": 13,
      "current_value": 500
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\debug_manager.py",
    "line_number": 162,
    "column": 35,
    "description": "Excessive magic literals detected (13 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    159: \n    160:         debug_info = {\n    161:             \"query\": query[:500],  # Truncate very long queries\n>>> 162:             \"params\": str(params)[:200] if params else None,\n    163:             \"duration_ms\": duration_ms,\n    164:             \"result_count\": result_count,\n    165:             \"timestamp\": datetime.now().isoformat(),",
    "context": {
      "total_magic_literals": 13,
      "current_value": 200
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\debug_manager.py",
    "line_number": 203,
    "column": 49,
    "description": "Excessive magic literals detected (13 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    200:         \"\"\"Stop resource monitoring.\"\"\"\n    201:         self._monitoring_active = False\n    202:         if self._monitoring_thread and self._monitoring_thread.is_alive():\n>>> 203:             self._monitoring_thread.join(timeout=5.0)\n    204: \n    205:         self.logger.info(\"Stopped resource monitoring\")\n    206: ",
    "context": {
      "total_magic_literals": 13,
      "current_value": 5.0
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\debug_manager.py",
    "line_number": 219,
    "column": 53,
    "description": "Excessive magic literals detected (13 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    216:                 resource_info = {\n    217:                     \"cpu_percent\": cpu_percent,\n    218:                     \"memory_percent\": memory.percent,\n>>> 219:                     \"memory_used_mb\": memory.used / (1024 * 1024),\n    220:                     \"memory_available_mb\": memory.available / (1024 * 1024),\n    221:                     \"disk_percent\": disk.percent,\n    222:                     \"disk_free_gb\": disk.free / (1024 * 1024 * 1024),",
    "context": {
      "total_magic_literals": 13,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\debug_manager.py",
    "line_number": 219,
    "column": 60,
    "description": "Excessive magic literals detected (13 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    216:                 resource_info = {\n    217:                     \"cpu_percent\": cpu_percent,\n    218:                     \"memory_percent\": memory.percent,\n>>> 219:                     \"memory_used_mb\": memory.used / (1024 * 1024),\n    220:                     \"memory_available_mb\": memory.available / (1024 * 1024),\n    221:                     \"disk_percent\": disk.percent,\n    222:                     \"disk_free_gb\": disk.free / (1024 * 1024 * 1024),",
    "context": {
      "total_magic_literals": 13,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\logger_config.py",
    "line_number": 59,
    "column": 0,
    "description": "Method 'setup_debug_logging' is too complex: 6 complexity, 83 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     56:         return super().format(record)\n     57: \n     58: \n>>>  59: def setup_debug_logging(\n     60:     log_level: str = \"DEBUG\",\n     61:     log_file: str | None = None,\n     62:     enable_console: bool = True,",
    "context": {
      "complexity": 6,
      "lines": 83,
      "max_nesting": 5,
      "method_name": "setup_debug_logging"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\logger_config.py",
    "line_number": 59,
    "column": 0,
    "description": "Function 'setup_debug_logging' has 6 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "     56:         return super().format(record)\n     57: \n     58: \n>>>  59: def setup_debug_logging(\n     60:     log_level: str = \"DEBUG\",\n     61:     log_file: str | None = None,\n     62:     enable_console: bool = True,",
    "context": {
      "parameter_count": 6,
      "function_name": "setup_debug_logging"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\logger_config.py",
    "line_number": 181,
    "column": 4,
    "description": "Method 'log_request' is too complex: 6 complexity, 24 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    178:         self.logger = logging.getLogger(logger_name)\n    179:         self.enabled = os.getenv(\"AIVILLAGE_DEBUG_MODE\", \"false\").lower() == \"true\"\n    180: \n>>> 181:     def log_request(\n    182:         self,\n    183:         endpoint: str,\n    184:         method: str = \"POST\",",
    "context": {
      "complexity": 6,
      "lines": 24,
      "max_nesting": 5,
      "method_name": "log_request"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\logger_config.py",
    "line_number": 181,
    "column": 4,
    "description": "Function 'log_request' has 6 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    178:         self.logger = logging.getLogger(logger_name)\n    179:         self.enabled = os.getenv(\"AIVILLAGE_DEBUG_MODE\", \"false\").lower() == \"true\"\n    180: \n>>> 181:     def log_request(\n    182:         self,\n    183:         endpoint: str,\n    184:         method: str = \"POST\",",
    "context": {
      "parameter_count": 6,
      "function_name": "log_request"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\logger_config.py",
    "line_number": 207,
    "column": 4,
    "description": "Function 'log_response' has 6 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    204:                 data_str = data_str[:1000] + \"... (truncated)\"\n    205:             self.logger.debug(f\"  Data: {data_str}\")\n    206: \n>>> 207:     def log_response(\n    208:         self,\n    209:         endpoint: str,\n    210:         status_code: int | None = None,",
    "context": {
      "parameter_count": 6,
      "function_name": "log_response"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\logger_config.py",
    "line_number": 234,
    "column": 4,
    "description": "Function 'log_database_query' has 6 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    231:                 data_str = data_str[:1000] + \"... (truncated)\"\n    232:             self.logger.debug(f\"  Response: {data_str}\")\n    233: \n>>> 234:     def log_database_query(\n    235:         self,\n    236:         query: str,\n    237:         params: Any | None = None,",
    "context": {
      "parameter_count": 6,
      "function_name": "log_database_query"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\logger_config.py",
    "line_number": 264,
    "column": 4,
    "description": "Function 'log_cache_operation' has 6 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    261:                 params_str = params_str[:500] + \"... (truncated)\"\n    262:             self.logger.debug(f\"  Params: {params_str}\")\n    263: \n>>> 264:     def log_cache_operation(\n    265:         self,\n    266:         operation: str,\n    267:         key: str,",
    "context": {
      "parameter_count": 6,
      "function_name": "log_cache_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\logger_config.py",
    "line_number": 286,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    283:         self.logger.debug(f\"[CACHE_{hit_str}]{duration_str} {operation}: {display_key}{size_str}\")\n    284: \n    285:     def _sanitize_headers(self, headers: dict[str, str]) -> dict[str, str]:\n>>> 286:         \"\"\"Remove sensitive information from headers.\"\"\"\n    287:         sensitive_headers = [\"authorization\", \"api-key\", \"x-api-key\", \"cookie\"]\n    288: \n    289:         sanitized = {}",
    "context": {
      "query_preview": "Remove sensitive information from headers."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\logger_config.py",
    "line_number": 299,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    296:         return sanitized\n    297: \n    298:     def _sanitize_query(self, query: str) -> str:\n>>> 299:         \"\"\"Remove or mask sensitive data from SQL queries.\"\"\"\n    300:         # Truncate very long queries\n    301:         if len(query) > 500:\n    302:             query = query[:500] + \"... (truncated)\"",
    "context": {
      "query_preview": "Remove or mask sensitive data from SQL queries."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\logger_config.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logging' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logging",
      "method_count": 7,
      "methods": [
        "StreamHandler",
        "getLogger",
        "Formatter"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\logger_config.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'aivillage_logger' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "aivillage_logger",
      "method_count": 11,
      "methods": [
        "setLevel",
        "info"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\logger_config.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'os' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "os",
      "method_count": 6,
      "methods": [
        "getenv"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 18,
    "column": 0,
    "description": "Class 'TroubleshootingTools' is a God Object: 23 methods, ~671 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "     15: import psutil\n     16: \n     17: \n>>>  18: class TroubleshootingTools:\n     19:     \"\"\"Comprehensive troubleshooting toolkit for AIVillage system.\n     20: \n     21:     Implements all debugging tools specified in CODEX Integration Requirements:",
    "context": {
      "method_count": 23,
      "estimated_lines": 671,
      "class_name": "TroubleshootingTools",
      "data_methods": 1,
      "business_methods": 22
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 172,
    "column": 4,
    "description": "Method '_analyze_database' is too complex: 5 complexity, 60 lines, 2 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    169: \n    170:         return results\n    171: \n>>> 172:     def _analyze_database(self, db_path: str) -> dict[str, Any]:\n    173:         \"\"\"Analyze a single database file.\"\"\"\n    174:         db_info = {\n    175:             \"path\": db_path,",
    "context": {
      "complexity": 5,
      "lines": 60,
      "max_nesting": 2,
      "method_name": "_analyze_database"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 212,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    209: \n    210:                 # Get journal mode\n    211:                 cursor = conn.cursor()\n>>> 212:                 cursor.execute(\"PRAGMA journal_mode\")\n    213:                 db_info[\"journal_mode\"] = cursor.fetchone()[0]\n    214: \n    215:                 # Test if database is locked by trying a simple operation",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 216,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    213:                 db_info[\"journal_mode\"] = cursor.fetchone()[0]\n    214: \n    215:                 # Test if database is locked by trying a simple operation\n>>> 216:                 cursor.execute(\"BEGIN IMMEDIATE\")\n    217:                 cursor.execute(\"ROLLBACK\")\n    218: \n    219:                 conn.close()",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 217,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    214: \n    215:                 # Test if database is locked by trying a simple operation\n    216:                 cursor.execute(\"BEGIN IMMEDIATE\")\n>>> 217:                 cursor.execute(\"ROLLBACK\")\n    218: \n    219:                 conn.close()\n    220: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 234,
    "column": 4,
    "description": "Method 'profile_memory_usage' is too complex: 6 complexity, 60 lines, 4 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    231: \n    232:         return db_info\n    233: \n>>> 234:     def profile_memory_usage(self, include_faiss_simulation: bool = True) -> dict[str, Any]:\n    235:         \"\"\"Profile memory usage with FAISS memory simulation.\n    236: \n    237:         Args:",
    "context": {
      "complexity": 6,
      "lines": 60,
      "max_nesting": 4,
      "method_name": "profile_memory_usage"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 612,
    "column": 4,
    "description": "Method 'run_comprehensive_diagnosis' is too complex: 5 complexity, 51 lines, 3 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    609: \n    610:         return env_status\n    611: \n>>> 612:     def run_comprehensive_diagnosis(self) -> dict[str, Any]:\n    613:         \"\"\"Run comprehensive system diagnosis.\n    614: \n    615:         Returns:",
    "context": {
      "complexity": 5,
      "lines": 51,
      "max_nesting": 3,
      "method_name": "run_comprehensive_diagnosis"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 665,
    "column": 4,
    "description": "Method '_calculate_health_score' is too complex: 6 complexity, 24 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    662: \n    663:         return diagnosis\n    664: \n>>> 665:     def _calculate_health_score(self, diagnosis: dict[str, Any]) -> float:\n    666:         \"\"\"Calculate overall system health score.\"\"\"\n    667:         score = 1.0\n    668: ",
    "context": {
      "complexity": 6,
      "lines": 24,
      "max_nesting": 5,
      "method_name": "_calculate_health_score"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 74,
    "column": 4,
    "description": "Duplicate code block detected in function '_check_single_port'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "     71: \n     72:         return results\n     73: \n>>>  74:     def _check_single_port(self, port: int) -> dict[str, Any]:\n     75:         \"\"\"Check if a single port is in use.\"\"\"\n     76:         port_info = {\n     77:             \"port\": port,",
    "context": {
      "duplicate_count": 4,
      "function_name": "_check_single_port",
      "signature": "ASSIGN|TRY|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 113,
    "column": 4,
    "description": "Duplicate code block detected in function '_get_all_listening_ports'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    110: \n    111:         return port_info\n    112: \n>>> 113:     def _get_all_listening_ports(self) -> list[dict[str, Any]]:\n    114:         \"\"\"Get all currently listening ports.\"\"\"\n    115:         listening_ports = []\n    116: ",
    "context": {
      "duplicate_count": 4,
      "function_name": "_get_all_listening_ports",
      "signature": "ASSIGN|TRY|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 172,
    "column": 4,
    "description": "Duplicate code block detected in function '_analyze_database'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    169: \n    170:         return results\n    171: \n>>> 172:     def _analyze_database(self, db_path: str) -> dict[str, Any]:\n    173:         \"\"\"Analyze a single database file.\"\"\"\n    174:         db_info = {\n    175:             \"path\": db_path,",
    "context": {
      "duplicate_count": 4,
      "function_name": "_analyze_database",
      "signature": "ASSIGN|TRY|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 421,
    "column": 4,
    "description": "Duplicate code block detected in function '_test_connection'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    418: \n    419:         return connectivity_tests\n    420: \n>>> 421:     def _test_connection(self, host: str, port: int, timeout: float = 5.0) -> dict[str, Any]:\n    422:         \"\"\"Test connection to a specific host and port.\"\"\"\n    423:         result = {\n    424:             \"host\": host,",
    "context": {
      "duplicate_count": 4,
      "function_name": "_test_connection",
      "signature": "ASSIGN|TRY|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 445,
    "column": 4,
    "description": "Duplicate code block detected in function '_test_dns_resolution'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    442: \n    443:         return result\n    444: \n>>> 445:     def _test_dns_resolution(self) -> dict[str, Any]:\n    446:         \"\"\"Test DNS resolution.\"\"\"\n    447:         test_hosts = [\"localhost\", \"127.0.0.1\"]\n    448:         results = {}",
    "context": {
      "duplicate_count": 2,
      "function_name": "_test_dns_resolution",
      "signature": "ASSIGN|ASSIGN|FOR|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 593,
    "column": 4,
    "description": "Duplicate code block detected in function '_check_environment_variables'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    590:         except Exception as e:\n    591:             result[\"errors\"].append(f\"Invalid TOML: {e}\")\n    592: \n>>> 593:     def _check_environment_variables(self) -> dict[str, Any]:\n    594:         \"\"\"Check important environment variables.\"\"\"\n    595:         important_vars = [\n    596:             \"AIVILLAGE_DEBUG_MODE\",",
    "context": {
      "duplicate_count": 2,
      "function_name": "_check_environment_variables",
      "signature": "ASSIGN|ASSIGN|FOR|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'time' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "time",
      "method_count": 11,
      "methods": [
        "time"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (21 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 21,
      "methods": [
        "_validate_config_file",
        "_test_dns_resolution",
        "_check_environment_variables",
        "_calculate_health_score",
        "_test_connection",
        "check_port_conflicts",
        "_validate_yaml_file",
        "_validate_toml_file",
        "profile_memory_usage",
        "validate_configuration",
        "_analyze_database",
        "_test_mdns_functionality",
        "debug_network_discovery",
        "_test_connectivity",
        "_get_all_listening_ports",
        "_check_single_port",
        "_test_local_network",
        "detect_database_locks",
        "_simulate_faiss_memory",
        "_validate_json_file",
        "_simulate_peer_discovery"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'psutil' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "psutil",
      "method_count": 7,
      "methods": [
        "net_if_addrs",
        "net_connections",
        "Process",
        "virtual_memory"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'process' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "process",
      "method_count": 6,
      "methods": [
        "num_threads",
        "name",
        "memory_percent",
        "open_files",
        "memory_info"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 43,
    "column": 30,
    "description": "Excessive magic literals detected (61 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     40:         \"\"\"\n     41:         if required_ports is None:\n     42:             # CODEX Integration Requirements ports\n>>>  43:             required_ports = [8080, 8081, 8082, 8083, 4001, 4002, 6379, 5432]\n     44: \n     45:         results = {\n     46:             \"timestamp\": time.time(),",
    "context": {
      "total_magic_literals": 61,
      "current_value": 8080
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 43,
    "column": 36,
    "description": "Excessive magic literals detected (61 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     40:         \"\"\"\n     41:         if required_ports is None:\n     42:             # CODEX Integration Requirements ports\n>>>  43:             required_ports = [8080, 8081, 8082, 8083, 4001, 4002, 6379, 5432]\n     44: \n     45:         results = {\n     46:             \"timestamp\": time.time(),",
    "context": {
      "total_magic_literals": 61,
      "current_value": 8081
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 43,
    "column": 42,
    "description": "Excessive magic literals detected (61 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     40:         \"\"\"\n     41:         if required_ports is None:\n     42:             # CODEX Integration Requirements ports\n>>>  43:             required_ports = [8080, 8081, 8082, 8083, 4001, 4002, 6379, 5432]\n     44: \n     45:         results = {\n     46:             \"timestamp\": time.time(),",
    "context": {
      "total_magic_literals": 61,
      "current_value": 8082
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 43,
    "column": 48,
    "description": "Excessive magic literals detected (61 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     40:         \"\"\"\n     41:         if required_ports is None:\n     42:             # CODEX Integration Requirements ports\n>>>  43:             required_ports = [8080, 8081, 8082, 8083, 4001, 4002, 6379, 5432]\n     44: \n     45:         results = {\n     46:             \"timestamp\": time.time(),",
    "context": {
      "total_magic_literals": 61,
      "current_value": 8083
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\debug\\troubleshooting.py",
    "line_number": 43,
    "column": 54,
    "description": "Excessive magic literals detected (61 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     40:         \"\"\"\n     41:         if required_ports is None:\n     42:             # CODEX Integration Requirements ports\n>>>  43:             required_ports = [8080, 8081, 8082, 8083, 4001, 4002, 6379, 5432]\n     44: \n     45:         results = {\n     46:             \"timestamp\": time.time(),",
    "context": {
      "total_magic_literals": 61,
      "current_value": 4001
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\knowledge\\rag_offline_config.py",
    "line_number": 30,
    "column": 0,
    "description": "Method 'resolve_model_path' is too complex: 9 complexity, 39 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     27: logger = logging.getLogger(__name__)\n     28: \n     29: \n>>>  30: def resolve_model_path(\n     31:     model_name: str,\n     32:     device: str | None = None,\n     33:     base_dir: str | Path | None = None,",
    "context": {
      "complexity": 9,
      "lines": 39,
      "max_nesting": 8,
      "method_name": "resolve_model_path"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\knowledge\\rag_offline_config.py",
    "line_number": 275,
    "column": 4,
    "description": "Method 'adapt_for_mobile' is too complex: 1 complexity, 51 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    272:     validation_date: str | None = None\n    273:     validation_errors: list[str] = field(default_factory=list)\n    274: \n>>> 275:     def adapt_for_mobile(self) -> \"OfflineRAGConfig\":\n    276:         \"\"\"Create mobile-optimized variant of this config.\"\"\"\n    277:         base_dir = Path(self.embedding.model_path).parent if self.embedding.model_path else None\n    278: ",
    "context": {
      "complexity": 1,
      "lines": 51,
      "max_nesting": 0,
      "method_name": "adapt_for_mobile"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\knowledge\\rag_offline_config.py",
    "line_number": 276,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    273:     validation_errors: list[str] = field(default_factory=list)\n    274: \n    275:     def adapt_for_mobile(self) -> \"OfflineRAGConfig\":\n>>> 276:         \"\"\"Create mobile-optimized variant of this config.\"\"\"\n    277:         base_dir = Path(self.embedding.model_path).parent if self.embedding.model_path else None\n    278: \n    279:         mobile_config = OfflineRAGConfig(",
    "context": {
      "query_preview": "Create mobile-optimized variant of this config."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\knowledge\\rag_offline_config.py",
    "line_number": 328,
    "column": 4,
    "description": "Method 'validate_config' is too complex: 15 complexity, 56 lines, 14 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    325: \n    326:         return mobile_config\n    327: \n>>> 328:     def validate_config(self) -> bool:\n    329:         \"\"\"Validate configuration for consistency and feasibility.\"\"\"\n    330:         errors = []\n    331: ",
    "context": {
      "complexity": 15,
      "lines": 56,
      "max_nesting": 14,
      "method_name": "validate_config"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\knowledge\\rag_offline_config.py",
    "line_number": 401,
    "column": 4,
    "description": "Method '_initialize_default_configs' is too complex: 1 complexity, 84 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    398: \n    399:         logger.info(f\"OfflineRAGConfigRegistry initialized with {len(self.validated_configs)} validated configs\")\n    400: \n>>> 401:     def _initialize_default_configs(self):\n    402:         \"\"\"Initialize default RAG configurations for common scenarios.\"\"\"\n    403:         # 1. Standard Offline RAG\n    404:         standard_config = OfflineRAGConfig(",
    "context": {
      "complexity": 1,
      "lines": 84,
      "max_nesting": 0,
      "method_name": "_initialize_default_configs"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\knowledge\\rag_offline_config.py",
    "line_number": 545,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    542:             return False\n    543: \n    544:     def import_config(self, file_path: Path, validate: bool = True) -> str | None:\n>>> 545:         \"\"\"Import configuration from file.\"\"\"\n    546:         try:\n    547:             with open(file_path) as f:\n    548:                 if file_path.suffix.lower() == \".yaml\" or file_path.suffix.lower() == \".yml\":",
    "context": {
      "query_preview": "Import configuration from file."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\knowledge\\rag_offline_config.py",
    "line_number": 572,
    "column": 27,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    569:             return config_name\n    570: \n    571:         except Exception as e:\n>>> 572:             logger.error(f\"Failed to import config from {file_path}: {e}\")\n    573:             return None\n    574: \n    575:     def get_registry_status(self) -> dict[str, Any]:",
    "context": {
      "query_preview": "Failed to import config from "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\knowledge\\rag_offline_config.py",
    "line_number": 622,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    619:     top_k: int = 5,\n    620:     **kwargs,\n    621: ) -> OfflineRAGConfig:\n>>> 622:     \"\"\"Create custom RAG configuration with validated defaults.\"\"\"\n    623:     config = OfflineRAGConfig(\n    624:         name=name,\n    625:         description=f\"Custom RAG config: {name}\",",
    "context": {
      "query_preview": "Create custom RAG configuration with validated defaults."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\knowledge\\rag_offline_config.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'errors' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "errors",
      "method_count": 11,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\knowledge\\rag_offline_config.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 11,
      "methods": [
        "info",
        "warning",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\knowledge\\rag_offline_config.py",
    "line_number": 120,
    "column": 22,
    "description": "Excessive magic literals detected (66 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    117:     provider: EmbeddingProvider\n    118:     model_name: str\n    119:     model_path: str | None = None  # Local path for offline models\n>>> 120:     dimensions: int = 384\n    121:     max_seq_length: int = 512\n    122:     batch_size: int = 32\n    123:     device: str = \"cpu\"  # cpu, cuda, mps",
    "context": {
      "total_magic_literals": 66,
      "current_value": 384
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\knowledge\\rag_offline_config.py",
    "line_number": 121,
    "column": 26,
    "description": "Excessive magic literals detected (66 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    118:     model_name: str\n    119:     model_path: str | None = None  # Local path for offline models\n    120:     dimensions: int = 384\n>>> 121:     max_seq_length: int = 512\n    122:     batch_size: int = 32\n    123:     device: str = \"cpu\"  # cpu, cuda, mps\n    124: ",
    "context": {
      "total_magic_literals": 66,
      "current_value": 512
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\knowledge\\rag_offline_config.py",
    "line_number": 122,
    "column": 22,
    "description": "Excessive magic literals detected (66 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    119:     model_path: str | None = None  # Local path for offline models\n    120:     dimensions: int = 384\n    121:     max_seq_length: int = 512\n>>> 122:     batch_size: int = 32\n    123:     device: str = \"cpu\"  # cpu, cuda, mps\n    124: \n    125:     # Validation metadata",
    "context": {
      "total_magic_literals": 66,
      "current_value": 32
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\knowledge\\rag_offline_config.py",
    "line_number": 135,
    "column": 22,
    "description": "Excessive magic literals detected (66 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    132: class ChunkingConfig:\n    133:     \"\"\"Configuration for text chunking.\"\"\"\n    134: \n>>> 135:     chunk_size: int = 512\n    136:     chunk_overlap: int = 50\n    137:     separator: str = \"\\n\\n\"\n    138:     keep_separator: bool = True",
    "context": {
      "total_magic_literals": 66,
      "current_value": 512
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\knowledge\\rag_offline_config.py",
    "line_number": 136,
    "column": 25,
    "description": "Excessive magic literals detected (66 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    133:     \"\"\"Configuration for text chunking.\"\"\"\n    134: \n    135:     chunk_size: int = 512\n>>> 136:     chunk_overlap: int = 50\n    137:     separator: str = \"\\n\\n\"\n    138:     keep_separator: bool = True\n    139: ",
    "context": {
      "total_magic_literals": 66,
      "current_value": 50
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 135,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    132: \n    133:             for pragma_sql, description in optimizations:\n    134:                 start_time = time.time()\n>>> 135:                 cursor.execute(pragma_sql)\n    136:                 duration = (time.time() - start_time) * 1000\n    137:                 results[description] = f\"Applied in {duration:.2f}ms\"\n    138: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 142,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    139:             # Create performance indexes\n    140:             self._create_performance_indexes(cursor, db_path)\n    141: \n>>> 142:             conn.commit()\n    143:             conn.close()\n    144: \n    145:             logger.info(f\"Database optimized: {db_path}\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 153,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    150:             return {\"error\": str(e)}\n    151: \n    152:     def _create_performance_indexes(self, cursor: sqlite3.Cursor, db_path: str):\n>>> 153:         \"\"\"Create performance indexes based on database type.\"\"\"\n    154:         db_name = Path(db_path).stem\n    155: \n    156:         if db_name == \"evolution_metrics\":",
    "context": {
      "query_preview": "Create performance indexes based on database type."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 158,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    155: \n    156:         if db_name == \"evolution_metrics\":\n    157:             indexes = [\n>>> 158:                 \"CREATE INDEX IF NOT EXISTS idx_evolution_rounds_timestamp ON evolution_rounds(timestamp)\",\n    159:                 \"CREATE INDEX IF NOT EXISTS idx_fitness_metrics_agent_timestamp ON fitness_metrics(agent_id, timestamp)\",\n    160:                 \"CREATE INDEX IF NOT EXISTS idx_fitness_metrics_score ON fitness_metrics(fitness_score DESC)\",\n    161:                 \"CREATE INDEX IF NOT EXISTS idx_resource_metrics_timestamp ON resource_metrics(timestamp)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_evolution_rounds_timestamp ON evolution_rounds(timestamp)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 159,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    156:         if db_name == \"evolution_metrics\":\n    157:             indexes = [\n    158:                 \"CREATE INDEX IF NOT EXISTS idx_evolution_rounds_timestamp ON evolution_rounds(timestamp)\",\n>>> 159:                 \"CREATE INDEX IF NOT EXISTS idx_fitness_metrics_agent_timestamp ON fitness_metrics(agent_id, timestamp)\",\n    160:                 \"CREATE INDEX IF NOT EXISTS idx_fitness_metrics_score ON fitness_metrics(fitness_score DESC)\",\n    161:                 \"CREATE INDEX IF NOT EXISTS idx_resource_metrics_timestamp ON resource_metrics(timestamp)\",\n    162:                 \"CREATE INDEX IF NOT EXISTS idx_selection_outcomes_round_method ON selection_outcomes(round_id, selection_method)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_fitness_metrics_agent_timestamp ON fitness_metrics(agent_id, timestam..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 160,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    157:             indexes = [\n    158:                 \"CREATE INDEX IF NOT EXISTS idx_evolution_rounds_timestamp ON evolution_rounds(timestamp)\",\n    159:                 \"CREATE INDEX IF NOT EXISTS idx_fitness_metrics_agent_timestamp ON fitness_metrics(agent_id, timestamp)\",\n>>> 160:                 \"CREATE INDEX IF NOT EXISTS idx_fitness_metrics_score ON fitness_metrics(fitness_score DESC)\",\n    161:                 \"CREATE INDEX IF NOT EXISTS idx_resource_metrics_timestamp ON resource_metrics(timestamp)\",\n    162:                 \"CREATE INDEX IF NOT EXISTS idx_selection_outcomes_round_method ON selection_outcomes(round_id, selection_method)\",\n    163:             ]",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_fitness_metrics_score ON fitness_metrics(fitness_score DESC)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 161,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    158:                 \"CREATE INDEX IF NOT EXISTS idx_evolution_rounds_timestamp ON evolution_rounds(timestamp)\",\n    159:                 \"CREATE INDEX IF NOT EXISTS idx_fitness_metrics_agent_timestamp ON fitness_metrics(agent_id, timestamp)\",\n    160:                 \"CREATE INDEX IF NOT EXISTS idx_fitness_metrics_score ON fitness_metrics(fitness_score DESC)\",\n>>> 161:                 \"CREATE INDEX IF NOT EXISTS idx_resource_metrics_timestamp ON resource_metrics(timestamp)\",\n    162:                 \"CREATE INDEX IF NOT EXISTS idx_selection_outcomes_round_method ON selection_outcomes(round_id, selection_method)\",\n    163:             ]\n    164:         elif db_name == \"digital_twin\":",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_resource_metrics_timestamp ON resource_metrics(timestamp)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 162,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    159:                 \"CREATE INDEX IF NOT EXISTS idx_fitness_metrics_agent_timestamp ON fitness_metrics(agent_id, timestamp)\",\n    160:                 \"CREATE INDEX IF NOT EXISTS idx_fitness_metrics_score ON fitness_metrics(fitness_score DESC)\",\n    161:                 \"CREATE INDEX IF NOT EXISTS idx_resource_metrics_timestamp ON resource_metrics(timestamp)\",\n>>> 162:                 \"CREATE INDEX IF NOT EXISTS idx_selection_outcomes_round_method ON selection_outcomes(round_id, selection_method)\",\n    163:             ]\n    164:         elif db_name == \"digital_twin\":\n    165:             indexes = [",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_selection_outcomes_round_method ON selection_outcomes(round_id, selec..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 166,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    163:             ]\n    164:         elif db_name == \"digital_twin\":\n    165:             indexes = [\n>>> 166:                 \"CREATE INDEX IF NOT EXISTS idx_learning_profiles_updated ON learning_profiles(updated_at)\",\n    167:                 \"CREATE INDEX IF NOT EXISTS idx_learning_sessions_profile_start ON learning_sessions(profile_id, start_time)\",\n    168:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_states_profile_domain ON knowledge_states(profile_id, knowledge_domain)\",\n    169:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_states_mastery ON knowledge_states(mastery_level DESC)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_learning_profiles_updated ON learning_profiles(updated_at)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 167,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    164:         elif db_name == \"digital_twin\":\n    165:             indexes = [\n    166:                 \"CREATE INDEX IF NOT EXISTS idx_learning_profiles_updated ON learning_profiles(updated_at)\",\n>>> 167:                 \"CREATE INDEX IF NOT EXISTS idx_learning_sessions_profile_start ON learning_sessions(profile_id, start_time)\",\n    168:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_states_profile_domain ON knowledge_states(profile_id, knowledge_domain)\",\n    169:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_states_mastery ON knowledge_states(mastery_level DESC)\",\n    170:             ]",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_learning_sessions_profile_start ON learning_sessions(profile_id, star..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 168,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    165:             indexes = [\n    166:                 \"CREATE INDEX IF NOT EXISTS idx_learning_profiles_updated ON learning_profiles(updated_at)\",\n    167:                 \"CREATE INDEX IF NOT EXISTS idx_learning_sessions_profile_start ON learning_sessions(profile_id, start_time)\",\n>>> 168:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_states_profile_domain ON knowledge_states(profile_id, knowledge_domain)\",\n    169:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_states_mastery ON knowledge_states(mastery_level DESC)\",\n    170:             ]\n    171:         elif db_name == \"rag_index\":",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_knowledge_states_profile_domain ON knowledge_states(profile_id, knowl..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 169,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    166:                 \"CREATE INDEX IF NOT EXISTS idx_learning_profiles_updated ON learning_profiles(updated_at)\",\n    167:                 \"CREATE INDEX IF NOT EXISTS idx_learning_sessions_profile_start ON learning_sessions(profile_id, start_time)\",\n    168:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_states_profile_domain ON knowledge_states(profile_id, knowledge_domain)\",\n>>> 169:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_states_mastery ON knowledge_states(mastery_level DESC)\",\n    170:             ]\n    171:         elif db_name == \"rag_index\":\n    172:             indexes = [",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_knowledge_states_mastery ON knowledge_states(mastery_level DESC)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 173,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    170:             ]\n    171:         elif db_name == \"rag_index\":\n    172:             indexes = [\n>>> 173:                 \"CREATE INDEX IF NOT EXISTS idx_documents_created ON documents(created_at)\",\n    174:                 \"CREATE INDEX IF NOT EXISTS idx_documents_hash ON documents(file_hash)\",\n    175:                 \"CREATE INDEX IF NOT EXISTS idx_chunks_document_index ON chunks(document_id, chunk_index)\",\n    176:                 \"CREATE INDEX IF NOT EXISTS idx_embeddings_faiss ON embeddings_metadata(faiss_index_id)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_documents_created ON documents(created_at)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 174,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    171:         elif db_name == \"rag_index\":\n    172:             indexes = [\n    173:                 \"CREATE INDEX IF NOT EXISTS idx_documents_created ON documents(created_at)\",\n>>> 174:                 \"CREATE INDEX IF NOT EXISTS idx_documents_hash ON documents(file_hash)\",\n    175:                 \"CREATE INDEX IF NOT EXISTS idx_chunks_document_index ON chunks(document_id, chunk_index)\",\n    176:                 \"CREATE INDEX IF NOT EXISTS idx_embeddings_faiss ON embeddings_metadata(faiss_index_id)\",\n    177:                 \"CREATE INDEX IF NOT EXISTS idx_embeddings_queries ON embeddings_metadata(query_count DESC)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_documents_hash ON documents(file_hash)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 175,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    172:             indexes = [\n    173:                 \"CREATE INDEX IF NOT EXISTS idx_documents_created ON documents(created_at)\",\n    174:                 \"CREATE INDEX IF NOT EXISTS idx_documents_hash ON documents(file_hash)\",\n>>> 175:                 \"CREATE INDEX IF NOT EXISTS idx_chunks_document_index ON chunks(document_id, chunk_index)\",\n    176:                 \"CREATE INDEX IF NOT EXISTS idx_embeddings_faiss ON embeddings_metadata(faiss_index_id)\",\n    177:                 \"CREATE INDEX IF NOT EXISTS idx_embeddings_queries ON embeddings_metadata(query_count DESC)\",\n    178:             ]",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_chunks_document_index ON chunks(document_id, chunk_index)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 176,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    173:                 \"CREATE INDEX IF NOT EXISTS idx_documents_created ON documents(created_at)\",\n    174:                 \"CREATE INDEX IF NOT EXISTS idx_documents_hash ON documents(file_hash)\",\n    175:                 \"CREATE INDEX IF NOT EXISTS idx_chunks_document_index ON chunks(document_id, chunk_index)\",\n>>> 176:                 \"CREATE INDEX IF NOT EXISTS idx_embeddings_faiss ON embeddings_metadata(faiss_index_id)\",\n    177:                 \"CREATE INDEX IF NOT EXISTS idx_embeddings_queries ON embeddings_metadata(query_count DESC)\",\n    178:             ]\n    179:         else:",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_embeddings_faiss ON embeddings_metadata(faiss_index_id)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 177,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    174:                 \"CREATE INDEX IF NOT EXISTS idx_documents_hash ON documents(file_hash)\",\n    175:                 \"CREATE INDEX IF NOT EXISTS idx_chunks_document_index ON chunks(document_id, chunk_index)\",\n    176:                 \"CREATE INDEX IF NOT EXISTS idx_embeddings_faiss ON embeddings_metadata(faiss_index_id)\",\n>>> 177:                 \"CREATE INDEX IF NOT EXISTS idx_embeddings_queries ON embeddings_metadata(query_count DESC)\",\n    178:             ]\n    179:         else:\n    180:             indexes = []",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_embeddings_queries ON embeddings_metadata(query_count DESC)"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 185,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    182:         for index_sql in indexes:\n    183:             try:\n    184:                 start_time = time.time()\n>>> 185:                 cursor.execute(index_sql)\n    186:                 duration = (time.time() - start_time) * 1000\n    187:                 logger.debug(f\"Index created in {duration:.2f}ms: {index_sql.split()[-1]}\")\n    188:             except Exception as e:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 201,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    198:             conn.row_factory = sqlite3.Row\n    199: \n    200:             # Apply runtime optimizations\n>>> 201:             conn.execute(\"PRAGMA journal_mode=WAL\")\n    202:             conn.execute(\"PRAGMA synchronous=NORMAL\")\n    203:             conn.execute(\"PRAGMA cache_size=10000\")\n    204:             conn.execute(\"PRAGMA temp_store=MEMORY\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 202,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    199: \n    200:             # Apply runtime optimizations\n    201:             conn.execute(\"PRAGMA journal_mode=WAL\")\n>>> 202:             conn.execute(\"PRAGMA synchronous=NORMAL\")\n    203:             conn.execute(\"PRAGMA cache_size=10000\")\n    204:             conn.execute(\"PRAGMA temp_store=MEMORY\")\n    205: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 203,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    200:             # Apply runtime optimizations\n    201:             conn.execute(\"PRAGMA journal_mode=WAL\")\n    202:             conn.execute(\"PRAGMA synchronous=NORMAL\")\n>>> 203:             conn.execute(\"PRAGMA cache_size=10000\")\n    204:             conn.execute(\"PRAGMA temp_store=MEMORY\")\n    205: \n    206:             self.connection_pool[connection_key] = conn",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 204,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    201:             conn.execute(\"PRAGMA journal_mode=WAL\")\n    202:             conn.execute(\"PRAGMA synchronous=NORMAL\")\n    203:             conn.execute(\"PRAGMA cache_size=10000\")\n>>> 204:             conn.execute(\"PRAGMA temp_store=MEMORY\")\n    205: \n    206:             self.connection_pool[connection_key] = conn\n    207: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 231,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    228: \n    229:         with self.get_optimized_connection(db_path) as conn:\n    230:             cursor = conn.cursor()\n>>> 231:             cursor.execute(query, params)\n    232:             result = cursor.fetchall()\n    233: \n    234:         duration_ms = (time.time() - start_time) * 1000",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 257,
    "column": 4,
    "description": "Method 'get_database_stats' is too complex: 7 complexity, 53 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    254: \n    255:         return duration_ms, result\n    256: \n>>> 257:     def get_database_stats(self, db_path: str) -> Dict[str, Any]:\n    258:         \"\"\"Get comprehensive database statistics.\"\"\"\n    259:         try:\n    260:             with self.get_optimized_connection(db_path) as conn:",
    "context": {
      "complexity": 7,
      "lines": 53,
      "max_nesting": 5,
      "method_name": "get_database_stats"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 266,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    263:                 stats = {}\n    264: \n    265:                 # Basic database info\n>>> 266:                 cursor.execute(\"PRAGMA page_count\")\n    267:                 page_count = cursor.fetchone()[0]\n    268:                 cursor.execute(\"PRAGMA page_size\")\n    269:                 page_size = cursor.fetchone()[0]",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 268,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    265:                 # Basic database info\n    266:                 cursor.execute(\"PRAGMA page_count\")\n    267:                 page_count = cursor.fetchone()[0]\n>>> 268:                 cursor.execute(\"PRAGMA page_size\")\n    269:                 page_size = cursor.fetchone()[0]\n    270:                 stats[\"size_mb\"] = (page_count * page_size) / (1024 * 1024)\n    271: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 273,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    270:                 stats[\"size_mb\"] = (page_count * page_size) / (1024 * 1024)\n    271: \n    272:                 # Journal mode\n>>> 273:                 cursor.execute(\"PRAGMA journal_mode\")\n    274:                 stats[\"journal_mode\"] = cursor.fetchone()[0]\n    275: \n    276:                 # Cache statistics",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 277,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    274:                 stats[\"journal_mode\"] = cursor.fetchone()[0]\n    275: \n    276:                 # Cache statistics\n>>> 277:                 cursor.execute(\"PRAGMA cache_size\")\n    278:                 stats[\"cache_size\"] = cursor.fetchone()[0]\n    279: \n    280:                 # WAL size",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 288,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    285:                     stats[\"wal_size_mb\"] = 0\n    286: \n    287:                 # Table statistics\n>>> 288:                 cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n    289:                 tables = [row[0] for row in cursor.fetchall()]\n    290: \n    291:                 table_stats = {}",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 288,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    285:                     stats[\"wal_size_mb\"] = 0\n    286: \n    287:                 # Table statistics\n>>> 288:                 cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n    289:                 tables = [row[0] for row in cursor.fetchall()]\n    290: \n    291:                 table_stats = {}",
    "context": {
      "query_preview": "SELECT name FROM sqlite_master WHERE type='table'"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 294,
    "column": 24,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    291:                 table_stats = {}\n    292:                 for table in tables:\n    293:                     if not table.startswith(\"sqlite_\"):\n>>> 294:                         cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n    295:                         table_stats[table] = cursor.fetchone()[0]\n    296: \n    297:                 stats[\"tables\"] = table_stats",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 294,
    "column": 41,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    291:                 table_stats = {}\n    292:                 for table in tables:\n    293:                     if not table.startswith(\"sqlite_\"):\n>>> 294:                         cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n    295:                         table_stats[table] = cursor.fetchone()[0]\n    296: \n    297:                 stats[\"tables\"] = table_stats",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 695,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    692: \n    693:         # Test query performance\n    694:         test_queries = [\n>>> 695:             \"SELECT COUNT(*) FROM fitness_metrics\",\n    696:             \"SELECT AVG(fitness_score) FROM fitness_metrics WHERE agent_id = ?\",\n    697:             \"SELECT * FROM evolution_rounds ORDER BY timestamp DESC LIMIT 10\",\n    698:         ]",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM fitness_metrics"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 696,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    693:         # Test query performance\n    694:         test_queries = [\n    695:             \"SELECT COUNT(*) FROM fitness_metrics\",\n>>> 696:             \"SELECT AVG(fitness_score) FROM fitness_metrics WHERE agent_id = ?\",\n    697:             \"SELECT * FROM evolution_rounds ORDER BY timestamp DESC LIMIT 10\",\n    698:         ]\n    699: ",
    "context": {
      "query_preview": "SELECT AVG(fitness_score) FROM fitness_metrics WHERE agent_id = ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 697,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    694:         test_queries = [\n    695:             \"SELECT COUNT(*) FROM fitness_metrics\",\n    696:             \"SELECT AVG(fitness_score) FROM fitness_metrics WHERE agent_id = ?\",\n>>> 697:             \"SELECT * FROM evolution_rounds ORDER BY timestamp DESC LIMIT 10\",\n    698:         ]\n    699: \n    700:         query_times = []",
    "context": {
      "query_preview": "SELECT * FROM evolution_rounds ORDER BY timestamp DESC LIMIT 10"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 850,
    "column": 4,
    "description": "Method '_generate_summary' is too complex: 8 complexity, 50 lines, 7 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    847:             },\n    848:         }\n    849: \n>>> 850:     def _generate_summary(self, benchmarks: Dict[str, Any]) -> Dict[str, Any]:\n    851:         \"\"\"Generate benchmark summary.\"\"\"\n    852:         summary = {\n    853:             \"overall_performance\": \"excellent\",",
    "context": {
      "complexity": 8,
      "lines": 50,
      "max_nesting": 7,
      "method_name": "_generate_summary"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 902,
    "column": 4,
    "description": "Method '_generate_recommendations' is too complex: 11 complexity, 37 lines, 10 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    899: \n    900:         return summary\n    901: \n>>> 902:     def _generate_recommendations(self, benchmarks: Dict[str, Any]) -> List[str]:\n    903:         \"\"\"Generate performance recommendations.\"\"\"\n    904:         recommendations = []\n    905: ",
    "context": {
      "complexity": 11,
      "lines": 37,
      "max_nesting": 10,
      "method_name": "_generate_recommendations"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 106,
    "column": 4,
    "description": "Duplicate code block detected in function '__init__'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    103: class DatabasePerformanceOptimizer:\n    104:     \"\"\"Database performance optimization and monitoring.\"\"\"\n    105: \n>>> 106:     def __init__(self, db_paths: List[str]):\n    107:         self.db_paths = db_paths\n    108:         self.connection_pool = {}\n    109:         self.query_cache = {}",
    "context": {
      "duplicate_count": 2,
      "function_name": "__init__",
      "signature": "ASSIGN|ASSIGN|ASSIGN|ASSIGN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 528,
    "column": 4,
    "description": "Duplicate code block detected in function '__init__'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    525: class NetworkPerformanceOptimizer:\n    526:     \"\"\"Network performance optimization for P2P communications.\"\"\"\n    527: \n>>> 528:     def __init__(self):\n    529:         self.network_stats = deque(maxlen=1000)\n    530:         self.message_compression = True\n    531:         self.batch_size = 10",
    "context": {
      "duplicate_count": 2,
      "function_name": "__init__",
      "signature": "ASSIGN|ASSIGN|ASSIGN|ASSIGN"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'conn' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "conn",
      "method_count": 9,
      "methods": [
        "close",
        "execute",
        "cursor",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'time' methods (14 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "time",
      "method_count": 14,
      "methods": [
        "sleep",
        "time"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'cursor' methods (16 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "cursor",
      "method_count": 16,
      "methods": [
        "execute",
        "fetchone",
        "fetchall"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (23 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 23,
      "methods": [
        "_estimate_faiss_memory",
        "_generate_summary",
        "_calculate_memory_fragmentation",
        "optimize_all_systems",
        "_optimize_faiss_memory",
        "_benchmark_network",
        "_serialize_message",
        "_create_performance_indexes",
        "get_memory_stats",
        "get_optimized_connection",
        "_optimize_eviction_policy",
        "_benchmark_api",
        "_generate_recommendations",
        "_benchmark_memory",
        "_benchmark_cache",
        "_trigger_memory_cleanup",
        "_benchmark_database",
        "_preload_cache",
        "_estimate_cache_memory",
        "_compress_data"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (12 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 12,
      "methods": [
        "info",
        "warning",
        "error",
        "debug"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 6,
      "methods": [
        "now"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'psutil' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "psutil",
      "method_count": 6,
      "methods": [
        "cpu_count",
        "Process",
        "virtual_memory"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'recommendations' methods (12 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "recommendations",
      "method_count": 12,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 223,
    "column": 56,
    "description": "Excessive magic literals detected (86 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    220:         # Check query cache first\n    221:         if cache_key in self.query_cache:\n    222:             cache_entry = self.query_cache[cache_key]\n>>> 223:             if time.time() - cache_entry[\"timestamp\"] < 60:  # 1 minute cache\n    224:                 return 0.1, cache_entry[\"result\"]  # Cache hit - very fast\n    225: \n    226:         # Execute query with timing",
    "context": {
      "total_magic_literals": 86,
      "current_value": 60
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 224,
    "column": 23,
    "description": "Excessive magic literals detected (86 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    221:         if cache_key in self.query_cache:\n    222:             cache_entry = self.query_cache[cache_key]\n    223:             if time.time() - cache_entry[\"timestamp\"] < 60:  # 1 minute cache\n>>> 224:                 return 0.1, cache_entry[\"result\"]  # Cache hit - very fast\n    225: \n    226:         # Execute query with timing\n    227:         start_time = time.time()",
    "context": {
      "total_magic_literals": 86,
      "current_value": 0.1
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 242,
    "column": 107,
    "description": "Excessive magic literals detected (86 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    239:         # Clean cache if too large\n    240:         if len(self.query_cache) > 1000:\n    241:             # Remove oldest 20%\n>>> 242:             oldest_keys = sorted(self.query_cache.keys(), key=lambda k: self.query_cache[k][\"timestamp\"])[:200]\n    243:             for key in oldest_keys:\n    244:                 del self.query_cache[key]\n    245: ",
    "context": {
      "total_magic_literals": 86,
      "current_value": 200
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 249,
    "column": 60,
    "description": "Excessive magic literals detected (86 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    246:         # Record performance stats\n    247:         self.performance_stats[db_path].append(\n    248:             {\n>>> 249:                 \"query\": query[:50] + \"...\" if len(query) > 50 else query,\n    250:                 \"duration_ms\": duration_ms,\n    251:                 \"timestamp\": datetime.now(),\n    252:             }",
    "context": {
      "total_magic_literals": 86,
      "current_value": 50
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\performance\\performance_optimizer.py",
    "line_number": 249,
    "column": 32,
    "description": "Excessive magic literals detected (86 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    246:         # Record performance stats\n    247:         self.performance_stats[db_path].append(\n    248:             {\n>>> 249:                 \"query\": query[:50] + \"...\" if len(query) > 50 else query,\n    250:                 \"duration_ms\": duration_ms,\n    251:                 \"timestamp\": datetime.now(),\n    252:             }",
    "context": {
      "total_magic_literals": 86,
      "current_value": 50
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\privacy\\zero_knowledge_proofs.py",
    "line_number": 90,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     87: \n     88:     # Schnorr Signature - Prove knowledge of private key\n     89:     def create_schnorr_proof(self, message: bytes) -> ProofResponse:\n>>>  90:         \"\"\"Create Schnorr signature proof of knowledge.\n     91: \n     92:         This proves we know the private key without revealing it.\n     93:         \"\"\"",
    "context": {
      "query_preview": "Create Schnorr signature proof of knowledge.\n\n        This proves we know the private key without re..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\privacy\\zero_knowledge_proofs.py",
    "line_number": 135,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    132: \n    133:     # Pedersen Commitment - Commit to value without revealing it\n    134:     def create_pedersen_commitment(self, value: int) -> tuple[bytes, bytes]:\n>>> 135:         \"\"\"Create Pedersen commitment to a value.\n    136: \n    137:         Returns commitment and opening (keep opening secret).\n    138:         \"\"\"",
    "context": {
      "query_preview": "Create Pedersen commitment to a value.\n\n        Returns commitment and opening (keep opening secret)..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\privacy\\zero_knowledge_proofs.py",
    "line_number": 176,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    173: \n    174:     # Range Proof - Prove value is in range without revealing it\n    175:     def create_range_proof(self, value: int, min_val: int, max_val: int) -> ProofResponse:\n>>> 176:         \"\"\"Create range proof that min_val <= value <= max_val.\n    177: \n    178:         Simplified version - production would use Bulletproofs.\n    179:         \"\"\"",
    "context": {
      "query_preview": "Create range proof that min_val <= value <= max_val.\n\n        Simplified version - production would ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\privacy\\zero_knowledge_proofs.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'int' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "int",
      "method_count": 7,
      "methods": [
        "from_bytes"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\privacy\\zero_knowledge_proofs.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'hashlib' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "hashlib",
      "method_count": 8,
      "methods": [
        "sha256"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\privacy\\zero_knowledge_proofs.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 8,
      "methods": [
        "info",
        "warning",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\privacy\\zero_knowledge_proofs.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'json' methods (13 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "json",
      "method_count": 13,
      "methods": [
        "dumps",
        "loads"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\privacy\\zero_knowledge_proofs.py",
    "line_number": 65,
    "column": 11,
    "description": "Excessive magic literals detected (18 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     62: \n     63:     # Cryptographic parameters (simplified for demonstration)\n     64:     # In production, use proper elliptic curve parameters\n>>>  65:     P = 2**256 - 2**32 - 977  # Prime modulus (simplified)\n     66:     G = 2  # Generator\n     67: \n     68:     def __init__(self, identity_key: bytes | None = None):",
    "context": {
      "total_magic_literals": 18,
      "current_value": 256
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\privacy\\zero_knowledge_proofs.py",
    "line_number": 65,
    "column": 20,
    "description": "Excessive magic literals detected (18 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     62: \n     63:     # Cryptographic parameters (simplified for demonstration)\n     64:     # In production, use proper elliptic curve parameters\n>>>  65:     P = 2**256 - 2**32 - 977  # Prime modulus (simplified)\n     66:     G = 2  # Generator\n     67: \n     68:     def __init__(self, identity_key: bytes | None = None):",
    "context": {
      "total_magic_literals": 18,
      "current_value": 32
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\privacy\\zero_knowledge_proofs.py",
    "line_number": 65,
    "column": 25,
    "description": "Excessive magic literals detected (18 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     62: \n     63:     # Cryptographic parameters (simplified for demonstration)\n     64:     # In production, use proper elliptic curve parameters\n>>>  65:     P = 2**256 - 2**32 - 977  # Prime modulus (simplified)\n     66:     G = 2  # Generator\n     67: \n     68:     def __init__(self, identity_key: bytes | None = None):",
    "context": {
      "total_magic_literals": 18,
      "current_value": 977
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\privacy\\zero_knowledge_proofs.py",
    "line_number": 86,
    "column": 40,
    "description": "Excessive magic literals detected (18 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     83: \n     84:     def get_public_key(self) -> bytes:\n     85:         \"\"\"Get public key for verification.\"\"\"\n>>>  86:         return self.public_key.to_bytes(32, \"big\")\n     87: \n     88:     # Schnorr Signature - Prove knowledge of private key\n     89:     def create_schnorr_proof(self, message: bytes) -> ProofResponse:",
    "context": {
      "total_magic_literals": 18,
      "current_value": 32
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\privacy\\zero_knowledge_proofs.py",
    "line_number": 99,
    "column": 45,
    "description": "Excessive magic literals detected (18 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     96:         commitment = pow(self.G, r, self.P)\n     97: \n     98:         # Challenge (Fiat-Shamir heuristic for non-interactive)\n>>>  99:         challenge_data = commitment.to_bytes(32, \"big\") + message\n    100:         challenge = int.from_bytes(hashlib.sha256(challenge_data).digest(), \"big\") % self.P\n    101: \n    102:         # Response",
    "context": {
      "total_magic_literals": 18,
      "current_value": 32
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\quality\\stub_elimination_system.py",
    "line_number": 137,
    "column": 4,
    "description": "Method 'detect_file_stubs' is too complex: 10 complexity, 34 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    134:             \"Replace with actual implementation\",\n    135:         ]\n    136: \n>>> 137:     def detect_file_stubs(self, file_path: Path) -> list[StubAnalysis]:\n    138:         \"\"\"Detect all stubs in a single file.\"\"\"\n    139:         if not file_path.exists() or file_path.suffix != \".py\":\n    140:             return []",
    "context": {
      "complexity": 10,
      "lines": 34,
      "max_nesting": 6,
      "method_name": "detect_file_stubs"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\quality\\stub_elimination_system.py",
    "line_number": 173,
    "column": 4,
    "description": "Function '_create_stub_analysis' has 6 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    170:             logger.error(f\"Error analyzing {file_path}: {e}\")\n    171:             return []\n    172: \n>>> 173:     def _create_stub_analysis(\n    174:         self,\n    175:         file_path: Path,\n    176:         line_num: int,",
    "context": {
      "parameter_count": 6,
      "function_name": "_create_stub_analysis"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\quality\\stub_elimination_system.py",
    "line_number": 181,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    178:         stub_type: StubType,\n    179:         all_lines: list[str],\n    180:     ) -> StubAnalysis | None:\n>>> 181:         \"\"\"Create stub analysis from detected pattern.\"\"\"\n    182:         location = StubLocation(file_path, line_num)\n    183: \n    184:         # Extract context",
    "context": {
      "query_preview": "Create stub analysis from detected pattern."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\quality\\stub_elimination_system.py",
    "line_number": 212,
    "column": 4,
    "description": "Method '_detect_ast_stubs' is too complex: 8 complexity, 37 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    209: \n    210:         return stub\n    211: \n>>> 212:     def _detect_ast_stubs(self, file_path: Path, tree: ast.AST, lines: list[str]) -> list[StubAnalysis]:\n    213:         \"\"\"Detect stubs using AST analysis.\"\"\"\n    214:         stubs = []\n    215: ",
    "context": {
      "complexity": 8,
      "lines": 37,
      "max_nesting": 5,
      "method_name": "_detect_ast_stubs"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\quality\\stub_elimination_system.py",
    "line_number": 404,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    401:         return results\n    402: \n    403:     def create_elimination_plan(self, target_count: int = 50) -> list[StubAnalysis]:\n>>> 404:         \"\"\"Create prioritized elimination plan for top N stubs.\"\"\"\n    405:         # Calculate composite scores for prioritization\n    406:         scored_stubs = []\n    407:         for stub in self.all_stubs.values():",
    "context": {
      "query_preview": "Create prioritized elimination plan for top N stubs."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\quality\\stub_elimination_system.py",
    "line_number": 434,
    "column": 22,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    431:         # Update elimination plan\n    432:         self.elimination_plan = [stub.stub_id for stub in top_stubs]\n    433: \n>>> 434:         logger.info(f\"Created elimination plan for top {len(top_stubs)} stubs\")\n    435:         return top_stubs\n    436: \n    437:     def generate_elimination_report(self, top_stubs: list[StubAnalysis]) -> dict[str, Any]:",
    "context": {
      "query_preview": "Created elimination plan for top "
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\quality\\stub_elimination_system.py",
    "line_number": 437,
    "column": 4,
    "description": "Method 'generate_elimination_report' is too complex: 5 complexity, 53 lines, 4 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    434:         logger.info(f\"Created elimination plan for top {len(top_stubs)} stubs\")\n    435:         return top_stubs\n    436: \n>>> 437:     def generate_elimination_report(self, top_stubs: list[StubAnalysis]) -> dict[str, Any]:\n    438:         \"\"\"Generate comprehensive elimination report.\"\"\"\n    439:         # Categorize by type and priority\n    440:         by_type = {}",
    "context": {
      "complexity": 5,
      "lines": 53,
      "max_nesting": 4,
      "method_name": "generate_elimination_report"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\quality\\stub_elimination_system.py",
    "line_number": 542,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    539: def scan_and_plan_elimination(\n    540:     project_root: Path, target_count: int = 50, output_dir: Path | None = None,\n    541: ) -> tuple[dict[str, Any], list[StubAnalysis]]:\n>>> 542:     \"\"\"Scan project and create elimination plan in one step.\"\"\"\n    543:     planner = StubEliminationPlanner(project_root)\n    544: \n    545:     # Scan project",
    "context": {
      "query_preview": "Scan project and create elimination plan in one step."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\quality\\stub_elimination_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'f' methods (22 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "f",
      "method_count": 22,
      "methods": [
        "write",
        "writelines",
        "read"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\quality\\stub_elimination_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 10,
      "methods": [
        "_export_markdown_report",
        "_calculate_function_priority",
        "_generate_description",
        "_detect_ast_stubs",
        "generate_elimination_report",
        "_calculate_priority",
        "_estimate_elimination_effort",
        "_estimate_risk",
        "_create_stub_analysis",
        "_estimate_complexity"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\quality\\stub_elimination_system.py",
    "line_number": 46,
    "column": 13,
    "description": "Excessive magic literals detected (24 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     43: \n     44:     CRITICAL = 1  # Blocks core functionality\n     45:     HIGH = 2  # Important for integration\n>>>  46:     MEDIUM = 3  # Quality improvement\n     47:     LOW = 4  # Nice to have\n     48:     DEFERRED = 5  # Not in current scope\n     49: ",
    "context": {
      "total_magic_literals": 24,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\quality\\stub_elimination_system.py",
    "line_number": 47,
    "column": 10,
    "description": "Excessive magic literals detected (24 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     44:     CRITICAL = 1  # Blocks core functionality\n     45:     HIGH = 2  # Important for integration\n     46:     MEDIUM = 3  # Quality improvement\n>>>  47:     LOW = 4  # Nice to have\n     48:     DEFERRED = 5  # Not in current scope\n     49: \n     50: ",
    "context": {
      "total_magic_literals": 24,
      "current_value": 4
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\quality\\stub_elimination_system.py",
    "line_number": 48,
    "column": 15,
    "description": "Excessive magic literals detected (24 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     45:     HIGH = 2  # Important for integration\n     46:     MEDIUM = 3  # Quality improvement\n     47:     LOW = 4  # Nice to have\n>>>  48:     DEFERRED = 5  # Not in current scope\n     49: \n     50: \n     51: @dataclass",
    "context": {
      "total_magic_literals": 24,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\quality\\stub_elimination_system.py",
    "line_number": 185,
    "column": 42,
    "description": "Excessive magic literals detected (24 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    182:         location = StubLocation(file_path, line_num)\n    183: \n    184:         # Extract context\n>>> 185:         start_context = max(0, line_num - 3)\n    186:         end_context = min(len(all_lines), line_num + 2)\n    187:         context_lines = all_lines[start_context:end_context]\n    188: ",
    "context": {
      "total_magic_literals": 24,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\quality\\stub_elimination_system.py",
    "line_number": 243,
    "column": 41,
    "description": "Excessive magic literals detected (24 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    240:                         priority=StubPriority.MEDIUM,\n    241:                         content=f\"class {node.name}: pass\",\n    242:                         class_name=node.name,\n>>> 243:                         complexity_score=1.5,\n    244:                         elimination_effort=3.0,\n    245:                         description=f\"Empty class: {node.name}\",\n    246:                     )",
    "context": {
      "total_magic_literals": 24,
      "current_value": 1.5
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 28,
    "column": 0,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     25: from typing import Any\n     26: \n     27: # Add src to path for imports\n>>>  28: sys.path.insert(0, str(Path(__file__).parent.parent.parent))\n     29: \n     30: \n     31: class ErrorSeverity(Enum):",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 168,
    "column": 4,
    "description": "Function 'record_error' has 7 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    165:         self.component_health: dict[str, HealthStatus] = {}\n    166:         self._lock = threading.Lock()\n    167: \n>>> 168:     def record_error(\n    169:         self,\n    170:         component: str,\n    171:         operation: str,",
    "context": {
      "parameter_count": 7,
      "function_name": "record_error"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 208,
    "column": 4,
    "description": "Method '_categorize_error' is too complex: 6 complexity, 14 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    205: \n    206:         return error_id\n    207: \n>>> 208:     def _categorize_error(self, error: Exception) -> ErrorCategory:\n    209:         \"\"\"Automatically categorize error based on type.\"\"\"\n    210:         error_type = type(error).__name__.lower()\n    211: ",
    "context": {
      "complexity": 6,
      "lines": 14,
      "max_nesting": 5,
      "method_name": "_categorize_error"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 224,
    "column": 4,
    "description": "Method '_update_component_health' is too complex: 6 complexity, 10 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    221:             return ErrorCategory.TIMEOUT\n    222:         return ErrorCategory.INTERNAL\n    223: \n>>> 224:     def _update_component_health(self, component: str, severity: ErrorSeverity):\n    225:         \"\"\"Update component health based on error severity.\"\"\"\n    226:         if severity == ErrorSeverity.CRITICAL:\n    227:             self.component_health[component] = HealthStatus.CRITICAL",
    "context": {
      "complexity": 6,
      "lines": 10,
      "max_nesting": 5,
      "method_name": "_update_component_health"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 225,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    222:         return ErrorCategory.INTERNAL\n    223: \n    224:     def _update_component_health(self, component: str, severity: ErrorSeverity):\n>>> 225:         \"\"\"Update component health based on error severity.\"\"\"\n    226:         if severity == ErrorSeverity.CRITICAL:\n    227:             self.component_health[component] = HealthStatus.CRITICAL\n    228:         elif severity == ErrorSeverity.HIGH:",
    "context": {
      "query_preview": "Update component health based on error severity."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 624,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    621:             return False\n    622: \n    623:     def _update_overall_status(self):\n>>> 624:         \"\"\"Update overall system status.\"\"\"\n    625:         if self.health_status.critical_failures:\n    626:             self.health_status.overall_status = HealthStatus.CRITICAL\n    627:         elif self.health_status.degraded_services:",
    "context": {
      "query_preview": "Update overall system status."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 659,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    656:         self._register_default_health_checks()\n    657: \n    658:     def get_circuit_breaker(self, name: str, config: CircuitBreakerConfig | None = None) -> CircuitBreaker:\n>>> 659:         \"\"\"Get or create circuit breaker.\"\"\"\n    660:         if name not in self.circuit_breakers:\n    661:             self.circuit_breakers[name] = CircuitBreaker(name, config)\n    662:         return self.circuit_breakers[name]",
    "context": {
      "query_preview": "Get or create circuit breaker."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 665,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    662:         return self.circuit_breakers[name]\n    663: \n    664:     def get_retry_handler(self, name: str, config: RetryConfig | None = None) -> RetryHandler:\n>>> 665:         \"\"\"Get or create retry handler.\"\"\"\n    666:         if name not in self.retry_handlers:\n    667:             self.retry_handlers[name] = RetryHandler(config)\n    668:         return self.retry_handlers[name]",
    "context": {
      "query_preview": "Get or create retry handler."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 670,
    "column": 4,
    "description": "Method 'resilient_call' is too complex: 5 complexity, 52 lines, 2 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    667:             self.retry_handlers[name] = RetryHandler(config)\n    668:         return self.retry_handlers[name]\n    669: \n>>> 670:     def resilient_call(\n    671:         self,\n    672:         component: str,\n    673:         operation: str,",
    "context": {
      "complexity": 5,
      "lines": 52,
      "max_nesting": 2,
      "method_name": "resilient_call"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 670,
    "column": 4,
    "description": "Function 'resilient_call' has 9 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    667:             self.retry_handlers[name] = RetryHandler(config)\n    668:         return self.retry_handlers[name]\n    669: \n>>> 670:     def resilient_call(\n    671:         self,\n    672:         component: str,\n    673:         operation: str,",
    "context": {
      "parameter_count": 9,
      "function_name": "resilient_call"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'time' methods (18 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "time",
      "method_count": 18,
      "methods": [
        "sleep",
        "time"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (20 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 20,
      "methods": [
        "check_system_health",
        "call",
        "_change_state",
        "get_retry_handler",
        "_is_retryable",
        "_record_success",
        "_execute_health_check",
        "_calculate_delay",
        "_register_default_health_checks",
        "_update_overall_status",
        "get_circuit_breaker",
        "_determine_error_severity",
        "_categorize_error",
        "execute_with_retry",
        "_record_failure",
        "get_fallback_data",
        "_update_component_health"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logging' methods (14 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logging",
      "method_count": 14,
      "methods": [
        "exception",
        "warning",
        "getLogger",
        "basicConfig",
        "info",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 92,
    "column": 24,
    "description": "Excessive magic literals detected (19 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     89: class RetryConfig:\n     90:     \"\"\"Retry configuration.\"\"\"\n     91: \n>>>  92:     max_attempts: int = 3\n     93:     initial_delay_ms: float = 100.0\n     94:     max_delay_ms: float = 30000.0\n     95:     backoff_multiplier: float = 2.0",
    "context": {
      "total_magic_literals": 19,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 94,
    "column": 26,
    "description": "Excessive magic literals detected (19 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     91: \n     92:     max_attempts: int = 3\n     93:     initial_delay_ms: float = 100.0\n>>>  94:     max_delay_ms: float = 30000.0\n     95:     backoff_multiplier: float = 2.0\n     96:     jitter: bool = True\n     97:     strategy: RetryStrategy = RetryStrategy.EXPONENTIAL_BACKOFF",
    "context": {
      "total_magic_literals": 19,
      "current_value": 30000.0
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 106,
    "column": 29,
    "description": "Excessive magic literals detected (19 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    103: class CircuitBreakerConfig:\n    104:     \"\"\"Circuit breaker configuration.\"\"\"\n    105: \n>>> 106:     failure_threshold: int = 5\n    107:     success_threshold: int = 3\n    108:     timeout_ms: float = 60000.0\n    109:     half_open_max_calls: int = 5",
    "context": {
      "total_magic_literals": 19,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 107,
    "column": 29,
    "description": "Excessive magic literals detected (19 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    104:     \"\"\"Circuit breaker configuration.\"\"\"\n    105: \n    106:     failure_threshold: int = 5\n>>> 107:     success_threshold: int = 3\n    108:     timeout_ms: float = 60000.0\n    109:     half_open_max_calls: int = 5\n    110:     failure_rate_threshold: float = 0.5",
    "context": {
      "total_magic_literals": 19,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resilience\\error_handling.py",
    "line_number": 108,
    "column": 24,
    "description": "Excessive magic literals detected (19 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    105: \n    106:     failure_threshold: int = 5\n    107:     success_threshold: int = 3\n>>> 108:     timeout_ms: float = 60000.0\n    109:     half_open_max_calls: int = 5\n    110:     failure_rate_threshold: float = 0.5\n    111:     minimum_calls: int = 10",
    "context": {
      "total_magic_literals": 19,
      "current_value": 60000.0
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\legacy\\resources\\adaptive_loader.py",
    "line_number": 80,
    "column": 0,
    "description": "Class 'AdaptiveLoader' is a God Object: 12 methods, ~507 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "     77:     cache_enabled: bool = True\n     78: \n     79: \n>>>  80: class AdaptiveLoader:\n     81:     \"\"\"Adaptive model loader that selects optimal loading strategy based on device resources.\"\"\"\n     82: \n     83:     def __init__(self, device_profiler: DeviceProfiler, constraint_manager: ConstraintManager) -> None:",
    "context": {
      "method_count": 12,
      "estimated_lines": 507,
      "class_name": "AdaptiveLoader",
      "data_methods": 4,
      "business_methods": 8
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\adaptive_loader.py",
    "line_number": 81,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     78: \n     79: \n     80: class AdaptiveLoader:\n>>>  81:     \"\"\"Adaptive model loader that selects optimal loading strategy based on device resources.\"\"\"\n     82: \n     83:     def __init__(self, device_profiler: DeviceProfiler, constraint_manager: ConstraintManager) -> None:\n     84:         self.device_profiler = device_profiler",
    "context": {
      "query_preview": "Adaptive model loader that selects optimal loading strategy based on device resources."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\adaptive_loader.py",
    "line_number": 279,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    276:             return None, {\"error\": str(e)}\n    277: \n    278:     async def _select_optimal_variant(self, model_name: str, context: LoadingContext) -> ModelVariant | None:\n>>> 279:         \"\"\"Select optimal model variant based on current resources and context.\"\"\"\n    280:         if model_name not in self.model_variants:\n    281:             logger.warning(f\"No variants registered for model {model_name}\")\n    282:             return None",
    "context": {
      "query_preview": "Select optimal model variant based on current resources and context."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\adaptive_loader.py",
    "line_number": 504,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    501:         return await self._load_compressed_model(model_name, fallback_variant)\n    502: \n    503:     def unload_model(self, model_name: str) -> bool:\n>>> 504:         \"\"\"Unload model from cache.\"\"\"\n    505:         if model_name in self.loaded_models:\n    506:             del self.loaded_models[model_name]\n    507:             if model_name in self.model_metadata:",
    "context": {
      "query_preview": "Unload model from cache."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\adaptive_loader.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (15 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 15,
      "methods": [
        "_load_quantized_model",
        "_initialize_preferred_strategies",
        "_load_streaming_model",
        "get_cache_usage",
        "_load_full_model",
        "_load_model_variant",
        "_load_compressed_model",
        "_calculate_variant_score",
        "_load_layered_model",
        "_load_cached_model",
        "register_model_variants",
        "_initialize_builtin_variants",
        "_select_optimal_variant"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\adaptive_loader.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 11,
      "methods": [
        "exception",
        "warning",
        "debug",
        "info",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\adaptive_loader.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'asyncio' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "asyncio",
      "method_count": 6,
      "methods": [
        "sleep",
        "run"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\adaptive_loader.py",
    "line_number": 83,
    "column": 4,
    "description": "Sequential coupling detected: Function '__init__' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     80: class AdaptiveLoader:\n     81:     \"\"\"Adaptive model loader that selects optimal loading strategy based on device resources.\"\"\"\n     82: \n>>>  83:     def __init__(self, device_profiler: DeviceProfiler, constraint_manager: ConstraintManager) -> None:\n     84:         self.device_profiler = device_profiler\n     85:         self.constraint_manager = constraint_manager\n     86: ",
    "context": {
      "function_name": "__init__",
      "sequential_functions": [
        "__init__",
        "_initialize_preferred_strategies",
        "_initialize_builtin_variants"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\adaptive_loader.py",
    "line_number": 118,
    "column": 4,
    "description": "Sequential coupling detected: Function '_initialize_preferred_strategies' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    115:         # Initialize built-in model variants\n    116:         self._initialize_builtin_variants()\n    117: \n>>> 118:     def _initialize_preferred_strategies(\n    119:         self,\n    120:     ) -> dict[DeviceType, list[LoadingStrategy]]:\n    121:         \"\"\"Initialize preferred loading strategies by device type.\"\"\"",
    "context": {
      "function_name": "_initialize_preferred_strategies",
      "sequential_functions": [
        "__init__",
        "_initialize_preferred_strategies",
        "_initialize_builtin_variants"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\adaptive_loader.py",
    "line_number": 161,
    "column": 4,
    "description": "Sequential coupling detected: Function '_initialize_builtin_variants' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    158:             ],\n    159:         }\n    160: \n>>> 161:     def _initialize_builtin_variants(self) -> None:\n    162:         \"\"\"Initialize built-in model variants for common evolution models.\"\"\"\n    163:         # Example model variants for evolution systems\n    164:         self.register_model_variants(",
    "context": {
      "function_name": "_initialize_builtin_variants",
      "sequential_functions": [
        "__init__",
        "_initialize_preferred_strategies",
        "_initialize_builtin_variants"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\adaptive_loader.py",
    "line_number": 99,
    "column": 45,
    "description": "Excessive magic literals detected (40 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     96:         self.preferred_strategies = self._initialize_preferred_strategies()\n     97: \n     98:         # Adaptive parameters\n>>>  99:         self.quality_degradation_threshold = 0.7  # Below this, prefer speed\n    100:         self.memory_safety_margin = 0.8  # Use 80% of available memory max\n    101:         self.cpu_safety_margin = 0.75  # Use 75% of available CPU max\n    102: ",
    "context": {
      "total_magic_literals": 40,
      "current_value": 0.7
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\adaptive_loader.py",
    "line_number": 100,
    "column": 36,
    "description": "Excessive magic literals detected (40 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     97: \n     98:         # Adaptive parameters\n     99:         self.quality_degradation_threshold = 0.7  # Below this, prefer speed\n>>> 100:         self.memory_safety_margin = 0.8  # Use 80% of available memory max\n    101:         self.cpu_safety_margin = 0.75  # Use 75% of available CPU max\n    102: \n    103:         # Statistics",
    "context": {
      "total_magic_literals": 40,
      "current_value": 0.8
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\adaptive_loader.py",
    "line_number": 101,
    "column": 33,
    "description": "Excessive magic literals detected (40 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     98:         # Adaptive parameters\n     99:         self.quality_degradation_threshold = 0.7  # Below this, prefer speed\n    100:         self.memory_safety_margin = 0.8  # Use 80% of available memory max\n>>> 101:         self.cpu_safety_margin = 0.75  # Use 75% of available CPU max\n    102: \n    103:         # Statistics\n    104:         self.stats = {",
    "context": {
      "total_magic_literals": 40,
      "current_value": 0.75
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\adaptive_loader.py",
    "line_number": 170,
    "column": 28,
    "description": "Excessive magic literals detected (40 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    167:                 ModelVariant(\n    168:                     name=\"base_evolution_model_tiny\",\n    169:                     strategy=LoadingStrategy.QUANTIZED,\n>>> 170:                     size_mb=50,\n    171:                     memory_requirement_mb=100,\n    172:                     cpu_requirement_percent=20.0,\n    173:                     quality_score=0.6,",
    "context": {
      "total_magic_literals": 40,
      "current_value": 50
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\adaptive_loader.py",
    "line_number": 172,
    "column": 44,
    "description": "Excessive magic literals detected (40 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    169:                     strategy=LoadingStrategy.QUANTIZED,\n    170:                     size_mb=50,\n    171:                     memory_requirement_mb=100,\n>>> 172:                     cpu_requirement_percent=20.0,\n    173:                     quality_score=0.6,\n    174:                     loading_time_estimate_seconds=2.0,\n    175:                     supports_quantization=True,",
    "context": {
      "total_magic_literals": 40,
      "current_value": 20.0
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\legacy\\resources\\constraint_manager.py",
    "line_number": 128,
    "column": 0,
    "description": "Class 'ConstraintManager' is a God Object: 13 methods, ~528 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "    125:         }\n    126: \n    127: \n>>> 128: class ConstraintManager:\n    129:     \"\"\"Manages resource constraints for evolution tasks.\"\"\"\n    130: \n    131:     def __init__(self, device_profiler: DeviceProfiler) -> None:",
    "context": {
      "method_count": 13,
      "estimated_lines": 528,
      "class_name": "ConstraintManager",
      "data_methods": 3,
      "business_methods": 10
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\constraint_manager.py",
    "line_number": 165,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    162:         self.constraint_templates = self._create_constraint_templates()\n    163: \n    164:     def _create_default_constraints(self) -> ResourceConstraints:\n>>> 165:         \"\"\"Create default constraints based on device profile.\"\"\"\n    166:         profile = self.device_profiler.profile\n    167: \n    168:         # Calculate memory constraints (conservative)",
    "context": {
      "query_preview": "Create default constraints based on device profile."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\resources\\constraint_manager.py",
    "line_number": 212,
    "column": 4,
    "description": "Method '_create_constraint_templates' is too complex: 1 complexity, 69 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    209:             can_resume=True,\n    210:         )\n    211: \n>>> 212:     def _create_constraint_templates(self) -> dict[str, ResourceConstraints]:\n    213:         \"\"\"Create pre-defined constraint templates.\"\"\"\n    214:         base = self.default_constraints\n    215: ",
    "context": {
      "complexity": 1,
      "lines": 69,
      "max_nesting": 0,
      "method_name": "_create_constraint_templates"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\constraint_manager.py",
    "line_number": 213,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    210:         )\n    211: \n    212:     def _create_constraint_templates(self) -> dict[str, ResourceConstraints]:\n>>> 213:         \"\"\"Create pre-defined constraint templates.\"\"\"\n    214:         base = self.default_constraints\n    215: \n    216:         return {",
    "context": {
      "query_preview": "Create pre-defined constraint templates."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\resources\\constraint_manager.py",
    "line_number": 569,
    "column": 4,
    "description": "Method '_check_resource_availability' is too complex: 8 complexity, 32 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    566: \n    567:         logger.info(f\"Task {task_id} unregistered\")\n    568: \n>>> 569:     def _check_resource_availability(self, constraints: ResourceConstraints) -> bool:\n    570:         \"\"\"Check if resources are available for task.\"\"\"\n    571:         current_snapshot = self.device_profiler.current_snapshot\n    572:         if not current_snapshot:",
    "context": {
      "complexity": 8,
      "lines": 32,
      "max_nesting": 5,
      "method_name": "_check_resource_availability"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\constraint_manager.py",
    "line_number": 616,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    613:         return self.constraint_templates.get(evolution_type)\n    614: \n    615:     def update_constraints(self, task_id: str, new_constraints: ResourceConstraints) -> None:\n>>> 616:         \"\"\"Update constraints for active task.\"\"\"\n    617:         if task_id in self.active_tasks:\n    618:             self.active_tasks[task_id] = new_constraints\n    619:             logger.info(f\"Updated constraints for task {task_id}\")",
    "context": {
      "query_preview": "Update constraints for active task."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\constraint_manager.py",
    "line_number": 619,
    "column": 26,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    616:         \"\"\"Update constraints for active task.\"\"\"\n    617:         if task_id in self.active_tasks:\n    618:             self.active_tasks[task_id] = new_constraints\n>>> 619:             logger.info(f\"Updated constraints for task {task_id}\")\n    620: \n    621:     def register_violation_callback(self, callback: Callable[[str, ConstraintViolation], None]) -> None:\n    622:         \"\"\"Register violation callback.\"\"\"",
    "context": {
      "query_preview": "Updated constraints for task "
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\constraint_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 9,
      "methods": [
        "_monitoring_loop",
        "_check_task_constraints",
        "_create_constraint_templates",
        "_enforce_action",
        "_handle_violations",
        "_check_all_constraints",
        "_check_resource_availability",
        "_create_default_constraints"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\constraint_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 11,
      "methods": [
        "info",
        "warning",
        "exception"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\constraint_manager.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'violations' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "violations",
      "method_count": 11,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\constraint_manager.py",
    "line_number": 65,
    "column": 38,
    "description": "Excessive magic literals detected (54 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     62:     storage_warning_gb: float = 2.0\n     63: \n     64:     # Time-based constraints\n>>>  65:     max_execution_time_minutes: int = 60\n     66:     max_idle_time_minutes: int = 5\n     67: \n     68:     # Device-specific constraints",
    "context": {
      "total_magic_literals": 54,
      "current_value": 60
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\constraint_manager.py",
    "line_number": 66,
    "column": 33,
    "description": "Excessive magic literals detected (54 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     63: \n     64:     # Time-based constraints\n     65:     max_execution_time_minutes: int = 60\n>>>  66:     max_idle_time_minutes: int = 5\n     67: \n     68:     # Device-specific constraints\n     69:     require_charging: bool = False",
    "context": {
      "total_magic_literals": 54,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\constraint_manager.py",
    "line_number": 169,
    "column": 56,
    "description": "Excessive magic literals detected (54 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    166:         profile = self.device_profiler.profile\n    167: \n    168:         # Calculate memory constraints (conservative)\n>>> 169:         total_memory_mb = int(profile.total_memory_gb * 1024)\n    170:         max_memory = min(\n    171:             total_memory_mb // 2,  # Max 50% of total memory\n    172:             profile.max_evolution_memory_mb or (total_memory_mb // 2),",
    "context": {
      "total_magic_literals": 54,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\constraint_manager.py",
    "line_number": 176,
    "column": 55,
    "description": "Excessive magic literals detected (54 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    173:         )\n    174: \n    175:         # CPU constraints\n>>> 176:         max_cpu = profile.max_evolution_cpu_percent or 70.0\n    177: \n    178:         # Battery constraints (if applicable)\n    179:         min_battery = None",
    "context": {
      "total_magic_literals": 54,
      "current_value": 70.0
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\constraint_manager.py",
    "line_number": 182,
    "column": 26,
    "description": "Excessive magic literals detected (54 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    179:         min_battery = None\n    180:         battery_warning = None\n    181:         if profile.device_type in [DeviceType.PHONE, DeviceType.TABLET]:\n>>> 182:             min_battery = 15.0 if not profile.battery_optimization else 25.0\n    183:             battery_warning = 20.0 if not profile.battery_optimization else 30.0\n    184: \n    185:         # Thermal constraints",
    "context": {
      "total_magic_literals": 54,
      "current_value": 15.0
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\resource_monitor.py",
    "line_number": 223,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    220: \n    221: \n    222: def get_monitor_instance():\n>>> 223:     \"\"\"Get or create monitor instance.\"\"\"\n    224:     global _monitor_instance\n    225:     if _monitor_instance is None:\n    226:         _monitor_instance = ResourceMonitor()",
    "context": {
      "query_preview": "Get or create monitor instance."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\resource_monitor.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 10,
      "methods": [
        "get_gpu_usage",
        "get_disk_usage",
        "get_network_usage",
        "get_memory_usage",
        "get_battery",
        "get_cpu_usage"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\resource_monitor.py",
    "line_number": 31,
    "column": 48,
    "description": "Excessive magic literals detected (30 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     28:     def get_cpu_usage(self) -> float:\n     29:         \"\"\"Get current CPU usage percentage.\"\"\"\n     30:         if psutil:\n>>>  31:             value = psutil.cpu_percent(interval=0.1)\n     32:         else:  # Fallback to load average\n     33:             try:\n     34:                 load, _, _ = os.getloadavg()",
    "context": {
      "total_magic_literals": 30,
      "current_value": 0.1
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\resource_monitor.py",
    "line_number": 39,
    "column": 35,
    "description": "Excessive magic literals detected (30 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     36:             except Exception:  # pragma: no cover\n     37:                 value = 0.0\n     38:         self.cpu_history.append(value)\n>>>  39:         if len(self.cpu_history) > 60:\n     40:             self.cpu_history.pop(0)\n     41:         return value\n     42: ",
    "context": {
      "total_magic_literals": 30,
      "current_value": 60
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\resource_monitor.py",
    "line_number": 58,
    "column": 70,
    "description": "Excessive magic literals detected (30 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     55:                     for line in fh:\n     56:                         if \":\" in line:\n     57:                             key, val = line.split(\":\", 1)\n>>>  58:                             info[key] = int(val.strip().split()[0]) * 1024\n     59:                 total = info.get(\"MemTotal\", 0)\n     60:                 available = info.get(\"MemAvailable\", info.get(\"MemFree\", 0))\n     61:                 used = total - available",
    "context": {
      "total_magic_literals": 30,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\resource_monitor.py",
    "line_number": 67,
    "column": 33,
    "description": "Excessive magic literals detected (30 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     64:                 total = available = used = 0\n     65:                 percent = 0.0\n     66:         return {\n>>>  67:             \"total_gb\": total / (1024**3),\n     68:             \"available_gb\": available / (1024**3),\n     69:             \"used_gb\": used / (1024**3),\n     70:             \"percent\": percent,",
    "context": {
      "total_magic_literals": 30,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\resources\\resource_monitor.py",
    "line_number": 67,
    "column": 39,
    "description": "Excessive magic literals detected (30 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     64:                 total = available = used = 0\n     65:                 percent = 0.0\n     66:         return {\n>>>  67:             \"total_gb\": total / (1024**3),\n     68:             \"available_gb\": available / (1024**3),\n     69:             \"used_gb\": used / (1024**3),\n     70:             \"percent\": percent,",
    "context": {
      "total_magic_literals": 30,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\digital_twin_encryption.py",
    "line_number": 35,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     32:     \"\"\"Secure encryption for Digital Twin sensitive data fields.\"\"\"\n     33: \n     34:     def __init__(self, encryption_key: str | None = None) -> None:\n>>>  35:         \"\"\"Initialize encryption with CODEX-compliant configuration.\n     36: \n     37:         Args:\n     38:             encryption_key: Base64-encoded 32-byte key from environment",
    "context": {
      "query_preview": "Initialize encryption with CODEX-compliant configuration.\n\n        Args:\n            encryption_key:..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\digital_twin_encryption.py",
    "line_number": 66,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     63:         )\n     64: \n     65:     def _validate_and_derive_key(self, base64_key: str) -> bytes:\n>>>  66:         \"\"\"Validate and derive Fernet key from base64 encoded key.\n     67: \n     68:         Args:\n     69:             base64_key: Base64-encoded 32-byte key",
    "context": {
      "query_preview": "Validate and derive Fernet key from base64 encoded key.\n\n        Args:\n            base64_key: Base6..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\digital_twin_encryption.py",
    "line_number": 147,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    144:             raise DigitalTwinEncryptionError(msg)\n    145: \n    146:     def decrypt_sensitive_field(self, encrypted_data: bytes, field_name: str = \"\") -> Any:\n>>> 147:         \"\"\"Decrypt sensitive field value from database.\n    148: \n    149:         Args:\n    150:             encrypted_data: Encrypted bytes from database",
    "context": {
      "query_preview": "Decrypt sensitive field value from database.\n\n        Args:\n            encrypted_data: Encrypted by..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\digital_twin_encryption.py",
    "line_number": 208,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    205:             raise ComplianceViolationError(msg)\n    206: \n    207:     def hash_user_id(self, user_id: str) -> str:\n>>> 208:         \"\"\"Create privacy-compliant hash of user ID.\n    209: \n    210:         Args:\n    211:             user_id: Original user identifier",
    "context": {
      "query_preview": "Create privacy-compliant hash of user ID.\n\n        Args:\n            user_id: Original user identifi..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\digital_twin_encryption.py",
    "line_number": 224,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    221:         return hash_obj.hexdigest()\n    222: \n    223:     def check_data_retention_compliance(self, created_at: datetime) -> dict[str, Any]:\n>>> 224:         \"\"\"Check if data meets retention policy requirements.\n    225: \n    226:         Args:\n    227:             created_at: When the data was created",
    "context": {
      "query_preview": "Check if data meets retention policy requirements.\n\n        Args:\n            created_at: When the d..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\digital_twin_encryption.py",
    "line_number": 248,
    "column": 48,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    245:         # GDPR right to be forgotten\n    246:         if self.gdpr_compliant and age_days > self.profile_ttl_days:\n    247:             status[\"requires_deletion\"] = True\n>>> 248:             status[\"compliance_actions\"].append(\"GDPR_DELETE_EXPIRED_DATA\")\n    249: \n    250:         # COPPA special handling for minors\n    251:         if self.coppa_compliant and age_days > 180:  # 6 months for COPPA",
    "context": {
      "query_preview": "GDPR_DELETE_EXPIRED_DATA"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\digital_twin_encryption.py",
    "line_number": 261,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    258:         return status\n    259: \n    260:     def create_audit_log_entry(self, action: str, field_name: str, user_id_hash: str) -> dict[str, Any]:\n>>> 261:         \"\"\"Create audit log entry for compliance tracking.\n    262: \n    263:         Args:\n    264:             action: Action performed (encrypt, decrypt, access, delete)",
    "context": {
      "query_preview": "Create audit log entry for compliance tracking.\n\n        Args:\n            action: Action performed ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\digital_twin_encryption.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'os' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "os",
      "method_count": 8,
      "methods": [
        "getenv",
        "urandom"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\http_security_validator.py",
    "line_number": 46,
    "column": 0,
    "description": "Method 'validate_config_dict_for_production' is too complex: 11 complexity, 25 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     43:     return url\n     44: \n     45: \n>>>  46: def validate_config_dict_for_production(config: dict[str, Any], path: str = \"\") -> None:\n     47:     \"\"\"Recursively validate configuration dictionary for HTTP URLs in production.\n     48: \n     49:     Args:",
    "context": {
      "complexity": 11,
      "lines": 25,
      "max_nesting": 8,
      "method_name": "validate_config_dict_for_production"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\http_security_validator.py",
    "line_number": 64,
    "column": 57,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "     61: \n     62:         if isinstance(value, dict):\n     63:             validate_config_dict_for_production(value, current_path)\n>>>  64:         elif isinstance(value, str) and value.startswith(\"http://\"):\n     65:             validate_url_for_production(value, f\"config key '{current_path}'\")\n     66:         elif isinstance(value, list):\n     67:             for i, item in enumerate(value):",
    "context": {
      "hardcoded_value": "http://"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\http_security_validator.py",
    "line_number": 68,
    "column": 61,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "     65:             validate_url_for_production(value, f\"config key '{current_path}'\")\n     66:         elif isinstance(value, list):\n     67:             for i, item in enumerate(value):\n>>>  68:                 if isinstance(item, str) and item.startswith(\"http://\"):\n     69:                     validate_url_for_production(item, f\"config key '{current_path}[{i}]'\")\n     70:                 elif isinstance(item, dict):\n     71:                     validate_config_dict_for_production(item, f\"{current_path}[{i}]\")",
    "context": {
      "hardcoded_value": "http://"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\http_security_validator.py",
    "line_number": 85,
    "column": 19,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "     82:         List of found HTTP URLs\n     83:     \"\"\"\n     84:     # Pattern to find HTTP URLs in strings\n>>>  85:     http_pattern = r'\"http://[^\"]*\"|\\'http://[^\\']*\\'|`http://[^`]*`'\n     86:     matches = re.findall(http_pattern, source_code)\n     87: \n     88:     # Clean up the quotes",
    "context": {
      "hardcoded_value": "\"http://[^\"]*\"|\\'http://[^\\']*\\'|`http://[^`]*`"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\http_security_validator.py",
    "line_number": 122,
    "column": 38,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    119:     violations = []\n    120:     for var_name in env_vars_to_check:\n    121:         value = os.getenv(var_name)\n>>> 122:         if value and value.startswith(\"http://\"):\n    123:             violations.append(f\"{var_name}={value}\")\n    124: \n    125:     if violations:",
    "context": {
      "hardcoded_value": "http://"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\http_security_validator.py",
    "line_number": 133,
    "column": 0,
    "description": "Method 'require_https_in_production' is too complex: 8 complexity, 20 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    130:     logger.info(\"Production environment HTTPS validation passed\")\n    131: \n    132: \n>>> 133: def require_https_in_production(func):\n    134:     \"\"\"Decorator to validate HTTPS URLs in production before function execution.\n    135: \n    136:     This decorator can be applied to functions that accept URL parameters.",
    "context": {
      "complexity": 8,
      "lines": 20,
      "max_nesting": 5,
      "method_name": "require_https_in_production"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\http_security_validator.py",
    "line_number": 139,
    "column": 4,
    "description": "Method 'wrapper' is too complex: 8 complexity, 12 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    136:     This decorator can be applied to functions that accept URL parameters.\n    137:     \"\"\"\n    138: \n>>> 139:     def wrapper(*args, **kwargs):\n    140:         if os.getenv(\"AIVILLAGE_ENV\") == \"production\":\n    141:             # Check all string arguments for HTTP URLs\n    142:             for arg in args:",
    "context": {
      "complexity": 8,
      "lines": 12,
      "max_nesting": 5,
      "method_name": "wrapper"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\http_security_validator.py",
    "line_number": 143,
    "column": 59,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    140:         if os.getenv(\"AIVILLAGE_ENV\") == \"production\":\n    141:             # Check all string arguments for HTTP URLs\n    142:             for arg in args:\n>>> 143:                 if isinstance(arg, str) and arg.startswith(\"http://\"):\n    144:                     validate_url_for_production(arg, f\"function {func.__name__}\")\n    145: \n    146:             # Check keyword arguments for HTTP URLs",
    "context": {
      "hardcoded_value": "http://"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\http_security_validator.py",
    "line_number": 148,
    "column": 63,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    145: \n    146:             # Check keyword arguments for HTTP URLs\n    147:             for key, value in kwargs.items():\n>>> 148:                 if isinstance(value, str) and value.startswith(\"http://\"):\n    149:                     validate_url_for_production(value, f\"function {func.__name__} parameter '{key}'\")\n    150: \n    151:         return func(*args, **kwargs)",
    "context": {
      "hardcoded_value": "http://"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 61,
    "column": 4,
    "description": "Method '_generate_ca' is too complex: 1 complexity, 74 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     58:             logger.info(f\"Generating P2P node certificate for {self.node_id}\")\n     59:             self._generate_node_cert()\n     60: \n>>>  61:     def _generate_ca(self) -> None:\n     62:         \"\"\"Generate Certificate Authority for P2P network.\"\"\"\n     63:         # Generate CA private key\n     64:         ca_private_key = rsa.generate_private_key(",
    "context": {
      "complexity": 1,
      "lines": 74,
      "max_nesting": 0,
      "method_name": "_generate_ca"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 137,
    "column": 4,
    "description": "Method '_generate_node_cert' is too complex: 1 complexity, 92 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    134: \n    135:         logger.info(f\"Generated P2P CA certificate: {self.ca_cert_path}\")\n    136: \n>>> 137:     def _generate_node_cert(self) -> None:\n    138:         \"\"\"Generate node certificate signed by CA.\"\"\"\n    139:         # Load CA\n    140:         with open(self.ca_cert_path, \"rb\") as f:",
    "context": {
      "complexity": 1,
      "lines": 92,
      "max_nesting": 0,
      "method_name": "_generate_node_cert"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 232,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    229:         logger.info(f\"Generated P2P node certificate: {self.node_cert_path}\")\n    230: \n    231:     def create_ssl_context_server(self) -> ssl.SSLContext:\n>>> 232:         \"\"\"Create SSL context for server-side P2P connections.\"\"\"\n    233:         context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n    234: \n    235:         # TLS 1.3 only for maximum security",
    "context": {
      "query_preview": "Create SSL context for server-side P2P connections."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 261,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    258:         return context\n    259: \n    260:     def create_ssl_context_client(self) -> ssl.SSLContext:\n>>> 261:         \"\"\"Create SSL context for client-side P2P connections.\"\"\"\n    262:         context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n    263: \n    264:         # TLS 1.3 only for maximum security",
    "context": {
      "query_preview": "Create SSL context for client-side P2P connections."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 397,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    394: \n    395: \n    396: def create_p2p_mtls_config(node_id: str, cert_dir: str | None = None) -> P2PMTLSConfig:\n>>> 397:     \"\"\"Create mTLS configuration for P2P node.\n    398: \n    399:     Args:\n    400:         node_id: Unique node identifier",
    "context": {
      "query_preview": "Create mTLS configuration for P2P node.\n\n    Args:\n        node_id: Unique node identifier\n        c..."
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 231,
    "column": 4,
    "description": "Duplicate code block detected in function 'create_ssl_context_server'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    228: \n    229:         logger.info(f\"Generated P2P node certificate: {self.node_cert_path}\")\n    230: \n>>> 231:     def create_ssl_context_server(self) -> ssl.SSLContext:\n    232:         \"\"\"Create SSL context for server-side P2P connections.\"\"\"\n    233:         context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n    234: ",
    "context": {
      "duplicate_count": 2,
      "function_name": "create_ssl_context_server",
      "signature": "ASSIGN|ASSIGN|ASSIGN|CALL_load_cert_chain|CALL_load_verify_locations|ASSIGN|ASSIGN|CALL_set_ciphers|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 260,
    "column": 4,
    "description": "Duplicate code block detected in function 'create_ssl_context_client'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    257: \n    258:         return context\n    259: \n>>> 260:     def create_ssl_context_client(self) -> ssl.SSLContext:\n    261:         \"\"\"Create SSL context for client-side P2P connections.\"\"\"\n    262:         context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n    263: ",
    "context": {
      "duplicate_count": 2,
      "function_name": "create_ssl_context_client",
      "signature": "ASSIGN|ASSIGN|ASSIGN|CALL_load_cert_chain|CALL_load_verify_locations|ASSIGN|ASSIGN|CALL_set_ciphers|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 8,
      "methods": [
        "info",
        "exception",
        "debug"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'x509' methods (34 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "x509",
      "method_count": 34,
      "methods": [
        "BasicConstraints",
        "SubjectAlternativeName",
        "load_der_x509_certificate",
        "Name",
        "ExtendedKeyUsage",
        "RFC822Name",
        "NameAttribute",
        "UniformResourceIdentifier",
        "KeyUsage",
        "random_serial_number",
        "CertificateBuilder",
        "load_pem_x509_certificate",
        "DNSName"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 7,
      "methods": [
        "utcnow"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'f' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "f",
      "method_count": 9,
      "methods": [
        "write",
        "read"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'context' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "context",
      "method_count": 6,
      "methods": [
        "load_cert_chain",
        "set_ciphers",
        "load_verify_locations"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 65,
    "column": 28,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     62:         \"\"\"Generate Certificate Authority for P2P network.\"\"\"\n     63:         # Generate CA private key\n     64:         ca_private_key = rsa.generate_private_key(\n>>>  65:             public_exponent=65537,\n     66:             key_size=4096,  # Stronger key for CA\n     67:         )\n     68: ",
    "context": {
      "total_magic_literals": 11,
      "current_value": 65537
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 66,
    "column": 21,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     63:         # Generate CA private key\n     64:         ca_private_key = rsa.generate_private_key(\n     65:             public_exponent=65537,\n>>>  66:             key_size=4096,  # Stronger key for CA\n     67:         )\n     68: \n     69:         # Generate CA certificate",
    "context": {
      "total_magic_literals": 11,
      "current_value": 4096
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 88,
    "column": 64,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     85:             .public_key(ca_private_key.public_key())\n     86:             .serial_number(x509.random_serial_number())\n     87:             .not_valid_before(datetime.utcnow())\n>>>  88:             .not_valid_after(datetime.utcnow() + timedelta(days=3650))  # 10 years for CA\n     89:             .add_extension(\n     90:                 x509.BasicConstraints(ca=True, path_length=0),\n     91:                 critical=True,",
    "context": {
      "total_magic_literals": 11,
      "current_value": 3650
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 132,
    "column": 35,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    129:             f.write(ca_certificate.public_bytes(serialization.Encoding.PEM))\n    130: \n    131:         # Set restrictive permissions\n>>> 132:         os.chmod(self.ca_key_path, 0o600)\n    133:         os.chmod(self.ca_cert_path, 0o644)\n    134: \n    135:         logger.info(f\"Generated P2P CA certificate: {self.ca_cert_path}\")",
    "context": {
      "total_magic_literals": 11,
      "current_value": 384
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\p2p_mtls_config.py",
    "line_number": 133,
    "column": 36,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    130: \n    131:         # Set restrictive permissions\n    132:         os.chmod(self.ca_key_path, 0o600)\n>>> 133:         os.chmod(self.ca_cert_path, 0o644)\n    134: \n    135:         logger.info(f\"Generated P2P CA certificate: {self.ca_cert_path}\")\n    136: ",
    "context": {
      "total_magic_literals": 11,
      "current_value": 420
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 91,
    "column": 0,
    "description": "Class 'RBACSystem' is a God Object: 16 methods, ~741 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "     88:     \"\"\"Raised when access is denied.\"\"\"\n     89: \n     90: \n>>>  91: class RBACSystem:\n     92:     \"\"\"Role-Based Access Control system.\"\"\"\n     93: \n     94:     def __init__(self, db_path: str | None = None) -> None:",
    "context": {
      "method_count": 16,
      "estimated_lines": 741,
      "class_name": "RBACSystem",
      "data_methods": 7,
      "business_methods": 9
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 118,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    115:         \"\"\"Get database connection.\"\"\"\n    116:         conn = sqlite3.connect(self.db_path, timeout=30.0)\n    117:         conn.row_factory = sqlite3.Row\n>>> 118:         conn.execute(\"PRAGMA foreign_keys=ON\")\n    119:         try:\n    120:             yield conn\n    121:             conn.commit()",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 121,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    118:         conn.execute(\"PRAGMA foreign_keys=ON\")\n    119:         try:\n    120:             yield conn\n>>> 121:             conn.commit()\n    122:         except Exception:\n    123:             conn.rollback()\n    124:             raise",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 128,
    "column": 4,
    "description": "Method '_init_database' is too complex: 2 complexity, 138 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    125:         finally:\n    126:             conn.close()\n    127: \n>>> 128:     def _init_database(self) -> None:\n    129:         \"\"\"Initialize RBAC database schema.\"\"\"\n    130:         with self._get_connection() as conn:\n    131:             # Roles table",
    "context": {
      "complexity": 2,
      "lines": 138,
      "max_nesting": 1,
      "method_name": "_init_database"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 132,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    129:         \"\"\"Initialize RBAC database schema.\"\"\"\n    130:         with self._get_connection() as conn:\n    131:             # Roles table\n>>> 132:             conn.execute(\n    133:                 \"\"\"\n    134:                 CREATE TABLE IF NOT EXISTS roles (\n    135:                     id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 133,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    130:         with self._get_connection() as conn:\n    131:             # Roles table\n    132:             conn.execute(\n>>> 133:                 \"\"\"\n    134:                 CREATE TABLE IF NOT EXISTS roles (\n    135:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    136:                     name TEXT UNIQUE NOT NULL,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS roles (\n                    id INTEGER PRIMARY KEY AUTOI..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 148,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    145:             )\n    146: \n    147:             # Permissions table\n>>> 148:             conn.execute(\n    149:                 \"\"\"\n    150:                 CREATE TABLE IF NOT EXISTS permissions (\n    151:                     id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 149,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    146: \n    147:             # Permissions table\n    148:             conn.execute(\n>>> 149:                 \"\"\"\n    150:                 CREATE TABLE IF NOT EXISTS permissions (\n    151:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    152:                     name TEXT UNIQUE NOT NULL,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS permissions (\n                    id INTEGER PRIMARY KEY..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 163,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    160:             )\n    161: \n    162:             # Role-Permission assignments\n>>> 163:             conn.execute(\n    164:                 \"\"\"\n    165:                 CREATE TABLE IF NOT EXISTS role_permissions (\n    166:                     id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 164,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    161: \n    162:             # Role-Permission assignments\n    163:             conn.execute(\n>>> 164:                 \"\"\"\n    165:                 CREATE TABLE IF NOT EXISTS role_permissions (\n    166:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    167:                     role_name TEXT NOT NULL,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS role_permissions (\n                    id INTEGER PRIMAR..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 184,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    181:             )\n    182: \n    183:             # Users table\n>>> 184:             conn.execute(\n    185:                 \"\"\"\n    186:                 CREATE TABLE IF NOT EXISTS users (\n    187:                     id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 185,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    182: \n    183:             # Users table\n    184:             conn.execute(\n>>> 185:                 \"\"\"\n    186:                 CREATE TABLE IF NOT EXISTS users (\n    187:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    188:                     user_id TEXT UNIQUE NOT NULL,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS users (\n                    id INTEGER PRIMARY KEY AUTOI..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 214,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    211:             )\n    212: \n    213:             # User-Role assignments\n>>> 214:             conn.execute(\n    215:                 \"\"\"\n    216:                 CREATE TABLE IF NOT EXISTS user_roles (\n    217:                     id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 215,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    212: \n    213:             # User-Role assignments\n    214:             conn.execute(\n>>> 215:                 \"\"\"\n    216:                 CREATE TABLE IF NOT EXISTS user_roles (\n    217:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    218:                     user_id TEXT NOT NULL,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS user_roles (\n                    id INTEGER PRIMARY KEY ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 235,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    232:             )\n    233: \n    234:             # Access log\n>>> 235:             conn.execute(\n    236:                 \"\"\"\n    237:                 CREATE TABLE IF NOT EXISTS access_log (\n    238:                     id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 236,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    233: \n    234:             # Access log\n    235:             conn.execute(\n>>> 236:                 \"\"\"\n    237:                 CREATE TABLE IF NOT EXISTS access_log (\n    238:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    239:                     timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS access_log (\n                    id INTEGER PRIMARY KEY ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 255,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    252: \n    253:             # Create indexes\n    254:             indexes = [\n>>> 255:                 \"CREATE INDEX IF NOT EXISTS idx_role_permissions_role ON role_permissions (role_name)\",\n    256:                 \"CREATE INDEX IF NOT EXISTS idx_role_permissions_permission ON role_permissions (permission_name)\",\n    257:                 \"CREATE INDEX IF NOT EXISTS idx_user_roles_user ON user_roles (user_id)\",\n    258:                 \"CREATE INDEX IF NOT EXISTS idx_user_roles_role ON user_roles (role_name)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_role_permissions_role ON role_permissions (role_name)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 256,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    253:             # Create indexes\n    254:             indexes = [\n    255:                 \"CREATE INDEX IF NOT EXISTS idx_role_permissions_role ON role_permissions (role_name)\",\n>>> 256:                 \"CREATE INDEX IF NOT EXISTS idx_role_permissions_permission ON role_permissions (permission_name)\",\n    257:                 \"CREATE INDEX IF NOT EXISTS idx_user_roles_user ON user_roles (user_id)\",\n    258:                 \"CREATE INDEX IF NOT EXISTS idx_user_roles_role ON user_roles (role_name)\",\n    259:                 \"CREATE INDEX IF NOT EXISTS idx_access_log_user ON access_log (user_id)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_role_permissions_permission ON role_permissions (permission_name)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 257,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    254:             indexes = [\n    255:                 \"CREATE INDEX IF NOT EXISTS idx_role_permissions_role ON role_permissions (role_name)\",\n    256:                 \"CREATE INDEX IF NOT EXISTS idx_role_permissions_permission ON role_permissions (permission_name)\",\n>>> 257:                 \"CREATE INDEX IF NOT EXISTS idx_user_roles_user ON user_roles (user_id)\",\n    258:                 \"CREATE INDEX IF NOT EXISTS idx_user_roles_role ON user_roles (role_name)\",\n    259:                 \"CREATE INDEX IF NOT EXISTS idx_access_log_user ON access_log (user_id)\",\n    260:                 \"CREATE INDEX IF NOT EXISTS idx_access_log_timestamp ON access_log (timestamp)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_user_roles_user ON user_roles (user_id)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 258,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    255:                 \"CREATE INDEX IF NOT EXISTS idx_role_permissions_role ON role_permissions (role_name)\",\n    256:                 \"CREATE INDEX IF NOT EXISTS idx_role_permissions_permission ON role_permissions (permission_name)\",\n    257:                 \"CREATE INDEX IF NOT EXISTS idx_user_roles_user ON user_roles (user_id)\",\n>>> 258:                 \"CREATE INDEX IF NOT EXISTS idx_user_roles_role ON user_roles (role_name)\",\n    259:                 \"CREATE INDEX IF NOT EXISTS idx_access_log_user ON access_log (user_id)\",\n    260:                 \"CREATE INDEX IF NOT EXISTS idx_access_log_timestamp ON access_log (timestamp)\",\n    261:                 \"CREATE INDEX IF NOT EXISTS idx_users_username ON users (username)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_user_roles_role ON user_roles (role_name)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 259,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    256:                 \"CREATE INDEX IF NOT EXISTS idx_role_permissions_permission ON role_permissions (permission_name)\",\n    257:                 \"CREATE INDEX IF NOT EXISTS idx_user_roles_user ON user_roles (user_id)\",\n    258:                 \"CREATE INDEX IF NOT EXISTS idx_user_roles_role ON user_roles (role_name)\",\n>>> 259:                 \"CREATE INDEX IF NOT EXISTS idx_access_log_user ON access_log (user_id)\",\n    260:                 \"CREATE INDEX IF NOT EXISTS idx_access_log_timestamp ON access_log (timestamp)\",\n    261:                 \"CREATE INDEX IF NOT EXISTS idx_users_username ON users (username)\",\n    262:                 \"CREATE INDEX IF NOT EXISTS idx_users_email ON users (email)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_access_log_user ON access_log (user_id)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 260,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    257:                 \"CREATE INDEX IF NOT EXISTS idx_user_roles_user ON user_roles (user_id)\",\n    258:                 \"CREATE INDEX IF NOT EXISTS idx_user_roles_role ON user_roles (role_name)\",\n    259:                 \"CREATE INDEX IF NOT EXISTS idx_access_log_user ON access_log (user_id)\",\n>>> 260:                 \"CREATE INDEX IF NOT EXISTS idx_access_log_timestamp ON access_log (timestamp)\",\n    261:                 \"CREATE INDEX IF NOT EXISTS idx_users_username ON users (username)\",\n    262:                 \"CREATE INDEX IF NOT EXISTS idx_users_email ON users (email)\",\n    263:             ]",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_access_log_timestamp ON access_log (timestamp)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 261,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    258:                 \"CREATE INDEX IF NOT EXISTS idx_user_roles_role ON user_roles (role_name)\",\n    259:                 \"CREATE INDEX IF NOT EXISTS idx_access_log_user ON access_log (user_id)\",\n    260:                 \"CREATE INDEX IF NOT EXISTS idx_access_log_timestamp ON access_log (timestamp)\",\n>>> 261:                 \"CREATE INDEX IF NOT EXISTS idx_users_username ON users (username)\",\n    262:                 \"CREATE INDEX IF NOT EXISTS idx_users_email ON users (email)\",\n    263:             ]\n    264: ",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_users_username ON users (username)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 262,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    259:                 \"CREATE INDEX IF NOT EXISTS idx_access_log_user ON access_log (user_id)\",\n    260:                 \"CREATE INDEX IF NOT EXISTS idx_access_log_timestamp ON access_log (timestamp)\",\n    261:                 \"CREATE INDEX IF NOT EXISTS idx_users_username ON users (username)\",\n>>> 262:                 \"CREATE INDEX IF NOT EXISTS idx_users_email ON users (email)\",\n    263:             ]\n    264: \n    265:             for index_sql in indexes:",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_users_email ON users (email)"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 266,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    263:             ]\n    264: \n    265:             for index_sql in indexes:\n>>> 266:                 conn.execute(index_sql)\n    267: \n    268:     def _init_default_roles(self) -> None:\n    269:         \"\"\"Initialize default roles and permissions.\"\"\"",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 268,
    "column": 4,
    "description": "Method '_init_default_roles' is too complex: 5 complexity, 179 lines, 4 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    265:             for index_sql in indexes:\n    266:                 conn.execute(index_sql)\n    267: \n>>> 268:     def _init_default_roles(self) -> None:\n    269:         \"\"\"Initialize default roles and permissions.\"\"\"\n    270:         # Define default role hierarchy and permissions\n    271:         role_configs = {",
    "context": {
      "complexity": 5,
      "lines": 179,
      "max_nesting": 4,
      "method_name": "_init_default_roles"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 408,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    405:         with self._get_connection() as conn:\n    406:             # Insert roles\n    407:             for role, config in role_configs.items():\n>>> 408:                 conn.execute(\n    409:                     \"\"\"\n    410:                     INSERT OR IGNORE INTO roles (name, display_name, description, parent_role, is_system_role)\n    411:                     VALUES (?, ?, ?, ?, 1)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 409,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    406:             # Insert roles\n    407:             for role, config in role_configs.items():\n    408:                 conn.execute(\n>>> 409:                     \"\"\"\n    410:                     INSERT OR IGNORE INTO roles (name, display_name, description, parent_role, is_system_role)\n    411:                     VALUES (?, ?, ?, ?, 1)\n    412:                 \"\"\",",
    "context": {
      "query_preview": "\n                    INSERT OR IGNORE INTO roles (name, display_name, description, parent_role, is_s..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 424,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    421:             # Insert permissions\n    422:             for permission in Permission:\n    423:                 resource, action = permission.value.split(\":\")\n>>> 424:                 conn.execute(\n    425:                     \"\"\"\n    426:                     INSERT OR IGNORE INTO permissions (name, display_name, description, resource, action)\n    427:                     VALUES (?, ?, ?, ?, ?)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 425,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    422:             for permission in Permission:\n    423:                 resource, action = permission.value.split(\":\")\n    424:                 conn.execute(\n>>> 425:                     \"\"\"\n    426:                     INSERT OR IGNORE INTO permissions (name, display_name, description, resource, action)\n    427:                     VALUES (?, ?, ?, ?, ?)\n    428:                 \"\"\",",
    "context": {
      "query_preview": "\n                    INSERT OR IGNORE INTO permissions (name, display_name, description, resource, a..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 441,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    438:             # Assign permissions to roles\n    439:             for role, config in role_configs.items():\n    440:                 for permission in config[\"permissions\"]:\n>>> 441:                     conn.execute(\n    442:                         \"\"\"\n    443:                         INSERT OR IGNORE INTO role_permissions (role_name, permission_name, granted_by)\n    444:                         VALUES (?, ?, 'SYSTEM_INIT')",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 442,
    "column": 24,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    439:             for role, config in role_configs.items():\n    440:                 for permission in config[\"permissions\"]:\n    441:                     conn.execute(\n>>> 442:                         \"\"\"\n    443:                         INSERT OR IGNORE INTO role_permissions (role_name, permission_name, granted_by)\n    444:                         VALUES (?, ?, 'SYSTEM_INIT')\n    445:                     \"\"\",",
    "context": {
      "query_preview": "\n                        INSERT OR IGNORE INTO role_permissions (role_name, permission_name, granted..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 449,
    "column": 4,
    "description": "Method 'create_user' is too complex: 4 complexity, 56 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    446:                         (role.value, permission.value),\n    447:                     )\n    448: \n>>> 449:     def create_user(\n    450:         self,\n    451:         user_id: str,\n    452:         username: str,",
    "context": {
      "complexity": 4,
      "lines": 56,
      "max_nesting": 1,
      "method_name": "create_user"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 449,
    "column": 4,
    "description": "Function 'create_user' has 8 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    446:                         (role.value, permission.value),\n    447:                     )\n    448: \n>>> 449:     def create_user(\n    450:         self,\n    451:         user_id: str,\n    452:         username: str,",
    "context": {
      "parameter_count": 8,
      "function_name": "create_user"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 459,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    456:         roles: list[Role] | None = None,\n    457:         **kwargs,\n    458:     ) -> bool:\n>>> 459:         \"\"\"Create new user with roles.\n    460: \n    461:         Args:\n    462:             user_id: Unique user identifier",
    "context": {
      "query_preview": "Create new user with roles.\n\n        Args:\n            user_id: Unique user identifier\n            u..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 476,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    473:         with self._get_connection() as conn:\n    474:             try:\n    475:                 # Create user\n>>> 476:                 conn.execute(\n    477:                     \"\"\"\n    478:                     INSERT INTO users (\n    479:                         user_id, username, email, password_hash, password_salt,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 477,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    474:             try:\n    475:                 # Create user\n    476:                 conn.execute(\n>>> 477:                     \"\"\"\n    478:                     INSERT INTO users (\n    479:                         user_id, username, email, password_hash, password_salt,\n    480:                         requires_coppa_consent, gdpr_consent, data_retention_expires",
    "context": {
      "query_preview": "\n                    INSERT INTO users (\n                        user_id, username, email, password_..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 504,
    "column": 35,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    501:                 return True\n    502: \n    503:             except sqlite3.IntegrityError as e:\n>>> 504:                 logger.exception(f\"Failed to create user {username}: {e}\")\n    505:                 return False\n    506: \n    507:     def assign_role_to_user(",
    "context": {
      "query_preview": "Failed to create user "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 527,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    524:         \"\"\"\n    525:         with self._get_connection() as conn:\n    526:             try:\n>>> 527:                 conn.execute(\n    528:                     \"\"\"\n    529:                     INSERT OR REPLACE INTO user_roles (user_id, role_name, assigned_by, expires_at)\n    530:                     VALUES (?, ?, ?, ?)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 528,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    525:         with self._get_connection() as conn:\n    526:             try:\n    527:                 conn.execute(\n>>> 528:                     \"\"\"\n    529:                     INSERT OR REPLACE INTO user_roles (user_id, role_name, assigned_by, expires_at)\n    530:                     VALUES (?, ?, ?, ?)\n    531:                 \"\"\",",
    "context": {
      "query_preview": "\n                    INSERT OR REPLACE INTO user_roles (user_id, role_name, assigned_by, expires_at)..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 543,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    540:                 return False\n    541: \n    542:     def revoke_role_from_user(self, user_id: str, role: Role) -> bool:\n>>> 543:         \"\"\"Revoke role from user.\n    544: \n    545:         Args:\n    546:             user_id: User identifier",
    "context": {
      "query_preview": "Revoke role from user.\n\n        Args:\n            user_id: User identifier\n            role: Role to..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 553,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    550:             True if role revoked successfully\n    551:         \"\"\"\n    552:         with self._get_connection() as conn:\n>>> 553:             conn.execute(\n    554:                 \"\"\"\n    555:                 DELETE FROM user_roles WHERE user_id = ? AND role_name = ?\n    556:             \"\"\",",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 554,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    551:         \"\"\"\n    552:         with self._get_connection() as conn:\n    553:             conn.execute(\n>>> 554:                 \"\"\"\n    555:                 DELETE FROM user_roles WHERE user_id = ? AND role_name = ?\n    556:             \"\"\",\n    557:                 (user_id, role.value),",
    "context": {
      "query_preview": "\n                DELETE FROM user_roles WHERE user_id = ? AND role_name = ?\n            "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 573,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    570:             List of active roles\n    571:         \"\"\"\n    572:         with self._get_connection() as conn:\n>>> 573:             cursor = conn.execute(\n    574:                 \"\"\"\n    575:                 SELECT role_name FROM user_roles\n    576:                 WHERE user_id = ?",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 574,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    571:         \"\"\"\n    572:         with self._get_connection() as conn:\n    573:             cursor = conn.execute(\n>>> 574:                 \"\"\"\n    575:                 SELECT role_name FROM user_roles\n    576:                 WHERE user_id = ?\n    577:                 AND (expires_at IS NULL OR expires_at > CURRENT_TIMESTAMP)",
    "context": {
      "query_preview": "\n                SELECT role_name FROM user_roles\n                WHERE user_id = ?\n                ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 599,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    596: \n    597:         for role in user_roles:\n    598:             role_permissions = self.get_role_permissions(role)\n>>> 599:             all_permissions.update(role_permissions)\n    600: \n    601:             # Add inherited permissions from parent roles\n    602:             parent_permissions = self._get_inherited_permissions(role)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 603,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    600: \n    601:             # Add inherited permissions from parent roles\n    602:             parent_permissions = self._get_inherited_permissions(role)\n>>> 603:             all_permissions.update(parent_permissions)\n    604: \n    605:         # Super admin gets all permissions\n    606:         if Role.SUPER_ADMIN in user_roles:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 621,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    618:             Set of permissions\n    619:         \"\"\"\n    620:         with self._get_connection() as conn:\n>>> 621:             cursor = conn.execute(\n    622:                 \"\"\"\n    623:                 SELECT permission_name FROM role_permissions\n    624:                 WHERE role_name = ?",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 622,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    619:         \"\"\"\n    620:         with self._get_connection() as conn:\n    621:             cursor = conn.execute(\n>>> 622:                 \"\"\"\n    623:                 SELECT permission_name FROM role_permissions\n    624:                 WHERE role_name = ?\n    625:                 AND (expires_at IS NULL OR expires_at > CURRENT_TIMESTAMP)",
    "context": {
      "query_preview": "\n                SELECT permission_name FROM role_permissions\n                WHERE role_name = ?\n  ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 634,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    631:             return {Permission(name) for name in permission_names if name in [p.value for p in Permission]}\n    632: \n    633:     def _get_inherited_permissions(self, role: Role) -> set[Permission]:\n>>> 634:         \"\"\"Get permissions inherited from parent roles.\n    635: \n    636:         Args:\n    637:             role: Role to check",
    "context": {
      "query_preview": "Get permissions inherited from parent roles.\n\n        Args:\n            role: Role to check\n\n       ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 646,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    643: \n    644:         with self._get_connection() as conn:\n    645:             # Find parent role\n>>> 646:             cursor = conn.execute(\n    647:                 \"\"\"\n    648:                 SELECT parent_role FROM roles WHERE name = ?\n    649:             \"\"\",",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 647,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    644:         with self._get_connection() as conn:\n    645:             # Find parent role\n    646:             cursor = conn.execute(\n>>> 647:                 \"\"\"\n    648:                 SELECT parent_role FROM roles WHERE name = ?\n    649:             \"\"\",\n    650:                 (role.value,),",
    "context": {
      "query_preview": "\n                SELECT parent_role FROM roles WHERE name = ?\n            "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 659,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    656:                     parent_role = Role(row[0])\n    657:                     # Get parent role's permissions\n    658:                     parent_permissions = self.get_role_permissions(parent_role)\n>>> 659:                     inherited_permissions.update(parent_permissions)\n    660: \n    661:                     # Recursively get grandparent permissions\n    662:                     grandparent_permissions = self._get_inherited_permissions(parent_role)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 663,
    "column": 20,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    660: \n    661:                     # Recursively get grandparent permissions\n    662:                     grandparent_permissions = self._get_inherited_permissions(parent_role)\n>>> 663:                     inherited_permissions.update(grandparent_permissions)\n    664:                 except ValueError:\n    665:                     pass  # Invalid parent role\n    666: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 703,
    "column": 4,
    "description": "Function '_log_access' has 9 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    700:             msg = f\"User {user_id} does not have permission {permission.value}\"\n    701:             raise AccessDeniedException(msg)\n    702: \n>>> 703:     def _log_access(\n    704:         self,\n    705:         user_id: str,\n    706:         action: str,",
    "context": {
      "parameter_count": 9,
      "function_name": "_log_access"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 727,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    724:             session_id: Session identifier\n    725:         \"\"\"\n    726:         with self._get_connection() as conn:\n>>> 727:             conn.execute(\n    728:                 \"\"\"\n    729:                 INSERT INTO access_log (\n    730:                     user_id, action, resource, permission_required,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 728,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    725:         \"\"\"\n    726:         with self._get_connection() as conn:\n    727:             conn.execute(\n>>> 728:                 \"\"\"\n    729:                 INSERT INTO access_log (\n    730:                     user_id, action, resource, permission_required,\n    731:                     access_granted, denial_reason, ip_address, user_agent, session_id",
    "context": {
      "query_preview": "\n                INSERT INTO access_log (\n                    user_id, action, resource, permission_..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 759,
    "column": 25,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    756:         \"\"\"\n    757:         with self._get_connection() as conn:\n    758:             if user_id:\n>>> 759:                 cursor = conn.execute(\n    760:                     \"\"\"\n    761:                     SELECT * FROM access_log WHERE user_id = ?\n    762:                     ORDER BY timestamp DESC LIMIT ?",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 760,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    757:         with self._get_connection() as conn:\n    758:             if user_id:\n    759:                 cursor = conn.execute(\n>>> 760:                     \"\"\"\n    761:                     SELECT * FROM access_log WHERE user_id = ?\n    762:                     ORDER BY timestamp DESC LIMIT ?\n    763:                 \"\"\",",
    "context": {
      "query_preview": "\n                    SELECT * FROM access_log WHERE user_id = ?\n                    ORDER BY timesta..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 767,
    "column": 25,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    764:                     (user_id, limit),\n    765:                 )\n    766:             else:\n>>> 767:                 cursor = conn.execute(\n    768:                     \"\"\"\n    769:                     SELECT * FROM access_log\n    770:                     ORDER BY timestamp DESC LIMIT ?",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 768,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    765:                 )\n    766:             else:\n    767:                 cursor = conn.execute(\n>>> 768:                     \"\"\"\n    769:                     SELECT * FROM access_log\n    770:                     ORDER BY timestamp DESC LIMIT ?\n    771:                 \"\"\",",
    "context": {
      "query_preview": "\n                    SELECT * FROM access_log\n                    ORDER BY timestamp DESC LIMIT ?\n  ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 777,
    "column": 4,
    "description": "Method 'get_rbac_stats' is too complex: 1 complexity, 55 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    774: \n    775:             return [dict(row) for row in cursor.fetchall()]\n    776: \n>>> 777:     def get_rbac_stats(self) -> dict[str, Any]:\n    778:         \"\"\"Get RBAC system statistics.\n    779: \n    780:         Returns:",
    "context": {
      "complexity": 1,
      "lines": 55,
      "max_nesting": 0,
      "method_name": "get_rbac_stats"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 787,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    784:             stats = {}\n    785: \n    786:             # User statistics\n>>> 787:             cursor = conn.execute(\"SELECT COUNT(*) FROM users\")\n    788:             stats[\"total_users\"] = cursor.fetchone()[0]\n    789: \n    790:             cursor = conn.execute(\"SELECT COUNT(*) FROM users WHERE is_active = 1\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 787,
    "column": 34,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    784:             stats = {}\n    785: \n    786:             # User statistics\n>>> 787:             cursor = conn.execute(\"SELECT COUNT(*) FROM users\")\n    788:             stats[\"total_users\"] = cursor.fetchone()[0]\n    789: \n    790:             cursor = conn.execute(\"SELECT COUNT(*) FROM users WHERE is_active = 1\")",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM users"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 790,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    787:             cursor = conn.execute(\"SELECT COUNT(*) FROM users\")\n    788:             stats[\"total_users\"] = cursor.fetchone()[0]\n    789: \n>>> 790:             cursor = conn.execute(\"SELECT COUNT(*) FROM users WHERE is_active = 1\")\n    791:             stats[\"active_users\"] = cursor.fetchone()[0]\n    792: \n    793:             # Role statistics",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 790,
    "column": 34,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    787:             cursor = conn.execute(\"SELECT COUNT(*) FROM users\")\n    788:             stats[\"total_users\"] = cursor.fetchone()[0]\n    789: \n>>> 790:             cursor = conn.execute(\"SELECT COUNT(*) FROM users WHERE is_active = 1\")\n    791:             stats[\"active_users\"] = cursor.fetchone()[0]\n    792: \n    793:             # Role statistics",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM users WHERE is_active = 1"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 794,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    791:             stats[\"active_users\"] = cursor.fetchone()[0]\n    792: \n    793:             # Role statistics\n>>> 794:             cursor = conn.execute(\"SELECT COUNT(*) FROM roles\")\n    795:             stats[\"total_roles\"] = cursor.fetchone()[0]\n    796: \n    797:             cursor = conn.execute(\"SELECT COUNT(*) FROM permissions\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 794,
    "column": 34,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    791:             stats[\"active_users\"] = cursor.fetchone()[0]\n    792: \n    793:             # Role statistics\n>>> 794:             cursor = conn.execute(\"SELECT COUNT(*) FROM roles\")\n    795:             stats[\"total_roles\"] = cursor.fetchone()[0]\n    796: \n    797:             cursor = conn.execute(\"SELECT COUNT(*) FROM permissions\")",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM roles"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 797,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    794:             cursor = conn.execute(\"SELECT COUNT(*) FROM roles\")\n    795:             stats[\"total_roles\"] = cursor.fetchone()[0]\n    796: \n>>> 797:             cursor = conn.execute(\"SELECT COUNT(*) FROM permissions\")\n    798:             stats[\"total_permissions\"] = cursor.fetchone()[0]\n    799: \n    800:             # Assignment statistics",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 797,
    "column": 34,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    794:             cursor = conn.execute(\"SELECT COUNT(*) FROM roles\")\n    795:             stats[\"total_roles\"] = cursor.fetchone()[0]\n    796: \n>>> 797:             cursor = conn.execute(\"SELECT COUNT(*) FROM permissions\")\n    798:             stats[\"total_permissions\"] = cursor.fetchone()[0]\n    799: \n    800:             # Assignment statistics",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM permissions"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 801,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    798:             stats[\"total_permissions\"] = cursor.fetchone()[0]\n    799: \n    800:             # Assignment statistics\n>>> 801:             cursor = conn.execute(\"SELECT COUNT(*) FROM user_roles\")\n    802:             stats[\"role_assignments\"] = cursor.fetchone()[0]\n    803: \n    804:             cursor = conn.execute(\"SELECT COUNT(*) FROM role_permissions\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 801,
    "column": 34,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    798:             stats[\"total_permissions\"] = cursor.fetchone()[0]\n    799: \n    800:             # Assignment statistics\n>>> 801:             cursor = conn.execute(\"SELECT COUNT(*) FROM user_roles\")\n    802:             stats[\"role_assignments\"] = cursor.fetchone()[0]\n    803: \n    804:             cursor = conn.execute(\"SELECT COUNT(*) FROM role_permissions\")",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM user_roles"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 804,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    801:             cursor = conn.execute(\"SELECT COUNT(*) FROM user_roles\")\n    802:             stats[\"role_assignments\"] = cursor.fetchone()[0]\n    803: \n>>> 804:             cursor = conn.execute(\"SELECT COUNT(*) FROM role_permissions\")\n    805:             stats[\"permission_assignments\"] = cursor.fetchone()[0]\n    806: \n    807:             # Access log statistics",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 804,
    "column": 34,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    801:             cursor = conn.execute(\"SELECT COUNT(*) FROM user_roles\")\n    802:             stats[\"role_assignments\"] = cursor.fetchone()[0]\n    803: \n>>> 804:             cursor = conn.execute(\"SELECT COUNT(*) FROM role_permissions\")\n    805:             stats[\"permission_assignments\"] = cursor.fetchone()[0]\n    806: \n    807:             # Access log statistics",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM role_permissions"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 808,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    805:             stats[\"permission_assignments\"] = cursor.fetchone()[0]\n    806: \n    807:             # Access log statistics\n>>> 808:             cursor = conn.execute(\"SELECT COUNT(*) FROM access_log\")\n    809:             stats[\"total_access_attempts\"] = cursor.fetchone()[0]\n    810: \n    811:             cursor = conn.execute(",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 808,
    "column": 34,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    805:             stats[\"permission_assignments\"] = cursor.fetchone()[0]\n    806: \n    807:             # Access log statistics\n>>> 808:             cursor = conn.execute(\"SELECT COUNT(*) FROM access_log\")\n    809:             stats[\"total_access_attempts\"] = cursor.fetchone()[0]\n    810: \n    811:             cursor = conn.execute(",
    "context": {
      "query_preview": "SELECT COUNT(*) FROM access_log"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 811,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    808:             cursor = conn.execute(\"SELECT COUNT(*) FROM access_log\")\n    809:             stats[\"total_access_attempts\"] = cursor.fetchone()[0]\n    810: \n>>> 811:             cursor = conn.execute(\n    812:                 \"\"\"\n    813:                 SELECT COUNT(*) FROM access_log\n    814:                 WHERE access_granted = 0 AND timestamp > datetime('now', '-24 hours')",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 812,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    809:             stats[\"total_access_attempts\"] = cursor.fetchone()[0]\n    810: \n    811:             cursor = conn.execute(\n>>> 812:                 \"\"\"\n    813:                 SELECT COUNT(*) FROM access_log\n    814:                 WHERE access_granted = 0 AND timestamp > datetime('now', '-24 hours')\n    815:             \"\"\",",
    "context": {
      "query_preview": "\n                SELECT COUNT(*) FROM access_log\n                WHERE access_granted = 0 AND timest..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 820,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    817:             stats[\"denied_access_24h\"] = cursor.fetchone()[0]\n    818: \n    819:             # Most active users\n>>> 820:             cursor = conn.execute(\n    821:                 \"\"\"\n    822:                 SELECT user_id, COUNT(*) as access_count\n    823:                 FROM access_log",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 821,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    818: \n    819:             # Most active users\n    820:             cursor = conn.execute(\n>>> 821:                 \"\"\"\n    822:                 SELECT user_id, COUNT(*) as access_count\n    823:                 FROM access_log\n    824:                 WHERE timestamp > datetime('now', '-7 days')",
    "context": {
      "query_preview": "\n                SELECT user_id, COUNT(*) as access_count\n                FROM access_log\n          ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (22 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 22,
      "methods": [
        "_get_connection",
        "_get_inherited_permissions",
        "_init_database",
        "get_user_permissions",
        "_init_default_roles",
        "get_role_permissions",
        "_log_access",
        "check_permission",
        "assign_role_to_user",
        "get_user_roles"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 6,
      "methods": [
        "info",
        "exception"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'conn' methods (32 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "conn",
      "method_count": 32,
      "methods": [
        "close",
        "execute",
        "rollback",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'cursor' methods (13 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "cursor",
      "method_count": 13,
      "methods": [
        "fetchone",
        "fetchall"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'rbac' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "rbac",
      "method_count": 6,
      "methods": [
        "require_permission",
        "create_user",
        "get_user_permissions",
        "check_permission",
        "get_rbac_stats"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 94,
    "column": 4,
    "description": "Sequential coupling detected: Function '__init__' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     91: class RBACSystem:\n     92:     \"\"\"Role-Based Access Control system.\"\"\"\n     93: \n>>>  94:     def __init__(self, db_path: str | None = None) -> None:\n     95:         \"\"\"Initialize RBAC system.\n     96: \n     97:         Args:",
    "context": {
      "function_name": "__init__",
      "sequential_functions": [
        "__init__",
        "_init_database",
        "_init_default_roles"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 128,
    "column": 4,
    "description": "Sequential coupling detected: Function '_init_database' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    125:         finally:\n    126:             conn.close()\n    127: \n>>> 128:     def _init_database(self) -> None:\n    129:         \"\"\"Initialize RBAC database schema.\"\"\"\n    130:         with self._get_connection() as conn:\n    131:             # Roles table",
    "context": {
      "function_name": "_init_database",
      "sequential_functions": [
        "__init__",
        "_init_database",
        "_init_default_roles"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\rbac_system.py",
    "line_number": 268,
    "column": 4,
    "description": "Sequential coupling detected: Function '_init_default_roles' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    265:             for index_sql in indexes:\n    266:                 conn.execute(index_sql)\n    267: \n>>> 268:     def _init_default_roles(self) -> None:\n    269:         \"\"\"Initialize default roles and permissions.\"\"\"\n    270:         # Define default role hierarchy and permissions\n    271:         role_configs = {",
    "context": {
      "function_name": "_init_default_roles",
      "sequential_functions": [
        "__init__",
        "_init_database",
        "_init_default_roles"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 116,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    113:         roles: list[str] | None = None,\n    114:         permissions: list[str] | None = None,\n    115:     ) -> str:\n>>> 116:         \"\"\"Create JWT access token.\"\"\"\n    117:         now = datetime.utcnow()\n    118:         payload = {\n    119:             \"user_id\": user_id,",
    "context": {
      "query_preview": "Create JWT access token."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 131,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    128:         return jwt.encode(payload, self.secret_key, algorithm=self.algorithm)\n    129: \n    130:     def create_refresh_token(self, user_id: str) -> str:\n>>> 131:         \"\"\"Create JWT refresh token.\"\"\"\n    132:         now = datetime.utcnow()\n    133:         payload = {\n    134:             \"user_id\": user_id,",
    "context": {
      "query_preview": "Create JWT refresh token."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 185,
    "column": 4,
    "description": "Method 'validate_json' is too complex: 22 complexity, 65 lines, 15 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    182:     \"\"\"Input validation and sanitization.\"\"\"\n    183: \n    184:     @staticmethod\n>>> 185:     def validate_json(data: Any, schema: dict[str, Any]) -> dict[str, Any]:\n    186:         \"\"\"Validate JSON data against schema.\"\"\"\n    187:         if not isinstance(data, dict):\n    188:             msg = \"Request body must be JSON object\"",
    "context": {
      "complexity": 22,
      "lines": 65,
      "max_nesting": 15,
      "method_name": "validate_json"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 268,
    "column": 0,
    "description": "Class 'SecureAPIServer' is a God Object: 5 methods, ~644 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "    265:         return sanitized.strip()\n    266: \n    267: \n>>> 268: class SecureAPIServer:\n    269:     \"\"\"Secure API server with TLS 1.3 and comprehensive security.\"\"\"\n    270: \n    271:     def __init__(",
    "context": {
      "method_count": 5,
      "estimated_lines": 644,
      "class_name": "SecureAPIServer",
      "data_methods": 0,
      "business_methods": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 303,
    "column": 58,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    300: \n    301:         # CORS settings\n    302:         self.cors_enabled = os.getenv(\"API_CORS_ENABLED\", \"true\").lower() == \"true\"\n>>> 303:         self.cors_origins = os.getenv(\"API_CORS_ORIGINS\", \"https://localhost:3000\").split(\",\")\n    304: \n    305:         # Apps\n    306:         self.apps = {}",
    "context": {
      "hardcoded_value": "https://localhost:3000"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 312,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    309:         self._create_apps()\n    310: \n    311:     def _create_apps(self) -> None:\n>>> 312:         \"\"\"Create aiohttp applications for each service.\"\"\"\n    313:         for service in self.ports:\n    314:             app = web.Application(\n    315:                 middlewares=[",
    "context": {
      "query_preview": "Create aiohttp applications for each service."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 625,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    622:         try:\n    623:             # Execute a lightweight query to ensure the connection is healthy\n    624:             with self.profile_db.get_connection() as conn:\n>>> 625:                 conn.execute(\"SELECT 1\")\n    626:             db_health[\"latency_ms\"] = (time.perf_counter() - start_time) * 1000\n    627:         except Exception as exc:  # pragma: no cover - defensive, errors handled below\n    628:             db_health[\"status\"] = \"degraded\"",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 673,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    670:             raise web.HTTPInternalServerError(text=json.dumps({\"error\": \"Failed to retrieve profile\"}))\n    671: \n    672:     async def _create_profile(self, request: web_request.Request) -> web.Response:\n>>> 673:         \"\"\"Create learning profile.\"\"\"\n    674:         user_id = request.get(\"user\", {}).get(\"user_id\")\n    675: \n    676:         if not user_id:",
    "context": {
      "query_preview": "Create learning profile."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 696,
    "column": 28,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    693:             profile_id = self.profile_db.create_profile(user_id, validated_data)\n    694: \n    695:             return web.json_response(\n>>> 696:                 {\"message\": \"Profile created successfully\", \"profile_id\": profile_id},\n    697:                 status=201,\n    698:             )\n    699:         except (ValueError, json.JSONDecodeError):",
    "context": {
      "query_preview": "Profile created successfully"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 702,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    699:         except (ValueError, json.JSONDecodeError):\n    700:             raise web.HTTPBadRequest(text=json.dumps({\"error\": \"Invalid JSON\"}))\n    701:         except Exception as e:\n>>> 702:             logger.exception(f\"Failed to create profile: {e}\")\n    703:             raise web.HTTPInternalServerError(text=json.dumps({\"error\": \"Failed to create profile\"}))\n    704: \n    705:     async def _update_profile(self, request: web_request.Request) -> web.Response:",
    "context": {
      "query_preview": "Failed to create profile: "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 703,
    "column": 72,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    700:             raise web.HTTPBadRequest(text=json.dumps({\"error\": \"Invalid JSON\"}))\n    701:         except Exception as e:\n    702:             logger.exception(f\"Failed to create profile: {e}\")\n>>> 703:             raise web.HTTPInternalServerError(text=json.dumps({\"error\": \"Failed to create profile\"}))\n    704: \n    705:     async def _update_profile(self, request: web_request.Request) -> web.Response:\n    706:         \"\"\"Update learning profile.\"\"\"",
    "context": {
      "query_preview": "Failed to create profile"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 706,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    703:             raise web.HTTPInternalServerError(text=json.dumps({\"error\": \"Failed to create profile\"}))\n    704: \n    705:     async def _update_profile(self, request: web_request.Request) -> web.Response:\n>>> 706:         \"\"\"Update learning profile.\"\"\"\n    707:         profile_id = request.match_info[\"profile_id\"]\n    708:         user_id = request.get(\"user\", {}).get(\"user_id\")\n    709: ",
    "context": {
      "query_preview": "Update learning profile."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 726,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    723:         except (ValueError, json.JSONDecodeError):\n    724:             raise web.HTTPBadRequest(text=json.dumps({\"error\": \"Invalid JSON\"}))\n    725:         except Exception as e:\n>>> 726:             logger.exception(f\"Failed to update profile {profile_id}: {e}\")\n    727:             raise web.HTTPInternalServerError(text=json.dumps({\"error\": \"Failed to update profile\"}))\n    728: \n    729:     async def _delete_profile(self, request: web_request.Request) -> web.Response:",
    "context": {
      "query_preview": "Failed to update profile "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 727,
    "column": 72,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    724:             raise web.HTTPBadRequest(text=json.dumps({\"error\": \"Invalid JSON\"}))\n    725:         except Exception as e:\n    726:             logger.exception(f\"Failed to update profile {profile_id}: {e}\")\n>>> 727:             raise web.HTTPInternalServerError(text=json.dumps({\"error\": \"Failed to update profile\"}))\n    728: \n    729:     async def _delete_profile(self, request: web_request.Request) -> web.Response:\n    730:         \"\"\"Delete learning profile.\"\"\"",
    "context": {
      "query_preview": "Failed to update profile"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 730,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    727:             raise web.HTTPInternalServerError(text=json.dumps({\"error\": \"Failed to update profile\"}))\n    728: \n    729:     async def _delete_profile(self, request: web_request.Request) -> web.Response:\n>>> 730:         \"\"\"Delete learning profile.\"\"\"\n    731:         profile_id = request.match_info[\"profile_id\"]\n    732:         user_id = request.get(\"user\", {}).get(\"user_id\")\n    733: ",
    "context": {
      "query_preview": "Delete learning profile."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 746,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    743: \n    744:             return web.json_response({\"profile_id\": profile_id, \"status\": \"deleted\", \"gdpr_compliant\": True})\n    745:         except Exception as e:\n>>> 746:             logger.exception(f\"Failed to delete profile {profile_id}: {e}\")\n    747:             raise web.HTTPInternalServerError(text=json.dumps({\"error\": \"Failed to delete profile\"}))\n    748: \n    749:     async def _export_profile_data(self, request: web_request.Request) -> web.Response:",
    "context": {
      "query_preview": "Failed to delete profile "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 747,
    "column": 72,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    744:             return web.json_response({\"profile_id\": profile_id, \"status\": \"deleted\", \"gdpr_compliant\": True})\n    745:         except Exception as e:\n    746:             logger.exception(f\"Failed to delete profile {profile_id}: {e}\")\n>>> 747:             raise web.HTTPInternalServerError(text=json.dumps({\"error\": \"Failed to delete profile\"}))\n    748: \n    749:     async def _export_profile_data(self, request: web_request.Request) -> web.Response:\n    750:         \"\"\"Export profile data for GDPR compliance.\"\"\"",
    "context": {
      "query_preview": "Failed to delete profile"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 800,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    797:         return web.json_response({\"message\": \"Document added\"}, status=201)\n    798: \n    799:     async def _get_document(self, request: web_request.Request) -> web.Response:\n>>> 800:         \"\"\"Get document from RAG index.\"\"\"\n    801:         doc_id = request.match_info[\"doc_id\"]\n    802:         return web.json_response({\"doc_id\": doc_id, \"content\": \"placeholder\"})\n    803: ",
    "context": {
      "query_preview": "Get document from RAG index."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 805,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    802:         return web.json_response({\"doc_id\": doc_id, \"content\": \"placeholder\"})\n    803: \n    804:     def _create_ssl_context(self) -> ssl.SSLContext:\n>>> 805:         \"\"\"Create SSL context for TLS 1.3.\"\"\"\n    806:         context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n    807: \n    808:         # TLS 1.3 configuration",
    "context": {
      "query_preview": "Create SSL context for TLS 1.3."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 827,
    "column": 4,
    "description": "Method '_generate_self_signed_cert' is too complex: 1 complexity, 57 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    824: \n    825:         return context\n    826: \n>>> 827:     def _generate_self_signed_cert(self) -> None:\n    828:         \"\"\"Generate self-signed certificate for development.\"\"\"\n    829:         # Create certificates directory\n    830:         cert_dir = Path(self.cert_file).parent",
    "context": {
      "complexity": 1,
      "lines": 57,
      "max_nesting": 0,
      "method_name": "_generate_self_signed_cert"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 110,
    "column": 4,
    "description": "Duplicate code block detected in function 'create_access_token'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    107:             msg = \"API_SECRET_KEY must be at least 32 characters long\"\n    108:             raise SecurityError(msg)\n    109: \n>>> 110:     def create_access_token(\n    111:         self,\n    112:         user_id: str,\n    113:         roles: list[str] | None = None,",
    "context": {
      "duplicate_count": 3,
      "function_name": "create_access_token",
      "signature": "ASSIGN|ASSIGN|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 130,
    "column": 4,
    "description": "Duplicate code block detected in function 'create_refresh_token'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    127: \n    128:         return jwt.encode(payload, self.secret_key, algorithm=self.algorithm)\n    129: \n>>> 130:     def create_refresh_token(self, user_id: str) -> str:\n    131:         \"\"\"Create JWT refresh token.\"\"\"\n    132:         now = datetime.utcnow()\n    133:         payload = {",
    "context": {
      "duplicate_count": 3,
      "function_name": "create_refresh_token",
      "signature": "ASSIGN|ASSIGN|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 161,
    "column": 4,
    "description": "Duplicate code block detected in function 'hash_password'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    158:             msg = f\"Invalid token: {e}\"\n    159:             raise AuthenticationError(msg)\n    160: \n>>> 161:     def hash_password(self, password: str) -> tuple[str, str]:\n    162:         \"\"\"Hash password with salt using PBKDF2.\"\"\"\n    163:         salt = os.urandom(32)\n    164:         password_hash = hashlib.pbkdf2_hmac(\"sha256\", password.encode(\"utf-8\"), salt, 100000)",
    "context": {
      "duplicate_count": 3,
      "function_name": "hash_password",
      "signature": "ASSIGN|ASSIGN|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'time' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "time",
      "method_count": 9,
      "methods": [
        "time",
        "perf_counter"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'os' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "os",
      "method_count": 10,
      "methods": [
        "getenv",
        "urandom"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'datetime' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "datetime",
      "method_count": 6,
      "methods": [
        "utcnow"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'rules' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "rules",
      "method_count": 9,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'web' methods (48 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "web",
      "method_count": 48,
      "methods": [
        "AppRunner",
        "HTTPNotFound",
        "HTTPBadRequest",
        "HTTPUnauthorized",
        "json_response",
        "TCPSite",
        "HTTPTooManyRequests",
        "Application",
        "HTTPInternalServerError"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'json' methods (30 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "json",
      "method_count": 30,
      "methods": [
        "dumps"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'request' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "request",
      "method_count": 10,
      "methods": [
        "get",
        "json"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 11,
      "methods": [
        "exception",
        "info",
        "warning"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'x509' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "x509",
      "method_count": 11,
      "methods": [
        "SubjectAlternativeName",
        "Name",
        "NameAttribute",
        "random_serial_number",
        "CertificateBuilder",
        "DNSName"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 57,
    "column": 43,
    "description": "Excessive magic literals detected (35 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     54: class RateLimiter:\n     55:     \"\"\"In-memory rate limiter with sliding window.\"\"\"\n     56: \n>>>  57:     def __init__(self, max_requests: int = 60, window_seconds: int = 60) -> None:\n     58:         self.max_requests = max_requests\n     59:         self.window_seconds = window_seconds\n     60:         self.requests = {}  # client_id -> list of timestamps",
    "context": {
      "total_magic_literals": 35,
      "current_value": 60
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 57,
    "column": 69,
    "description": "Excessive magic literals detected (35 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     54: class RateLimiter:\n     55:     \"\"\"In-memory rate limiter with sliding window.\"\"\"\n     56: \n>>>  57:     def __init__(self, max_requests: int = 60, window_seconds: int = 60) -> None:\n     58:         self.max_requests = max_requests\n     59:         self.window_seconds = window_seconds\n     60:         self.requests = {}  # client_id -> list of timestamps",
    "context": {
      "total_magic_literals": 35,
      "current_value": 60
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 101,
    "column": 93,
    "description": "Excessive magic literals detected (35 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     98:     \"\"\"JWT token authentication and management.\"\"\"\n     99: \n    100:     def __init__(self, secret_key: str | None = None) -> None:\n>>> 101:         self.secret_key = secret_key or os.getenv(\"API_SECRET_KEY\") or secrets.token_urlsafe(32)\n    102:         self.algorithm = \"HS256\"\n    103:         self.token_expiry_hours = int(os.getenv(\"API_JWT_EXPIRY_HOURS\", \"24\"))\n    104:         self.refresh_expiry_days = int(os.getenv(\"API_REFRESH_TOKEN_EXPIRY_DAYS\", \"30\"))",
    "context": {
      "total_magic_literals": 35,
      "current_value": 32
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 106,
    "column": 34,
    "description": "Excessive magic literals detected (35 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    103:         self.token_expiry_hours = int(os.getenv(\"API_JWT_EXPIRY_HOURS\", \"24\"))\n    104:         self.refresh_expiry_days = int(os.getenv(\"API_REFRESH_TOKEN_EXPIRY_DAYS\", \"30\"))\n    105: \n>>> 106:         if len(self.secret_key) < 32:\n    107:             msg = \"API_SECRET_KEY must be at least 32 characters long\"\n    108:             raise SecurityError(msg)\n    109: ",
    "context": {
      "total_magic_literals": 35,
      "current_value": 32
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_api_server.py",
    "line_number": 125,
    "column": 41,
    "description": "Excessive magic literals detected (35 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    122:             \"iat\": now,\n    123:             \"exp\": now + timedelta(hours=self.token_expiry_hours),\n    124:             \"type\": \"access_token\",\n>>> 125:             \"jti\": secrets.token_urlsafe(16),  # JWT ID for revocation\n    126:         }\n    127: \n    128:         return jwt.encode(payload, self.secret_key, algorithm=self.algorithm)",
    "context": {
      "total_magic_literals": 35,
      "current_value": 16
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 22,
    "column": 0,
    "description": "Class 'SecureDigitalTwinDB' is a God Object: 13 methods, ~810 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "     19: logger = logging.getLogger(__name__)\n     20: \n     21: \n>>>  22: class SecureDigitalTwinDB:\n     23:     \"\"\"Secure database operations for Digital Twin with encryption and compliance.\"\"\"\n     24: \n     25:     def __init__(self, db_path: str | None = None) -> None:",
    "context": {
      "method_count": 13,
      "estimated_lines": 810,
      "class_name": "SecureDigitalTwinDB",
      "data_methods": 4,
      "business_methods": 9
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 57,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     54:         try:\n     55:             # Configure SQLite for security and performance\n     56:             if self.enable_wal:\n>>>  57:                 conn.execute(\"PRAGMA journal_mode=WAL\")\n     58: \n     59:             conn.execute(\"PRAGMA synchronous=NORMAL\")\n     60:             conn.execute(\"PRAGMA cache_size=10000\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 59,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     56:             if self.enable_wal:\n     57:                 conn.execute(\"PRAGMA journal_mode=WAL\")\n     58: \n>>>  59:             conn.execute(\"PRAGMA synchronous=NORMAL\")\n     60:             conn.execute(\"PRAGMA cache_size=10000\")\n     61:             conn.execute(\"PRAGMA temp_store=MEMORY\")\n     62:             conn.execute(\"PRAGMA mmap_size=268435456\")  # 256MB",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 60,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     57:                 conn.execute(\"PRAGMA journal_mode=WAL\")\n     58: \n     59:             conn.execute(\"PRAGMA synchronous=NORMAL\")\n>>>  60:             conn.execute(\"PRAGMA cache_size=10000\")\n     61:             conn.execute(\"PRAGMA temp_store=MEMORY\")\n     62:             conn.execute(\"PRAGMA mmap_size=268435456\")  # 256MB\n     63: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 61,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     58: \n     59:             conn.execute(\"PRAGMA synchronous=NORMAL\")\n     60:             conn.execute(\"PRAGMA cache_size=10000\")\n>>>  61:             conn.execute(\"PRAGMA temp_store=MEMORY\")\n     62:             conn.execute(\"PRAGMA mmap_size=268435456\")  # 256MB\n     63: \n     64:             # Enable foreign key constraints",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 62,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     59:             conn.execute(\"PRAGMA synchronous=NORMAL\")\n     60:             conn.execute(\"PRAGMA cache_size=10000\")\n     61:             conn.execute(\"PRAGMA temp_store=MEMORY\")\n>>>  62:             conn.execute(\"PRAGMA mmap_size=268435456\")  # 256MB\n     63: \n     64:             # Enable foreign key constraints\n     65:             conn.execute(\"PRAGMA foreign_keys=ON\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 65,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     62:             conn.execute(\"PRAGMA mmap_size=268435456\")  # 256MB\n     63: \n     64:             # Enable foreign key constraints\n>>>  65:             conn.execute(\"PRAGMA foreign_keys=ON\")\n     66: \n     67:             conn.row_factory = sqlite3.Row\n     68:             yield conn",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 73,
    "column": 4,
    "description": "Method 'init_database' is too complex: 2 complexity, 181 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     70:         finally:\n     71:             conn.close()\n     72: \n>>>  73:     def init_database(self) -> None:\n     74:         \"\"\"Initialize database schema with encryption and compliance features.\"\"\"\n     75:         with self.get_connection() as conn:\n     76:             # Learning profiles with encrypted sensitive data",
    "context": {
      "complexity": 2,
      "lines": 181,
      "max_nesting": 1,
      "method_name": "init_database"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 77,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     74:         \"\"\"Initialize database schema with encryption and compliance features.\"\"\"\n     75:         with self.get_connection() as conn:\n     76:             # Learning profiles with encrypted sensitive data\n>>>  77:             conn.execute(\n     78:                 \"\"\"\n     79:                 CREATE TABLE IF NOT EXISTS learning_profiles (\n     80:                     id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 78,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     75:         with self.get_connection() as conn:\n     76:             # Learning profiles with encrypted sensitive data\n     77:             conn.execute(\n>>>  78:                 \"\"\"\n     79:                 CREATE TABLE IF NOT EXISTS learning_profiles (\n     80:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n     81:                     profile_id TEXT UNIQUE NOT NULL,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS learning_profiles (\n                    id INTEGER PRIMA..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 111,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    108:             )\n    109: \n    110:             # Learning sessions with privacy protection\n>>> 111:             conn.execute(\n    112:                 \"\"\"\n    113:                 CREATE TABLE IF NOT EXISTS learning_sessions (\n    114:                     id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 112,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    109: \n    110:             # Learning sessions with privacy protection\n    111:             conn.execute(\n>>> 112:                 \"\"\"\n    113:                 CREATE TABLE IF NOT EXISTS learning_sessions (\n    114:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    115:                     session_id TEXT UNIQUE NOT NULL,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS learning_sessions (\n                    id INTEGER PRIMA..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 148,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    145:             )\n    146: \n    147:             # Knowledge states with domain protection\n>>> 148:             conn.execute(\n    149:                 \"\"\"\n    150:                 CREATE TABLE IF NOT EXISTS knowledge_states (\n    151:                     id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 149,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    146: \n    147:             # Knowledge states with domain protection\n    148:             conn.execute(\n>>> 149:                 \"\"\"\n    150:                 CREATE TABLE IF NOT EXISTS knowledge_states (\n    151:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    152:                     profile_id TEXT NOT NULL,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS knowledge_states (\n                    id INTEGER PRIMAR..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 177,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    174:             )\n    175: \n    176:             # Compliance audit log\n>>> 177:             conn.execute(\n    178:                 \"\"\"\n    179:                 CREATE TABLE IF NOT EXISTS compliance_audit_log (\n    180:                     id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 178,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    175: \n    176:             # Compliance audit log\n    177:             conn.execute(\n>>> 178:                 \"\"\"\n    179:                 CREATE TABLE IF NOT EXISTS compliance_audit_log (\n    180:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    181:                     timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS compliance_audit_log (\n                    id INTEGER PR..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 209,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    206:             )\n    207: \n    208:             # Data retention tracking\n>>> 209:             conn.execute(\n    210:                 \"\"\"\n    211:                 CREATE TABLE IF NOT EXISTS data_retention_tracking (\n    212:                     id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 210,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    207: \n    208:             # Data retention tracking\n    209:             conn.execute(\n>>> 210:                 \"\"\"\n    211:                 CREATE TABLE IF NOT EXISTS data_retention_tracking (\n    212:                     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    213:                     profile_id TEXT NOT NULL,",
    "context": {
      "query_preview": "\n                CREATE TABLE IF NOT EXISTS data_retention_tracking (\n                    id INTEGER..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 238,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    235: \n    236:             # Create indexes for performance\n    237:             indexes = [\n>>> 238:                 \"CREATE INDEX IF NOT EXISTS idx_profiles_user_hash ON learning_profiles (user_id_hash)\",\n    239:                 \"CREATE INDEX IF NOT EXISTS idx_profiles_expires ON learning_profiles (ttl_expires_at)\",\n    240:                 \"CREATE INDEX IF NOT EXISTS idx_profiles_updated ON learning_profiles (updated_at)\",\n    241:                 \"CREATE INDEX IF NOT EXISTS idx_sessions_profile ON learning_sessions (profile_id)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_profiles_user_hash ON learning_profiles (user_id_hash)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 239,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    236:             # Create indexes for performance\n    237:             indexes = [\n    238:                 \"CREATE INDEX IF NOT EXISTS idx_profiles_user_hash ON learning_profiles (user_id_hash)\",\n>>> 239:                 \"CREATE INDEX IF NOT EXISTS idx_profiles_expires ON learning_profiles (ttl_expires_at)\",\n    240:                 \"CREATE INDEX IF NOT EXISTS idx_profiles_updated ON learning_profiles (updated_at)\",\n    241:                 \"CREATE INDEX IF NOT EXISTS idx_sessions_profile ON learning_sessions (profile_id)\",\n    242:                 \"CREATE INDEX IF NOT EXISTS idx_sessions_start ON learning_sessions (start_time)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_profiles_expires ON learning_profiles (ttl_expires_at)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 240,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    237:             indexes = [\n    238:                 \"CREATE INDEX IF NOT EXISTS idx_profiles_user_hash ON learning_profiles (user_id_hash)\",\n    239:                 \"CREATE INDEX IF NOT EXISTS idx_profiles_expires ON learning_profiles (ttl_expires_at)\",\n>>> 240:                 \"CREATE INDEX IF NOT EXISTS idx_profiles_updated ON learning_profiles (updated_at)\",\n    241:                 \"CREATE INDEX IF NOT EXISTS idx_sessions_profile ON learning_sessions (profile_id)\",\n    242:                 \"CREATE INDEX IF NOT EXISTS idx_sessions_start ON learning_sessions (start_time)\",\n    243:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_profile ON knowledge_states (profile_id)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_profiles_updated ON learning_profiles (updated_at)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 241,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    238:                 \"CREATE INDEX IF NOT EXISTS idx_profiles_user_hash ON learning_profiles (user_id_hash)\",\n    239:                 \"CREATE INDEX IF NOT EXISTS idx_profiles_expires ON learning_profiles (ttl_expires_at)\",\n    240:                 \"CREATE INDEX IF NOT EXISTS idx_profiles_updated ON learning_profiles (updated_at)\",\n>>> 241:                 \"CREATE INDEX IF NOT EXISTS idx_sessions_profile ON learning_sessions (profile_id)\",\n    242:                 \"CREATE INDEX IF NOT EXISTS idx_sessions_start ON learning_sessions (start_time)\",\n    243:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_profile ON knowledge_states (profile_id)\",\n    244:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_domain ON knowledge_states (knowledge_domain)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_sessions_profile ON learning_sessions (profile_id)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 242,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    239:                 \"CREATE INDEX IF NOT EXISTS idx_profiles_expires ON learning_profiles (ttl_expires_at)\",\n    240:                 \"CREATE INDEX IF NOT EXISTS idx_profiles_updated ON learning_profiles (updated_at)\",\n    241:                 \"CREATE INDEX IF NOT EXISTS idx_sessions_profile ON learning_sessions (profile_id)\",\n>>> 242:                 \"CREATE INDEX IF NOT EXISTS idx_sessions_start ON learning_sessions (start_time)\",\n    243:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_profile ON knowledge_states (profile_id)\",\n    244:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_domain ON knowledge_states (knowledge_domain)\",\n    245:                 \"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON compliance_audit_log (timestamp)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_sessions_start ON learning_sessions (start_time)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 243,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    240:                 \"CREATE INDEX IF NOT EXISTS idx_profiles_updated ON learning_profiles (updated_at)\",\n    241:                 \"CREATE INDEX IF NOT EXISTS idx_sessions_profile ON learning_sessions (profile_id)\",\n    242:                 \"CREATE INDEX IF NOT EXISTS idx_sessions_start ON learning_sessions (start_time)\",\n>>> 243:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_profile ON knowledge_states (profile_id)\",\n    244:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_domain ON knowledge_states (knowledge_domain)\",\n    245:                 \"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON compliance_audit_log (timestamp)\",\n    246:                 \"CREATE INDEX IF NOT EXISTS idx_audit_profile ON compliance_audit_log (profile_id)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_knowledge_profile ON knowledge_states (profile_id)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 244,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    241:                 \"CREATE INDEX IF NOT EXISTS idx_sessions_profile ON learning_sessions (profile_id)\",\n    242:                 \"CREATE INDEX IF NOT EXISTS idx_sessions_start ON learning_sessions (start_time)\",\n    243:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_profile ON knowledge_states (profile_id)\",\n>>> 244:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_domain ON knowledge_states (knowledge_domain)\",\n    245:                 \"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON compliance_audit_log (timestamp)\",\n    246:                 \"CREATE INDEX IF NOT EXISTS idx_audit_profile ON compliance_audit_log (profile_id)\",\n    247:                 \"CREATE INDEX IF NOT EXISTS idx_retention_scheduled ON data_retention_tracking (scheduled_deletion_at)\",",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_knowledge_domain ON knowledge_states (knowledge_domain)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 245,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    242:                 \"CREATE INDEX IF NOT EXISTS idx_sessions_start ON learning_sessions (start_time)\",\n    243:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_profile ON knowledge_states (profile_id)\",\n    244:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_domain ON knowledge_states (knowledge_domain)\",\n>>> 245:                 \"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON compliance_audit_log (timestamp)\",\n    246:                 \"CREATE INDEX IF NOT EXISTS idx_audit_profile ON compliance_audit_log (profile_id)\",\n    247:                 \"CREATE INDEX IF NOT EXISTS idx_retention_scheduled ON data_retention_tracking (scheduled_deletion_at)\",\n    248:             ]",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON compliance_audit_log (timestamp)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 246,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    243:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_profile ON knowledge_states (profile_id)\",\n    244:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_domain ON knowledge_states (knowledge_domain)\",\n    245:                 \"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON compliance_audit_log (timestamp)\",\n>>> 246:                 \"CREATE INDEX IF NOT EXISTS idx_audit_profile ON compliance_audit_log (profile_id)\",\n    247:                 \"CREATE INDEX IF NOT EXISTS idx_retention_scheduled ON data_retention_tracking (scheduled_deletion_at)\",\n    248:             ]\n    249: ",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_audit_profile ON compliance_audit_log (profile_id)"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 247,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    244:                 \"CREATE INDEX IF NOT EXISTS idx_knowledge_domain ON knowledge_states (knowledge_domain)\",\n    245:                 \"CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON compliance_audit_log (timestamp)\",\n    246:                 \"CREATE INDEX IF NOT EXISTS idx_audit_profile ON compliance_audit_log (profile_id)\",\n>>> 247:                 \"CREATE INDEX IF NOT EXISTS idx_retention_scheduled ON data_retention_tracking (scheduled_deletion_at)\",\n    248:             ]\n    249: \n    250:             for index_sql in indexes:",
    "context": {
      "query_preview": "CREATE INDEX IF NOT EXISTS idx_retention_scheduled ON data_retention_tracking (scheduled_deletion_at..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 251,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    248:             ]\n    249: \n    250:             for index_sql in indexes:\n>>> 251:                 conn.execute(index_sql)\n    252: \n    253:             conn.execute(\"COMMIT\")\n    254:             logger.info(\"Database schema initialized successfully\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 253,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    250:             for index_sql in indexes:\n    251:                 conn.execute(index_sql)\n    252: \n>>> 253:             conn.execute(\"COMMIT\")\n    254:             logger.info(\"Database schema initialized successfully\")\n    255: \n    256:     def create_learning_profile(self, profile_data: dict[str, Any]) -> str:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 256,
    "column": 4,
    "description": "Method 'create_learning_profile' is too complex: 4 complexity, 100 lines, 2 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    253:             conn.execute(\"COMMIT\")\n    254:             logger.info(\"Database schema initialized successfully\")\n    255: \n>>> 256:     def create_learning_profile(self, profile_data: dict[str, Any]) -> str:\n    257:         \"\"\"Create new learning profile with encryption.\n    258: \n    259:         Args:",
    "context": {
      "complexity": 4,
      "lines": 100,
      "max_nesting": 2,
      "method_name": "create_learning_profile"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 257,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    254:             logger.info(\"Database schema initialized successfully\")\n    255: \n    256:     def create_learning_profile(self, profile_data: dict[str, Any]) -> str:\n>>> 257:         \"\"\"Create new learning profile with encryption.\n    258: \n    259:         Args:\n    260:             profile_data: Profile data including sensitive fields",
    "context": {
      "query_preview": "Create new learning profile with encryption.\n\n        Args:\n            profile_data: Profile data i..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 301,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    298:                     )\n    299: \n    300:             # Insert profile\n>>> 301:             conn.execute(\n    302:                 \"\"\"\n    303:                 INSERT INTO learning_profiles (\n    304:                     profile_id, user_id_hash, preferred_difficulty,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 302,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    299: \n    300:             # Insert profile\n    301:             conn.execute(\n>>> 302:                 \"\"\"\n    303:                 INSERT INTO learning_profiles (\n    304:                     profile_id, user_id_hash, preferred_difficulty,\n    305:                     learning_style_encrypted, knowledge_domains_encrypted,",
    "context": {
      "query_preview": "\n                INSERT INTO learning_profiles (\n                    profile_id, user_id_hash, prefe..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 324,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    321:             )\n    322: \n    323:             # Create retention tracking record\n>>> 324:             conn.execute(\n    325:                 \"\"\"\n    326:                 INSERT INTO data_retention_tracking (\n    327:                     profile_id, created_at, scheduled_deletion_at, retention_policy",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 325,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    322: \n    323:             # Create retention tracking record\n    324:             conn.execute(\n>>> 325:                 \"\"\"\n    326:                 INSERT INTO data_retention_tracking (\n    327:                     profile_id, created_at, scheduled_deletion_at, retention_policy\n    328:                 ) VALUES (?, ?, ?, ?)",
    "context": {
      "query_preview": "\n                INSERT INTO data_retention_tracking (\n                    profile_id, created_at, s..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 354,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    351:                 ),\n    352:             )\n    353: \n>>> 354:             conn.execute(\"COMMIT\")\n    355:             logger.info(f\"Created encrypted learning profile: {profile_id}\")\n    356:             return profile_id\n    357: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 355,
    "column": 26,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    352:             )\n    353: \n    354:             conn.execute(\"COMMIT\")\n>>> 355:             logger.info(f\"Created encrypted learning profile: {profile_id}\")\n    356:             return profile_id\n    357: \n    358:     def get_learning_profile(self, profile_id: str, decrypt: bool = True) -> dict[str, Any] | None:",
    "context": {
      "query_preview": "Created encrypted learning profile: "
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 358,
    "column": 4,
    "description": "Method 'get_learning_profile' is too complex: 7 complexity, 74 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    355:             logger.info(f\"Created encrypted learning profile: {profile_id}\")\n    356:             return profile_id\n    357: \n>>> 358:     def get_learning_profile(self, profile_id: str, decrypt: bool = True) -> dict[str, Any] | None:\n    359:         \"\"\"Retrieve learning profile with optional decryption.\n    360: \n    361:         Args:",
    "context": {
      "complexity": 7,
      "lines": 74,
      "max_nesting": 5,
      "method_name": "get_learning_profile"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 369,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    366:             Profile data or None if not found\n    367:         \"\"\"\n    368:         with self.get_connection() as conn:\n>>> 369:             cursor = conn.execute(\n    370:                 \"\"\"\n    371:                 SELECT * FROM learning_profiles WHERE profile_id = ?\n    372:             \"\"\",",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 370,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    367:         \"\"\"\n    368:         with self.get_connection() as conn:\n    369:             cursor = conn.execute(\n>>> 370:                 \"\"\"\n    371:                 SELECT * FROM learning_profiles WHERE profile_id = ?\n    372:             \"\"\",\n    373:                 (profile_id,),",
    "context": {
      "query_preview": "\n                SELECT * FROM learning_profiles WHERE profile_id = ?\n            "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 383,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    380:             profile = dict(row)\n    381: \n    382:             # Update access tracking\n>>> 383:             conn.execute(\n    384:                 \"\"\"\n    385:                 UPDATE learning_profiles\n    386:                 SET last_accessed = CURRENT_TIMESTAMP, access_count = access_count + 1",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 384,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    381: \n    382:             # Update access tracking\n    383:             conn.execute(\n>>> 384:                 \"\"\"\n    385:                 UPDATE learning_profiles\n    386:                 SET last_accessed = CURRENT_TIMESTAMP, access_count = access_count + 1\n    387:                 WHERE profile_id = ?",
    "context": {
      "query_preview": "\n                UPDATE learning_profiles\n                SET last_accessed = CURRENT_TIMESTAMP, acc..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 431,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    428:                 compliance_type=\"GENERAL\",\n    429:             )\n    430: \n>>> 431:             conn.execute(\"COMMIT\")\n    432:             return profile\n    433: \n    434:     def update_learning_profile(self, profile_id: str, updates: dict[str, Any]) -> bool:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 434,
    "column": 4,
    "description": "Method 'update_learning_profile' is too complex: 7 complexity, 75 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    431:             conn.execute(\"COMMIT\")\n    432:             return profile\n    433: \n>>> 434:     def update_learning_profile(self, profile_id: str, updates: dict[str, Any]) -> bool:\n    435:         \"\"\"Update learning profile with encryption.\n    436: \n    437:         Args:",
    "context": {
      "complexity": 7,
      "lines": 75,
      "max_nesting": 6,
      "method_name": "update_learning_profile"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 435,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    432:             return profile\n    433: \n    434:     def update_learning_profile(self, profile_id: str, updates: dict[str, Any]) -> bool:\n>>> 435:         \"\"\"Update learning profile with encryption.\n    436: \n    437:         Args:\n    438:             profile_id: Profile to update",
    "context": {
      "query_preview": "Update learning profile with encryption.\n\n        Args:\n            profile_id: Profile to update\n  ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 479,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    476:                 return True  # Nothing to update\n    477: \n    478:             # Add updated timestamp\n>>> 479:             set_clauses.append(\"updated_at = CURRENT_TIMESTAMP\")\n    480:             values.append(profile_id)\n    481: \n    482:             # Execute update",
    "context": {
      "query_preview": "updated_at = CURRENT_TIMESTAMP"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 483,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    480:             values.append(profile_id)\n    481: \n    482:             # Execute update\n>>> 483:             conn.execute(\n    484:                 f\"\"\"\n    485:                 UPDATE learning_profiles\n    486:                 SET {\", \".join(set_clauses)}",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 484,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    481: \n    482:             # Execute update\n    483:             conn.execute(\n>>> 484:                 f\"\"\"\n    485:                 UPDATE learning_profiles\n    486:                 SET {\", \".join(set_clauses)}\n    487:                 WHERE profile_id = ?",
    "context": {
      "query_preview": "\n                UPDATE learning_profiles\n                SET "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 486,
    "column": 44,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    483:             conn.execute(\n    484:                 f\"\"\"\n    485:                 UPDATE learning_profiles\n>>> 486:                 SET {\", \".join(set_clauses)}\n    487:                 WHERE profile_id = ?\n    488:             \"\"\",\n    489:                 values,",
    "context": {
      "query_preview": "\n                WHERE profile_id = ?\n            "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 507,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    504:                 ),\n    505:             )\n    506: \n>>> 507:             conn.execute(\"COMMIT\")\n    508:             logger.info(f\"Updated encrypted learning profile: {profile_id}\")\n    509:             return True\n    510: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 508,
    "column": 26,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    505:             )\n    506: \n    507:             conn.execute(\"COMMIT\")\n>>> 508:             logger.info(f\"Updated encrypted learning profile: {profile_id}\")\n    509:             return True\n    510: \n    511:     def delete_learning_profile(self, profile_id: str, reason: str = \"user_request\") -> bool:",
    "context": {
      "query_preview": "Updated encrypted learning profile: "
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 511,
    "column": 4,
    "description": "Method 'delete_learning_profile' is too complex: 2 complexity, 53 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    508:             logger.info(f\"Updated encrypted learning profile: {profile_id}\")\n    509:             return True\n    510: \n>>> 511:     def delete_learning_profile(self, profile_id: str, reason: str = \"user_request\") -> bool:\n    512:         \"\"\"Delete learning profile with GDPR compliance.\n    513: \n    514:         Args:",
    "context": {
      "complexity": 2,
      "lines": 53,
      "max_nesting": 1,
      "method_name": "delete_learning_profile"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 512,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    509:             return True\n    510: \n    511:     def delete_learning_profile(self, profile_id: str, reason: str = \"user_request\") -> bool:\n>>> 512:         \"\"\"Delete learning profile with GDPR compliance.\n    513: \n    514:         Args:\n    515:             profile_id: Profile to delete",
    "context": {
      "query_preview": "Delete learning profile with GDPR compliance.\n\n        Args:\n            profile_id: Profile to dele..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 523,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    520:         \"\"\"\n    521:         with self.get_connection() as conn:\n    522:             # Get profile for audit logging\n>>> 523:             cursor = conn.execute(\n    524:                 \"\"\"\n    525:                 SELECT user_id_hash FROM learning_profiles WHERE profile_id = ?\n    526:             \"\"\",",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 524,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    521:         with self.get_connection() as conn:\n    522:             # Get profile for audit logging\n    523:             cursor = conn.execute(\n>>> 524:                 \"\"\"\n    525:                 SELECT user_id_hash FROM learning_profiles WHERE profile_id = ?\n    526:             \"\"\",\n    527:                 (profile_id,),",
    "context": {
      "query_preview": "\n                SELECT user_id_hash FROM learning_profiles WHERE profile_id = ?\n            "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 536,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    533:             user_id_hash = row[0]\n    534: \n    535:             # Delete profile (cascades to sessions and knowledge states)\n>>> 536:             conn.execute(\"DELETE FROM learning_profiles WHERE profile_id = ?\", (profile_id,))\n    537: \n    538:             # Update retention tracking\n    539:             conn.execute(",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 536,
    "column": 25,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    533:             user_id_hash = row[0]\n    534: \n    535:             # Delete profile (cascades to sessions and knowledge states)\n>>> 536:             conn.execute(\"DELETE FROM learning_profiles WHERE profile_id = ?\", (profile_id,))\n    537: \n    538:             # Update retention tracking\n    539:             conn.execute(",
    "context": {
      "query_preview": "DELETE FROM learning_profiles WHERE profile_id = ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 539,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    536:             conn.execute(\"DELETE FROM learning_profiles WHERE profile_id = ?\", (profile_id,))\n    537: \n    538:             # Update retention tracking\n>>> 539:             conn.execute(\n    540:                 \"\"\"\n    541:                 DELETE FROM data_retention_tracking WHERE profile_id = ?\n    542:             \"\"\",",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 540,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    537: \n    538:             # Update retention tracking\n    539:             conn.execute(\n>>> 540:                 \"\"\"\n    541:                 DELETE FROM data_retention_tracking WHERE profile_id = ?\n    542:             \"\"\",\n    543:                 (profile_id,),",
    "context": {
      "query_preview": "\n                DELETE FROM data_retention_tracking WHERE profile_id = ?\n            "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 562,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    559:                 ),\n    560:             )\n    561: \n>>> 562:             conn.execute(\"COMMIT\")\n    563:             logger.info(f\"Deleted learning profile with GDPR compliance: {profile_id}\")\n    564:             return True\n    565: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 563,
    "column": 26,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    560:             )\n    561: \n    562:             conn.execute(\"COMMIT\")\n>>> 563:             logger.info(f\"Deleted learning profile with GDPR compliance: {profile_id}\")\n    564:             return True\n    565: \n    566:     def _check_compliance_access(self, profile: dict[str, Any]) -> dict[str, Any]:",
    "context": {
      "query_preview": "Deleted learning profile with GDPR compliance: "
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 606,
    "column": 4,
    "description": "Function '_log_compliance_audit' has 8 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    603: \n    604:         return {\"access_allowed\": True, \"reason\": \"Compliance checks passed\"}\n    605: \n>>> 606:     def _log_compliance_audit(\n    607:         self,\n    608:         conn,\n    609:         action: str,",
    "context": {
      "parameter_count": 8,
      "function_name": "_log_compliance_audit"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 627,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    624:             compliance_type: Type of compliance\n    625:             additional_data: Extra context as JSON\n    626:         \"\"\"\n>>> 627:         conn.execute(\n    628:             \"\"\"\n    629:             INSERT INTO compliance_audit_log (\n    630:                 action, profile_id, user_id_hash, field_name,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 628,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    625:             additional_data: Extra context as JSON\n    626:         \"\"\"\n    627:         conn.execute(\n>>> 628:             \"\"\"\n    629:             INSERT INTO compliance_audit_log (\n    630:                 action, profile_id, user_id_hash, field_name,\n    631:                 compliance_type, compliance_status, session_id, additional_data",
    "context": {
      "query_preview": "\n            INSERT INTO compliance_audit_log (\n                action, profile_id, user_id_hash, fi..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 653,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    650:             List of expired profiles requiring deletion\n    651:         \"\"\"\n    652:         with self.get_connection() as conn:\n>>> 653:             cursor = conn.execute(\n    654:                 \"\"\"\n    655:                 SELECT profile_id, user_id_hash, ttl_expires_at, compliance_flags\n    656:                 FROM learning_profiles",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 654,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    651:         \"\"\"\n    652:         with self.get_connection() as conn:\n    653:             cursor = conn.execute(\n>>> 654:                 \"\"\"\n    655:                 SELECT profile_id, user_id_hash, ttl_expires_at, compliance_flags\n    656:                 FROM learning_profiles\n    657:                 WHERE ttl_expires_at < CURRENT_TIMESTAMP",
    "context": {
      "query_preview": "\n                SELECT profile_id, user_id_hash, ttl_expires_at, compliance_flags\n                F..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 677,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    674:             return expired\n    675: \n    676:     def cleanup_expired_data(self) -> int:\n>>> 677:         \"\"\"Clean up expired profiles per retention policy.\n    678: \n    679:         Returns:\n    680:             Number of profiles deleted",
    "context": {
      "query_preview": "Clean up expired profiles per retention policy.\n\n        Returns:\n            Number of profiles del..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 693,
    "column": 4,
    "description": "Method 'export_user_data' is too complex: 5 complexity, 80 lines, 4 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    690:         logger.info(f\"Cleaned up {deleted_count} expired profiles\")\n    691:         return deleted_count\n    692: \n>>> 693:     def export_user_data(self, user_id_hash: str) -> dict[str, Any]:\n    694:         \"\"\"Export all user data for GDPR compliance.\n    695: \n    696:         Args:",
    "context": {
      "complexity": 5,
      "lines": 80,
      "max_nesting": 4,
      "method_name": "export_user_data"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 704,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    701:         \"\"\"\n    702:         with self.get_connection() as conn:\n    703:             # Get all profiles for user\n>>> 704:             cursor = conn.execute(\n    705:                 \"\"\"\n    706:                 SELECT * FROM learning_profiles WHERE user_id_hash = ?\n    707:             \"\"\",",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 705,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    702:         with self.get_connection() as conn:\n    703:             # Get all profiles for user\n    704:             cursor = conn.execute(\n>>> 705:                 \"\"\"\n    706:                 SELECT * FROM learning_profiles WHERE user_id_hash = ?\n    707:             \"\"\",\n    708:                 (user_id_hash,),",
    "context": {
      "query_preview": "\n                SELECT * FROM learning_profiles WHERE user_id_hash = ?\n            "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 720,
    "column": 33,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    717:             # Get all sessions\n    718:             sessions = []\n    719:             for profile in profiles:\n>>> 720:                 session_cursor = conn.execute(\n    721:                     \"\"\"\n    722:                     SELECT * FROM learning_sessions WHERE profile_id = ?\n    723:                 \"\"\",",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 721,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    718:             sessions = []\n    719:             for profile in profiles:\n    720:                 session_cursor = conn.execute(\n>>> 721:                     \"\"\"\n    722:                     SELECT * FROM learning_sessions WHERE profile_id = ?\n    723:                 \"\"\",\n    724:                     (profile[\"profile_id\"],),",
    "context": {
      "query_preview": "\n                    SELECT * FROM learning_sessions WHERE profile_id = ?\n                "
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 731,
    "column": 27,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    728:                     sessions.append(dict(session_row))\n    729: \n    730:             # Get audit log\n>>> 731:             audit_cursor = conn.execute(\n    732:                 \"\"\"\n    733:                 SELECT * FROM compliance_audit_log\n    734:                 WHERE user_id_hash = ?",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 732,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    729: \n    730:             # Get audit log\n    731:             audit_cursor = conn.execute(\n>>> 732:                 \"\"\"\n    733:                 SELECT * FROM compliance_audit_log\n    734:                 WHERE user_id_hash = ?\n    735:                 ORDER BY timestamp DESC",
    "context": {
      "query_preview": "\n                SELECT * FROM compliance_audit_log\n                WHERE user_id_hash = ?\n         ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 772,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    769:                 ),\n    770:             )\n    771: \n>>> 772:             conn.execute(\"COMMIT\")\n    773:             return export_data\n    774: \n    775:     def get_compliance_stats(self) -> dict[str, Any]:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 775,
    "column": 4,
    "description": "Method 'get_compliance_stats' is too complex: 1 complexity, 57 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    772:             conn.execute(\"COMMIT\")\n    773:             return export_data\n    774: \n>>> 775:     def get_compliance_stats(self) -> dict[str, Any]:\n    776:         \"\"\"Get compliance and security statistics.\n    777: \n    778:         Returns:",
    "context": {
      "complexity": 1,
      "lines": 57,
      "max_nesting": 0,
      "method_name": "get_compliance_stats"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 785,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    782:             stats = {}\n    783: \n    784:             # Profile statistics\n>>> 785:             cursor = conn.execute(\n    786:                 \"\"\"\n    787:                 SELECT\n    788:                     COUNT(*) as total_profiles,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 786,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    783: \n    784:             # Profile statistics\n    785:             cursor = conn.execute(\n>>> 786:                 \"\"\"\n    787:                 SELECT\n    788:                     COUNT(*) as total_profiles,\n    789:                     COUNT(CASE WHEN ttl_expires_at > CURRENT_TIMESTAMP THEN 1 END) as active_profiles,",
    "context": {
      "query_preview": "\n                SELECT\n                    COUNT(*) as total_profiles,\n                    COUNT(CA..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 799,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    796:             stats[\"profiles\"] = profile_stats\n    797: \n    798:             # Compliance audit statistics\n>>> 799:             cursor = conn.execute(\n    800:                 \"\"\"\n    801:                 SELECT\n    802:                     compliance_type,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 800,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    797: \n    798:             # Compliance audit statistics\n    799:             cursor = conn.execute(\n>>> 800:                 \"\"\"\n    801:                 SELECT\n    802:                     compliance_type,\n    803:                     COUNT(*) as audit_entries,",
    "context": {
      "query_preview": "\n                SELECT\n                    compliance_type,\n                    COUNT(*) as audit_e..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 824,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    821:             }\n    822: \n    823:             # Database health\n>>> 824:             cursor = conn.execute(\"PRAGMA integrity_check\")\n    825:             integrity_result = cursor.fetchone()[0]\n    826:             stats[\"database_health\"] = {\n    827:                 \"integrity_check\": integrity_result,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (19 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 19,
      "methods": [
        "_check_compliance_access",
        "init_database",
        "get_connection",
        "get_expired_profiles",
        "delete_learning_profile",
        "get_learning_profile",
        "_log_compliance_audit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 7,
      "methods": [
        "info",
        "exception"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'conn' methods (35 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "conn",
      "method_count": 35,
      "methods": [
        "close",
        "execute"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'json' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "json",
      "method_count": 8,
      "methods": [
        "dumps",
        "loads"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 25,
    "column": 4,
    "description": "Sequential coupling detected: Function '__init__' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     22: class SecureDigitalTwinDB:\n     23:     \"\"\"Secure database operations for Digital Twin with encryption and compliance.\"\"\"\n     24: \n>>>  25:     def __init__(self, db_path: str | None = None) -> None:\n     26:         \"\"\"Initialize secure Digital Twin database.\n     27: \n     28:         Args:",
    "context": {
      "function_name": "__init__",
      "sequential_functions": [
        "__init__",
        "init_database",
        "cleanup_expired_data"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 73,
    "column": 4,
    "description": "Sequential coupling detected: Function 'init_database' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     70:         finally:\n     71:             conn.close()\n     72: \n>>>  73:     def init_database(self) -> None:\n     74:         \"\"\"Initialize database schema with encryption and compliance features.\"\"\"\n     75:         with self.get_connection() as conn:\n     76:             # Learning profiles with encrypted sensitive data",
    "context": {
      "function_name": "init_database",
      "sequential_functions": [
        "__init__",
        "init_database",
        "cleanup_expired_data"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_digital_twin_db.py",
    "line_number": 676,
    "column": 4,
    "description": "Sequential coupling detected: Function 'cleanup_expired_data' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    673: \n    674:             return expired\n    675: \n>>> 676:     def cleanup_expired_data(self) -> int:\n    677:         \"\"\"Clean up expired profiles per retention policy.\n    678: \n    679:         Returns:",
    "context": {
      "function_name": "cleanup_expired_data",
      "sequential_functions": [
        "__init__",
        "init_database",
        "cleanup_expired_data"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "god_object",
    "severity": "critical",
    "file_path": "packages\\core\\legacy\\security\\secure_file_upload.py",
    "line_number": 31,
    "column": 0,
    "description": "Class 'SecureFileUploadValidator' is a God Object: 15 methods, ~544 lines",
    "recommendation": "Split into smaller classes using composition or Extract Class refactoring",
    "code_snippet": "     28:     \"\"\"Malicious file detected.\"\"\"\n     29: \n     30: \n>>>  31: class SecureFileUploadValidator:\n     32:     \"\"\"Secure file upload validation and processing.\"\"\"\n     33: \n     34:     def __init__(self, config: dict[str, Any] | None = None) -> None:",
    "context": {
      "method_count": 15,
      "estimated_lines": 544,
      "class_name": "SecureFileUploadValidator",
      "data_methods": 1,
      "business_methods": 14
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_file_upload.py",
    "line_number": 34,
    "column": 4,
    "description": "Method '__init__' is too complex: 2 complexity, 160 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     31: class SecureFileUploadValidator:\n     32:     \"\"\"Secure file upload validation and processing.\"\"\"\n     33: \n>>>  34:     def __init__(self, config: dict[str, Any] | None = None) -> None:\n     35:         \"\"\"Initialize file upload validator.\n     36: \n     37:         Args:",
    "context": {
      "complexity": 2,
      "lines": 160,
      "max_nesting": 0,
      "method_name": "__init__"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_file_upload.py",
    "line_number": 213,
    "column": 4,
    "description": "Method 'validate_file' is too complex: 9 complexity, 85 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    210: \n    211:         return None\n    212: \n>>> 213:     def validate_file(\n    214:         self, file_path: str, filename: str | None = None, content: bytes | None = None,\n    215:     ) -> dict[str, Any]:\n    216:         \"\"\"Validate uploaded file for security issues.",
    "context": {
      "complexity": 9,
      "lines": 85,
      "max_nesting": 5,
      "method_name": "validate_file"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_file_upload.py",
    "line_number": 312,
    "column": 4,
    "description": "Method '_validate_filename' is too complex: 7 complexity, 46 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    309: \n    310:         result[\"metadata\"][\"file_size\"] = file_size\n    311: \n>>> 312:     def _validate_filename(self, filename: str, result: dict[str, Any]) -> None:\n    313:         \"\"\"Validate filename for security issues.\"\"\"\n    314:         # Check for path traversal attempts\n    315:         if \"..\" in filename or \"/\" in filename or \"\\\\\" in filename:",
    "context": {
      "complexity": 7,
      "lines": 46,
      "max_nesting": 5,
      "method_name": "_validate_filename"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_file_upload.py",
    "line_number": 415,
    "column": 4,
    "description": "Method '_analyze_file_content' is too complex: 10 complexity, 27 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    412:                 f\"File signature mismatch: signature '{detected_signature}', MIME type '{detected_mime}'\",\n    413:             )\n    414: \n>>> 415:     def _analyze_file_content(self, content: bytes, filename: str, result: dict[str, Any]) -> None:\n    416:         \"\"\"Analyze file content for dangerous patterns.\"\"\"\n    417:         # Check for dangerous patterns\n    418:         for pattern in self.dangerous_patterns:",
    "context": {
      "complexity": 10,
      "lines": 27,
      "max_nesting": 8,
      "method_name": "_analyze_file_content"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_file_upload.py",
    "line_number": 484,
    "column": 4,
    "description": "Method '_validate_zip_archive' is too complex: 9 complexity, 33 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    481:         except Exception as e:\n    482:             result[\"warnings\"].append(f\"Archive validation failed: {e}\")\n    483: \n>>> 484:     def _validate_zip_archive(self, zip_file: zipfile.ZipFile, result: dict[str, Any]) -> None:\n    485:         \"\"\"Validate ZIP archive contents.\"\"\"\n    486:         file_count = 0\n    487:         total_uncompressed_size = 0",
    "context": {
      "complexity": 9,
      "lines": 33,
      "max_nesting": 6,
      "method_name": "_validate_zip_archive"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_file_upload.py",
    "line_number": 539,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    536:         return filename\n    537: \n    538:     def get_safe_upload_path(self, base_dir: str, filename: str, create_subdirs: bool = True) -> Path:\n>>> 539:         \"\"\"Get safe path for file upload.\n    540: \n    541:         Args:\n    542:             base_dir: Base upload directory",
    "context": {
      "query_preview": "Get safe path for file upload.\n\n        Args:\n            base_dir: Base upload directory\n          ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_file_upload.py",
    "line_number": 300,
    "column": 4,
    "description": "Duplicate code block detected in function '_validate_file_size'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    297:             msg = f\"File validation failed: {e}\"\n    298:             raise FileUploadError(msg)\n    299: \n>>> 300:     def _validate_file_size(self, content: bytes, result: dict[str, Any]) -> None:\n    301:         \"\"\"Validate file size limits.\"\"\"\n    302:         file_size = len(content)\n    303: ",
    "context": {
      "duplicate_count": 2,
      "function_name": "_validate_file_size",
      "signature": "ASSIGN|IF|IF|ASSIGN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_file_upload.py",
    "line_number": 360,
    "column": 4,
    "description": "Duplicate code block detected in function '_validate_file_extension'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    357:         if basename in reserved_names:\n    358:             result[\"errors\"].append(f\"Filename uses reserved name: {basename}\")\n    359: \n>>> 360:     def _validate_file_extension(self, filename: str, result: dict[str, Any]) -> None:\n    361:         \"\"\"Validate file extension.\"\"\"\n    362:         # Get file extension\n    363:         extension = filename.lower().split(\".\")[-1] if \".\" in filename else \"\"",
    "context": {
      "duplicate_count": 2,
      "function_name": "_validate_file_extension",
      "signature": "ASSIGN|IF|IF|ASSIGN"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_file_upload.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (13 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 13,
      "methods": [
        "_validate_file_extension",
        "_validate_magic_numbers",
        "_scan_for_viruses",
        "sanitize_filename",
        "_validate_archive",
        "_validate_zip_archive",
        "_validate_mime_type",
        "_validate_file_size",
        "_analyze_file_content",
        "_init_virus_scanner",
        "_is_archive_file",
        "_validate_filename"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_file_upload.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 7,
      "methods": [
        "info",
        "warning",
        "exception",
        "debug"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_file_upload.py",
    "line_number": 43,
    "column": 67,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     40:         self.config = config or {}\n     41: \n     42:         # File size limits (in bytes)\n>>>  43:         self.max_file_size = self.config.get(\"max_file_size\", 10 * 1024 * 1024)  # 10MB\n     44:         self.max_total_size = self.config.get(\"max_total_size\", 100 * 1024 * 1024)  # 100MB\n     45: \n     46:         # Allowed file types and extensions",
    "context": {
      "total_magic_literals": 11,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_file_upload.py",
    "line_number": 43,
    "column": 74,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     40:         self.config = config or {}\n     41: \n     42:         # File size limits (in bytes)\n>>>  43:         self.max_file_size = self.config.get(\"max_file_size\", 10 * 1024 * 1024)  # 10MB\n     44:         self.max_total_size = self.config.get(\"max_total_size\", 100 * 1024 * 1024)  # 100MB\n     45: \n     46:         # Allowed file types and extensions",
    "context": {
      "total_magic_literals": 11,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_file_upload.py",
    "line_number": 44,
    "column": 70,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     41: \n     42:         # File size limits (in bytes)\n     43:         self.max_file_size = self.config.get(\"max_file_size\", 10 * 1024 * 1024)  # 10MB\n>>>  44:         self.max_total_size = self.config.get(\"max_total_size\", 100 * 1024 * 1024)  # 100MB\n     45: \n     46:         # Allowed file types and extensions\n     47:         self.allowed_extensions = set(",
    "context": {
      "total_magic_literals": 11,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_file_upload.py",
    "line_number": 44,
    "column": 77,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     41: \n     42:         # File size limits (in bytes)\n     43:         self.max_file_size = self.config.get(\"max_file_size\", 10 * 1024 * 1024)  # 10MB\n>>>  44:         self.max_total_size = self.config.get(\"max_total_size\", 100 * 1024 * 1024)  # 100MB\n     45: \n     46:         # Allowed file types and extensions\n     47:         self.allowed_extensions = set(",
    "context": {
      "total_magic_literals": 11,
      "current_value": 1024
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_file_upload.py",
    "line_number": 323,
    "column": 24,
    "description": "Excessive magic literals detected (11 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    320:             result[\"errors\"].append(\"Filename contains null bytes\")\n    321: \n    322:         # Check for control characters\n>>> 323:         if any(ord(c) < 32 for c in filename if c not in \"\\t\\n\\r\"):\n    324:             result[\"errors\"].append(\"Filename contains control characters\")\n    325: \n    326:         # Check filename length",
    "context": {
      "total_magic_literals": 11,
      "current_value": 32
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_redis_client.py",
    "line_number": 27,
    "column": 0,
    "description": "Method 'create_secure_redis_client' is too complex: 23 complexity, 121 lines, 13 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     24:     \"\"\"Raised when Redis security validation fails.\"\"\"\n     25: \n     26: \n>>>  27: def create_secure_redis_client(\n     28:     redis_url: str,\n     29:     ssl_required: bool | None = None,\n     30:     ssl_cert_reqs: str = \"required\",",
    "context": {
      "complexity": 23,
      "lines": 121,
      "max_nesting": 13,
      "method_name": "create_secure_redis_client"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_redis_client.py",
    "line_number": 27,
    "column": 0,
    "description": "Function 'create_secure_redis_client' has 7 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "     24:     \"\"\"Raised when Redis security validation fails.\"\"\"\n     25: \n     26: \n>>>  27: def create_secure_redis_client(\n     28:     redis_url: str,\n     29:     ssl_required: bool | None = None,\n     30:     ssl_cert_reqs: str = \"required\",",
    "context": {
      "parameter_count": 7,
      "function_name": "create_secure_redis_client"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_redis_client.py",
    "line_number": 36,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     33:     ssl_keyfile: str | None = None,\n     34:     **kwargs,\n     35: ) -> object | None:\n>>>  36:     \"\"\"Create a secure Redis client with TLS validation.\n     37: \n     38:     Args:\n     39:         redis_url: Redis connection URL",
    "context": {
      "query_preview": "Create a secure Redis client with TLS validation.\n\n    Args:\n        redis_url: Redis connection URL..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_redis_client.py",
    "line_number": 121,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    118:         if ssl_certfile and ssl_keyfile:\n    119:             ssl_context.load_cert_chain(ssl_certfile, ssl_keyfile)\n    120: \n>>> 121:         connection_params.update(\n    122:             {\n    123:                 \"ssl\": True,\n    124:                 \"ssl_context\": ssl_context,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_redis_client.py",
    "line_number": 151,
    "column": 0,
    "description": "Method 'validate_redis_url_security' is too complex: 6 complexity, 31 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    148:         return None\n    149: \n    150: \n>>> 151: def validate_redis_url_security(redis_url: str) -> None:\n    152:     \"\"\"Validate Redis URL for production security requirements.\n    153: \n    154:     Args:",
    "context": {
      "complexity": 6,
      "lines": 31,
      "max_nesting": 5,
      "method_name": "validate_redis_url_security"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_redis_client.py",
    "line_number": 203,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    200: \n    201: \n    202: def create_production_redis_pool(redis_url: str, **kwargs) -> object | None:\n>>> 203:     \"\"\"Create a production-ready Redis connection pool with security settings.\n    204: \n    205:     Args:\n    206:         redis_url: Redis connection URL",
    "context": {
      "query_preview": "Create a production-ready Redis connection pool with security settings.\n\n    Args:\n        redis_url..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_redis_client.py",
    "line_number": 217,
    "column": 4,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    214: \n    215:     # Get production configuration\n    216:     config = get_production_redis_config()\n>>> 217:     config.update(kwargs)\n    218: \n    219:     # Validate URL security\n    220:     validate_redis_url_security(redis_url)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_serializer.py",
    "line_number": 143,
    "column": 4,
    "description": "Method '_validate_data_security' is too complex: 6 complexity, 18 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    140:             if field not in obj or not isinstance(obj[field], expected_type):\n    141:                 raise SerializationError(f\"Field '{field}' missing or not of type {expected_type.__name__}\")\n    142: \n>>> 143:     def _validate_data_security(self, data: Any) -> None:\n    144:         \"\"\"Validate data for security concerns.\"\"\"\n    145:         if isinstance(data, str | bytes):\n    146:             if len(data) > self.max_size_bytes:",
    "context": {
      "complexity": 6,
      "lines": 18,
      "max_nesting": 5,
      "method_name": "_validate_data_security"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_serializer.py",
    "line_number": 163,
    "column": 4,
    "description": "Method '_prepare_data' is too complex: 11 complexity, 55 lines, 10 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    160:                 if pattern in data.lower():\n    161:                     logger.warning(f\"Suspicious pattern detected in data: {pattern}\")\n    162: \n>>> 163:     def _prepare_data(self, obj: Any) -> dict[str, Any]:\n    164:         \"\"\"Convert object to serializable dictionary with type metadata.\"\"\"\n    165: \n    166:         def convert_item(item):",
    "context": {
      "complexity": 11,
      "lines": 55,
      "max_nesting": 10,
      "method_name": "_prepare_data"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_serializer.py",
    "line_number": 166,
    "column": 8,
    "description": "Method 'convert_item' is too complex: 11 complexity, 50 lines, 10 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    163:     def _prepare_data(self, obj: Any) -> dict[str, Any]:\n    164:         \"\"\"Convert object to serializable dictionary with type metadata.\"\"\"\n    165: \n>>> 166:         def convert_item(item):\n    167:             if item is None:\n    168:                 return {\"__type__\": \"NoneType\", \"__value__\": None}\n    169:             if isinstance(item, str | int | float | bool):",
    "context": {
      "complexity": 11,
      "lines": 50,
      "max_nesting": 10,
      "method_name": "convert_item"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_serializer.py",
    "line_number": 220,
    "column": 4,
    "description": "Method '_restore_data' is too complex: 16 complexity, 46 lines, 14 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    217: \n    218:         return convert_item(obj)\n    219: \n>>> 220:     def _restore_data(self, data: dict[str, Any]) -> Any:\n    221:         \"\"\"Restore object from serializable dictionary with type metadata.\"\"\"\n    222:         if not isinstance(data, dict) or \"__type__\" not in data:\n    223:             return data",
    "context": {
      "complexity": 16,
      "lines": 46,
      "max_nesting": 14,
      "method_name": "_restore_data"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_serializer.py",
    "line_number": 221,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    218:         return convert_item(obj)\n    219: \n    220:     def _restore_data(self, data: dict[str, Any]) -> Any:\n>>> 221:         \"\"\"Restore object from serializable dictionary with type metadata.\"\"\"\n    222:         if not isinstance(data, dict) or \"__type__\" not in data:\n    223:             return data\n    224: ",
    "context": {
      "query_preview": "Restore object from serializable dictionary with type metadata."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_serializer.py",
    "line_number": 268,
    "column": 4,
    "description": "Method 'dumps' is too complex: 5 complexity, 57 lines, 3 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    265:         logger.error(f\"Unknown type: {obj_type}\")\n    266:         raise ValueError(f\"Unknown type: {obj_type}\")\n    267: \n>>> 268:     def dumps(\n    269:         self,\n    270:         obj: Any,\n    271:         serialization_type: SerializationType = SerializationType.JSON,",
    "context": {
      "complexity": 5,
      "lines": 57,
      "max_nesting": 3,
      "method_name": "dumps"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\secure_serializer.py",
    "line_number": 327,
    "column": 4,
    "description": "Method 'loads' is too complex: 9 complexity, 51 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    324:         except Exception as e:\n    325:             raise SerializationError(f\"Serialization failed: {e}\") from e\n    326: \n>>> 327:     def loads(self, data: bytes, schema: dict[str, type] | None = None) -> Any:\n    328:         \"\"\"Deserialize object from secure byte format.\n    329: \n    330:         Args:",
    "context": {
      "complexity": 9,
      "lines": 51,
      "max_nesting": 5,
      "method_name": "loads"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_serializer.py",
    "line_number": 328,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    325:             raise SerializationError(f\"Serialization failed: {e}\") from e\n    326: \n    327:     def loads(self, data: bytes, schema: dict[str, type] | None = None) -> Any:\n>>> 328:         \"\"\"Deserialize object from secure byte format.\n    329: \n    330:         Args:\n    331:             data: Serialized data as bytes",
    "context": {
      "query_preview": "Deserialize object from secure byte format.\n\n        Args:\n            data: Serialized data as byte..."
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_serializer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'data' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "data",
      "method_count": 7,
      "methods": [
        "decode",
        "startswith",
        "get",
        "lower"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_serializer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (15 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 15,
      "methods": [
        "_prepare_data",
        "_generate_key",
        "_validate_schema",
        "_validate_data_security",
        "_restore_data",
        "dumps",
        "loads"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\secure_serializer.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 8,
      "methods": [
        "warning",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 93,
    "column": 4,
    "description": "Method 'validate' is too complex: 17 complexity, 90 lines, 12 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     90:     def __init__(self, security_level: SecurityLevel = SecurityLevel.PRODUCTION):\n     91:         super().__init__(\"HTTPS Enforcement\", security_level)\n     92: \n>>>  93:     def validate(self, context: dict[str, Any]) -> GateReport:\n     94:         start_time = time.time()\n     95:         issues = []\n     96: ",
    "context": {
      "complexity": 17,
      "lines": 90,
      "max_nesting": 12,
      "method_name": "validate"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 105,
    "column": 34,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    102:             project_root / \"src\" / \"core\",\n    103:         ]\n    104: \n>>> 105:         http_pattern = re.compile(r'http://[^\\s\\'\"]+', re.IGNORECASE)\n    106: \n    107:         for src_dir in src_dirs:\n    108:             if not src_dir.exists():",
    "context": {
      "hardcoded_value": "http://[^\\s\\'\"]+"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 153,
    "column": 23,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    150:                     with open(config_file) as f:\n    151:                         content = f.read()\n    152: \n>>> 153:                     if \"http://\" in content and \"localhost\" not in content:\n    154:                         issues.append(\n    155:                             SecurityIssue(\n    156:                                 severity=\"HIGH\",",
    "context": {
      "hardcoded_value": "http://"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 192,
    "column": 4,
    "description": "Method 'validate' is too complex: 8 complexity, 70 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    189:     def __init__(self, security_level: SecurityLevel = SecurityLevel.PRODUCTION):\n    190:         super().__init__(\"Pickle Security\", security_level)\n    191: \n>>> 192:     def validate(self, context: dict[str, Any]) -> GateReport:\n    193:         start_time = time.time()\n    194:         issues = []\n    195: ",
    "context": {
      "complexity": 8,
      "lines": 70,
      "max_nesting": 6,
      "method_name": "validate"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 201,
    "column": 13,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    198:         # Patterns to detect unsafe pickle usage\n    199:         unsafe_patterns = [\n    200:             (r\"import\\s+pickle\", \"Direct pickle import\"),\n>>> 201:             (r\"from\\s+pickle\\s+import\", \"Pickle function import\"),\n    202:             (r\"pickle\\.loads?\\(\", \"Unsafe pickle load/loads call\"),\n    203:             (r\"pickle\\.dumps?\\(\", \"Direct pickle dump/dumps call\"),\n    204:             (r\"cPickle\", \"Legacy cPickle usage\"),",
    "context": {
      "query_preview": "from\\s+pickle\\s+import"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 243,
    "column": 51,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    240:                                     category=\"UNSAFE_SERIALIZATION\",\n    241:                                     description=f\"{description} found at line {line_num}\",\n    242:                                     location=f\"{py_file.relative_to(project_root)}:{line_num}\",\n>>> 243:                                     recommendation=\"Replace with SecureSerializer from core.security.secure_serializer\",\n    244:                                     cve_refs=[\"CVE-2022-42969\", \"CWE-502\"],\n    245:                                 ),\n    246:                             )",
    "context": {
      "query_preview": "Replace with SecureSerializer from core.security.secure_serializer"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 271,
    "column": 4,
    "description": "Method 'validate' is too complex: 9 complexity, 87 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    268:     def __init__(self, security_level: SecurityLevel = SecurityLevel.PRODUCTION):\n    269:         super().__init__(\"Dependency Security\", security_level)\n    270: \n>>> 271:     def validate(self, context: dict[str, Any]) -> GateReport:\n    272:         start_time = time.time()\n    273:         issues = []\n    274: ",
    "context": {
      "complexity": 9,
      "lines": 87,
      "max_nesting": 6,
      "method_name": "validate"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 293,
    "column": 35,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    290:                     category=\"DEPENDENCY_MANAGEMENT\",\n    291:                     description=\"No dependency files found\",\n    292:                     location=\"project root\",\n>>> 293:                     recommendation=\"Create requirements.txt or pyproject.toml\",\n    294:                 ),\n    295:             )\n    296: ",
    "context": {
      "query_preview": "Create requirements.txt or pyproject.toml"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 377,
    "column": 4,
    "description": "Method 'validate' is too complex: 10 complexity, 74 lines, 7 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    374:             (r\"[A-Za-z0-9]{20,}\", \"Generic secret-like string\"),\n    375:         ]\n    376: \n>>> 377:     def validate(self, context: dict[str, Any]) -> GateReport:\n    378:         start_time = time.time()\n    379:         issues = []\n    380: ",
    "context": {
      "complexity": 10,
      "lines": 74,
      "max_nesting": 7,
      "method_name": "validate"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 472,
    "column": 4,
    "description": "Method 'run_all_gates' is too complex: 8 complexity, 53 lines, 7 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    469:         \"\"\"Register a security gate.\"\"\"\n    470:         self.gates.append(gate)\n    471: \n>>> 472:     def run_all_gates(self, context: dict[str, Any] = None) -> dict[str, Any]:\n    473:         \"\"\"Run all registered security gates.\"\"\"\n    474:         if context is None:\n    475:             context = {\"project_root\": Path.cwd()}",
    "context": {
      "complexity": 8,
      "lines": 53,
      "max_nesting": 7,
      "method_name": "run_all_gates"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 527,
    "column": 4,
    "description": "Method 'get_security_summary' is too complex: 6 complexity, 26 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    524:             \"security_level\": self.security_level.value,\n    525:         }\n    526: \n>>> 527:     def get_security_summary(self) -> dict[str, Any]:\n    528:         \"\"\"Get comprehensive security summary.\"\"\"\n    529:         all_issues = []\n    530:         for report in self.reports:",
    "context": {
      "complexity": 6,
      "lines": 26,
      "max_nesting": 5,
      "method_name": "get_security_summary"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'time' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "time",
      "method_count": 8,
      "methods": [
        "time"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'Path' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "Path",
      "method_count": 6,
      "methods": [
        "cwd"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'src_dir' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "src_dir",
      "method_count": 6,
      "methods": [
        "exists",
        "rglob"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'match' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "match",
      "method_count": 6,
      "methods": [
        "group",
        "start",
        "groups",
        "lower"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'issues' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "issues",
      "method_count": 7,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 457,
    "column": 4,
    "description": "Sequential coupling detected: Function '__init__' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    454: class SecurityGateRunner:\n    455:     \"\"\"Manages and executes security gates.\"\"\"\n    456: \n>>> 457:     def __init__(self, security_level: SecurityLevel = SecurityLevel.PRODUCTION):\n    458:         self.security_level = security_level\n    459:         self.gates = []\n    460:         self.reports = []",
    "context": {
      "function_name": "__init__",
      "sequential_functions": [
        "__init__",
        "should_run",
        "run_all_gates",
        "run_security_gates"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 82,
    "column": 4,
    "description": "Sequential coupling detected: Function 'should_run' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     79:     def validate(self, context: dict[str, Any]) -> GateReport:\n     80:         \"\"\"Validate security requirements.\"\"\"\n     81: \n>>>  82:     def should_run(self, context: dict[str, Any]) -> bool:\n     83:         \"\"\"Check if gate should run in current context.\"\"\"\n     84:         return self.enabled\n     85: ",
    "context": {
      "function_name": "should_run",
      "sequential_functions": [
        "__init__",
        "should_run",
        "run_all_gates",
        "run_security_gates"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 472,
    "column": 4,
    "description": "Sequential coupling detected: Function 'run_all_gates' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    469:         \"\"\"Register a security gate.\"\"\"\n    470:         self.gates.append(gate)\n    471: \n>>> 472:     def run_all_gates(self, context: dict[str, Any] = None) -> dict[str, Any]:\n    473:         \"\"\"Run all registered security gates.\"\"\"\n    474:         if context is None:\n    475:             context = {\"project_root\": Path.cwd()}",
    "context": {
      "function_name": "run_all_gates",
      "sequential_functions": [
        "__init__",
        "should_run",
        "run_all_gates",
        "run_security_gates"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\security_gates.py",
    "line_number": 557,
    "column": 0,
    "description": "Sequential coupling detected: Function 'run_security_gates' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    554: \n    555: \n    556: # Convenience functions\n>>> 557: def run_security_gates(\n    558:     project_root: Path = None, security_level: SecurityLevel = SecurityLevel.PRODUCTION,\n    559: ) -> dict[str, Any]:\n    560:     \"\"\"Run all security gates for a project.\"\"\"",
    "context": {
      "function_name": "run_security_gates",
      "sequential_functions": [
        "__init__",
        "should_run",
        "run_all_gates",
        "run_security_gates"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\__init__.py",
    "line_number": 43,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     40:     \"secure_loads\",\n     41:     # Secure Redis\n     42:     \"SecureRedisError\",\n>>>  43:     \"create_secure_redis_client\",\n     44:     \"validate_redis_url_security\",\n     45:     \"get_production_redis_config\",\n     46:     \"create_production_redis_pool\",",
    "context": {
      "query_preview": "create_secure_redis_client"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\security\\__init__.py",
    "line_number": 46,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     43:     \"create_secure_redis_client\",\n     44:     \"validate_redis_url_security\",\n     45:     \"get_production_redis_config\",\n>>>  46:     \"create_production_redis_pool\",\n     47: ]",
    "context": {
      "query_preview": "create_production_redis_pool"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 84,
    "column": 4,
    "description": "Method 'measure_current_coverage' is too complex: 7 complexity, 63 lines, 2 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     81:             \"src/token_economy\",\n     82:         ]\n     83: \n>>>  84:     def measure_current_coverage(self) -> dict[str, CoverageMetrics]:\n     85:         \"\"\"Measure current test coverage across the project.\"\"\"\n     86:         print(\"Measuring current test coverage...\")\n     87: ",
    "context": {
      "complexity": 7,
      "lines": 63,
      "max_nesting": 2,
      "method_name": "measure_current_coverage"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 171,
    "column": 4,
    "description": "Method '_enhance_coverage_metrics' is too complex: 7 complexity, 75 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    168:             except (subprocess.TimeoutExpired, FileNotFoundError):\n    169:                 continue\n    170: \n>>> 171:     def _enhance_coverage_metrics(self, file_path: Path, metrics: CoverageMetrics):\n    172:         \"\"\"Enhance coverage metrics with component-specific analysis.\"\"\"\n    173:         try:\n    174:             with open(file_path, encoding=\"utf-8\") as f:",
    "context": {
      "complexity": 7,
      "lines": 75,
      "max_nesting": 5,
      "method_name": "_enhance_coverage_metrics"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 293,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    290:         return (covered_lines / total_lines * 100) if total_lines > 0 else 0.0\n    291: \n    292:     def identify_coverage_gaps(self, metrics: dict[str, CoverageMetrics]) -> list[CoverageTarget]:\n>>> 293:         \"\"\"Identify key coverage gaps and create improvement targets.\"\"\"\n    294:         gaps = []\n    295: \n    296:         # Priority 1: Critical components below 30%",
    "context": {
      "query_preview": "Identify key coverage gaps and create improvement targets."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 339,
    "column": 4,
    "description": "Method 'execute_coverage_campaign' is too complex: 3 complexity, 81 lines, 2 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    336:         self.target_coverage = target_coverage\n    337:         self.analyzer = CoverageAnalyzer(project_root)\n    338: \n>>> 339:     def execute_coverage_campaign(self) -> dict[str, Any]:\n    340:         \"\"\"Execute comprehensive coverage improvement campaign.\"\"\"\n    341:         print(f\"\\n=== Coverage Harness Campaign - Target: {self.target_coverage}% ===\")\n    342: ",
    "context": {
      "complexity": 3,
      "lines": 81,
      "max_nesting": 2,
      "method_name": "execute_coverage_campaign"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 504,
    "column": 4,
    "description": "Method '_generate_test_file_content' is too complex: 1 complexity, 55 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    501:             \"coverage_boost\": coverage_boost,\n    502:         }\n    503: \n>>> 504:     def _generate_test_file_content(self, gap: CoverageTarget) -> str:\n    505:         \"\"\"Generate basic test file content for a coverage gap.\"\"\"\n    506:         module_name = gap.component.split(\".\")[-1]\n    507: ",
    "context": {
      "complexity": 1,
      "lines": 55,
      "max_nesting": 0,
      "method_name": "_generate_test_file_content"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 513,
    "column": 41,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    510: Generated by Coverage Harness to address coverage gap.\n    511: \n    512: Current coverage: {gap.current_percent:.1f}%\n>>> 513: Target coverage: {gap.target_percent:.1f}%\n    514: \"\"\"\n    515: \n    516: import pytest",
    "context": {
      "query_preview": "%\n\"\"\"\n\nimport pytest\nimport sys\nfrom pathlib import Path\n\n# Add src to path for imports\nsys.path.ins..."
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 248,
    "column": 4,
    "description": "Duplicate code block detected in function '_generate_mock_coverage_data'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    245:         except Exception as e:\n    246:             logger.warning(f\"Error enhancing metrics for {file_path}: {e}\")\n    247: \n>>> 248:     def _generate_mock_coverage_data(self) -> dict[str, CoverageMetrics]:\n    249:         \"\"\"Generate mock coverage data for demonstration when real coverage fails.\"\"\"\n    250:         mock_data = {}\n    251: ",
    "context": {
      "duplicate_count": 2,
      "function_name": "_generate_mock_coverage_data",
      "signature": "ASSIGN|ASSIGN|FOR|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 470,
    "column": 4,
    "description": "Duplicate code block detected in function '_implement_coverage_improvements'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    467:             \"templates_used\": list(test_templates.keys()),\n    468:         }\n    469: \n>>> 470:     def _implement_coverage_improvements(self, priority_gaps: list[CoverageTarget]) -> dict[str, Any]:\n    471:         \"\"\"Implement actual coverage improvements for priority gaps.\"\"\"\n    472:         improvements_count = 0\n    473:         coverage_boost = 0.0",
    "context": {
      "duplicate_count": 2,
      "function_name": "_implement_coverage_improvements",
      "signature": "ASSIGN|ASSIGN|FOR|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 7,
      "methods": [
        "_implement_coverage_improvements",
        "_generate_mock_coverage_data",
        "_generate_test_file_content",
        "_setup_coverage_monitoring",
        "_enhance_coverage_metrics",
        "_generate_strategic_tests",
        "_run_existing_tests"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 6,
      "methods": [
        "warning",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'f' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "f",
      "method_count": 8,
      "methods": [
        "write",
        "writelines",
        "read"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 334,
    "column": 4,
    "description": "Sequential coupling detected: Function '__init__' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    331: class CoverageHarness:\n    332:     \"\"\"Main coverage harness for achieving 30%+ coverage target.\"\"\"\n    333: \n>>> 334:     def __init__(self, project_root: Path, target_coverage: float = 30.0):\n    335:         self.project_root = project_root\n    336:         self.target_coverage = target_coverage\n    337:         self.analyzer = CoverageAnalyzer(project_root)",
    "context": {
      "function_name": "__init__",
      "sequential_functions": [
        "__init__",
        "_run_existing_tests",
        "_setup_coverage_monitoring",
        "run_coverage_campaign"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 149,
    "column": 4,
    "description": "Sequential coupling detected: Function '_run_existing_tests' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    146: \n    147:         return coverage_metrics\n    148: \n>>> 149:     def _run_existing_tests(self):\n    150:         \"\"\"Run existing test suite to gather coverage data.\"\"\"\n    151:         test_commands = [\n    152:             \"python -m pytest tests/ --tb=short -q\",",
    "context": {
      "function_name": "_run_existing_tests",
      "sequential_functions": [
        "__init__",
        "_run_existing_tests",
        "_setup_coverage_monitoring",
        "run_coverage_campaign"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 561,
    "column": 4,
    "description": "Sequential coupling detected: Function '_setup_coverage_monitoring' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    558:     assert True\n    559: '''\n    560: \n>>> 561:     def _setup_coverage_monitoring(self) -> dict[str, Any]:\n    562:         \"\"\"Set up ongoing coverage monitoring.\"\"\"\n    563:         # Create coverage configuration\n    564:         coverage_config = {",
    "context": {
      "function_name": "_setup_coverage_monitoring",
      "sequential_functions": [
        "__init__",
        "_run_existing_tests",
        "_setup_coverage_monitoring",
        "run_coverage_campaign"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 606,
    "column": 0,
    "description": "Sequential coupling detected: Function 'run_coverage_campaign' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    603: \n    604: \n    605: # Convenience functions\n>>> 606: def run_coverage_campaign(project_root: Path = None, target: float = 30.0) -> dict[str, Any]:\n    607:     \"\"\"Run complete coverage improvement campaign.\"\"\"\n    608:     if project_root is None:\n    609:         project_root = Path.cwd()",
    "context": {
      "function_name": "run_coverage_campaign",
      "sequential_functions": [
        "__init__",
        "_run_existing_tests",
        "_setup_coverage_monitoring",
        "run_coverage_campaign"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 163,
    "column": 28,
    "description": "Excessive magic literals detected (57 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    160:                     check=False, cwd=self.project_root,\n    161:                     capture_output=True,\n    162:                     text=True,\n>>> 163:                     timeout=60,\n    164:                 )\n    165:                 if result.returncode == 0:\n    166:                     print(f\"  Ran tests: {cmd}\")",
    "context": {
      "total_magic_literals": 57,
      "current_value": 60
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 235,
    "column": 43,
    "description": "Excessive magic literals detected (57 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    232:             metrics.integration_points_covered = covered_integration\n    233: \n    234:             # Calculate complexity and risk scores\n>>> 235:             metrics.complexity_score = min(5.0, total_functions / 10.0)\n    236:             metrics.risk_score = max(0.0, 1.0 - function_coverage_ratio)\n    237: \n    238:             # Set priority based on component importance",
    "context": {
      "total_magic_literals": 57,
      "current_value": 5.0
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 241,
    "column": 67,
    "description": "Excessive magic literals detected (57 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    238:             # Set priority based on component importance\n    239:             component_path = str(file_path)\n    240:             if any(critical in component_path for critical in self.critical_components):\n>>> 241:                 metrics.priority = 1 if metrics.coverage_percent < 30 else 2\n    242:             else:\n    243:                 metrics.priority = 3 if metrics.coverage_percent < 20 else 4\n    244: ",
    "context": {
      "total_magic_literals": 57,
      "current_value": 30
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 243,
    "column": 67,
    "description": "Excessive magic literals detected (57 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    240:             if any(critical in component_path for critical in self.critical_components):\n    241:                 metrics.priority = 1 if metrics.coverage_percent < 30 else 2\n    242:             else:\n>>> 243:                 metrics.priority = 3 if metrics.coverage_percent < 20 else 4\n    244: \n    245:         except Exception as e:\n    246:             logger.warning(f\"Error enhancing metrics for {file_path}: {e}\")",
    "context": {
      "total_magic_literals": 57,
      "current_value": 20
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\testing\\coverage_harness.py",
    "line_number": 243,
    "column": 35,
    "description": "Excessive magic literals detected (57 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    240:             if any(critical in component_path for critical in self.critical_components):\n    241:                 metrics.priority = 1 if metrics.coverage_percent < 30 else 2\n    242:             else:\n>>> 243:                 metrics.priority = 3 if metrics.coverage_percent < 20 else 4\n    244: \n    245:         except Exception as e:\n    246:             logger.warning(f\"Error enhancing metrics for {file_path}: {e}\")",
    "context": {
      "total_magic_literals": 57,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": ">>>   1: \"\"\"Navigator Policy + Mobile Resource Manager Integration - Prompt 3\n      2: \n      3: This module wires together the Navigator's transport selection with the Mobile\n      4: Resource Manager to create intelligent, constraint-aware routing decisions.",
    "context": {
      "query_preview": "Navigator Policy + Mobile Resource Manager Integration - Prompt 3\n\nThis module wires together the Na..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 93,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     90: \n     91: \n     92: class ConstraintType(Enum):\n>>>  93:     \"\"\"Types of device constraints affecting transport selection.\"\"\"\n     94: \n     95:     BATTERY_LOW = \"battery_low\"\n     96:     BATTERY_CRITICAL = \"battery_critical\"",
    "context": {
      "query_preview": "Types of device constraints affecting transport selection."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 108,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    105: \n    106: @dataclass\n    107: class TransportConstraints:\n>>> 108:     \"\"\"Device constraints that affect transport selection.\"\"\"\n    109: \n    110:     battery_level: int | None = None  # Percentage\n    111:     cpu_temp: float | None = None  # Celsius",
    "context": {
      "query_preview": "Device constraints that affect transport selection."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 130,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    127: \n    128: \n    129: class MobileResourceNavigator:\n>>> 130:     \"\"\"Navigator that integrates Mobile Resource Manager constraints into routing decisions.\n    131: \n    132:     This creates the integration between transport selection and device constraints,\n    133:     enabling intelligent BitChat \u2194 Betanet handoff based on real device state.",
    "context": {
      "query_preview": "Navigator that integrates Mobile Resource Manager constraints into routing decisions.\n\n    This crea..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 171,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    168:         message_size_bytes: int,\n    169:         priority: TransportPriority = TransportPriority.NORMAL,\n    170:     ) -> MobileAwareRoutingDecision:\n>>> 171:         \"\"\"Make routing decision considering both transport availability and device constraints.\n    172: \n    173:         This is the core integration method that combines Navigator transport selection\n    174:         with Mobile Resource Manager constraint evaluation.",
    "context": {
      "query_preview": "Make routing decision considering both transport availability and device constraints.\n\n        This ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 244,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    241:         )\n    242: \n    243:     async def _evaluate_device_constraints(self) -> TransportConstraints:\n>>> 244:         \"\"\"Evaluate current device constraints that affect transport selection.\"\"\"\n    245:         constraints = TransportConstraints()\n    246:         active_constraints = []\n    247: ",
    "context": {
      "query_preview": "Evaluate current device constraints that affect transport selection."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 295,
    "column": 4,
    "description": "Method '_generate_mobile_transport_candidates' is too complex: 4 complexity, 56 lines, 2 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    292: \n    293:         return constraints\n    294: \n>>> 295:     def _generate_mobile_transport_candidates(\n    296:         self, target: str, message_size: int, constraints: TransportConstraints,\n    297:     ) -> list[TransportCandidate]:\n    298:         \"\"\"Generate mobile-optimized transport candidates.\"\"\"",
    "context": {
      "complexity": 4,
      "lines": 56,
      "max_nesting": 2,
      "method_name": "_generate_mobile_transport_candidates"
    },
    "related_files": null
  },
  {
    "pattern_type": "hardcoded_path",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 338,
    "column": 27,
    "description": "Hardcoded path or URL detected",
    "recommendation": "Use configuration files, environment variables, or path utilities",
    "code_snippet": "    335:         candidates.append(\n    336:             TransportCandidate(\n    337:                 transport_type=\"betanet\",\n>>> 338:                 endpoint=f\"https://{target}:8443\",\n    339:                 priority=betanet_priority,\n    340:                 estimated_latency_ms=80.0,\n    341:                 reliability_score=betanet_reliability,",
    "context": {
      "hardcoded_value": "https://"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 353,
    "column": 4,
    "description": "Method '_apply_constraint_filtering' is too complex: 9 complexity, 30 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    350: \n    351:         return candidates\n    352: \n>>> 353:     def _apply_constraint_filtering(\n    354:         self, transports: list[TransportCandidate], constraints: TransportConstraints,\n    355:     ) -> list[TransportCandidate]:\n    356:         \"\"\"Filter transports based on active constraints.\"\"\"",
    "context": {
      "complexity": 9,
      "lines": 30,
      "max_nesting": 8,
      "method_name": "_apply_constraint_filtering"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 385,
    "column": 4,
    "description": "Method '_score_transports_for_constraints' is too complex: 6 complexity, 37 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    382: \n    383:         return filtered\n    384: \n>>> 385:     def _score_transports_for_constraints(\n    386:         self,\n    387:         transports: list[TransportCandidate],\n    388:         constraints: TransportConstraints,",
    "context": {
      "complexity": 6,
      "lines": 37,
      "max_nesting": 5,
      "method_name": "_score_transports_for_constraints"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 486,
    "column": 4,
    "description": "Method '_generate_decision_reason' is too complex: 6 complexity, 22 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    483: \n    484:         return min(5.0, estimated_drain)  # Cap at 5% drain per message\n    485: \n>>> 486:     def _generate_decision_reason(\n    487:         self, constraints: TransportConstraints, selected_transport: TransportCandidate,\n    488:     ) -> str:\n    489:         \"\"\"Generate human-readable decision reason.\"\"\"",
    "context": {
      "complexity": 6,
      "lines": 22,
      "max_nesting": 5,
      "method_name": "_generate_decision_reason"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 525,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    522: async def create_mobile_aware_navigator(\n    523:     scion_config: Any | None = None, enable_resource_management: bool = True,\n    524: ) -> MobileResourceNavigator:\n>>> 525:     \"\"\"Factory function to create integrated mobile-aware navigator.\"\"\"\n    526:     base_navigator = None\n    527:     resource_manager = None\n    528: ",
    "context": {
      "query_preview": "Factory function to create integrated mobile-aware navigator."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 552,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    549: \n    550:     navigator = MobileResourceNavigator(base_navigator=base_navigator, resource_manager=resource_manager)\n    551: \n>>> 552:     logger.info(\"Mobile-aware navigator created successfully\")\n    553:     return navigator\n    554: \n    555: ",
    "context": {
      "query_preview": "Mobile-aware navigator created successfully"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 437,
    "column": 4,
    "description": "Duplicate code block detected in function '_calculate_power_efficiency'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    434:             metadata={\"fallback\": True, \"reason\": \"no_suitable_transports\"},\n    435:         )\n    436: \n>>> 437:     def _calculate_power_efficiency(self, transport: TransportCandidate, message_size: int) -> float:\n    438:         \"\"\"Calculate power efficiency score for transport.\"\"\"\n    439:         transport_type = transport.transport_type\n    440:         if transport_type in self.transport_efficiency:",
    "context": {
      "duplicate_count": 2,
      "function_name": "_calculate_power_efficiency",
      "signature": "ASSIGN|IF|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 450,
    "column": 4,
    "description": "Duplicate code block detected in function '_estimate_data_usage'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    447: \n    448:         return 0.5  # Default efficiency\n    449: \n>>> 450:     def _estimate_data_usage(self, transport: TransportCandidate, message_size: int) -> float:\n    451:         \"\"\"Estimate data usage in MB.\"\"\"\n    452:         transport_type = transport.transport_type\n    453:         if transport_type in self.transport_efficiency:",
    "context": {
      "duplicate_count": 2,
      "function_name": "_estimate_data_usage",
      "signature": "ASSIGN|IF|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (14 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 14,
      "methods": [
        "info",
        "warning",
        "debug"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 11,
      "methods": [
        "_evaluate_device_constraints",
        "_score_transports_for_constraints",
        "_get_fallback_transport",
        "_generate_decision_reason",
        "_estimate_battery_drain",
        "_generate_mobile_transport_candidates",
        "_estimate_data_usage",
        "_apply_constraint_filtering",
        "_calculate_power_efficiency"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'active_constraints' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "active_constraints",
      "method_count": 7,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 51,
    "column": 17,
    "description": "Excessive magic literals detected (53 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     48:     class TransportPriority(Enum):\n     49:         CRITICAL = 1\n     50:         HIGH = 2\n>>>  51:         NORMAL = 3\n     52:         LOW = 4\n     53:         FALLBACK = 5\n     54: ",
    "context": {
      "total_magic_literals": 53,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 52,
    "column": 14,
    "description": "Excessive magic literals detected (53 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     49:         CRITICAL = 1\n     50:         HIGH = 2\n     51:         NORMAL = 3\n>>>  52:         LOW = 4\n     53:         FALLBACK = 5\n     54: \n     55:     @dataclass",
    "context": {
      "total_magic_literals": 53,
      "current_value": 4
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 53,
    "column": 19,
    "description": "Excessive magic literals detected (53 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     50:         HIGH = 2\n     51:         NORMAL = 3\n     52:         LOW = 4\n>>>  53:         FALLBACK = 5\n     54: \n     55:     @dataclass\n     56:     class TransportCandidate:",
    "context": {
      "total_magic_literals": 53,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 149,
    "column": 32,
    "description": "Excessive magic literals detected (53 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    146:         # Transport efficiency profiles (power consumption estimates)\n    147:         self.transport_efficiency = {\n    148:             \"bitchat\": {\n>>> 149:                 \"power_factor\": 0.3,\n    150:                 \"data_efficiency\": 0.9,\n    151:             },  # Low power, high compression\n    152:             \"betanet\": {",
    "context": {
      "total_magic_literals": 53,
      "current_value": 0.3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\legacy\\transport\\navigator_mobile_integration.py",
    "line_number": 150,
    "column": 35,
    "description": "Excessive magic literals detected (53 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    147:         self.transport_efficiency = {\n    148:             \"bitchat\": {\n    149:                 \"power_factor\": 0.3,\n>>> 150:                 \"data_efficiency\": 0.9,\n    151:             },  # Low power, high compression\n    152:             \"betanet\": {\n    153:                 \"power_factor\": 0.7,",
    "context": {
      "total_magic_literals": 53,
      "current_value": 0.9
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\benchmarks\\__init__.py",
    "line_number": 1,
    "column": 0,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": ">>>   1: \"\"\"AIVillage Tools - Benchmarks.\n      2: \n      3: Benchmark suites moved from root/benchmarks/:\n      4: - Performance benchmarks",
    "context": {
      "query_preview": "AIVillage Tools - Benchmarks.\n\nBenchmark suites moved from root/benchmarks/:\n- Performance benchmark..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 90,
    "column": 4,
    "description": "Method '_init_database' is too complex: 1 complexity, 60 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     87:         self.conn.row_factory = sqlite3.Row\n     88:         self._init_database()\n     89: \n>>>  90:     def _init_database(self):\n     91:         \"\"\"Initialize database schema\"\"\"\n     92:         cursor = self.conn.cursor()\n     93: ",
    "context": {
      "complexity": 1,
      "lines": 60,
      "max_nesting": 0,
      "method_name": "_init_database"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 95,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     92:         cursor = self.conn.cursor()\n     93: \n     94:         # Message metrics table\n>>>  95:         cursor.execute(\n     96:             \"\"\"\n     97:             CREATE TABLE IF NOT EXISTS message_metrics (\n     98:                 message_id TEXT PRIMARY KEY,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 96,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     93: \n     94:         # Message metrics table\n     95:         cursor.execute(\n>>>  96:             \"\"\"\n     97:             CREATE TABLE IF NOT EXISTS message_metrics (\n     98:                 message_id TEXT PRIMARY KEY,\n     99:                 timestamp REAL,",
    "context": {
      "query_preview": "\n            CREATE TABLE IF NOT EXISTS message_metrics (\n                message_id TEXT PRIMARY KE..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 114,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    111:         )\n    112: \n    113:         # Peer metrics table\n>>> 114:         cursor.execute(\n    115:             \"\"\"\n    116:             CREATE TABLE IF NOT EXISTS peer_metrics (\n    117:                 peer_id TEXT PRIMARY KEY,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 115,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    112: \n    113:         # Peer metrics table\n    114:         cursor.execute(\n>>> 115:             \"\"\"\n    116:             CREATE TABLE IF NOT EXISTS peer_metrics (\n    117:                 peer_id TEXT PRIMARY KEY,\n    118:                 platform TEXT,",
    "context": {
      "query_preview": "\n            CREATE TABLE IF NOT EXISTS peer_metrics (\n                peer_id TEXT PRIMARY KEY,\n   ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 132,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    129:         )\n    130: \n    131:         # Network snapshots table\n>>> 132:         cursor.execute(\n    133:             \"\"\"\n    134:             CREATE TABLE IF NOT EXISTS network_snapshots (\n    135:                 id INTEGER PRIMARY KEY AUTOINCREMENT,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 133,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    130: \n    131:         # Network snapshots table\n    132:         cursor.execute(\n>>> 133:             \"\"\"\n    134:             CREATE TABLE IF NOT EXISTS network_snapshots (\n    135:                 id INTEGER PRIMARY KEY AUTOINCREMENT,\n    136:                 timestamp REAL,",
    "context": {
      "query_preview": "\n            CREATE TABLE IF NOT EXISTS network_snapshots (\n                id INTEGER PRIMARY KEY A..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 150,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    147:         \"\"\",\n    148:         )\n    149: \n>>> 150:         self.conn.commit()\n    151: \n    152:     def record_message(self, metrics: MessageMetrics):\n    153:         \"\"\"Record message transmission metrics\"\"\"",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 155,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    152:     def record_message(self, metrics: MessageMetrics):\n    153:         \"\"\"Record message transmission metrics\"\"\"\n    154:         cursor = self.conn.cursor()\n>>> 155:         cursor.execute(\n    156:             \"\"\"\n    157:             INSERT OR REPLACE INTO message_metrics\n    158:             VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 156,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    153:         \"\"\"Record message transmission metrics\"\"\"\n    154:         cursor = self.conn.cursor()\n    155:         cursor.execute(\n>>> 156:             \"\"\"\n    157:             INSERT OR REPLACE INTO message_metrics\n    158:             VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n    159:         \"\"\",",
    "context": {
      "query_preview": "\n            INSERT OR REPLACE INTO message_metrics\n            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 174,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    171:                 metrics.transport_type,\n    172:             ),\n    173:         )\n>>> 174:         self.conn.commit()\n    175: \n    176:     def update_peer(self, peer: PeerMetrics):\n    177:         \"\"\"Update peer connectivity metrics\"\"\"",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 177,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    174:         self.conn.commit()\n    175: \n    176:     def update_peer(self, peer: PeerMetrics):\n>>> 177:         \"\"\"Update peer connectivity metrics\"\"\"\n    178:         cursor = self.conn.cursor()\n    179:         cursor.execute(\n    180:             \"\"\"",
    "context": {
      "query_preview": "Update peer connectivity metrics"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 179,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    176:     def update_peer(self, peer: PeerMetrics):\n    177:         \"\"\"Update peer connectivity metrics\"\"\"\n    178:         cursor = self.conn.cursor()\n>>> 179:         cursor.execute(\n    180:             \"\"\"\n    181:             INSERT OR REPLACE INTO peer_metrics\n    182:             VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 180,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    177:         \"\"\"Update peer connectivity metrics\"\"\"\n    178:         cursor = self.conn.cursor()\n    179:         cursor.execute(\n>>> 180:             \"\"\"\n    181:             INSERT OR REPLACE INTO peer_metrics\n    182:             VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n    183:         \"\"\",",
    "context": {
      "query_preview": "\n            INSERT OR REPLACE INTO peer_metrics\n            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 197,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    194:                 1 if peer.is_active else 0,\n    195:             ),\n    196:         )\n>>> 197:         self.conn.commit()\n    198: \n    199:     def calculate_delivery_rate(self, window_minutes: int = 5) -> float:\n    200:         \"\"\"Calculate message delivery success rate\"\"\"",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 204,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    201:         cursor = self.conn.cursor()\n    202:         cutoff = time.time() - (window_minutes * 60)\n    203: \n>>> 204:         cursor.execute(\n    205:             \"\"\"\n    206:             SELECT COUNT(*) as total,\n    207:                    SUM(CASE WHEN status = 'delivered' THEN 1 ELSE 0 END) as delivered",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 205,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    202:         cutoff = time.time() - (window_minutes * 60)\n    203: \n    204:         cursor.execute(\n>>> 205:             \"\"\"\n    206:             SELECT COUNT(*) as total,\n    207:                    SUM(CASE WHEN status = 'delivered' THEN 1 ELSE 0 END) as delivered\n    208:             FROM message_metrics",
    "context": {
      "query_preview": "\n            SELECT COUNT(*) as total,\n                   SUM(CASE WHEN status = 'delivered' THEN 1 ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 224,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    221:         cursor = self.conn.cursor()\n    222:         cutoff = time.time() - (window_minutes * 60)\n    223: \n>>> 224:         cursor.execute(\n    225:             \"\"\"\n    226:             SELECT AVG(latency_ms) as avg_latency\n    227:             FROM message_metrics",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 225,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    222:         cutoff = time.time() - (window_minutes * 60)\n    223: \n    224:         cursor.execute(\n>>> 225:             \"\"\"\n    226:             SELECT AVG(latency_ms) as avg_latency\n    227:             FROM message_metrics\n    228:             WHERE timestamp > ? AND latency_ms IS NOT NULL",
    "context": {
      "query_preview": "\n            SELECT AVG(latency_ms) as avg_latency\n            FROM message_metrics\n            WHER..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 241,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    238:         cursor = self.conn.cursor()\n    239:         cutoff = time.time() - timeout_seconds\n    240: \n>>> 241:         cursor.execute(\n    242:             \"\"\"\n    243:             SELECT COUNT(*) as active_count\n    244:             FROM peer_metrics",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 242,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    239:         cutoff = time.time() - timeout_seconds\n    240: \n    241:         cursor.execute(\n>>> 242:             \"\"\"\n    243:             SELECT COUNT(*) as active_count\n    244:             FROM peer_metrics\n    245:             WHERE last_seen > ? AND is_active = 1",
    "context": {
      "query_preview": "\n            SELECT COUNT(*) as active_count\n            FROM peer_metrics\n            WHERE last_se..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 261,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    258: \n    259:         # Estimate based on average connections per peer\n    260:         cursor = self.conn.cursor()\n>>> 261:         cursor.execute(\n    262:             \"\"\"\n    263:             SELECT AVG(messages_sent + messages_received) as avg_messages\n    264:             FROM peer_metrics",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 262,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    259:         # Estimate based on average connections per peer\n    260:         cursor = self.conn.cursor()\n    261:         cursor.execute(\n>>> 262:             \"\"\"\n    263:             SELECT AVG(messages_sent + messages_received) as avg_messages\n    264:             FROM peer_metrics\n    265:             WHERE is_active = 1",
    "context": {
      "query_preview": "\n            SELECT AVG(messages_sent + messages_received) as avg_messages\n            FROM peer_met..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 294,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    291: \n    292:         # Store snapshot\n    293:         cursor = self.conn.cursor()\n>>> 294:         cursor.execute(\n    295:             \"\"\"\n    296:             INSERT INTO network_snapshots\n    297:             VALUES (NULL, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 295,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    292:         # Store snapshot\n    293:         cursor = self.conn.cursor()\n    294:         cursor.execute(\n>>> 295:             \"\"\"\n    296:             INSERT INTO network_snapshots\n    297:             VALUES (NULL, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n    298:         \"\"\",",
    "context": {
      "query_preview": "\n            INSERT INTO network_snapshots\n            VALUES (NULL, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 312,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    309:                 snapshot.battery_impact,\n    310:             ),\n    311:         )\n>>> 312:         self.conn.commit()\n    313: \n    314:         return snapshot\n    315: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 319,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    316:     def _get_total_peer_count(self) -> int:\n    317:         \"\"\"Get total number of known peers\"\"\"\n    318:         cursor = self.conn.cursor()\n>>> 319:         cursor.execute(\"SELECT COUNT(*) as total FROM peer_metrics\")\n    320:         row = cursor.fetchone()\n    321:         return row[\"total\"] if row else 0\n    322: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 319,
    "column": 23,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    316:     def _get_total_peer_count(self) -> int:\n    317:         \"\"\"Get total number of known peers\"\"\"\n    318:         cursor = self.conn.cursor()\n>>> 319:         cursor.execute(\"SELECT COUNT(*) as total FROM peer_metrics\")\n    320:         row = cursor.fetchone()\n    321:         return row[\"total\"] if row else 0\n    322: ",
    "context": {
      "query_preview": "SELECT COUNT(*) as total FROM peer_metrics"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 328,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    325:         cursor = self.conn.cursor()\n    326:         cutoff = time.time() - 60\n    327: \n>>> 328:         cursor.execute(\n    329:             \"\"\"\n    330:             SELECT COUNT(*) as count\n    331:             FROM message_metrics",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 329,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    326:         cutoff = time.time() - 60\n    327: \n    328:         cursor.execute(\n>>> 329:             \"\"\"\n    330:             SELECT COUNT(*) as count\n    331:             FROM message_metrics\n    332:             WHERE timestamp > ?",
    "context": {
      "query_preview": "\n            SELECT COUNT(*) as count\n            FROM message_metrics\n            WHERE timestamp >..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 345,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    342:         cursor = self.conn.cursor()\n    343:         cutoff = time.time() - 300  # 5 minutes\n    344: \n>>> 345:         cursor.execute(\n    346:             \"\"\"\n    347:             SELECT COUNT(*) as total,\n    348:                    SUM(CASE WHEN status IN ('stored', 'forwarded') THEN 1 ELSE 0 END) as sf_count",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 346,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    343:         cutoff = time.time() - 300  # 5 minutes\n    344: \n    345:         cursor.execute(\n>>> 346:             \"\"\"\n    347:             SELECT COUNT(*) as total,\n    348:                    SUM(CASE WHEN status IN ('stored', 'forwarded') THEN 1 ELSE 0 END) as sf_count\n    349:             FROM message_metrics",
    "context": {
      "query_preview": "\n            SELECT COUNT(*) as total,\n                   SUM(CASE WHEN status IN ('stored', 'forwar..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 365,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    362:         cursor = self.conn.cursor()\n    363:         cutoff = time.time() - 300\n    364: \n>>> 365:         cursor.execute(\n    366:             \"\"\"\n    367:             SELECT AVG(hop_count) as avg_hops\n    368:             FROM message_metrics",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 366,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    363:         cutoff = time.time() - 300\n    364: \n    365:         cursor.execute(\n>>> 366:             \"\"\"\n    367:             SELECT AVG(hop_count) as avg_hops\n    368:             FROM message_metrics\n    369:             WHERE timestamp > ? AND status = 'delivered'",
    "context": {
      "query_preview": "\n            SELECT AVG(hop_count) as avg_hops\n            FROM message_metrics\n            WHERE ti..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 378,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    375:         return row[\"avg_hops\"] if row and row[\"avg_hops\"] else 0.0\n    376: \n    377:     def _estimate_battery_impact(self) -> float | None:\n>>> 378:         \"\"\"Estimate battery impact from peer reports\"\"\"\n    379:         cursor = self.conn.cursor()\n    380: \n    381:         cursor.execute(",
    "context": {
      "query_preview": "Estimate battery impact from peer reports"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 381,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    378:         \"\"\"Estimate battery impact from peer reports\"\"\"\n    379:         cursor = self.conn.cursor()\n    380: \n>>> 381:         cursor.execute(\n    382:             \"\"\"\n    383:             SELECT AVG(battery_level) as avg_battery\n    384:             FROM peer_metrics",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 382,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    379:         cursor = self.conn.cursor()\n    380: \n    381:         cursor.execute(\n>>> 382:             \"\"\"\n    383:             SELECT AVG(battery_level) as avg_battery\n    384:             FROM peer_metrics\n    385:             WHERE is_active = 1 AND battery_level IS NOT NULL",
    "context": {
      "query_preview": "\n            SELECT AVG(battery_level) as avg_battery\n            FROM peer_metrics\n            WHER..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 398,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    395: \n    396:         # Get historical data for trends\n    397:         cursor = self.conn.cursor()\n>>> 398:         cursor.execute(\n    399:             \"\"\"\n    400:             SELECT * FROM network_snapshots\n    401:             ORDER BY timestamp DESC",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 399,
    "column": 12,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    396:         # Get historical data for trends\n    397:         cursor = self.conn.cursor()\n    398:         cursor.execute(\n>>> 399:             \"\"\"\n    400:             SELECT * FROM network_snapshots\n    401:             ORDER BY timestamp DESC\n    402:             LIMIT 100",
    "context": {
      "query_preview": "\n            SELECT * FROM network_snapshots\n            ORDER BY timestamp DESC\n            LIMIT 1..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 458,
    "column": 4,
    "description": "Method '_generate_recommendations' is too complex: 7 complexity, 19 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    455: \n    456:         return sum(scores)\n    457: \n>>> 458:     def _generate_recommendations(self, snapshot: NetworkSnapshot) -> list[str]:\n    459:         \"\"\"Generate performance improvement recommendations\"\"\"\n    460:         recommendations = []\n    461: ",
    "context": {
      "complexity": 7,
      "lines": 19,
      "max_nesting": 5,
      "method_name": "_generate_recommendations"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 152,
    "column": 4,
    "description": "Duplicate code block detected in function 'record_message'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    149: \n    150:         self.conn.commit()\n    151: \n>>> 152:     def record_message(self, metrics: MessageMetrics):\n    153:         \"\"\"Record message transmission metrics\"\"\"\n    154:         cursor = self.conn.cursor()\n    155:         cursor.execute(",
    "context": {
      "duplicate_count": 2,
      "function_name": "record_message",
      "signature": "ASSIGN|CALL_execute|CALL_commit"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 176,
    "column": 4,
    "description": "Duplicate code block detected in function 'update_peer'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    173:         )\n    174:         self.conn.commit()\n    175: \n>>> 176:     def update_peer(self, peer: PeerMetrics):\n    177:         \"\"\"Update peer connectivity metrics\"\"\"\n    178:         cursor = self.conn.cursor()\n    179:         cursor.execute(",
    "context": {
      "duplicate_count": 2,
      "function_name": "update_peer",
      "signature": "ASSIGN|CALL_execute|CALL_commit"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 199,
    "column": 4,
    "description": "Duplicate code block detected in function 'calculate_delivery_rate'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    196:         )\n    197:         self.conn.commit()\n    198: \n>>> 199:     def calculate_delivery_rate(self, window_minutes: int = 5) -> float:\n    200:         \"\"\"Calculate message delivery success rate\"\"\"\n    201:         cursor = self.conn.cursor()\n    202:         cutoff = time.time() - (window_minutes * 60)",
    "context": {
      "duplicate_count": 3,
      "function_name": "calculate_delivery_rate",
      "signature": "ASSIGN|ASSIGN|CALL_execute|ASSIGN|IF|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 340,
    "column": 4,
    "description": "Duplicate code block detected in function '_calculate_store_forward_rate'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    337:         row = cursor.fetchone()\n    338:         return row[\"count\"] if row else 0.0\n    339: \n>>> 340:     def _calculate_store_forward_rate(self) -> float:\n    341:         \"\"\"Calculate store-and-forward usage rate\"\"\"\n    342:         cursor = self.conn.cursor()\n    343:         cutoff = time.time() - 300  # 5 minutes",
    "context": {
      "duplicate_count": 3,
      "function_name": "_calculate_store_forward_rate",
      "signature": "ASSIGN|ASSIGN|CALL_execute|ASSIGN|IF|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 392,
    "column": 4,
    "description": "Duplicate code block detected in function 'generate_report'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    389:         row = cursor.fetchone()\n    390:         return row[\"avg_battery\"] if row and row[\"avg_battery\"] else None\n    391: \n>>> 392:     def generate_report(self) -> dict:\n    393:         \"\"\"Generate comprehensive KPI report\"\"\"\n    394:         snapshot = self.take_network_snapshot()\n    395: ",
    "context": {
      "duplicate_count": 3,
      "function_name": "generate_report",
      "signature": "ASSIGN|ASSIGN|CALL_execute|ASSIGN|IF|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 219,
    "column": 4,
    "description": "Duplicate code block detected in function 'calculate_avg_latency'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    216:             return row[\"delivered\"] / row[\"total\"]\n    217:         return 0.0\n    218: \n>>> 219:     def calculate_avg_latency(self, window_minutes: int = 5) -> float:\n    220:         \"\"\"Calculate average message latency\"\"\"\n    221:         cursor = self.conn.cursor()\n    222:         cutoff = time.time() - (window_minutes * 60)",
    "context": {
      "duplicate_count": 4,
      "function_name": "calculate_avg_latency",
      "signature": "ASSIGN|ASSIGN|CALL_execute|ASSIGN|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 236,
    "column": 4,
    "description": "Duplicate code block detected in function 'get_active_peer_count'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    233:         row = cursor.fetchone()\n    234:         return row[\"avg_latency\"] if row and row[\"avg_latency\"] else 0.0\n    235: \n>>> 236:     def get_active_peer_count(self, timeout_seconds: int = 60) -> int:\n    237:         \"\"\"Get count of currently active peers\"\"\"\n    238:         cursor = self.conn.cursor()\n    239:         cutoff = time.time() - timeout_seconds",
    "context": {
      "duplicate_count": 4,
      "function_name": "get_active_peer_count",
      "signature": "ASSIGN|ASSIGN|CALL_execute|ASSIGN|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 323,
    "column": 4,
    "description": "Duplicate code block detected in function '_calculate_message_rate'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    320:         row = cursor.fetchone()\n    321:         return row[\"total\"] if row else 0\n    322: \n>>> 323:     def _calculate_message_rate(self) -> float:\n    324:         \"\"\"Calculate messages per minute\"\"\"\n    325:         cursor = self.conn.cursor()\n    326:         cutoff = time.time() - 60",
    "context": {
      "duplicate_count": 4,
      "function_name": "_calculate_message_rate",
      "signature": "ASSIGN|ASSIGN|CALL_execute|ASSIGN|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 360,
    "column": 4,
    "description": "Duplicate code block detected in function '_calculate_avg_hop_count'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    357:             return row[\"sf_count\"] / row[\"total\"]\n    358:         return 0.0\n    359: \n>>> 360:     def _calculate_avg_hop_count(self) -> float:\n    361:         \"\"\"Calculate average hop count for delivered messages\"\"\"\n    362:         cursor = self.conn.cursor()\n    363:         cutoff = time.time() - 300",
    "context": {
      "duplicate_count": 4,
      "function_name": "_calculate_avg_hop_count",
      "signature": "ASSIGN|ASSIGN|CALL_execute|ASSIGN|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 316,
    "column": 4,
    "description": "Duplicate code block detected in function '_get_total_peer_count'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    313: \n    314:         return snapshot\n    315: \n>>> 316:     def _get_total_peer_count(self) -> int:\n    317:         \"\"\"Get total number of known peers\"\"\"\n    318:         cursor = self.conn.cursor()\n    319:         cursor.execute(\"SELECT COUNT(*) as total FROM peer_metrics\")",
    "context": {
      "duplicate_count": 2,
      "function_name": "_get_total_peer_count",
      "signature": "ASSIGN|CALL_execute|ASSIGN|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 377,
    "column": 4,
    "description": "Duplicate code block detected in function '_estimate_battery_impact'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    374:         row = cursor.fetchone()\n    375:         return row[\"avg_hops\"] if row and row[\"avg_hops\"] else 0.0\n    376: \n>>> 377:     def _estimate_battery_impact(self) -> float | None:\n    378:         \"\"\"Estimate battery impact from peer reports\"\"\"\n    379:         cursor = self.conn.cursor()\n    380: ",
    "context": {
      "duplicate_count": 2,
      "function_name": "_estimate_battery_impact",
      "signature": "ASSIGN|CALL_execute|ASSIGN|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (15 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 15,
      "methods": [
        "_calculate_store_forward_rate",
        "_generate_recommendations",
        "take_network_snapshot",
        "get_active_peer_count",
        "_init_database",
        "_estimate_battery_impact",
        "calculate_delivery_rate",
        "generate_report",
        "_calculate_message_rate",
        "calculate_avg_latency",
        "calculate_network_density",
        "_calculate_avg_hop_count",
        "_calculate_health_score",
        "_get_total_peer_count"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'cursor' methods (26 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "cursor",
      "method_count": 26,
      "methods": [
        "execute",
        "fetchone",
        "fetchall"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'time' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "time",
      "method_count": 10,
      "methods": [
        "time"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'random' methods (21 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "random",
      "method_count": 21,
      "methods": [
        "choice",
        "uniform",
        "random",
        "randint"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'tracker' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "tracker",
      "method_count": 6,
      "methods": [
        "close",
        "take_network_snapshot",
        "generate_report",
        "update_peer",
        "export_metrics",
        "record_message"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 199,
    "column": 60,
    "description": "Excessive magic literals detected (38 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    196:         )\n    197:         self.conn.commit()\n    198: \n>>> 199:     def calculate_delivery_rate(self, window_minutes: int = 5) -> float:\n    200:         \"\"\"Calculate message delivery success rate\"\"\"\n    201:         cursor = self.conn.cursor()\n    202:         cutoff = time.time() - (window_minutes * 60)",
    "context": {
      "total_magic_literals": 38,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 202,
    "column": 49,
    "description": "Excessive magic literals detected (38 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    199:     def calculate_delivery_rate(self, window_minutes: int = 5) -> float:\n    200:         \"\"\"Calculate message delivery success rate\"\"\"\n    201:         cursor = self.conn.cursor()\n>>> 202:         cutoff = time.time() - (window_minutes * 60)\n    203: \n    204:         cursor.execute(\n    205:             \"\"\"",
    "context": {
      "total_magic_literals": 38,
      "current_value": 60
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 219,
    "column": 58,
    "description": "Excessive magic literals detected (38 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    216:             return row[\"delivered\"] / row[\"total\"]\n    217:         return 0.0\n    218: \n>>> 219:     def calculate_avg_latency(self, window_minutes: int = 5) -> float:\n    220:         \"\"\"Calculate average message latency\"\"\"\n    221:         cursor = self.conn.cursor()\n    222:         cutoff = time.time() - (window_minutes * 60)",
    "context": {
      "total_magic_literals": 38,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 222,
    "column": 49,
    "description": "Excessive magic literals detected (38 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    219:     def calculate_avg_latency(self, window_minutes: int = 5) -> float:\n    220:         \"\"\"Calculate average message latency\"\"\"\n    221:         cursor = self.conn.cursor()\n>>> 222:         cutoff = time.time() - (window_minutes * 60)\n    223: \n    224:         cursor.execute(\n    225:             \"\"\"",
    "context": {
      "total_magic_literals": 38,
      "current_value": 60
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\bitchat\\kpi_tracker.py",
    "line_number": 236,
    "column": 59,
    "description": "Excessive magic literals detected (38 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    233:         row = cursor.fetchone()\n    234:         return row[\"avg_latency\"] if row and row[\"avg_latency\"] else 0.0\n    235: \n>>> 236:     def get_active_peer_count(self, timeout_seconds: int = 60) -> int:\n    237:         \"\"\"Get count of currently active peers\"\"\"\n    238:         cursor = self.conn.cursor()\n    239:         cutoff = time.time() - timeout_seconds",
    "context": {
      "total_magic_literals": 38,
      "current_value": 60
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 74,
    "column": 4,
    "description": "Method 'detect_available_tools' is too complex: 10 complexity, 69 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     71:             else:\n     72:                 base[key] = value\n     73: \n>>>  74:     def detect_available_tools(self) -> dict[str, bool]:\n     75:         \"\"\"Detect which linting tools are available.\"\"\"\n     76:         tools = {}\n     77: ",
    "context": {
      "complexity": 10,
      "lines": 69,
      "max_nesting": 0,
      "method_name": "detect_available_tools"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 370,
    "column": 4,
    "description": "Method 'lint_python' is too complex: 12 complexity, 58 lines, 9 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    367:         except Exception as e:\n    368:             return {\"status\": \"error\", \"error\": str(e)}\n    369: \n>>> 370:     def lint_python(self, path: str = \".\", fix: bool = False, parallel: bool = True) -> dict[str, Any]:\n    371:         \"\"\"Run comprehensive Python linting.\"\"\"\n    372:         print(f\"[PYTHON] Running Python linting on: {path}\")\n    373: ",
    "context": {
      "complexity": 12,
      "lines": 58,
      "max_nesting": 9,
      "method_name": "lint_python"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 502,
    "column": 0,
    "description": "Method 'main' is too complex: 11 complexity, 59 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    499:         return \"\\n\".join(lines)\n    500: \n    501: \n>>> 502: def main():\n    503:     \"\"\"Main entry point for the unified linting system.\"\"\"\n    504:     parser = argparse.ArgumentParser(description=\"AIVillage Unified Linting System\")\n    505:     parser.add_argument(\"path\", nargs=\"?\", default=\".\", help=\"Path to lint (default: current directory)\")",
    "context": {
      "complexity": 11,
      "lines": 59,
      "max_nesting": 8,
      "method_name": "main"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 506,
    "column": 59,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    503:     \"\"\"Main entry point for the unified linting system.\"\"\"\n    504:     parser = argparse.ArgumentParser(description=\"AIVillage Unified Linting System\")\n    505:     parser.add_argument(\"path\", nargs=\"?\", default=\".\", help=\"Path to lint (default: current directory)\")\n>>> 506:     parser.add_argument(\"--fix\", action=\"store_true\", help=\"Apply fixes where possible\")\n    507:     parser.add_argument(\"--config\", help=\"Path to custom configuration file\")\n    508:     parser.add_argument(\n    509:         \"--output\",",
    "context": {
      "query_preview": "Apply fixes where possible"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 164,
    "column": 4,
    "description": "Duplicate code block detected in function 'run_ruff'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    161: \n    162:         return sorted(python_files)\n    163: \n>>> 164:     def run_ruff(self, files: list[Path] = None, fix: bool = False) -> dict[str, Any]:\n    165:         \"\"\"Run Ruff linting.\"\"\"\n    166:         if not self.available_tools.get(\"ruff\", False):\n    167:             return {\"status\": \"skipped\", \"reason\": \"ruff not available\"}",
    "context": {
      "duplicate_count": 2,
      "function_name": "run_ruff",
      "signature": "IF|ASSIGN|ASSIGN|IF|IF|TRY"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 257,
    "column": 4,
    "description": "Duplicate code block detected in function 'run_isort'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    254:         except Exception as e:\n    255:             return {\"status\": \"error\", \"error\": str(e)}\n    256: \n>>> 257:     def run_isort(self, files: list[Path] = None, check_only: bool = True) -> dict[str, Any]:\n    258:         \"\"\"Run isort import sorting.\"\"\"\n    259:         if not self.available_tools.get(\"isort\", False):\n    260:             return {\"status\": \"skipped\", \"reason\": \"isort not available\"}",
    "context": {
      "duplicate_count": 2,
      "function_name": "run_isort",
      "signature": "IF|ASSIGN|ASSIGN|IF|IF|TRY"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 295,
    "column": 4,
    "description": "Duplicate code block detected in function 'run_mypy'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    292:         except Exception as e:\n    293:             return {\"status\": \"error\", \"error\": str(e)}\n    294: \n>>> 295:     def run_mypy(self, files: list[Path] = None) -> dict[str, Any]:\n    296:         \"\"\"Run mypy type checking.\"\"\"\n    297:         if not self.available_tools.get(\"mypy\", False):\n    298:             return {\"status\": \"skipped\", \"reason\": \"mypy not available\"}",
    "context": {
      "duplicate_count": 2,
      "function_name": "run_mypy",
      "signature": "IF|ASSIGN|ASSIGN|IF|TRY"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 331,
    "column": 4,
    "description": "Duplicate code block detected in function 'run_flake8'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    328:         except Exception as e:\n    329:             return {\"status\": \"error\", \"error\": str(e)}\n    330: \n>>> 331:     def run_flake8(self, files: list[Path] = None) -> dict[str, Any]:\n    332:         \"\"\"Run flake8 linting.\"\"\"\n    333:         if not self.available_tools.get(\"flake8\", False):\n    334:             return {\"status\": \"skipped\", \"reason\": \"flake8 not available\"}",
    "context": {
      "duplicate_count": 2,
      "function_name": "run_flake8",
      "signature": "IF|ASSIGN|ASSIGN|IF|TRY"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'time' methods (17 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "time",
      "method_count": 17,
      "methods": [
        "time"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (12 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 12,
      "methods": [
        "run_isort",
        "run_mypy",
        "run_flake8",
        "generate_summary",
        "detect_available_tools",
        "generate_text_summary",
        "merge_config",
        "load_config",
        "find_python_files",
        "run_ruff",
        "run_black"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'subprocess' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "subprocess",
      "method_count": 10,
      "methods": [
        "run"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'cmd' methods (14 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "cmd",
      "method_count": 14,
      "methods": [
        "append",
        "extend"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'lines' methods (15 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "lines",
      "method_count": 15,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'parser' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "parser",
      "method_count": 8,
      "methods": [
        "parse_args",
        "add_argument"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 20,
    "column": 4,
    "description": "Sequential coupling detected: Function '__init__' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     17: class LintingOrchestrator:\n     18:     \"\"\"Unified linting system for AIVillage project.\"\"\"\n     19: \n>>>  20:     def __init__(self, config_path: str | None = None):\n     21:         self.project_root = Path.cwd()\n     22:         self.results = {}\n     23:         self.start_time = time.time()",
    "context": {
      "function_name": "__init__",
      "sequential_functions": [
        "__init__",
        "run_ruff",
        "run_black",
        "run_isort",
        "run_mypy",
        "run_flake8"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 164,
    "column": 4,
    "description": "Sequential coupling detected: Function 'run_ruff' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    161: \n    162:         return sorted(python_files)\n    163: \n>>> 164:     def run_ruff(self, files: list[Path] = None, fix: bool = False) -> dict[str, Any]:\n    165:         \"\"\"Run Ruff linting.\"\"\"\n    166:         if not self.available_tools.get(\"ruff\", False):\n    167:             return {\"status\": \"skipped\", \"reason\": \"ruff not available\"}",
    "context": {
      "function_name": "run_ruff",
      "sequential_functions": [
        "__init__",
        "run_ruff",
        "run_black",
        "run_isort",
        "run_mypy",
        "run_flake8"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 210,
    "column": 4,
    "description": "Sequential coupling detected: Function 'run_black' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    207:         except Exception as e:\n    208:             return {\"status\": \"error\", \"error\": str(e)}\n    209: \n>>> 210:     def run_black(self, files: list[Path] = None, check_only: bool = True) -> dict[str, Any]:\n    211:         \"\"\"Run Black formatter.\"\"\"\n    212:         if not self.available_tools.get(\"black\", False):\n    213:             return {\"status\": \"skipped\", \"reason\": \"black not available\"}",
    "context": {
      "function_name": "run_black",
      "sequential_functions": [
        "__init__",
        "run_ruff",
        "run_black",
        "run_isort",
        "run_mypy",
        "run_flake8"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 257,
    "column": 4,
    "description": "Sequential coupling detected: Function 'run_isort' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    254:         except Exception as e:\n    255:             return {\"status\": \"error\", \"error\": str(e)}\n    256: \n>>> 257:     def run_isort(self, files: list[Path] = None, check_only: bool = True) -> dict[str, Any]:\n    258:         \"\"\"Run isort import sorting.\"\"\"\n    259:         if not self.available_tools.get(\"isort\", False):\n    260:             return {\"status\": \"skipped\", \"reason\": \"isort not available\"}",
    "context": {
      "function_name": "run_isort",
      "sequential_functions": [
        "__init__",
        "run_ruff",
        "run_black",
        "run_isort",
        "run_mypy",
        "run_flake8"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 295,
    "column": 4,
    "description": "Sequential coupling detected: Function 'run_mypy' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    292:         except Exception as e:\n    293:             return {\"status\": \"error\", \"error\": str(e)}\n    294: \n>>> 295:     def run_mypy(self, files: list[Path] = None) -> dict[str, Any]:\n    296:         \"\"\"Run mypy type checking.\"\"\"\n    297:         if not self.available_tools.get(\"mypy\", False):\n    298:             return {\"status\": \"skipped\", \"reason\": \"mypy not available\"}",
    "context": {
      "function_name": "run_mypy",
      "sequential_functions": [
        "__init__",
        "run_ruff",
        "run_black",
        "run_isort",
        "run_mypy",
        "run_flake8"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\linting\\lint.py",
    "line_number": 331,
    "column": 4,
    "description": "Sequential coupling detected: Function 'run_flake8' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    328:         except Exception as e:\n    329:             return {\"status\": \"error\", \"error\": str(e)}\n    330: \n>>> 331:     def run_flake8(self, files: list[Path] = None) -> dict[str, Any]:\n    332:         \"\"\"Run flake8 linting.\"\"\"\n    333:         if not self.available_tools.get(\"flake8\", False):\n    334:             return {\"status\": \"skipped\", \"reason\": \"flake8 not available\"}",
    "context": {
      "function_name": "run_flake8",
      "sequential_functions": [
        "__init__",
        "run_ruff",
        "run_black",
        "run_isort",
        "run_mypy",
        "run_flake8"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\p2p\\hw_probe.py",
    "line_number": 135,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    132:             powershell_cmd = [\n    133:                 \"powershell\",\n    134:                 \"-Command\",\n>>> 135:                 \"Get-PnpDevice -Class Bluetooth -Status OK | Select-Object FriendlyName, Status\",\n    136:             ]\n    137: \n    138:             result = await self._run_command_timeout(powershell_cmd, timeout=5)",
    "context": {
      "query_preview": "Get-PnpDevice -Class Bluetooth -Status OK | Select-Object FriendlyName, Status"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\p2p\\hw_probe.py",
    "line_number": 149,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    146:             service_cmd = [\n    147:                 \"powershell\",\n    148:                 \"-Command\",\n>>> 149:                 'Get-Service -Name \"bthserv\" | Select-Object Status',\n    150:             ]\n    151: \n    152:             service_result = await self._run_command_timeout(service_cmd, timeout=3)",
    "context": {
      "query_preview": "Get-Service -Name \"bthserv\" | Select-Object Status"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\p2p\\hw_probe.py",
    "line_number": 361,
    "column": 4,
    "description": "Method '_determine_hardware_status' is too complex: 13 complexity, 48 lines, 9 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    358:             logger.debug(f\"Command error: {' '.join(command)} - {e}\")\n    359:             return None\n    360: \n>>> 361:     def _determine_hardware_status(self):\n    362:         \"\"\"Determine overall hardware status and recommendations\"\"\"\n    363:         bluetooth_ok = self.results[\"bluetooth\"].get(\"available\", False)\n    364:         wifi_ok = self.results[\"wifi\"].get(\"available\", False)",
    "context": {
      "complexity": 13,
      "lines": 48,
      "max_nesting": 9,
      "method_name": "_determine_hardware_status"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\p2p\\hw_probe.py",
    "line_number": 412,
    "column": 0,
    "description": "Method 'print_hardware_status' is too complex: 6 complexity, 17 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    409:                 self.results[\"summary\"][\"reason\"] = \"Bluetooth available but no WiFi for Betanet\"\n    410: \n    411: \n>>> 412: def print_hardware_status(results: dict[str, Any], verbose: bool = False):\n    413:     \"\"\"Print hardware status in required format\"\"\"\n    414:     hardware_ok = results[\"summary\"][\"hardware_ok\"]\n    415: ",
    "context": {
      "complexity": 6,
      "lines": 17,
      "max_nesting": 5,
      "method_name": "print_hardware_status"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\p2p\\hw_probe.py",
    "line_number": 432,
    "column": 0,
    "description": "Method 'print_detailed_report' is too complex: 14 complexity, 72 lines, 12 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    429:                     print(f\"# Suggestion: {rec}\")\n    430: \n    431: \n>>> 432: def print_detailed_report(results: dict[str, Any]):\n    433:     \"\"\"Print detailed hardware report\"\"\"\n    434:     print(\"\\n\" + \"=\" * 60)\n    435:     print(\"BitChat/Betanet Hardware Probe Report\")",
    "context": {
      "complexity": 14,
      "lines": 72,
      "max_nesting": 12,
      "method_name": "print_detailed_report"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\p2p\\hw_probe.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'platform' methods (11 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "platform",
      "method_count": 11,
      "methods": [
        "system",
        "version",
        "architecture"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\p2p\\hw_probe.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (25 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 25,
      "methods": [
        "_probe_network_interfaces",
        "_run_all_probes",
        "_probe_bluetooth_windows",
        "_test_bluetooth_discovery",
        "_probe_bluetooth_macos",
        "_probe_wifi_windows",
        "_determine_hardware_status",
        "_run_command_timeout",
        "_probe_wifi",
        "_probe_bluetooth_linux",
        "_probe_bluetooth",
        "_probe_wifi_linux",
        "_probe_wifi_macos"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\p2p\\hw_probe.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (20 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 20,
      "methods": [
        "warning",
        "error",
        "debug"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\p2p\\hw_probe.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'result' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "result",
      "method_count": 9,
      "methods": [
        "split",
        "strip",
        "lower"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\p2p\\hw_probe.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'line' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "line",
      "method_count": 10,
      "methods": [
        "split",
        "strip",
        "startswith",
        "lower"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\p2p\\hw_probe.py",
    "line_number": 113,
    "column": 76,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    110:         \"\"\"Linux-specific Bluetooth detection\"\"\"\n    111:         try:\n    112:             # Check for Bluetooth adapters via hciconfig\n>>> 113:             result = await self._run_command_timeout([\"hciconfig\"], timeout=3)\n    114:             if result and \"hci\" in result.lower():\n    115:                 self.results[\"bluetooth\"][\"adapter_present\"] = True\n    116:                 self.results[\"bluetooth\"][\"details\"][\"hciconfig\"] = result[:200]",
    "context": {
      "total_magic_literals": 21,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\p2p\\hw_probe.py",
    "line_number": 116,
    "column": 76,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    113:             result = await self._run_command_timeout([\"hciconfig\"], timeout=3)\n    114:             if result and \"hci\" in result.lower():\n    115:                 self.results[\"bluetooth\"][\"adapter_present\"] = True\n>>> 116:                 self.results[\"bluetooth\"][\"details\"][\"hciconfig\"] = result[:200]\n    117:             else:\n    118:                 self.results[\"bluetooth\"][\"adapter_present\"] = False\n    119: ",
    "context": {
      "total_magic_literals": 21,
      "current_value": 200
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\p2p\\hw_probe.py",
    "line_number": 138,
    "column": 77,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    135:                 \"Get-PnpDevice -Class Bluetooth -Status OK | Select-Object FriendlyName, Status\",\n    136:             ]\n    137: \n>>> 138:             result = await self._run_command_timeout(powershell_cmd, timeout=5)\n    139:             if result and \"bluetooth\" in result.lower():\n    140:                 self.results[\"bluetooth\"][\"adapter_present\"] = True\n    141:                 self.results[\"bluetooth\"][\"details\"][\"adapters\"] = result[:300]",
    "context": {
      "total_magic_literals": 21,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\p2p\\hw_probe.py",
    "line_number": 141,
    "column": 75,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    138:             result = await self._run_command_timeout(powershell_cmd, timeout=5)\n    139:             if result and \"bluetooth\" in result.lower():\n    140:                 self.results[\"bluetooth\"][\"adapter_present\"] = True\n>>> 141:                 self.results[\"bluetooth\"][\"details\"][\"adapters\"] = result[:300]\n    142:             else:\n    143:                 self.results[\"bluetooth\"][\"adapter_present\"] = False\n    144: ",
    "context": {
      "total_magic_literals": 21,
      "current_value": 300
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\p2p\\hw_probe.py",
    "line_number": 152,
    "column": 82,
    "description": "Excessive magic literals detected (21 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    149:                 'Get-Service -Name \"bthserv\" | Select-Object Status',\n    150:             ]\n    151: \n>>> 152:             service_result = await self._run_command_timeout(service_cmd, timeout=3)\n    153:             if service_result:\n    154:                 self.results[\"bluetooth\"][\"details\"][\"service_status\"] = service_result.strip()\n    155: ",
    "context": {
      "total_magic_literals": 21,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\scripts\\demonstrate_cleanup.py",
    "line_number": 9,
    "column": 0,
    "description": "Method 'demonstrate_cleanup' is too complex: 5 complexity, 108 lines, 4 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "      6: from pathlib import Path\n      7: \n      8: \n>>>   9: def demonstrate_cleanup() -> None:\n     10:     base_path = Path.cwd()\n     11: \n     12:     print(\"=== AIVillage Documentation Cleanup Demonstration ===\\n\")",
    "context": {
      "complexity": 5,
      "lines": 108,
      "max_nesting": 4,
      "method_name": "demonstrate_cleanup"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\demonstrate_cleanup.py",
    "line_number": 19,
    "column": 10,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     16:     print(\"   - Root level: 50+ report/summary files\")\n     17:     print(\"   - docs/: 80+ scattered markdown files\")\n     18:     print(\"   - Hidden dirs: .claude_cleanup/, .cleanup_analysis/, etc.\")\n>>>  19:     print(\"   - Duplicates: README_backup.md, README_updated.md, etc.\\n\")\n     20: \n     21:     # Step 2: Show new structure created\n     22:     print(\"2. NEW STRUCTURE CREATED:\")",
    "context": {
      "query_preview": "   - Duplicates: README_backup.md, README_updated.md, etc.\n"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\demonstrate_cleanup.py",
    "line_number": 22,
    "column": 10,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     19:     print(\"   - Duplicates: README_backup.md, README_updated.md, etc.\\n\")\n     20: \n     21:     # Step 2: Show new structure created\n>>>  22:     print(\"2. NEW STRUCTURE CREATED:\")\n     23:     dirs_created = [\n     24:         \"docs/architecture/\",\n     25:         \"docs/guides/\",",
    "context": {
      "query_preview": "2. NEW STRUCTURE CREATED:"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\demonstrate_cleanup.py",
    "line_number": 90,
    "column": 10,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     87:     print(\"   \ud83d\uddc2\ufe0f  Organize ~80 docs/ files into categories\")\n     88:     print(\"   \ud83d\uddd1\ufe0f  Remove 5+ duplicate README variants\")\n     89:     print(\"   \ud83e\uddf9 Clean 5 hidden directories\")\n>>>  90:     print(\"   \ud83d\udd17 Update cross-references and links\\n\")\n     91: \n     92:     # Step 6: Show benefits\n     93:     print(\"6. BENEFITS ACHIEVED:\")",
    "context": {
      "query_preview": "   \ud83d\udd17 Update cross-references and links\n"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\demonstrate_cleanup.py",
    "line_number": 95,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     92:     # Step 6: Show benefits\n     93:     print(\"6. BENEFITS ACHIEVED:\")\n     94:     benefits = [\n>>>  95:         \"Reduced from 218+ scattered files to organized hierarchy\",\n     96:         \"Clear navigation with categorical structure\",\n     97:         \"Historical documentation preserved in archive\",\n     98:         \"Improved discoverability and maintainability\",",
    "context": {
      "query_preview": "Reduced from 218+ scattered files to organized hierarchy"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\demonstrate_cleanup.py",
    "line_number": 108,
    "column": 10,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    105: \n    106:     print(\"7. EXECUTION STATUS:\")\n    107:     print(\"   \u2705 Structure design complete\")\n>>> 108:     print(\"   \u2705 Master index created\")\n    109:     print(\"   \u2705 Directory READMEs created\")\n    110:     print(\"   \u2705 Categorization strategy defined\")\n    111:     print(\"   \u23f3 File moves pending (use cleanup_documentation.py)\")",
    "context": {
      "query_preview": "   \u2705 Master index created"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\demonstrate_cleanup.py",
    "line_number": 109,
    "column": 10,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    106:     print(\"7. EXECUTION STATUS:\")\n    107:     print(\"   \u2705 Structure design complete\")\n    108:     print(\"   \u2705 Master index created\")\n>>> 109:     print(\"   \u2705 Directory READMEs created\")\n    110:     print(\"   \u2705 Categorization strategy defined\")\n    111:     print(\"   \u23f3 File moves pending (use cleanup_documentation.py)\")\n    112:     print(\"   \u23f3 Duplicate removal pending\")",
    "context": {
      "query_preview": "   \u2705 Directory READMEs created"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\scripts\\deploy_production.py",
    "line_number": 55,
    "column": 16,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     52:             try:\n     53:                 with open(config_file) as f:\n     54:                     user_config = json.load(f)\n>>>  55:                 default_config.update(user_config)\n     56:             except Exception as e:\n     57:                 logger.warning(f\"Failed to load config from {config_file}: {e}\")\n     58: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\deploy_production.py",
    "line_number": 57,
    "column": 33,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     54:                     user_config = json.load(f)\n     55:                 default_config.update(user_config)\n     56:             except Exception as e:\n>>>  57:                 logger.warning(f\"Failed to load config from {config_file}: {e}\")\n     58: \n     59:         return default_config\n     60: ",
    "context": {
      "query_preview": "Failed to load config from "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\deploy_production.py",
    "line_number": 141,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    138:         return True\n    139: \n    140:     def create_namespace(self) -> bool:\n>>> 141:         \"\"\"Create Kubernetes namespace if it doesn't exist.\"\"\"\n    142:         logger.info(f\"\ud83d\udce6 Ensuring namespace {self.config['namespace']} exists...\")\n    143: \n    144:         # Check if namespace exists",
    "context": {
      "query_preview": "Create Kubernetes namespace if it doesn't exist."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\deploy_production.py",
    "line_number": 151,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    148:             # Create namespace\n    149:             returncode, _, _ = self.run_command([\"kubectl\", \"create\", \"namespace\", self.config[\"namespace\"]])\n    150:             if returncode != 0:\n>>> 151:                 logger.error(f\"Failed to create namespace {self.config['namespace']}\")\n    152:                 return False\n    153:             logger.info(f\"\u2705 Created namespace: {self.config['namespace']}\")\n    154:         else:",
    "context": {
      "query_preview": "Failed to create namespace "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\deploy_production.py",
    "line_number": 153,
    "column": 26,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    150:             if returncode != 0:\n    151:                 logger.error(f\"Failed to create namespace {self.config['namespace']}\")\n    152:                 return False\n>>> 153:             logger.info(f\"\u2705 Created namespace: {self.config['namespace']}\")\n    154:         else:\n    155:             logger.info(f\"\u2705 Namespace {self.config['namespace']} already exists\")\n    156: ",
    "context": {
      "query_preview": "\u2705 Created namespace: "
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\scripts\\deploy_production.py",
    "line_number": 206,
    "column": 4,
    "description": "Method 'wait_for_deployment' is too complex: 8 complexity, 46 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    203:         logger.info(\"\u2705 Helm deployment successful\")\n    204:         return True\n    205: \n>>> 206:     def wait_for_deployment(self) -> bool:\n    207:         \"\"\"Wait for deployment to be ready.\"\"\"\n    208:         logger.info(\"\u23f3 Waiting for deployment to be ready...\")\n    209: ",
    "context": {
      "complexity": 8,
      "lines": 46,
      "max_nesting": 5,
      "method_name": "wait_for_deployment"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\scripts\\deploy_production.py",
    "line_number": 334,
    "column": 4,
    "description": "Method 'deploy' is too complex: 12 complexity, 44 lines, 10 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    331:         logger.info(\"\u2705 Cleanup completed\")\n    332:         return True\n    333: \n>>> 334:     def deploy(self) -> bool:\n    335:         \"\"\"Run the complete deployment process.\"\"\"\n    336:         logger.info(f\"\ud83d\ude80 Starting deployment to {self.environment}\")\n    337: ",
    "context": {
      "complexity": 12,
      "lines": 44,
      "max_nesting": 10,
      "method_name": "deploy"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\scripts\\deploy_production.py",
    "line_number": 380,
    "column": 4,
    "description": "Method 'get_deployment_status' is too complex: 5 complexity, 54 lines, 2 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    377: \n    378:             return False\n    379: \n>>> 380:     def get_deployment_status(self) -> dict[str, Any]:\n    381:         \"\"\"Get current deployment status.\"\"\"\n    382:         logger.info(\"\ud83d\udcca Getting deployment status...\")\n    383: ",
    "context": {
      "complexity": 5,
      "lines": 54,
      "max_nesting": 2,
      "method_name": "get_deployment_status"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\deploy_production.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (25 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 25,
      "methods": [
        "check_prerequisites",
        "build_image",
        "run_command",
        "cleanup_old_resources",
        "deploy_helm_chart",
        "load_environment_config",
        "wait_for_deployment",
        "run_health_checks",
        "create_namespace",
        "rollback_deployment"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\deploy_production.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'json' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "json",
      "method_count": 6,
      "methods": [
        "dumps",
        "load",
        "loads"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\deploy_production.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (42 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 42,
      "methods": [
        "error",
        "info",
        "warning",
        "exception"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\deploy_production.py",
    "line_number": 25,
    "column": 4,
    "description": "Sequential coupling detected: Function '__init__' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     22: class ProductionDeployer:\n     23:     \"\"\"Production deployment orchestrator.\"\"\"\n     24: \n>>>  25:     def __init__(self, environment: str, project_root: Path | None = None) -> None:\n     26:         self.environment = environment\n     27:         self.project_root = project_root or Path.cwd()\n     28:         self.deploy_dir = self.project_root / \"deploy\"",
    "context": {
      "function_name": "__init__",
      "sequential_functions": [
        "__init__",
        "run_command",
        "run_health_checks",
        "cleanup_old_resources"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\deploy_production.py",
    "line_number": 61,
    "column": 4,
    "description": "Sequential coupling detected: Function 'run_command' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     58: \n     59:         return default_config\n     60: \n>>>  61:     def run_command(self, cmd: list[str], check: bool = True, timeout: int = 300) -> tuple[int, str, str]:\n     62:         \"\"\"Run a command with error handling.\"\"\"\n     63:         logger.info(f\"Running: {' '.join(cmd)}\")\n     64:         try:",
    "context": {
      "function_name": "run_command",
      "sequential_functions": [
        "__init__",
        "run_command",
        "run_health_checks",
        "cleanup_old_resources"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\deploy_production.py",
    "line_number": 254,
    "column": 4,
    "description": "Sequential coupling detected: Function 'run_health_checks' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    251:         logger.error(f\"Deployment not ready after {timeout} seconds\")\n    252:         return False\n    253: \n>>> 254:     def run_health_checks(self) -> bool:\n    255:         \"\"\"Run comprehensive health checks.\"\"\"\n    256:         logger.info(\"\ud83d\udd0d Running health checks...\")\n    257: ",
    "context": {
      "function_name": "run_health_checks",
      "sequential_functions": [
        "__init__",
        "run_command",
        "run_health_checks",
        "cleanup_old_resources"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\deploy_production.py",
    "line_number": 313,
    "column": 4,
    "description": "Sequential coupling detected: Function 'cleanup_old_resources' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    310:         logger.info(\"\u2705 Rollback completed\")\n    311:         return True\n    312: \n>>> 313:     def cleanup_old_resources(self) -> bool:\n    314:         \"\"\"Clean up old deployment resources.\"\"\"\n    315:         logger.info(\"\ud83e\uddf9 Cleaning up old resources...\")\n    316: ",
    "context": {
      "function_name": "cleanup_old_resources",
      "sequential_functions": [
        "__init__",
        "run_command",
        "run_health_checks",
        "cleanup_old_resources"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\scripts\\execute_cleanup.py",
    "line_number": 37,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     34: \n     35:     # If subprocess fails, try importing and running directly\n     36:     try:\n>>>  37:         sys.path.insert(0, str(PROJECT_ROOT))\n     38:         from cleanup_documentation import DocumentationCleanup\n     39: \n     40:         print(\"Running cleanup directly...\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\scripts\\setup_dev_env.py",
    "line_number": 67,
    "column": 4,
    "description": "Method 'install_dependencies' is too complex: 7 complexity, 25 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     64: \n     65:         return status\n     66: \n>>>  67:     def install_dependencies(self) -> bool:\n     68:         \"\"\"Install project dependencies.\"\"\"\n     69:         logger.info(\"Installing dependencies...\")\n     70: ",
    "context": {
      "complexity": 7,
      "lines": 25,
      "max_nesting": 5,
      "method_name": "install_dependencies"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\setup_dev_env.py",
    "line_number": 95,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     92:         return True\n     93: \n     94:     def setup_directories(self) -> bool:\n>>>  95:         \"\"\"Create necessary directory structure.\"\"\"\n     96:         logger.info(\"Setting up directory structure...\")\n     97: \n     98:         directories = [",
    "context": {
      "query_preview": "Create necessary directory structure."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\setup_dev_env.py",
    "line_number": 116,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    113:         return True\n    114: \n    115:     def create_env_file(self) -> bool:\n>>> 116:         \"\"\"Create .env file if it doesn't exist.\"\"\"\n    117:         env_file = self.project_root / \".env\"\n    118:         if env_file.exists():\n    119:             logger.info(\".env file already exists\")",
    "context": {
      "query_preview": "Create .env file if it doesn't exist."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\setup_dev_env.py",
    "line_number": 145,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    142: \"\"\"\n    143: \n    144:         env_file.write_text(env_content)\n>>> 145:         logger.info(\"Created .env file - please update with your API keys\")\n    146:         return True\n    147: \n    148:     def validate_setup(self) -> bool:",
    "context": {
      "query_preview": "Created .env file - please update with your API keys"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\scripts\\setup_dev_env.py",
    "line_number": 180,
    "column": 4,
    "description": "Method 'run_setup' is too complex: 8 complexity, 27 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    177: \n    178:         return True\n    179: \n>>> 180:     def run_setup(self, skip_deps: bool = False, skip_validation: bool = False) -> bool:\n    181:         \"\"\"Run the complete setup process.\"\"\"\n    182:         logger.info(\"Starting development environment setup...\")\n    183: ",
    "context": {
      "complexity": 8,
      "lines": 27,
      "max_nesting": 5,
      "method_name": "run_setup"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\setup_dev_env.py",
    "line_number": 203,
    "column": 20,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    200: \n    201:         logger.info(\"\u2705 Development environment setup complete!\")\n    202:         logger.info(\"Next steps:\")\n>>> 203:         logger.info(\"1. Update .env file with your API keys\")\n    204:         logger.info(\"2. Run 'make test' to verify everything works\")\n    205:         logger.info(\"3. Run 'make dev-up' to start development services\")\n    206: ",
    "context": {
      "query_preview": "1. Update .env file with your API keys"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\setup_dev_env.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (31 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 31,
      "methods": [
        "exception",
        "warning",
        "debug",
        "info",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\setup_dev_env.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (9 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 9,
      "methods": [
        "validate_setup",
        "create_env_file",
        "run_command",
        "check_python_version",
        "install_dependencies",
        "check_gpu_cuda",
        "setup_directories"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\setup_dev_env.py",
    "line_number": 20,
    "column": 4,
    "description": "Sequential coupling detected: Function '__init__' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     17: class DevEnvironmentSetup:\n     18:     \"\"\"Development environment setup and validation.\"\"\"\n     19: \n>>>  20:     def __init__(self, project_root: Path | None = None) -> None:\n     21:         self.project_root = project_root or Path.cwd()\n     22:         self.requirements_files = [\n     23:             \"requirements.txt\",",
    "context": {
      "function_name": "__init__",
      "sequential_functions": [
        "__init__",
        "run_command",
        "setup_directories",
        "validate_setup",
        "run_setup"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\setup_dev_env.py",
    "line_number": 28,
    "column": 4,
    "description": "Sequential coupling detected: Function 'run_command' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     25:             \"pyproject.toml\",\n     26:         ]\n     27: \n>>>  28:     def run_command(self, cmd: list[str], check: bool = True) -> tuple[int, str, str]:\n     29:         \"\"\"Run a command and return (returncode, stdout, stderr).\"\"\"\n     30:         logger.info(f\"Running: {' '.join(cmd)}\")\n     31:         try:",
    "context": {
      "function_name": "run_command",
      "sequential_functions": [
        "__init__",
        "run_command",
        "setup_directories",
        "validate_setup",
        "run_setup"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\setup_dev_env.py",
    "line_number": 94,
    "column": 4,
    "description": "Sequential coupling detected: Function 'setup_directories' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     91: \n     92:         return True\n     93: \n>>>  94:     def setup_directories(self) -> bool:\n     95:         \"\"\"Create necessary directory structure.\"\"\"\n     96:         logger.info(\"Setting up directory structure...\")\n     97: ",
    "context": {
      "function_name": "setup_directories",
      "sequential_functions": [
        "__init__",
        "run_command",
        "setup_directories",
        "validate_setup",
        "run_setup"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\setup_dev_env.py",
    "line_number": 148,
    "column": 4,
    "description": "Sequential coupling detected: Function 'validate_setup' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    145:         logger.info(\"Created .env file - please update with your API keys\")\n    146:         return True\n    147: \n>>> 148:     def validate_setup(self) -> bool:\n    149:         \"\"\"Validate the complete setup.\"\"\"\n    150:         logger.info(\"Validating setup...\")\n    151: ",
    "context": {
      "function_name": "validate_setup",
      "sequential_functions": [
        "__init__",
        "run_command",
        "setup_directories",
        "validate_setup",
        "run_setup"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\setup_dev_env.py",
    "line_number": 180,
    "column": 4,
    "description": "Sequential coupling detected: Function 'run_setup' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    177: \n    178:         return True\n    179: \n>>> 180:     def run_setup(self, skip_deps: bool = False, skip_validation: bool = False) -> bool:\n    181:         \"\"\"Run the complete setup process.\"\"\"\n    182:         logger.info(\"Starting development environment setup...\")\n    183: ",
    "context": {
      "function_name": "run_setup",
      "sequential_functions": [
        "__init__",
        "run_command",
        "setup_directories",
        "validate_setup",
        "run_setup"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\scripts\\__init__.py",
    "line_number": 1,
    "column": 0,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": ">>>   1: \"\"\"AIVillage Tools - Scripts.\n      2: \n      3: Development and utility scripts moved from root/scripts/:\n      4: - Performance monitoring",
    "context": {
      "query_preview": "AIVillage Tools - Scripts.\n\nDevelopment and utility scripts moved from root/scripts/:\n- Performance ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 127,
    "column": 4,
    "description": "Method 'validate_json_field' is too complex: 13 complexity, 28 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    124: class TestInputValidation(unittest.TestCase):\n    125:     \"\"\"Test input validation and sanitization.\"\"\"\n    126: \n>>> 127:     def validate_json_field(self, value, field_rules):\n    128:         \"\"\"Basic JSON field validation.\"\"\"\n    129:         # Check required\n    130:         if field_rules.get(\"required\", False) and value is None:",
    "context": {
      "complexity": 13,
      "lines": 28,
      "max_nesting": 8,
      "method_name": "validate_json_field"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 370,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    367:     \"\"\"Test database security configurations.\"\"\"\n    368: \n    369:     def create_secure_connection(self, db_path: str):\n>>> 370:         \"\"\"Create secure SQLite connection with proper settings.\"\"\"\n    371:         conn = sqlite3.connect(db_path, timeout=30.0, isolation_level=None)\n    372: \n    373:         # Security and performance settings",
    "context": {
      "query_preview": "Create secure SQLite connection with proper settings."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 374,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    371:         conn = sqlite3.connect(db_path, timeout=30.0, isolation_level=None)\n    372: \n    373:         # Security and performance settings\n>>> 374:         conn.execute(\"PRAGMA journal_mode=WAL\")\n    375:         conn.execute(\"PRAGMA synchronous=NORMAL\")\n    376:         conn.execute(\"PRAGMA foreign_keys=ON\")\n    377:         conn.execute(\"PRAGMA temp_store=MEMORY\")",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 375,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    372: \n    373:         # Security and performance settings\n    374:         conn.execute(\"PRAGMA journal_mode=WAL\")\n>>> 375:         conn.execute(\"PRAGMA synchronous=NORMAL\")\n    376:         conn.execute(\"PRAGMA foreign_keys=ON\")\n    377:         conn.execute(\"PRAGMA temp_store=MEMORY\")\n    378: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 376,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    373:         # Security and performance settings\n    374:         conn.execute(\"PRAGMA journal_mode=WAL\")\n    375:         conn.execute(\"PRAGMA synchronous=NORMAL\")\n>>> 376:         conn.execute(\"PRAGMA foreign_keys=ON\")\n    377:         conn.execute(\"PRAGMA temp_store=MEMORY\")\n    378: \n    379:         return conn",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 377,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    374:         conn.execute(\"PRAGMA journal_mode=WAL\")\n    375:         conn.execute(\"PRAGMA synchronous=NORMAL\")\n    376:         conn.execute(\"PRAGMA foreign_keys=ON\")\n>>> 377:         conn.execute(\"PRAGMA temp_store=MEMORY\")\n    378: \n    379:         return conn\n    380: ",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 387,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    384:             conn = self.create_secure_connection(temp_db.name)\n    385: \n    386:             # Create test table\n>>> 387:             conn.execute(\n    388:                 \"\"\"\n    389:                 CREATE TABLE users (\n    390:                     id INTEGER PRIMARY KEY,",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 388,
    "column": 16,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    385: \n    386:             # Create test table\n    387:             conn.execute(\n>>> 388:                 \"\"\"\n    389:                 CREATE TABLE users (\n    390:                     id INTEGER PRIMARY KEY,\n    391:                     username TEXT NOT NULL,",
    "context": {
      "query_preview": "\n                CREATE TABLE users (\n                    id INTEGER PRIMARY KEY,\n                  ..."
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 400,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    397:             # Test parameterized insert (safe)\n    398:             username = \"test_user\"\n    399:             email = \"test@example.com\"\n>>> 400:             conn.execute(\"INSERT INTO users (username, email) VALUES (?, ?)\", (username, email))\n    401: \n    402:             # Test parameterized select (safe)\n    403:             cursor = conn.execute(\"SELECT * FROM users WHERE username = ?\", (username,))",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 400,
    "column": 25,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    397:             # Test parameterized insert (safe)\n    398:             username = \"test_user\"\n    399:             email = \"test@example.com\"\n>>> 400:             conn.execute(\"INSERT INTO users (username, email) VALUES (?, ?)\", (username, email))\n    401: \n    402:             # Test parameterized select (safe)\n    403:             cursor = conn.execute(\"SELECT * FROM users WHERE username = ?\", (username,))",
    "context": {
      "query_preview": "INSERT INTO users (username, email) VALUES (?, ?)"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 403,
    "column": 21,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    400:             conn.execute(\"INSERT INTO users (username, email) VALUES (?, ?)\", (username, email))\n    401: \n    402:             # Test parameterized select (safe)\n>>> 403:             cursor = conn.execute(\"SELECT * FROM users WHERE username = ?\", (username,))\n    404:             result = cursor.fetchone()\n    405: \n    406:             self.assertIsNotNone(result)",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 403,
    "column": 34,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    400:             conn.execute(\"INSERT INTO users (username, email) VALUES (?, ?)\", (username, email))\n    401: \n    402:             # Test parameterized select (safe)\n>>> 403:             cursor = conn.execute(\"SELECT * FROM users WHERE username = ?\", (username,))\n    404:             result = cursor.fetchone()\n    405: \n    406:             self.assertIsNotNone(result)",
    "context": {
      "query_preview": "SELECT * FROM users WHERE username = ?"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 420,
    "column": 12,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    417:         try:\n    418:             # Create database\n    419:             conn = self.create_secure_connection(db_path)\n>>> 420:             conn.execute(\"CREATE TABLE test (id INTEGER)\")\n    421:             conn.close()\n    422: \n    423:             # Check file exists",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 420,
    "column": 25,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    417:         try:\n    418:             # Create database\n    419:             conn = self.create_secure_connection(db_path)\n>>> 420:             conn.execute(\"CREATE TABLE test (id INTEGER)\")\n    421:             conn.close()\n    422: \n    423:             # Check file exists",
    "context": {
      "query_preview": "CREATE TABLE test (id INTEGER)"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (76 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 76,
      "methods": [
        "assertIsInstance",
        "assertNotIn",
        "check_compliance_requirements",
        "get_security_headers",
        "create_secure_connection",
        "validate_json_field",
        "assertRaises",
        "assertTrue",
        "assertFalse",
        "is_rate_limited",
        "sanitize_filename",
        "assertIn",
        "hash_password",
        "verify_password",
        "assertGreater",
        "assertNotEqual",
        "assertIsNotNone",
        "assertEqual"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'field_rules' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "field_rules",
      "method_count": 6,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'conn' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "conn",
      "method_count": 10,
      "methods": [
        "close",
        "execute"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 19,
    "column": 27,
    "description": "Excessive magic literals detected (45 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     16: # Test the encryption key generation\n     17: def generate_encryption_key() -> str:\n     18:     \"\"\"Generate a new 32-byte base64-encoded encryption key.\"\"\"\n>>>  19:     key_bytes = os.urandom(32)\n     20:     return base64.b64encode(key_bytes).decode(\"utf-8\")\n     21: \n     22: ",
    "context": {
      "total_magic_literals": 45,
      "current_value": 32
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 35,
    "column": 39,
    "description": "Excessive magic literals detected (45 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     32: \n     33:         # Decoded key should be exactly 32 bytes\n     34:         decoded = base64.b64decode(key)\n>>>  35:         self.assertEqual(len(decoded), 32)\n     36: \n     37:         # Two generated keys should be different\n     38:         key2 = generate_encryption_key()",
    "context": {
      "total_magic_literals": 45,
      "current_value": 32
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 47,
    "column": 43,
    "description": "Excessive magic literals detected (45 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     44:         valid_key = generate_encryption_key()\n     45:         try:\n     46:             decoded = base64.b64decode(valid_key)\n>>>  47:             self.assertEqual(len(decoded), 32)\n     48:             validation_passed = True\n     49:         except Exception:\n     50:             validation_passed = False",
    "context": {
      "total_magic_literals": 45,
      "current_value": 32
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 58,
    "column": 48,
    "description": "Excessive magic literals detected (45 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     55:         invalid_key = base64.b64encode(b\"short\").decode(\"utf-8\")\n     56:         try:\n     57:             decoded = base64.b64decode(invalid_key)\n>>>  58:             validation_passed = len(decoded) == 32\n     59:         except Exception:\n     60:             validation_passed = False\n     61: ",
    "context": {
      "total_magic_literals": 45,
      "current_value": 32
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\test_security_standalone.py",
    "line_number": 70,
    "column": 26,
    "description": "Excessive magic literals detected (45 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     67: \n     68:     def hash_password(self, password: str):\n     69:         \"\"\"Hash password with salt using PBKDF2.\"\"\"\n>>>  70:         salt = os.urandom(32)\n     71:         password_hash = hashlib.pbkdf2_hmac(\"sha256\", password.encode(\"utf-8\"), salt, 100000)\n     72:         return salt.hex(), password_hash.hex()\n     73: ",
    "context": {
      "total_magic_literals": 45,
      "current_value": 32
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\verify_p2p_security.py",
    "line_number": 24,
    "column": 0,
    "description": "Method 'verify_security_configuration' is too complex: 5 complexity, 56 lines, 3 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     21:     print(\"=\" * 60)\n     22: \n     23: \n>>>  24: def verify_security_configuration():\n     25:     \"\"\"Verify security configuration matches CODEX requirements.\"\"\"\n     26:     print_header(\"SECURITY CONFIGURATION VERIFICATION\")\n     27: ",
    "context": {
      "complexity": 5,
      "lines": 56,
      "max_nesting": 3,
      "method_name": "verify_security_configuration"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\verify_p2p_security.py",
    "line_number": 83,
    "column": 0,
    "description": "Method 'test_message_encryption' is too complex: 10 complexity, 95 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     80:     return True\n     81: \n     82: \n>>>  83: def test_message_encryption():\n     84:     \"\"\"Test message encryption and MAC verification.\"\"\"\n     85:     print_header(\"MESSAGE ENCRYPTION & MAC TESTING\")\n     86: ",
    "context": {
      "complexity": 10,
      "lines": 95,
      "max_nesting": 6,
      "method_name": "test_message_encryption"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\verify_p2p_security.py",
    "line_number": 181,
    "column": 0,
    "description": "Method 'test_peer_reputation_system' is too complex: 10 complexity, 95 lines, 7 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    178:     return False\n    179: \n    180: \n>>> 181: def test_peer_reputation_system():\n    182:     \"\"\"Test peer reputation and blocking mechanisms.\"\"\"\n    183:     print_header(\"PEER REPUTATION SYSTEM TESTING\")\n    184: ",
    "context": {
      "complexity": 10,
      "lines": 95,
      "max_nesting": 7,
      "method_name": "test_peer_reputation_system"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\verify_p2p_security.py",
    "line_number": 279,
    "column": 0,
    "description": "Method 'test_rate_limiting' is too complex: 17 complexity, 103 lines, 14 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    276:     return True\n    277: \n    278: \n>>> 279: def test_rate_limiting():\n    280:     \"\"\"Test rate limiting mechanisms.\"\"\"\n    281:     print_header(\"RATE LIMITING TESTING\")\n    282: ",
    "context": {
      "complexity": 17,
      "lines": 103,
      "max_nesting": 14,
      "method_name": "test_rate_limiting"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\verify_p2p_security.py",
    "line_number": 292,
    "column": 4,
    "description": "Method 'check_rate_limits' is too complex: 7 complexity, 33 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    289:     connection_attempts = {}\n    290:     message_attempts = {}\n    291: \n>>> 292:     def check_rate_limits(peer_id: str, attempt_type: str) -> bool:\n    293:         now = time.time()\n    294: \n    295:         if attempt_type == \"connection\":",
    "context": {
      "complexity": 7,
      "lines": 33,
      "max_nesting": 6,
      "method_name": "check_rate_limits"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\verify_p2p_security.py",
    "line_number": 385,
    "column": 0,
    "description": "Method 'test_replay_attack_prevention' is too complex: 13 complexity, 99 lines, 12 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    382:     return False\n    383: \n    384: \n>>> 385: def test_replay_attack_prevention():\n    386:     \"\"\"Test replay attack prevention mechanisms.\"\"\"\n    387:     print_header(\"REPLAY ATTACK PREVENTION TESTING\")\n    388: ",
    "context": {
      "complexity": 13,
      "lines": 99,
      "max_nesting": 12,
      "method_name": "test_replay_attack_prevention"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\verify_p2p_security.py",
    "line_number": 487,
    "column": 0,
    "description": "Method 'test_security_monitoring' is too complex: 10 complexity, 101 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    484:     return True\n    485: \n    486: \n>>> 487: def test_security_monitoring():\n    488:     \"\"\"Test security event monitoring and alerting.\"\"\"\n    489:     print_header(\"SECURITY MONITORING TESTING\")\n    490: ",
    "context": {
      "complexity": 10,
      "lines": 101,
      "max_nesting": 8,
      "method_name": "test_security_monitoring"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\verify_p2p_security.py",
    "line_number": 564,
    "column": 31,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    561:             {\n    562:                 \"level\": \"high\",\n    563:                 \"title\": \"Coordinated Attack Pattern\",\n>>> 564:                 \"description\": \"Multiple attack types detected from different peers\",\n    565:             },\n    566:         )\n    567: ",
    "context": {
      "query_preview": "Multiple attack types detected from different peers"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\security\\verify_p2p_security.py",
    "line_number": 638,
    "column": 0,
    "description": "Method 'main' is too complex: 5 complexity, 56 lines, 3 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    635:         return False\n    636: \n    637: \n>>> 638: def main():\n    639:     \"\"\"Run all security verification tests.\"\"\"\n    640:     print(\"=\" * 60)\n    641:     print(\"P2P NETWORK SECURITY VERIFICATION\")",
    "context": {
      "complexity": 5,
      "lines": 56,
      "max_nesting": 3,
      "method_name": "main"
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\verify_p2p_security.py",
    "line_number": 19,
    "column": 23,
    "description": "Excessive magic literals detected (42 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     16: \n     17: def print_header(title: str):\n     18:     \"\"\"Print formatted header.\"\"\"\n>>>  19:     print(\"\\n\" + \"=\" * 60)\n     20:     print(title.center(60))\n     21:     print(\"=\" * 60)\n     22: ",
    "context": {
      "total_magic_literals": 42,
      "current_value": 60
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\verify_p2p_security.py",
    "line_number": 20,
    "column": 23,
    "description": "Excessive magic literals detected (42 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     17: def print_header(title: str):\n     18:     \"\"\"Print formatted header.\"\"\"\n     19:     print(\"\\n\" + \"=\" * 60)\n>>>  20:     print(title.center(60))\n     21:     print(\"=\" * 60)\n     22: \n     23: ",
    "context": {
      "total_magic_literals": 42,
      "current_value": 60
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\verify_p2p_security.py",
    "line_number": 21,
    "column": 16,
    "description": "Excessive magic literals detected (42 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     18:     \"\"\"Print formatted header.\"\"\"\n     19:     print(\"\\n\" + \"=\" * 60)\n     20:     print(title.center(60))\n>>>  21:     print(\"=\" * 60)\n     22: \n     23: \n     24: def verify_security_configuration():",
    "context": {
      "total_magic_literals": 42,
      "current_value": 60
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\verify_p2p_security.py",
    "line_number": 88,
    "column": 41,
    "description": "Excessive magic literals detected (42 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     85:     print_header(\"MESSAGE ENCRYPTION & MAC TESTING\")\n     86: \n     87:     # Generate test encryption key\n>>>  88:     encryption_key = secrets.token_bytes(32)\n     89:     print(f\"[OK] Generated 256-bit encryption key: {len(encryption_key)} bytes\")\n     90: \n     91:     # Test payloads of different sizes",
    "context": {
      "total_magic_literals": 42,
      "current_value": 32
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\security\\verify_p2p_security.py",
    "line_number": 94,
    "column": 58,
    "description": "Excessive magic literals detected (42 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     91:     # Test payloads of different sizes\n     92:     test_payloads = [\n     93:         b\"small_message\",\n>>>  94:         b\"medium_length_message_for_testing_encryption\" * 5,\n     95:         b\"large_message_payload_\" * 50,\n     96:         secrets.token_bytes(10000),  # Large random payload\n     97:     ]",
    "context": {
      "total_magic_literals": 42,
      "current_value": 5
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\utlsgen\\calibrate_fingerprint.py",
    "line_number": 2,
    "column": 0,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "      1: #!/usr/bin/env python3\n>>>   2: \"\"\"uTLS Fingerprint Calibrator for Betanet HTX\n      3: \n      4: Captures TLS fingerprints from origin servers and generates templates\n      5: for mimicking legitimate browser traffic patterns.",
    "context": {
      "query_preview": "uTLS Fingerprint Calibrator for Betanet HTX\n\nCaptures TLS fingerprints from origin servers and gener..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\utlsgen\\calibrate_fingerprint.py",
    "line_number": 73,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     70: \n     71: \n     72: class TLSCalibrator:\n>>>  73:     \"\"\"Calibrates TLS fingerprints from target origins.\"\"\"\n     74: \n     75:     def __init__(self):\n     76:         self.fingerprints: dict[str, TLSFingerprint] = {}",
    "context": {
      "query_preview": "Calibrates TLS fingerprints from target origins."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\utlsgen\\calibrate_fingerprint.py",
    "line_number": 80,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     77:         self.templates: dict[str, dict] = {}\n     78: \n     79:     async def capture_fingerprint(self, host: str, port: int = 443) -> TLSFingerprint:\n>>>  80:         \"\"\"Capture TLS fingerprint from target host.\"\"\"\n     81:         logger.info(f\"Capturing TLS fingerprint from {host}:{port}\")\n     82: \n     83:         # Create SSL context that captures handshake details",
    "context": {
      "query_preview": "Capture TLS fingerprint from target host."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\utlsgen\\calibrate_fingerprint.py",
    "line_number": 81,
    "column": 22,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     78: \n     79:     async def capture_fingerprint(self, host: str, port: int = 443) -> TLSFingerprint:\n     80:         \"\"\"Capture TLS fingerprint from target host.\"\"\"\n>>>  81:         logger.info(f\"Capturing TLS fingerprint from {host}:{port}\")\n     82: \n     83:         # Create SSL context that captures handshake details\n     84:         context = ssl.create_default_context()",
    "context": {
      "query_preview": "Capturing TLS fingerprint from "
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\tools\\utlsgen\\calibrate_fingerprint.py",
    "line_number": 188,
    "column": 4,
    "description": "Method 'generate_utls_template' is too complex: 2 complexity, 139 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    185: \n    186:         return fingerprint\n    187: \n>>> 188:     def generate_utls_template(self, browser: str = \"chrome\", version: str = \"120\") -> dict:\n    189:         \"\"\"Generate uTLS template for specific browser.\"\"\"\n    190:         logger.info(f\"Generating uTLS template for {browser} {version}\")\n    191: ",
    "context": {
      "complexity": 2,
      "lines": 139,
      "max_nesting": 1,
      "method_name": "generate_utls_template"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\utlsgen\\calibrate_fingerprint.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 6,
      "methods": [
        "_calculate_similarity",
        "generate_utls_template",
        "compare_fingerprints",
        "capture_fingerprint",
        "_analyze_handshake"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\utlsgen\\calibrate_fingerprint.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'calibrator' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "calibrator",
      "method_count": 6,
      "methods": [
        "save_calibration",
        "generate_utls_template",
        "capture_fingerprint",
        "run_selftest"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\utlsgen\\calibrate_fingerprint.py",
    "line_number": 64,
    "column": 113,
    "description": "Excessive magic literals detected (145 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     61:         alpn = \"h2\" if \"h2\" in self.alpn_protocols else \"h1\"\n     62: \n     63:         # Create hash of ciphers and extensions\n>>>  64:         cipher_hash = hashlib.sha256(\",\".join(str(c) for c in sorted(self.cipher_suites)).encode()).hexdigest()[:12]\n     65: \n     66:         ext_hash = hashlib.sha256(\",\".join(str(e) for e in sorted(self.extensions)).encode()).hexdigest()[:12]\n     67: ",
    "context": {
      "total_magic_literals": 145,
      "current_value": 12
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\utlsgen\\calibrate_fingerprint.py",
    "line_number": 66,
    "column": 107,
    "description": "Excessive magic literals detected (145 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     63:         # Create hash of ciphers and extensions\n     64:         cipher_hash = hashlib.sha256(\",\".join(str(c) for c in sorted(self.cipher_suites)).encode()).hexdigest()[:12]\n     65: \n>>>  66:         ext_hash = hashlib.sha256(\",\".join(str(e) for e in sorted(self.extensions)).encode()).hexdigest()[:12]\n     67: \n     68:         ja4_string = f\"t{tls_str}{sni}{num_ciphers}{num_ext}{alpn}_{cipher_hash}_{ext_hash}\"\n     69:         return ja4_string",
    "context": {
      "total_magic_literals": 145,
      "current_value": 12
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\utlsgen\\calibrate_fingerprint.py",
    "line_number": 79,
    "column": 63,
    "description": "Excessive magic literals detected (145 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     76:         self.fingerprints: dict[str, TLSFingerprint] = {}\n     77:         self.templates: dict[str, dict] = {}\n     78: \n>>>  79:     async def capture_fingerprint(self, host: str, port: int = 443) -> TLSFingerprint:\n     80:         \"\"\"Capture TLS fingerprint from target host.\"\"\"\n     81:         logger.info(f\"Capturing TLS fingerprint from {host}:{port}\")\n     82: ",
    "context": {
      "total_magic_literals": 145,
      "current_value": 443
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\utlsgen\\calibrate_fingerprint.py",
    "line_number": 115,
    "column": 24,
    "description": "Excessive magic literals detected (145 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    112:             ja3_hash=\"\",\n    113:             ja4_string=\"\",\n    114:             ja4_hash=\"\",\n>>> 115:             tls_version=0x0303 if \"1.2\" in version else 0x0304,  # TLS 1.2 or 1.3\n    116:             cipher_suites=[\n    117:                 0x1301,\n    118:                 0x1302,",
    "context": {
      "total_magic_literals": 145,
      "current_value": 771
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\tools\\utlsgen\\calibrate_fingerprint.py",
    "line_number": 115,
    "column": 56,
    "description": "Excessive magic literals detected (145 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    112:             ja3_hash=\"\",\n    113:             ja4_string=\"\",\n    114:             ja4_hash=\"\",\n>>> 115:             tls_version=0x0303 if \"1.2\" in version else 0x0304,  # TLS 1.2 or 1.3\n    116:             cipher_suites=[\n    117:                 0x1301,\n    118:                 0x1302,",
    "context": {
      "total_magic_literals": 145,
      "current_value": 772
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_benchmarks.py",
    "line_number": 28,
    "column": 0,
    "description": "Method 'download_benchmark_datasets' is too complex: 10 complexity, 88 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     25: logger = logging.getLogger(__name__)\n     26: \n     27: \n>>>  28: def download_benchmark_datasets():\n     29:     \"\"\"Download all benchmark datasets for EvoMerge evaluation.\"\"\"\n     30:     datasets_to_download = [\n     31:         {",
    "context": {
      "complexity": 10,
      "lines": 88,
      "max_nesting": 8,
      "method_name": "download_benchmark_datasets"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_benchmarks.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (20 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 20,
      "methods": [
        "info",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 31,
    "column": 4,
    "description": "Method '__init__' is too complex: 2 complexity, 57 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     28:     Extends existing HRRM training with benchmark datasets for improved performance.\n     29:     \"\"\"\n     30: \n>>>  31:     def __init__(self, output_dir: str = \"packages/core/training/datasets\"):\n     32:         self.output_dir = Path(output_dir)\n     33:         self.output_dir.mkdir(parents=True, exist_ok=True)\n     34: ",
    "context": {
      "complexity": 2,
      "lines": 57,
      "max_nesting": 1,
      "method_name": "__init__"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 121,
    "column": 4,
    "description": "Method 'process_for_training' is too complex: 6 complexity, 24 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    118:             logger.error(f\"Failed to download {dataset_name}: {e}\")\n    119:             return None\n    120: \n>>> 121:     def process_for_training(self, enhancement_type: str, datasets: list[dict[str, Any]]) -> dict[str, list[str]]:\n    122:         \"\"\"Process datasets into HRRM-specific training format.\"\"\"\n    123:         config = self.datasets[enhancement_type]\n    124:         model_target = config[\"model_target\"]",
    "context": {
      "complexity": 6,
      "lines": 24,
      "max_nesting": 5,
      "method_name": "process_for_training"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 147,
    "column": 4,
    "description": "Method '_process_for_reasoner' is too complex: 12 complexity, 35 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    144: \n    145:         return {model_target: training_data}\n    146: \n>>> 147:     def _process_for_reasoner(self, dataset, name: str) -> list[str]:\n    148:         \"\"\"Process datasets for reasoner enhancement (GSM8K, ARC, MATH format).\"\"\"\n    149:         examples = []\n    150: ",
    "context": {
      "complexity": 12,
      "lines": 35,
      "max_nesting": 8,
      "method_name": "_process_for_reasoner"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 184,
    "column": 4,
    "description": "Method '_process_for_planner' is too complex: 12 complexity, 30 lines, 8 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    181: \n    182:         return examples\n    183: \n>>> 184:     def _process_for_planner(self, dataset, name: str) -> list[str]:\n    185:         \"\"\"Process datasets for planner enhancement (code planning format).\"\"\"\n    186:         examples = []\n    187: ",
    "context": {
      "complexity": 12,
      "lines": 30,
      "max_nesting": 8,
      "method_name": "_process_for_planner"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 216,
    "column": 4,
    "description": "Method '_process_for_memory' is too complex: 17 complexity, 52 lines, 11 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    213: \n    214:         return examples\n    215: \n>>> 216:     def _process_for_memory(self, dataset, name: str) -> list[str]:\n    217:         \"\"\"Process datasets for memory enhancement (contextual knowledge format).\"\"\"\n    218:         examples = []\n    219: ",
    "context": {
      "complexity": 17,
      "lines": 52,
      "max_nesting": 11,
      "method_name": "_process_for_memory"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 270,
    "column": 4,
    "description": "Method '_process_code_dataset' is too complex: 9 complexity, 30 lines, 6 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    267: \n    268:         return examples\n    269: \n>>> 270:     def _process_code_dataset(self, dataset, name: str) -> dict[str, list[str]]:\n    271:         \"\"\"Process code datasets for HRRM training.\"\"\"\n    272:         data = {\"planner\": [], \"reasoner\": [], \"memory\": []}\n    273: ",
    "context": {
      "complexity": 9,
      "lines": 30,
      "max_nesting": 6,
      "method_name": "_process_code_dataset"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 302,
    "column": 4,
    "description": "Method '_process_math_dataset' is too complex: 8 complexity, 29 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    299: \n    300:         return data\n    301: \n>>> 302:     def _process_math_dataset(self, dataset, name: str) -> dict[str, list[str]]:\n    303:         \"\"\"Process math datasets for HRRM training.\"\"\"\n    304:         data = {\"planner\": [], \"reasoner\": [], \"memory\": []}\n    305: ",
    "context": {
      "complexity": 8,
      "lines": 29,
      "max_nesting": 5,
      "method_name": "_process_math_dataset"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 333,
    "column": 4,
    "description": "Method '_process_multilingual_dataset' is too complex: 8 complexity, 33 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    330: \n    331:         return data\n    332: \n>>> 333:     def _process_multilingual_dataset(self, dataset, name: str) -> dict[str, list[str]]:\n    334:         \"\"\"Process multilingual datasets for HRRM training.\"\"\"\n    335:         data = {\"planner\": [], \"reasoner\": [], \"memory\": []}\n    336: ",
    "context": {
      "complexity": 8,
      "lines": 33,
      "max_nesting": 5,
      "method_name": "_process_multilingual_dataset"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 368,
    "column": 4,
    "description": "Method '_process_structured_dataset' is too complex: 10 complexity, 45 lines, 7 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    365: \n    366:         return data\n    367: \n>>> 368:     def _process_structured_dataset(self, dataset, name: str) -> dict[str, list[str]]:\n    369:         \"\"\"Process structured reasoning datasets for HRRM training.\"\"\"\n    370:         data = {\"planner\": [], \"reasoner\": [], \"memory\": []}\n    371: ",
    "context": {
      "complexity": 10,
      "lines": 45,
      "max_nesting": 7,
      "method_name": "_process_structured_dataset"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 147,
    "column": 4,
    "description": "Duplicate code block detected in function '_process_for_reasoner'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    144: \n    145:         return {model_target: training_data}\n    146: \n>>> 147:     def _process_for_reasoner(self, dataset, name: str) -> list[str]:\n    148:         \"\"\"Process datasets for reasoner enhancement (GSM8K, ARC, MATH format).\"\"\"\n    149:         examples = []\n    150: ",
    "context": {
      "duplicate_count": 7,
      "function_name": "_process_for_reasoner",
      "signature": "ASSIGN|FOR|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 184,
    "column": 4,
    "description": "Duplicate code block detected in function '_process_for_planner'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    181: \n    182:         return examples\n    183: \n>>> 184:     def _process_for_planner(self, dataset, name: str) -> list[str]:\n    185:         \"\"\"Process datasets for planner enhancement (code planning format).\"\"\"\n    186:         examples = []\n    187: ",
    "context": {
      "duplicate_count": 7,
      "function_name": "_process_for_planner",
      "signature": "ASSIGN|FOR|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 216,
    "column": 4,
    "description": "Duplicate code block detected in function '_process_for_memory'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    213: \n    214:         return examples\n    215: \n>>> 216:     def _process_for_memory(self, dataset, name: str) -> list[str]:\n    217:         \"\"\"Process datasets for memory enhancement (contextual knowledge format).\"\"\"\n    218:         examples = []\n    219: ",
    "context": {
      "duplicate_count": 7,
      "function_name": "_process_for_memory",
      "signature": "ASSIGN|FOR|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 270,
    "column": 4,
    "description": "Duplicate code block detected in function '_process_code_dataset'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    267: \n    268:         return examples\n    269: \n>>> 270:     def _process_code_dataset(self, dataset, name: str) -> dict[str, list[str]]:\n    271:         \"\"\"Process code datasets for HRRM training.\"\"\"\n    272:         data = {\"planner\": [], \"reasoner\": [], \"memory\": []}\n    273: ",
    "context": {
      "duplicate_count": 7,
      "function_name": "_process_code_dataset",
      "signature": "ASSIGN|FOR|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 302,
    "column": 4,
    "description": "Duplicate code block detected in function '_process_math_dataset'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    299: \n    300:         return data\n    301: \n>>> 302:     def _process_math_dataset(self, dataset, name: str) -> dict[str, list[str]]:\n    303:         \"\"\"Process math datasets for HRRM training.\"\"\"\n    304:         data = {\"planner\": [], \"reasoner\": [], \"memory\": []}\n    305: ",
    "context": {
      "duplicate_count": 7,
      "function_name": "_process_math_dataset",
      "signature": "ASSIGN|FOR|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 333,
    "column": 4,
    "description": "Duplicate code block detected in function '_process_multilingual_dataset'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    330: \n    331:         return data\n    332: \n>>> 333:     def _process_multilingual_dataset(self, dataset, name: str) -> dict[str, list[str]]:\n    334:         \"\"\"Process multilingual datasets for HRRM training.\"\"\"\n    335:         data = {\"planner\": [], \"reasoner\": [], \"memory\": []}\n    336: ",
    "context": {
      "duplicate_count": 7,
      "function_name": "_process_multilingual_dataset",
      "signature": "ASSIGN|FOR|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 368,
    "column": 4,
    "description": "Duplicate code block detected in function '_process_structured_dataset'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    365: \n    366:         return data\n    367: \n>>> 368:     def _process_structured_dataset(self, dataset, name: str) -> dict[str, list[str]]:\n    369:         \"\"\"Process structured reasoning datasets for HRRM training.\"\"\"\n    370:         data = {\"planner\": [], \"reasoner\": [], \"memory\": []}\n    371: ",
    "context": {
      "duplicate_count": 7,
      "function_name": "_process_structured_dataset",
      "signature": "ASSIGN|FOR|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (19 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 19,
      "methods": [
        "info",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (7 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 7,
      "methods": [
        "_load_existing_configs",
        "_process_for_memory",
        "_process_for_planner",
        "save_training_data",
        "process_for_training",
        "download_dataset",
        "_process_for_reasoner"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'training_data' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "training_data",
      "method_count": 8,
      "methods": [
        "values",
        "items",
        "get",
        "extend"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'item' methods (45 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "item",
      "method_count": 45,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'examples' methods (10 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "examples",
      "method_count": 10,
      "methods": [
        "append"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'choices' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "choices",
      "method_count": 8,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 121,
    "column": 4,
    "description": "Sequential coupling detected: Function 'process_for_training' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    118:             logger.error(f\"Failed to download {dataset_name}: {e}\")\n    119:             return None\n    120: \n>>> 121:     def process_for_training(self, enhancement_type: str, datasets: list[dict[str, Any]]) -> dict[str, list[str]]:\n    122:         \"\"\"Process datasets into HRRM-specific training format.\"\"\"\n    123:         config = self.datasets[enhancement_type]\n    124:         model_target = config[\"model_target\"]",
    "context": {
      "function_name": "process_for_training",
      "sequential_functions": [
        "process_for_training",
        "_process_for_reasoner",
        "_process_for_planner",
        "_process_for_memory",
        "_process_code_dataset",
        "_process_math_dataset",
        "_process_multilingual_dataset",
        "_process_structured_dataset"
      ],
      "pattern_matched": [
        "begin",
        "process",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 147,
    "column": 4,
    "description": "Sequential coupling detected: Function '_process_for_reasoner' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    144: \n    145:         return {model_target: training_data}\n    146: \n>>> 147:     def _process_for_reasoner(self, dataset, name: str) -> list[str]:\n    148:         \"\"\"Process datasets for reasoner enhancement (GSM8K, ARC, MATH format).\"\"\"\n    149:         examples = []\n    150: ",
    "context": {
      "function_name": "_process_for_reasoner",
      "sequential_functions": [
        "process_for_training",
        "_process_for_reasoner",
        "_process_for_planner",
        "_process_for_memory",
        "_process_code_dataset",
        "_process_math_dataset",
        "_process_multilingual_dataset",
        "_process_structured_dataset"
      ],
      "pattern_matched": [
        "begin",
        "process",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 184,
    "column": 4,
    "description": "Sequential coupling detected: Function '_process_for_planner' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    181: \n    182:         return examples\n    183: \n>>> 184:     def _process_for_planner(self, dataset, name: str) -> list[str]:\n    185:         \"\"\"Process datasets for planner enhancement (code planning format).\"\"\"\n    186:         examples = []\n    187: ",
    "context": {
      "function_name": "_process_for_planner",
      "sequential_functions": [
        "process_for_training",
        "_process_for_reasoner",
        "_process_for_planner",
        "_process_for_memory",
        "_process_code_dataset",
        "_process_math_dataset",
        "_process_multilingual_dataset",
        "_process_structured_dataset"
      ],
      "pattern_matched": [
        "begin",
        "process",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 216,
    "column": 4,
    "description": "Sequential coupling detected: Function '_process_for_memory' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    213: \n    214:         return examples\n    215: \n>>> 216:     def _process_for_memory(self, dataset, name: str) -> list[str]:\n    217:         \"\"\"Process datasets for memory enhancement (contextual knowledge format).\"\"\"\n    218:         examples = []\n    219: ",
    "context": {
      "function_name": "_process_for_memory",
      "sequential_functions": [
        "process_for_training",
        "_process_for_reasoner",
        "_process_for_planner",
        "_process_for_memory",
        "_process_code_dataset",
        "_process_math_dataset",
        "_process_multilingual_dataset",
        "_process_structured_dataset"
      ],
      "pattern_matched": [
        "begin",
        "process",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 270,
    "column": 4,
    "description": "Sequential coupling detected: Function '_process_code_dataset' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    267: \n    268:         return examples\n    269: \n>>> 270:     def _process_code_dataset(self, dataset, name: str) -> dict[str, list[str]]:\n    271:         \"\"\"Process code datasets for HRRM training.\"\"\"\n    272:         data = {\"planner\": [], \"reasoner\": [], \"memory\": []}\n    273: ",
    "context": {
      "function_name": "_process_code_dataset",
      "sequential_functions": [
        "process_for_training",
        "_process_for_reasoner",
        "_process_for_planner",
        "_process_for_memory",
        "_process_code_dataset",
        "_process_math_dataset",
        "_process_multilingual_dataset",
        "_process_structured_dataset"
      ],
      "pattern_matched": [
        "begin",
        "process",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 302,
    "column": 4,
    "description": "Sequential coupling detected: Function '_process_math_dataset' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    299: \n    300:         return data\n    301: \n>>> 302:     def _process_math_dataset(self, dataset, name: str) -> dict[str, list[str]]:\n    303:         \"\"\"Process math datasets for HRRM training.\"\"\"\n    304:         data = {\"planner\": [], \"reasoner\": [], \"memory\": []}\n    305: ",
    "context": {
      "function_name": "_process_math_dataset",
      "sequential_functions": [
        "process_for_training",
        "_process_for_reasoner",
        "_process_for_planner",
        "_process_for_memory",
        "_process_code_dataset",
        "_process_math_dataset",
        "_process_multilingual_dataset",
        "_process_structured_dataset"
      ],
      "pattern_matched": [
        "begin",
        "process",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 333,
    "column": 4,
    "description": "Sequential coupling detected: Function '_process_multilingual_dataset' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    330: \n    331:         return data\n    332: \n>>> 333:     def _process_multilingual_dataset(self, dataset, name: str) -> dict[str, list[str]]:\n    334:         \"\"\"Process multilingual datasets for HRRM training.\"\"\"\n    335:         data = {\"planner\": [], \"reasoner\": [], \"memory\": []}\n    336: ",
    "context": {
      "function_name": "_process_multilingual_dataset",
      "sequential_functions": [
        "process_for_training",
        "_process_for_reasoner",
        "_process_for_planner",
        "_process_for_memory",
        "_process_code_dataset",
        "_process_math_dataset",
        "_process_multilingual_dataset",
        "_process_structured_dataset"
      ],
      "pattern_matched": [
        "begin",
        "process",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 368,
    "column": 4,
    "description": "Sequential coupling detected: Function '_process_structured_dataset' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    365: \n    366:         return data\n    367: \n>>> 368:     def _process_structured_dataset(self, dataset, name: str) -> dict[str, list[str]]:\n    369:         \"\"\"Process structured reasoning datasets for HRRM training.\"\"\"\n    370:         data = {\"planner\": [], \"reasoner\": [], \"memory\": []}\n    371: ",
    "context": {
      "function_name": "_process_structured_dataset",
      "sequential_functions": [
        "process_for_training",
        "_process_for_reasoner",
        "_process_for_planner",
        "_process_for_memory",
        "_process_code_dataset",
        "_process_math_dataset",
        "_process_multilingual_dataset",
        "_process_structured_dataset"
      ],
      "pattern_matched": [
        "begin",
        "process",
        "commit"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 51,
    "column": 65,
    "description": "Excessive magic literals detected (24 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     48:                 \"model_target\": \"reasoner\",\n     49:                 \"extends_config\": \"reasoner_sft_gsm_arc.yaml\",\n     50:                 \"sources\": [\n>>>  51:                     {\"name\": \"gsm8k\", \"split\": \"train\", \"limit\": 7500},  # Expand existing GSM8K\n     52:                     {\n     53:                         \"name\": \"ai2_arc\",\n     54:                         \"split\": \"train\",",
    "context": {
      "total_magic_literals": 24,
      "current_value": 7500
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 56,
    "column": 33,
    "description": "Excessive magic literals detected (24 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     53:                         \"name\": \"ai2_arc\",\n     54:                         \"split\": \"train\",\n     55:                         \"subset\": \"ARC-Challenge\",\n>>>  56:                         \"limit\": 1176,\n     57:                     },  # Full training set\n     58:                     {\"name\": \"ai2_arc\", \"split\": \"train\", \"subset\": \"ARC-Easy\", \"limit\": 2251},  # Full training set\n     59:                     {\"name\": \"competition_math\", \"split\": \"train\", \"limit\": 7500},  # Add advanced math",
    "context": {
      "total_magic_literals": 24,
      "current_value": 1176
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 58,
    "column": 89,
    "description": "Excessive magic literals detected (24 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     55:                         \"subset\": \"ARC-Challenge\",\n     56:                         \"limit\": 1176,\n     57:                     },  # Full training set\n>>>  58:                     {\"name\": \"ai2_arc\", \"split\": \"train\", \"subset\": \"ARC-Easy\", \"limit\": 2251},  # Full training set\n     59:                     {\"name\": \"competition_math\", \"split\": \"train\", \"limit\": 7500},  # Add advanced math\n     60:                 ],\n     61:                 \"description\": \"Enhanced mathematical and scientific reasoning\",",
    "context": {
      "total_magic_literals": 24,
      "current_value": 2251
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 59,
    "column": 76,
    "description": "Excessive magic literals detected (24 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     56:                         \"limit\": 1176,\n     57:                     },  # Full training set\n     58:                     {\"name\": \"ai2_arc\", \"split\": \"train\", \"subset\": \"ARC-Easy\", \"limit\": 2251},  # Full training set\n>>>  59:                     {\"name\": \"competition_math\", \"split\": \"train\", \"limit\": 7500},  # Add advanced math\n     60:                 ],\n     61:                 \"description\": \"Enhanced mathematical and scientific reasoning\",\n     62:             },",
    "context": {
      "total_magic_literals": 24,
      "current_value": 7500
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\download_training_datasets.py",
    "line_number": 70,
    "column": 73,
    "description": "Excessive magic literals detected (24 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     67:                 \"extends_config\": \"planner_pretrain.yaml\",\n     68:                 \"sources\": [\n     69:                     {\"name\": \"openai_humaneval\", \"split\": \"test\", \"limit\": None},  # All 164 examples\n>>>  70:                     {\"name\": \"code_contests\", \"split\": \"train\", \"limit\": 5000},  # Code planning tasks\n     71:                     {\"name\": \"apps\", \"split\": \"train\", \"limit\": 3000},  # Programming problems\n     72:                 ],\n     73:                 \"description\": \"Code planning and algorithmic thinking\",",
    "context": {
      "total_magic_literals": 24,
      "current_value": 5000
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 17,
    "column": 0,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     14: import yaml\n     15: \n     16: # Add paths to enable imports\n>>>  17: sys.path.insert(0, os.path.abspath(\".\"))\n     18: sys.path.insert(0, os.path.abspath(\"packages\"))\n     19: \n     20: # Import HRRM models",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 18,
    "column": 0,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     15: \n     16: # Add paths to enable imports\n     17: sys.path.insert(0, os.path.abspath(\".\"))\n>>>  18: sys.path.insert(0, os.path.abspath(\"packages\"))\n     19: \n     20: # Import HRRM models\n     21: from packages.hrrm.memory.model import MemoryAsContextTiny, MemoryConfig",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 120,
    "column": 8,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    117:         return MockTokenizer()\n    118: \n    119:     def _create_synthetic_data(self, batch_size: int = 8, seq_len: int = 256, num_batches: int = 100):\n>>> 120:         \"\"\"Create synthetic pretraining data.\"\"\"\n    121:         data = []\n    122:         for _ in range(num_batches):\n    123:             batch = torch.randint(1, min(1000, self.tokenizer.vocab_size - 1), (batch_size, seq_len))",
    "context": {
      "query_preview": "Create synthetic pretraining data."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 127,
    "column": 4,
    "description": "Method '_load_benchmark_data' is too complex: 11 complexity, 43 lines, 10 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    124:             data.append(batch)\n    125:         return data\n    126: \n>>> 127:     def _load_benchmark_data(self, model_type: str) -> list[str]:\n    128:         \"\"\"Load benchmark training data for specific model type.\"\"\"\n    129:         data = []\n    130: ",
    "context": {
      "complexity": 11,
      "lines": 43,
      "max_nesting": 10,
      "method_name": "_load_benchmark_data"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 135,
    "column": 30,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    132:             # Load reasoner enhancement data\n    133:             data_path = self.dataset_dir / \"reasoner_enhancement\" / \"reasoner_training_data.jsonl\"\n    134:             if data_path.exists():\n>>> 135:                 logger.info(f\"Loading reasoner benchmark data from {data_path}\")\n    136:                 with open(data_path, encoding=\"utf-8\") as f:\n    137:                     for line in f:\n    138:                         item = json.loads(line.strip())",
    "context": {
      "query_preview": "Loading reasoner benchmark data from "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 146,
    "column": 30,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    143:             # Load planner enhancement data\n    144:             data_path = self.dataset_dir / \"planner_enhancement\" / \"planner_training_data.jsonl\"\n    145:             if data_path.exists():\n>>> 146:                 logger.info(f\"Loading planner benchmark data from {data_path}\")\n    147:                 with open(data_path, encoding=\"utf-8\") as f:\n    148:                     for line in f:\n    149:                         item = json.loads(line.strip())",
    "context": {
      "query_preview": "Loading planner benchmark data from "
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 157,
    "column": 30,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    154:             # For memory, we'll use some of the reasoner data as contextual knowledge\n    155:             reasoner_data_path = self.dataset_dir / \"reasoner_enhancement\" / \"reasoner_training_data.jsonl\"\n    156:             if reasoner_data_path.exists():\n>>> 157:                 logger.info(f\"Loading memory benchmark data from {reasoner_data_path}\")\n    158:                 with open(reasoner_data_path, encoding=\"utf-8\") as f:\n    159:                     count = 0\n    160:                     for line in f:",
    "context": {
      "query_preview": "Loading memory benchmark data from "
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 200,
    "column": 4,
    "description": "Method '_train_phase' is too complex: 8 complexity, 74 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    197:         logger.info(f\"Created {len(batches)} benchmark batches\")\n    198:         return batches\n    199: \n>>> 200:     def _train_phase(self, model, optimizer, data, model_name: str, phase_name: str, epochs: int = 3):\n    201:         \"\"\"Train model for one phase.\"\"\"\n    202:         model.train()\n    203:         model.to(self.device)",
    "context": {
      "complexity": 8,
      "lines": 74,
      "max_nesting": 5,
      "method_name": "_train_phase"
    },
    "related_files": null
  },
  {
    "pattern_type": "long_parameter_list",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 200,
    "column": 4,
    "description": "Function '_train_phase' has 7 parameters (>5)",
    "recommendation": "Use parameter objects, data classes, or keyword-only arguments",
    "code_snippet": "    197:         logger.info(f\"Created {len(batches)} benchmark batches\")\n    198:         return batches\n    199: \n>>> 200:     def _train_phase(self, model, optimizer, data, model_name: str, phase_name: str, epochs: int = 3):\n    201:         \"\"\"Train model for one phase.\"\"\"\n    202:         model.train()\n    203:         model.to(self.device)",
    "context": {
      "parameter_count": 7,
      "function_name": "_train_phase"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 440,
    "column": 4,
    "description": "Method 'run_enhanced_training' is too complex: 2 complexity, 76 lines, 0 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    437:         model_path = self._save_model(memory, memory_config, \"memory\", finetune_loss)\n    438:         return model_path, finetune_loss\n    439: \n>>> 440:     def run_enhanced_training(self):\n    441:         \"\"\"Run the complete enhanced training pipeline.\"\"\"\n    442:         logger.info(\"=\" * 80)\n    443:         logger.info(\"ENHANCED HRRM TRAINING PIPELINE - COMBINING PRETRAINING + BENCHMARKS\")",
    "context": {
      "complexity": 2,
      "lines": 76,
      "max_nesting": 0,
      "method_name": "run_enhanced_training"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 481,
    "column": 42,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    478:                     \"memory\": {\n    479:                         \"final_loss\": memory_loss,\n    480:                         \"path\": memory_path,\n>>> 481:                         \"benchmark_data\": \"Contextual knowledge from reasoning tasks\",\n    482:                         \"format\": \"Memory-augmented contextual processing\",\n    483:                     },\n    484:                 },",
    "context": {
      "query_preview": "Contextual knowledge from reasoning tasks"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 302,
    "column": 4,
    "description": "Duplicate code block detected in function 'train_enhanced_reasoner'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    299:         logger.info(f\"Saved enhanced {model_name} to {model_dir}\")\n    300:         return str(model_dir)\n    301: \n>>> 302:     def train_enhanced_reasoner(self):\n    303:         \"\"\"Train the reasoner model with synthetic pretraining + benchmark fine-tuning.\"\"\"\n    304:         logger.info(\"=\" * 60)\n    305:         logger.info(\"TRAINING ENHANCED HRM REASONER\")",
    "context": {
      "duplicate_count": 2,
      "function_name": "train_enhanced_reasoner",
      "signature": "CALL_info|CALL_info|CALL_info|ASSIGN|ASSIGN|ASSIGN|CALL_info|ASSIGN|ASSIGN|ASSIGN|CALL_info|ASSIGN|IF|ASSIGN|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "copy_paste_programming",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 393,
    "column": 4,
    "description": "Duplicate code block detected in function 'train_enhanced_memory'",
    "recommendation": "Extract common code into a shared function or utility",
    "code_snippet": "    390:         model_path = self._save_model(planner, planner_config, \"planner\", finetune_loss)\n    391:         return model_path, finetune_loss\n    392: \n>>> 393:     def train_enhanced_memory(self):\n    394:         \"\"\"Train the memory model with synthetic pretraining + contextual fine-tuning.\"\"\"\n    395:         logger.info(\"=\" * 60)\n    396:         logger.info(\"TRAINING ENHANCED MEMORY MODEL\")",
    "context": {
      "duplicate_count": 2,
      "function_name": "train_enhanced_memory",
      "signature": "CALL_info|CALL_info|CALL_info|ASSIGN|ASSIGN|ASSIGN|CALL_info|ASSIGN|ASSIGN|ASSIGN|CALL_info|ASSIGN|IF|ASSIGN|RETURN"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (45 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 45,
      "methods": [
        "info",
        "warning",
        "error"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'self' methods (23 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "self",
      "method_count": 23,
      "methods": [
        "_train_phase",
        "_create_synthetic_data",
        "train_enhanced_reasoner",
        "_create_benchmark_batches",
        "train_enhanced_memory",
        "_load_configs",
        "_save_model",
        "_init_tokenizer",
        "_load_benchmark_data",
        "train_enhanced_planner"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'config_base' methods (30 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "config_base",
      "method_count": 30,
      "methods": [
        "get"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'optim' methods (6 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "optim",
      "method_count": 6,
      "methods": [
        "Adam"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 33,
    "column": 4,
    "description": "Sequential coupling detected: Function '__init__' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     30: class EnhancedHRRMTrainer:\n     31:     \"\"\"Enhanced HRRM trainer that combines synthetic pretraining with benchmark fine-tuning.\"\"\"\n     32: \n>>>  33:     def __init__(\n     34:         self,\n     35:         config_dir: str = \"configs/hrrm\",\n     36:         dataset_dir: str = \"packages/core/training/datasets\",",
    "context": {
      "function_name": "__init__",
      "sequential_functions": [
        "__init__",
        "_init_tokenizer",
        "run_enhanced_training"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 94,
    "column": 4,
    "description": "Sequential coupling detected: Function '_init_tokenizer' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "     91:         logger.info(f\"Loaded configs for: {list(configs.keys())}\")\n     92:         return configs\n     93: \n>>>  94:     def _init_tokenizer(self):\n     95:         \"\"\"Initialize tokenizer.\"\"\"\n     96: \n     97:         # Create a simple mock tokenizer for now",
    "context": {
      "function_name": "_init_tokenizer",
      "sequential_functions": [
        "__init__",
        "_init_tokenizer",
        "run_enhanced_training"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "sequential_coupling",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 440,
    "column": 4,
    "description": "Sequential coupling detected: Function 'run_enhanced_training' is part of a sequence-dependent API",
    "recommendation": "Consider using context managers, fluent interfaces, or state machines",
    "code_snippet": "    437:         model_path = self._save_model(memory, memory_config, \"memory\", finetune_loss)\n    438:         return model_path, finetune_loss\n    439: \n>>> 440:     def run_enhanced_training(self):\n    441:         \"\"\"Run the complete enhanced training pipeline.\"\"\"\n    442:         logger.info(\"=\" * 80)\n    443:         logger.info(\"ENHANCED HRRM TRAINING PIPELINE - COMBINING PRETRAINING + BENCHMARKS\")",
    "context": {
      "function_name": "run_enhanced_training",
      "sequential_functions": [
        "__init__",
        "_init_tokenizer",
        "run_enhanced_training"
      ],
      "pattern_matched": [
        "init",
        "setup",
        "run",
        "cleanup"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 78,
    "column": 30,
    "description": "Excessive magic literals detected (77 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     75:         else:\n     76:             # Use default memory config\n     77:             configs[\"memory\"] = {\n>>>  78:                 \"vocab_size\": 32000,\n     79:                 \"d_model\": 512,\n     80:                 \"n_layers\": 16,\n     81:                 \"n_head\": 8,",
    "context": {
      "total_magic_literals": 77,
      "current_value": 32000
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 79,
    "column": 27,
    "description": "Excessive magic literals detected (77 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     76:             # Use default memory config\n     77:             configs[\"memory\"] = {\n     78:                 \"vocab_size\": 32000,\n>>>  79:                 \"d_model\": 512,\n     80:                 \"n_layers\": 16,\n     81:                 \"n_head\": 8,\n     82:                 \"max_seq_len\": 2048,",
    "context": {
      "total_magic_literals": 77,
      "current_value": 512
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 80,
    "column": 28,
    "description": "Excessive magic literals detected (77 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     77:             configs[\"memory\"] = {\n     78:                 \"vocab_size\": 32000,\n     79:                 \"d_model\": 512,\n>>>  80:                 \"n_layers\": 16,\n     81:                 \"n_head\": 8,\n     82:                 \"max_seq_len\": 2048,\n     83:                 \"mem_dim\": 128,",
    "context": {
      "total_magic_literals": 77,
      "current_value": 16
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 81,
    "column": 26,
    "description": "Excessive magic literals detected (77 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     78:                 \"vocab_size\": 32000,\n     79:                 \"d_model\": 512,\n     80:                 \"n_layers\": 16,\n>>>  81:                 \"n_head\": 8,\n     82:                 \"max_seq_len\": 2048,\n     83:                 \"mem_dim\": 128,\n     84:                 \"mem_tokens\": 32,",
    "context": {
      "total_magic_literals": 77,
      "current_value": 8
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\enhanced_hrrm_training.py",
    "line_number": 82,
    "column": 31,
    "description": "Excessive magic literals detected (77 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     79:                 \"d_model\": 512,\n     80:                 \"n_layers\": 16,\n     81:                 \"n_head\": 8,\n>>>  82:                 \"max_seq_len\": 2048,\n     83:                 \"mem_dim\": 128,\n     84:                 \"mem_tokens\": 32,\n     85:                 \"mem_slots\": 64,",
    "context": {
      "total_magic_literals": 77,
      "current_value": 2048
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\simple_train_hrrm.py",
    "line_number": 14,
    "column": 0,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     11: from torch import optim\n     12: \n     13: # Add the current directory to Python path\n>>>  14: sys.path.insert(0, os.path.abspath(\".\"))\n     15: \n     16: from packages.hrrm.memory.model import MemoryAsContextTiny, MemoryConfig\n     17: from packages.hrrm.planner.heads import PlannerConfig",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\simple_train_hrrm.py",
    "line_number": 26,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     23: \n     24: \n     25: def create_synthetic_data(tokenizer, batch_size=8, seq_len=256, num_batches=100):\n>>>  26:     \"\"\"Create synthetic training data.\"\"\"\n     27:     data = []\n     28:     for _ in range(num_batches):\n     29:         # Create random token sequences",
    "context": {
      "query_preview": "Create synthetic training data."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\simple_train_hrrm.py",
    "line_number": 35,
    "column": 0,
    "description": "Method 'train_model' is too complex: 7 complexity, 55 lines, 5 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     32:     return data\n     33: \n     34: \n>>>  35: def train_model(model, optimizer, data, model_name, epochs=3):\n     36:     \"\"\"Simple training loop.\"\"\"\n     37:     model.train()\n     38:     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
    "context": {
      "complexity": 7,
      "lines": 55,
      "max_nesting": 5,
      "method_name": "train_model"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\simple_train_hrrm.py",
    "line_number": 115,
    "column": 0,
    "description": "Method 'main' is too complex: 2 complexity, 122 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    112:     logger.info(f\"Saved {model_name} to {checkpoint_dir}\")\n    113: \n    114: \n>>> 115: def main():\n    116:     \"\"\"Main training function.\"\"\"\n    117:     # Create tokenizer (simple approach)\n    118:     logger.info(\"Creating tokenizer...\")",
    "context": {
      "complexity": 2,
      "lines": 122,
      "max_nesting": 1,
      "method_name": "main"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\simple_train_hrrm.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (24 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 24,
      "methods": [
        "info"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\simple_train_hrrm.py",
    "line_number": 25,
    "column": 48,
    "description": "Excessive magic literals detected (33 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     22: logger = logging.getLogger(__name__)\n     23: \n     24: \n>>>  25: def create_synthetic_data(tokenizer, batch_size=8, seq_len=256, num_batches=100):\n     26:     \"\"\"Create synthetic training data.\"\"\"\n     27:     data = []\n     28:     for _ in range(num_batches):",
    "context": {
      "total_magic_literals": 33,
      "current_value": 8
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\simple_train_hrrm.py",
    "line_number": 25,
    "column": 59,
    "description": "Excessive magic literals detected (33 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     22: logger = logging.getLogger(__name__)\n     23: \n     24: \n>>>  25: def create_synthetic_data(tokenizer, batch_size=8, seq_len=256, num_batches=100):\n     26:     \"\"\"Create synthetic training data.\"\"\"\n     27:     data = []\n     28:     for _ in range(num_batches):",
    "context": {
      "total_magic_literals": 33,
      "current_value": 256
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\simple_train_hrrm.py",
    "line_number": 35,
    "column": 59,
    "description": "Excessive magic literals detected (33 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     32:     return data\n     33: \n     34: \n>>>  35: def train_model(model, optimizer, data, model_name, epochs=3):\n     36:     \"\"\"Simple training loop.\"\"\"\n     37:     model.train()\n     38:     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
    "context": {
      "total_magic_literals": 33,
      "current_value": 3
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\simple_train_hrrm.py",
    "line_number": 125,
    "column": 25,
    "description": "Excessive magic literals detected (33 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    122: \n    123:         # Create a simple mock tokenizer for now\n    124:         class MockTokenizer:\n>>> 125:             vocab_size = 32000\n    126: \n    127:         tokenizer = MockTokenizer()\n    128:     else:",
    "context": {
      "total_magic_literals": 33,
      "current_value": 32000
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\simple_train_hrrm.py",
    "line_number": 132,
    "column": 25,
    "description": "Excessive magic literals detected (33 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "    129:         logger.info(\"Creating mock tokenizer\")\n    130: \n    131:         class MockTokenizer:\n>>> 132:             vocab_size = 32000\n    133: \n    134:         tokenizer = MockTokenizer()\n    135: ",
    "context": {
      "total_magic_literals": 33,
      "current_value": 32000
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 16,
    "column": 0,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     13: from transformers import AutoTokenizer\n     14: \n     15: # Add paths\n>>>  16: sys.path.insert(0, os.path.abspath(\".\"))\n     17: sys.path.insert(0, os.path.abspath(\"packages\"))\n     18: \n     19: from packages.hrrm.memory.model import MemoryAsContextTiny, MemoryConfig",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 17,
    "column": 0,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "     14: \n     15: # Add paths\n     16: sys.path.insert(0, os.path.abspath(\".\"))\n>>>  17: sys.path.insert(0, os.path.abspath(\"packages\"))\n     18: \n     19: from packages.hrrm.memory.model import MemoryAsContextTiny, MemoryConfig\n     20: from packages.hrrm.planner.heads import PlannerConfig",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 47,
    "column": 0,
    "description": "Method 'create_50m_config' is too complex: 10 complexity, 109 lines, 9 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "     44:     return total_params\n     45: \n     46: \n>>>  47: def create_50m_config(model_type, vocab_size):\n     48:     \"\"\"Create configurations for 50M parameter models.\"\"\"\n     49:     if model_type == \"planner\":\n     50:         # Try different combinations to hit ~50M parameters",
    "context": {
      "complexity": 10,
      "lines": 109,
      "max_nesting": 9,
      "method_name": "create_50m_config"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 48,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "     45: \n     46: \n     47: def create_50m_config(model_type, vocab_size):\n>>>  48:     \"\"\"Create configurations for 50M parameter models.\"\"\"\n     49:     if model_type == \"planner\":\n     50:         # Try different combinations to hit ~50M parameters\n     51:         configs_to_try = [",
    "context": {
      "query_preview": "Create configurations for 50M parameter models."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 159,
    "column": 0,
    "description": "Method 'load_training_datasets' is too complex: 16 complexity, 63 lines, 10 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    156:         )\n    157: \n    158: \n>>> 159: def load_training_datasets():\n    160:     \"\"\"Load and prepare training datasets.\"\"\"\n    161:     logger.info(\"Loading training datasets...\")\n    162: ",
    "context": {
      "complexity": 16,
      "lines": 63,
      "max_nesting": 10,
      "method_name": "load_training_datasets"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 225,
    "column": 0,
    "description": "Method 'prepare_training_data' is too complex: 12 complexity, 49 lines, 11 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    222:     return datasets\n    223: \n    224: \n>>> 225: def prepare_training_data(datasets, tokenizer, model_type):\n    226:     \"\"\"Prepare training data for specific model type.\"\"\"\n    227:     all_texts = []\n    228: ",
    "context": {
      "complexity": 12,
      "lines": 49,
      "max_nesting": 11,
      "method_name": "prepare_training_data"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 307,
    "column": 4,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    304: \n    305: \n    306: def create_dataloader(input_ids_list, batch_size=4):\n>>> 307:     \"\"\"Create DataLoader from tokenized sequences.\"\"\"\n    308:     # Pad sequences to same length\n    309:     max_len = max(len(seq) for seq in input_ids_list)\n    310: ",
    "context": {
      "query_preview": "Create DataLoader from tokenized sequences."
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 326,
    "column": 0,
    "description": "Method 'train_model' is too complex: 10 complexity, 92 lines, 7 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    323:     return dataloader\n    324: \n    325: \n>>> 326: def train_model(model, dataloader, model_name, epochs=2):\n    327:     \"\"\"Train model with real datasets.\"\"\"\n    328:     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    329:     model.to(device)",
    "context": {
      "complexity": 10,
      "lines": 92,
      "max_nesting": 7,
      "method_name": "train_model"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 421,
    "column": 0,
    "description": "Method 'save_model_hf_format' is too complex: 2 complexity, 89 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    418:     return avg_total_loss, trainable_params\n    419: \n    420: \n>>> 421: def save_model_hf_format(model, config, tokenizer, model_name, save_dir):\n    422:     \"\"\"Save model in HuggingFace format for EvoMerge compatibility.\"\"\"\n    423:     save_dir = Path(save_dir)\n    424:     save_dir.mkdir(parents=True, exist_ok=True)",
    "context": {
      "complexity": 2,
      "lines": 89,
      "max_nesting": 1,
      "method_name": "save_model_hf_format"
    },
    "related_files": null
  },
  {
    "pattern_type": "database_as_ipc",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 444,
    "column": 8,
    "description": "Potential database-as-IPC anti-pattern detected",
    "recommendation": "Use proper message queues, REST APIs, or event systems for inter-process communication",
    "code_snippet": "    441: \n    442:     # Add model-specific config\n    443:     if hasattr(config, \"__dict__\"):\n>>> 444:         hf_config.update(config.__dict__)\n    445: \n    446:     # Save config.json\n    447:     with open(save_dir / \"config.json\", \"w\") as f:",
    "context": {
      "call_type": "database_operation"
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 469,
    "column": 65,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    466: ## Model Details\n    467: \n    468: - **Model Type**: {model_name}\n>>> 469: - **Parameters**: ~{sum(p.numel() for p in model.parameters()):,}\n    470: - **Architecture**: Hierarchical Recurrent Memory with two-timescale dynamics\n    471: - **Training**: Synthetic data + benchmark datasets (GSM8K, ARC, HumanEval)\n    472: ",
    "context": {
      "query_preview": "\n- **Architecture**: Hierarchical Recurrent Memory with two-timescale dynamics\n- **Training**: Synth..."
    },
    "related_files": null
  },
  {
    "pattern_type": "embedded_sql",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 478,
    "column": 54,
    "description": "Embedded SQL query detected in code",
    "recommendation": "Use ORM, query builders, or move SQL to separate files",
    "code_snippet": "    475: ```python\n    476: from transformers import AutoModel, AutoConfig\n    477: \n>>> 478: config = AutoConfig.from_pretrained(\"./{save_dir.name}\")\n    479: model = AutoModel.from_pretrained(\"./{save_dir.name}\")\n    480: \n    481: # Generate with the model",
    "context": {
      "query_preview": "\")\nmodel = AutoModel.from_pretrained(\"./"
    },
    "related_files": null
  },
  {
    "pattern_type": "god_method",
    "severity": "high",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 513,
    "column": 0,
    "description": "Method 'main' is too complex: 3 complexity, 141 lines, 1 max nesting",
    "recommendation": "Break down into smaller, focused methods following Single Responsibility Principle",
    "code_snippet": "    510:     logger.info(f\"Saved {model_name} to {save_dir} in HuggingFace format\")\n    511: \n    512: \n>>> 513: def main():\n    514:     \"\"\"Main training function for 50M parameter models.\"\"\"\n    515:     logger.info(\"=\" * 60)\n    516:     logger.info(\"Training 50M Parameter HRRM Models with Real Datasets\")",
    "context": {
      "complexity": 3,
      "lines": 141,
      "max_nesting": 1,
      "method_name": "main"
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'logger' methods (50 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "logger",
      "method_count": 50,
      "methods": [
        "info",
        "warning"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "feature_envy",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 1,
    "column": 0,
    "description": "Potential Feature Envy: Excessive use of 'model' methods (8 calls)",
    "recommendation": "Consider moving this behavior to the envied class or use delegation",
    "code_snippet": "",
    "context": {
      "envied_object": "model",
      "method_count": 8,
      "methods": [
        "train",
        "to",
        "state_dict",
        "parameters"
      ]
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 40,
    "column": 23,
    "description": "Excessive magic literals detected (97 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     37:     # Per layer parameters (attention + MLP)\n     38:     # Attention: 4 * d_model^2 (Q, K, V, O projections)\n     39:     # MLP: 4 * d_model^2 (up and down projections, typical 4x expansion)\n>>>  40:     per_layer_params = 4 * d_model * d_model + 4 * d_model * d_model\n     41: \n     42:     # Total parameters\n     43:     total_params = embedding_params + (n_layers * per_layer_params)",
    "context": {
      "total_magic_literals": 97,
      "current_value": 4
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 40,
    "column": 47,
    "description": "Excessive magic literals detected (97 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     37:     # Per layer parameters (attention + MLP)\n     38:     # Attention: 4 * d_model^2 (Q, K, V, O projections)\n     39:     # MLP: 4 * d_model^2 (up and down projections, typical 4x expansion)\n>>>  40:     per_layer_params = 4 * d_model * d_model + 4 * d_model * d_model\n     41: \n     42:     # Total parameters\n     43:     total_params = embedding_params + (n_layers * per_layer_params)",
    "context": {
      "total_magic_literals": 97,
      "current_value": 4
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 52,
    "column": 13,
    "description": "Excessive magic literals detected (97 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     49:     if model_type == \"planner\":\n     50:         # Try different combinations to hit ~50M parameters\n     51:         configs_to_try = [\n>>>  52:             (512, 12),  # d_model=512, n_layers=12\n     53:             (640, 10),  # d_model=640, n_layers=10\n     54:             (448, 14),  # d_model=448, n_layers=14\n     55:             (576, 11),  # d_model=576, n_layers=11",
    "context": {
      "total_magic_literals": 97,
      "current_value": 512
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 52,
    "column": 18,
    "description": "Excessive magic literals detected (97 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     49:     if model_type == \"planner\":\n     50:         # Try different combinations to hit ~50M parameters\n     51:         configs_to_try = [\n>>>  52:             (512, 12),  # d_model=512, n_layers=12\n     53:             (640, 10),  # d_model=640, n_layers=10\n     54:             (448, 14),  # d_model=448, n_layers=14\n     55:             (576, 11),  # d_model=576, n_layers=11",
    "context": {
      "total_magic_literals": 97,
      "current_value": 12
    },
    "related_files": null
  },
  {
    "pattern_type": "magic_number_abuse",
    "severity": "medium",
    "file_path": "packages\\core\\training\\scripts\\train_50m_hrrm.py",
    "line_number": 53,
    "column": 13,
    "description": "Excessive magic literals detected (97 total)",
    "recommendation": "Replace magic numbers with named constants or enums",
    "code_snippet": "     50:         # Try different combinations to hit ~50M parameters\n     51:         configs_to_try = [\n     52:             (512, 12),  # d_model=512, n_layers=12\n>>>  53:             (640, 10),  # d_model=640, n_layers=10\n     54:             (448, 14),  # d_model=448, n_layers=14\n     55:             (576, 11),  # d_model=576, n_layers=11\n     56:         ]",
    "context": {
      "total_magic_literals": 97,
      "current_value": 640
    },
    "related_files": null
  }
]