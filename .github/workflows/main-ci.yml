name: Main CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:
    inputs:
      run_performance_tests:
        description: 'Run performance benchmarks'
        required: false
        default: 'false'
        type: boolean
      run_security_scan:
        description: 'Run comprehensive security scan'
        required: false
        default: 'true'
        type: boolean
      target_components:
        description: 'Components to test (comma-separated or "all")'
        required: false
        default: 'all'
        type: string

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'
  CARGO_TERM_COLOR: always
  PIP_DISABLE_PIP_VERSION_CHECK: 1
  CACHE_VERSION: 'v2'

jobs:
  # ============================================
  # STAGE 1: Configuration & Setup
  # ============================================
  setup:
    name: Configuration Setup
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      python-components: ${{ steps.config.outputs.python-components }}
      run-frontend: ${{ steps.config.outputs.run-frontend }}
      run-tests: ${{ steps.config.outputs.run-tests }}
      run-security: ${{ steps.config.outputs.run-security }}
      cache-key: ${{ steps.config.outputs.cache-key }}
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Configure Component Matrix
        id: config
        run: |
          # Determine what components need testing based on changes
          if [[ "${{ github.event.inputs.target_components }}" == "all" || -z "${{ github.event.inputs.target_components }}" ]]; then
            # Check what directories exist and have changes
            COMPONENTS=()
            for dir in core infrastructure src packages; do
              if [[ -d "$dir" ]]; then
                if [[ "${{ github.event_name }}" == "push" ]] || git diff --quiet origin/${{ github.base_ref }} HEAD -- "$dir/" 2>/dev/null; then
                  COMPONENTS+=("\"$dir\"")
                fi
              fi
            done
            PYTHON_COMPONENTS="[$(IFS=,; echo "${COMPONENTS[*]}")]"
          else
            # Use specified components
            IFS=',' read -ra ADDR <<< "${{ github.event.inputs.target_components }}"
            COMPONENTS=()
            for component in "${ADDR[@]}"; do
              component=$(echo "$component" | xargs)  # trim whitespace
              COMPONENTS+=("\"$component\"")
            done
            PYTHON_COMPONENTS="[$(IFS=,; echo "${COMPONENTS[*]}")]"
          fi
          
          # Check if frontend changes exist
          RUN_FRONTEND="false"
          if [[ -d "ui/web" ]] && (git diff --quiet origin/${{ github.base_ref }} HEAD -- "ui/web/" 2>/dev/null || [[ "${{ github.event_name }}" == "push" ]]); then
            RUN_FRONTEND="true"
          fi
          
          # Determine if tests should run
          RUN_TESTS="true"
          if [[ "${{ github.event_name }}" == "pull_request" ]] && ! git diff --quiet origin/${{ github.base_ref }} HEAD -- "tests/" "**/*test*.py" 2>/dev/null; then
            RUN_TESTS="true"
          fi
          
          # Security scan configuration  
          RUN_SECURITY="${{ github.event.inputs.run_security_scan || 'true' }}"
          
          # Generate cache key
          CACHE_KEY="deps-${{ runner.os }}-python${{ env.PYTHON_VERSION }}-$(date +'%Y%m%d')"
          
          echo "python-components=$PYTHON_COMPONENTS" >> $GITHUB_OUTPUT
          echo "run-frontend=$RUN_FRONTEND" >> $GITHUB_OUTPUT
          echo "run-tests=$RUN_TESTS" >> $GITHUB_OUTPUT
          echo "run-security=$RUN_SECURITY" >> $GITHUB_OUTPUT
          echo "cache-key=$CACHE_KEY" >> $GITHUB_OUTPUT
          
          echo "Configuration:"
          echo "  Python components: $PYTHON_COMPONENTS"
          echo "  Run frontend: $RUN_FRONTEND"
          echo "  Run tests: $RUN_TESTS"
          echo "  Run security: $RUN_SECURITY"

  # ============================================
  # STAGE 2: Python Code Quality
  # ============================================
  python-quality:
    name: Python Quality (${{ matrix.component }})
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.python-components != '[]'
    timeout-minutes: 8
    strategy:
      fail-fast: false
      matrix:
        component: ${{ fromJson(needs.setup.outputs.python-components) }}
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        cache-dependency-path: '**/requirements*.txt'
    
    - name: Cache Python Dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ needs.setup.outputs.cache-key }}-${{ matrix.component }}
        restore-keys: |
          deps-${{ runner.os }}-python${{ env.PYTHON_VERSION }}-
    
    - name: Install Quality Tools
      run: |
        python -m pip install --upgrade pip
        pip install ruff black mypy bandit pytest pytest-cov
        pip install -r requirements.txt || echo "No requirements.txt found"
    
    - name: Run Linting Pipeline
      run: |
        echo "::group::Ruff Linting - ${{ matrix.component }}"
        if [[ -d "${{ matrix.component }}" ]]; then
          ruff check ${{ matrix.component }}/ --output-format=github --exit-zero
        fi
        echo "::endgroup::"
        
        echo "::group::Black Formatting - ${{ matrix.component }}"
        if [[ -d "${{ matrix.component }}" ]]; then
          black --check --diff ${{ matrix.component }}/ || true
        fi
        echo "::endgroup::"
        
        echo "::group::MyPy Type Checking - ${{ matrix.component }}"
        if [[ -d "${{ matrix.component }}" ]]; then
          mypy ${{ matrix.component }}/ --ignore-missing-imports --show-error-codes --no-error-summary || true
        fi
        echo "::endgroup::"

  # ============================================
  # STAGE 3: Frontend Quality (Conditional)
  # ============================================
  frontend-quality:
    name: Frontend Quality
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.run-frontend == 'true'
    timeout-minutes: 8
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: ui/web/package-lock.json
    
    - name: Install Frontend Dependencies
      working-directory: ui/web
      run: |
        npm ci
        npm install --save-dev eslint prettier @typescript-eslint/parser
    
    - name: Run Frontend Quality Checks
      working-directory: ui/web
      run: |
        echo "::group::ESLint Analysis"
        npx eslint src/ --ext .ts,.tsx,.js,.jsx --format=github --max-warnings=0 || true
        echo "::endgroup::"
        
        echo "::group::Prettier Formatting"
        npx prettier --check src/ || true
        echo "::endgroup::"
        
        echo "::group::TypeScript Compilation"
        npx tsc --noEmit --strict || true
        echo "::endgroup::"

  # ============================================
  # STAGE 4: Testing Pipeline (Conditional)
  # ============================================
  testing:
    name: Test Suite
    runs-on: ubuntu-latest
    needs: [setup, python-quality]
    if: needs.setup.outputs.run-tests == 'true'
    timeout-minutes: 15
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: aivillage_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s  
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Cache Test Dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ needs.setup.outputs.cache-key }}-testing
        restore-keys: |
          deps-${{ runner.os }}-python${{ env.PYTHON_VERSION }}-
    
    - name: Install Test Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov pytest-xdist pytest-mock pytest-asyncio
        pip install -r requirements.txt || echo "No requirements.txt found"
    
    - name: Run Unit Tests
      env:
        DB_PASSWORD: test_password
        REDIS_PASSWORD: test_redis
        JWT_SECRET: test_jwt_secret_key_minimum_32_characters
        AIVILLAGE_ENV: testing
      run: |
        echo "::group::Unit Tests"
        python -m pytest tests/ -v --tb=short --maxfail=10 \
          --cov=core --cov=infrastructure --cov=src --cov=packages \
          --cov-report=xml --cov-report=html --cov-report=term \
          --junit-xml=test-results.xml -x || true
        echo "::endgroup::"
    
    - name: Upload Test Results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results
        path: |
          test-results.xml
          htmlcov/
          coverage.xml
        retention-days: 30

  # ============================================
  # STAGE 5: Integration Tests
  # ============================================
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [testing]
    if: always() && needs.setup.outputs.run-tests == 'true'
    timeout-minutes: 12
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-asyncio pytest-mock
        pip install -r requirements.txt || echo "No requirements.txt found"
    
    - name: Run Integration Tests
      env:
        DB_PASSWORD: test_password
        REDIS_PASSWORD: test_redis
        JWT_SECRET: test_jwt_secret_key_minimum_32_characters
      run: |
        echo "::group::Integration Tests"
        python -m pytest tests/integration/ -v --tb=short --maxfail=5 || true
        echo "::endgroup::"

  # ============================================
  # STAGE 6: Performance Tests (Optional)
  # ============================================
  performance-tests:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    needs: [integration-tests]
    if: github.event.inputs.run_performance_tests == 'true' && always()
    timeout-minutes: 10
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install Performance Tools
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-benchmark psutil memory_profiler
        pip install -r requirements.txt || echo "No requirements.txt found"
    
    - name: Run Performance Tests
      run: |
        echo "::group::Performance Benchmarks"
        python -m pytest benchmarks/ -v --tb=short || true
        echo "::endgroup::"

  # ============================================
  # STAGE 7: Build & Package
  # ============================================
  build:
    name: Build & Package
    runs-on: ubuntu-latest
    needs: [python-quality, frontend-quality, testing]
    if: always() && (needs.python-quality.result == 'success' || needs.python-quality.result == 'skipped')
    timeout-minutes: 8
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install Build Tools
      run: |
        python -m pip install --upgrade pip build setuptools wheel
        pip install -r requirements.txt || echo "No requirements.txt found"
    
    - name: Build Package
      run: |
        echo "::group::Building Package"
        python -m build || echo "Build completed with warnings"
        echo "::endgroup::"
    
    - name: Upload Build Artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: build-artifacts
        path: dist/
        retention-days: 7

  # ============================================
  # STAGE 8: Quality Gates & Status
  # ============================================
  quality-gates:
    name: Quality Gates
    runs-on: ubuntu-latest
    needs: [python-quality, frontend-quality, testing, integration-tests]
    if: always()
    timeout-minutes: 3
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
    
    - name: Quality Gate Analysis
      run: |
        echo "::group::Quality Gate Analysis"
        
        # Check job statuses
        python_quality="${{ needs.python-quality.result }}"
        frontend_quality="${{ needs.frontend-quality.result }}"
        testing="${{ needs.testing.result }}"
        integration="${{ needs.integration-tests.result }}"
        
        echo "Job Results:"
        echo "- Python Quality: $python_quality"
        echo "- Frontend Quality: $frontend_quality"
        echo "- Testing: $testing"
        echo "- Integration Tests: $integration"
        
        # Determine overall status
        CRITICAL_FAILURES=0
        if [[ "$python_quality" == "failure" ]]; then
          echo "::warning::Python quality checks failed"
          ((CRITICAL_FAILURES++))
        fi
        
        if [[ "$testing" == "failure" ]]; then
          echo "::warning::Unit tests failed"
          ((CRITICAL_FAILURES++))
        fi
        
        if [[ $CRITICAL_FAILURES -eq 0 ]]; then
          echo "::notice::All quality gates passed successfully!"
          echo "quality_status=success" >> $GITHUB_ENV
        elif [[ $CRITICAL_FAILURES -le 1 ]]; then
          echo "::warning::Some quality gates failed but within tolerance"
          echo "quality_status=warning" >> $GITHUB_ENV
        else
          echo "::error::Multiple critical quality gates failed"
          echo "quality_status=failure" >> $GITHUB_ENV
          exit 1
        fi
        
        echo "::endgroup::"

  # ============================================
  # STAGE 9: Deployment Readiness (Main only)
  # ============================================
  deployment-readiness:
    name: Deployment Readiness
    runs-on: ubuntu-latest
    needs: [quality-gates, build]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push' && always()
    timeout-minutes: 5
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
    
    - name: Production Readiness Validation
      run: |
        echo "::group::Production Readiness Check"
        
        # Check for required files
        required_files=(
          "config/linting/unified_linting_manager.py"
          "tests/validation/production_readiness_validation.py"
        )
        
        missing_files=()
        for file in "${required_files[@]}"; do
          if [[ ! -f "$file" ]]; then
            missing_files+=("$file")
          fi
        done
        
        if [[ ${#missing_files[@]} -eq 0 ]]; then
          echo "::notice::All required files present - system ready for deployment"
          echo "deployment_ready=true" >> $GITHUB_ENV
        else
          echo "::error::Missing required files: ${missing_files[*]}"
          echo "deployment_ready=false" >> $GITHUB_ENV
        fi
        
        echo "::endgroup::"
    
    - name: Run Production Validation
      if: env.deployment_ready == 'true'
      run: |
        echo "::group::Production Validation"
        python tests/validation/production_readiness_validation.py || echo "Validation completed with warnings"
        echo "::endgroup::"