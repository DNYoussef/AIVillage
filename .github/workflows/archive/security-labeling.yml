name: Security Risk Labeling & Triage

on:
  issues:
    types: [opened, edited, reopened]
  pull_request:
    types: [opened, edited, reopened, synchronize]
  workflow_dispatch:
    inputs:
      issue_number:
        description: 'Issue number to re-analyze'
        required: false
        type: number

permissions:
  issues: write
  pull-requests: write
  contents: read

jobs:
  # ============================================
  # Security Risk Analysis & Labeling
  # ============================================
  security-risk-analysis:
    name: Security Risk Analysis & Auto-Labeling
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4

      - name: üîç Analyze Issue/PR for Security Risk
        id: analyze
        env:
          ISSUE_TITLE: ${{ github.event.issue.title || github.event.pull_request.title }}
          ISSUE_BODY: ${{ github.event.issue.body || github.event.pull_request.body }}
          ISSUE_NUMBER: ${{ github.event.issue.number || github.event.pull_request.number || github.event.inputs.issue_number }}
        run: |
          python3 << 'EOF'
          import os
          import re
          import json
          import sys
          
          def analyze_security_risk(title, body):
              """Analyze text for security risk indicators"""
              
              # Combine title and body for analysis
              text = f"{title} {body}".lower()
              
              # Security risk patterns with weights
              risk_patterns = {
                  'critical': [
                      (r'\b(rce|remote code execution|command injection|sql injection)\b', 10),
                      (r'\b(privilege escalation|admin bypass|authentication bypass)\b', 10),
                      (r'\b(data breach|sensitive data leak|pii exposure)\b', 10),
                      (r'\b(zero.day|0.day|cve.\d+.\d+)\b', 9),
                      (r'\b(backdoor|malware|trojan|rootkit)\b', 9),
                  ],
                  'high': [
                      (r'\b(xss|cross.site|csrf|cross.site.request.forgery)\b', 8),
                      (r'\b(password|credential|secret|token|api.key)\b.*\b(leak|expose|hardcoded)\b', 8),
                      (r'\b(directory traversal|path traversal|lfi|rfi)\b', 7),
                      (r'\b(deserialization|pickle|yaml.load|eval|exec)\b', 7),
                      (r'\b(dos|denial.of.service|ddos|resource exhaustion)\b', 6),
                  ],
                  'medium': [
                      (r'\b(information disclosure|error message|stack trace)\b', 5),
                      (r'\b(weak encryption|md5|sha1|weak cipher)\b', 5),
                      (r'\b(session|cookie).*\b(hijack|fixation|insecure)\b', 5),
                      (r'\b(clickjacking|frame|iframe).*\b(attack|vulnerability)\b', 4),
                      (r'\b(rate limit|brute force|enumeration)\b', 4),
                  ],
                  'low': [
                      (r'\b(information leak|verbose error|debug info)\b', 3),
                      (r'\b(missing header|security header|x.frame.options)\b', 3),
                      (r'\b(http.*https|insecure protocol|plain text)\b', 2),
                      (r'\b(weak password|default password|password policy)\b', 2),
                  ]
              }
              
              # Component-specific risk indicators
              component_risks = {
                  'authentication': 8,
                  'authorization': 8,
                  'p2p': 7,
                  'network': 6,
                  'api': 5,
                  'database': 6,
                  'crypto': 8,
                  'ai/ml': 4,
                  'mobile': 5,
                  'web': 5
              }
              
              # Calculate risk score
              max_risk_score = 0
              risk_category = 'none'
              matched_patterns = []
              
              for category, patterns in risk_patterns.items():
                  for pattern, score in patterns:
                      if re.search(pattern, text):
                          matched_patterns.append((category, pattern, score))
                          if score > max_risk_score:
                              max_risk_score = score
                              risk_category = category
              
              # Check for component-specific risks
              component_risk = 0
              affected_components = []
              for component, risk_boost in component_risks.items():
                  if component in text:
                      affected_components.append(component)
                      component_risk = max(component_risk, risk_boost)
              
              # Adjust risk based on components
              if component_risk > 0:
                  max_risk_score = max(max_risk_score, component_risk)
                  if max_risk_score >= 8 and risk_category in ['none', 'low']:
                      risk_category = 'high'
                  elif max_risk_score >= 6 and risk_category in ['none', 'low']:
                      risk_category = 'medium'
                  elif max_risk_score >= 3 and risk_category == 'none':
                      risk_category = 'low'
              
              # Threat modeling indicators
              threat_indicators = {
                  'spoofing': r'\b(spoofing|impersonation|identity theft)\b',
                  'tampering': r'\b(tampering|data modification|integrity)\b',
                  'repudiation': r'\b(repudiation|audit|logging|non.repudiation)\b',
                  'information_disclosure': r'\b(information disclosure|data leak|privacy)\b',
                  'denial_of_service': r'\b(dos|ddos|availability|resource)\b',
                  'elevation_of_privilege': r'\b(privilege|elevation|escalation|admin)\b'
              }
              
              stride_threats = []
              for threat, pattern in threat_indicators.items():
                  if re.search(pattern, text):
                      stride_threats.append(threat.replace('_', ' ').title())
              
              return {
                  'risk_score': max_risk_score,
                  'risk_category': risk_category,
                  'matched_patterns': matched_patterns,
                  'affected_components': affected_components,
                  'stride_threats': stride_threats,
                  'needs_security_review': max_risk_score >= 5
              }
          
          # Get issue/PR details
          title = os.environ.get('ISSUE_TITLE', '')
          body = os.environ.get('ISSUE_BODY', '')
          
          if not title and not body:
              print("No issue/PR content to analyze")
              sys.exit(0)
          
          # Perform security analysis
          analysis = analyze_security_risk(title, body)
          
          print(f"Security Risk Analysis Results:")
          print(f"  Risk Score: {analysis['risk_score']}/10")
          print(f"  Risk Category: {analysis['risk_category']}")
          print(f"  Needs Security Review: {analysis['needs_security_review']}")
          print(f"  Affected Components: {', '.join(analysis['affected_components']) or 'None identified'}")
          print(f"  STRIDE Threats: {', '.join(analysis['stride_threats']) or 'None identified'}")
          
          # Output for GitHub Actions
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"risk-score={analysis['risk_score']}\n")
              f.write(f"risk-category={analysis['risk_category']}\n")
              f.write(f"needs-security-review={str(analysis['needs_security_review']).lower()}\n")
              f.write(f"affected-components={','.join(analysis['affected_components'])}\n")
              f.write(f"stride-threats={','.join(analysis['stride_threats'])}\n")
          
          # Save detailed analysis
          with open('security-analysis.json', 'w') as f:
              json.dump(analysis, f, indent=2)
          EOF

      - name: üè∑Ô∏è Apply Security Risk Labels
        if: steps.analyze.outputs.risk-category != 'none'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          ISSUE_NUMBER: ${{ github.event.issue.number || github.event.pull_request.number || github.event.inputs.issue_number }}
        run: |
          echo "Applying security risk labels..."
          
          # Define labels based on risk category
          case "${{ steps.analyze.outputs.risk-category }}" in
            "critical")
              LABELS="security-critical,priority-critical,needs-immediate-attention"
              ;;
            "high")
              LABELS="security-high,priority-high,needs-security-review"
              ;;
            "medium")
              LABELS="security-medium,priority-medium,security-review"
              ;;
            "low")
              LABELS="security-low,security-minor"
              ;;
            *)
              LABELS=""
              ;;
          esac
          
          # Add component-specific labels
          COMPONENTS="${{ steps.analyze.outputs.affected-components }}"
          if [ -n "$COMPONENTS" ]; then
            IFS=',' read -ra COMP_ARRAY <<< "$COMPONENTS"
            for component in "${COMP_ARRAY[@]}"; do
              LABELS="${LABELS},component-${component}"
            done
          fi
          
          # Add STRIDE threat labels
          THREATS="${{ steps.analyze.outputs.stride-threats }}"
          if [ -n "$THREATS" ]; then
            IFS=',' read -ra THREAT_ARRAY <<< "$THREATS"
            for threat in "${THREAT_ARRAY[@]}"; do
              threat_label=$(echo "$threat" | tr '[:upper:]' '[:lower:]' | tr ' ' '-')
              LABELS="${LABELS},stride-${threat_label}"
            done
          fi
          
          # Apply labels to issue/PR
          if [ -n "$LABELS" ]; then
            echo "Adding labels: $LABELS"
            gh issue edit $ISSUE_NUMBER --add-label "$LABELS" || \
            gh pr edit $ISSUE_NUMBER --add-label "$LABELS" || \
            echo "Failed to add labels (might be a permissions issue)"
          fi

      - name: üîî Security Team Notification
        if: steps.analyze.outputs.needs-security-review == 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          ISSUE_NUMBER: ${{ github.event.issue.number || github.event.pull_request.number || github.event.inputs.issue_number }}
          RISK_SCORE: ${{ steps.analyze.outputs.risk-score }}
          RISK_CATEGORY: ${{ steps.analyze.outputs.risk-category }}
        run: |
          echo "Notifying security team of high-risk issue/PR..."
          
          # Create security team notification comment
          COMMENT_BODY=$(cat << EOF
          ## üö® Security Review Required
          
          This issue/PR has been automatically flagged for security review based on content analysis.
          
          **Risk Assessment:**
          - **Risk Level**: $RISK_CATEGORY (Score: $RISK_SCORE/10)
          - **Components Affected**: ${{ steps.analyze.outputs.affected-components }}
          - **STRIDE Threats**: ${{ steps.analyze.outputs.stride-threats }}
          
          **Security Team Actions:**
          - [ ] Initial security assessment completed
          - [ ] Threat model review (if applicable)  
          - [ ] Security testing requirements identified
          - [ ] Risk mitigation strategy defined
          - [ ] Security approval granted
          
          **SLA Commitments:**
          - **Critical (9-10)**: 15 minutes initial response
          - **High (7-8)**: 1 hour initial response  
          - **Medium (5-6)**: 24 hours initial response
          
          @security-team Please review this ${{ github.event.issue.number && 'issue' || 'PR' }} according to our security triage procedures.
          
          ---
          *This comment was automatically generated by the Security Risk Labeling system.*
          EOF
          )
          
          # Post comment mentioning security team
          gh issue comment $ISSUE_NUMBER --body "$COMMENT_BODY" || \
          gh pr comment $ISSUE_NUMBER --body "$COMMENT_BODY" || \
          echo "Failed to post security notification comment"

      - name: üìä Update Security Metrics
        if: steps.analyze.outputs.risk-category != 'none'
        env:
          RISK_CATEGORY: ${{ steps.analyze.outputs.risk-category }}
          RISK_SCORE: ${{ steps.analyze.outputs.risk-score }}
        run: |
          echo "Updating security metrics..."
          
          # Create/update security metrics file
          python3 << 'EOF'
          import json
          import os
          from datetime import datetime
          
          metrics_file = 'security-metrics.json'
          
          # Load existing metrics or create new
          try:
              with open(metrics_file, 'r') as f:
                  metrics = json.load(f)
          except FileNotFoundError:
              metrics = {
                  'total_security_issues': 0,
                  'by_risk_level': {
                      'critical': 0,
                      'high': 0,
                      'medium': 0,
                      'low': 0
                  },
                  'last_updated': None
              }
          
          # Update metrics
          risk_category = os.environ.get('RISK_CATEGORY', 'none')
          if risk_category in metrics['by_risk_level']:
              metrics['by_risk_level'][risk_category] += 1
              metrics['total_security_issues'] += 1
          
          metrics['last_updated'] = datetime.utcnow().isoformat() + 'Z'
          
          # Save updated metrics
          with open(metrics_file, 'w') as f:
              json.dump(metrics, f, indent=2)
          
          print(f"Security metrics updated:")
          print(f"  Total security issues: {metrics['total_security_issues']}")
          print(f"  By risk level: {metrics['by_risk_level']}")
          EOF

      - name: üìà Security Dashboard Update
        if: steps.analyze.outputs.risk-category != 'none'
        run: |
          echo "## üõ°Ô∏è Security Risk Analysis Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Issue/PR:** #${{ github.event.issue.number || github.event.pull_request.number || github.event.inputs.issue_number }}" >> $GITHUB_STEP_SUMMARY
          echo "**Risk Level:** ${{ steps.analyze.outputs.risk-category }} (Score: ${{ steps.analyze.outputs.risk-score }}/10)" >> $GITHUB_STEP_SUMMARY
          echo "**Security Review Required:** ${{ steps.analyze.outputs.needs-security-review }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ steps.analyze.outputs.affected-components }}" != "" ]; then
            echo "**Affected Components:** ${{ steps.analyze.outputs.affected-components }}" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ steps.analyze.outputs.stride-threats }}" != "" ]; then
            echo "**STRIDE Threats:** ${{ steps.analyze.outputs.stride-threats }}" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Actions Taken" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Automated security risk analysis completed" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Security risk labels applied" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ steps.analyze.outputs.needs-security-review }}" = "true" ]; then
            echo "- ‚úÖ Security team notification sent" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "- ‚úÖ Security metrics updated" >> $GITHUB_STEP_SUMMARY

  # ============================================
  # Security Label Management
  # ============================================
  label-management:
    name: Security Label Management
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'push'
    
    steps:
      - uses: actions/checkout@v4

      - name: üè∑Ô∏è Ensure Security Labels Exist
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "Ensuring all required security labels exist..."
          
          # Define security labels with descriptions and colors
          declare -A LABELS=(
            ["security-critical"]="Critical security vulnerability requiring immediate attention|d73a4a"
            ["security-high"]="High severity security issue|e99695"
            ["security-medium"]="Medium severity security issue|f9c513"
            ["security-low"]="Low severity security issue|0e8a16"
            ["security-review"]="Needs security team review|5319e7"
            ["needs-security-review"]="High priority security review required|d93f0b"
            ["needs-immediate-attention"]="Critical issue requiring immediate response|b60205"
            ["priority-critical"]="Critical priority|b60205"
            ["priority-high"]="High priority|d93f0b"
            ["priority-medium"]="Medium priority|fbca04"
            ["component-authentication"]="Authentication system|0052cc"
            ["component-authorization"]="Authorization/RBAC system|0052cc"
            ["component-p2p"]="P2P networking|0052cc"
            ["component-network"]="Network layer|0052cc"
            ["component-api"]="API endpoints|0052cc"
            ["component-database"]="Database layer|0052cc"
            ["component-crypto"]="Cryptographic operations|0052cc"
            ["component-ai/ml"]="AI/ML components|0052cc"
            ["component-mobile"]="Mobile applications|0052cc"
            ["component-web"]="Web interface|0052cc"
            ["stride-spoofing"]="STRIDE: Spoofing threat|8b5cf6"
            ["stride-tampering"]="STRIDE: Tampering threat|8b5cf6"
            ["stride-repudiation"]="STRIDE: Repudiation threat|8b5cf6"
            ["stride-information-disclosure"]="STRIDE: Information disclosure|8b5cf6"
            ["stride-denial-of-service"]="STRIDE: Denial of service|8b5cf6"
            ["stride-elevation-of-privilege"]="STRIDE: Elevation of privilege|8b5cf6"
          )
          
          for label in "${!LABELS[@]}"; do
            IFS='|' read -r description color <<< "${LABELS[$label]}"
            
            # Check if label exists
            if gh label list | grep -q "^$label"; then
              echo "‚úÖ Label '$label' exists"
            else
              echo "Creating label '$label'..."
              gh label create "$label" --description "$description" --color "$color" || \
              echo "‚ö†Ô∏è Failed to create label '$label' (might already exist)"
            fi
          done
          
          echo "‚úÖ Security label management completed"

      - name: üìä Generate Security Metrics Report
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "Generating security metrics report..."
          
          python3 << 'EOF'
          import subprocess
          import json
          import re
          from datetime import datetime, timedelta
          
          def run_gh_command(cmd):
              """Run GitHub CLI command and return output"""
              try:
                  result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
                  if result.returncode == 0:
                      return result.stdout.strip()
                  else:
                      print(f"Error running command: {cmd}")
                      print(f"Error: {result.stderr}")
                      return ""
              except Exception as e:
                  print(f"Exception running command: {e}")
                  return ""
          
          # Get security-labeled issues and PRs
          security_issues = run_gh_command('gh issue list --label "security-critical,security-high,security-medium,security-low" --state all --json number,title,labels,createdAt,state')
          security_prs = run_gh_command('gh pr list --label "security-critical,security-high,security-medium,security-low" --state all --json number,title,labels,createdAt,state')
          
          try:
              issues = json.loads(security_issues) if security_issues else []
              prs = json.loads(security_prs) if security_prs else []
          except json.JSONDecodeError:
              issues = []
              prs = []
          
          # Analyze security metrics
          total_security_items = len(issues) + len(prs)
          
          risk_counts = {'critical': 0, 'high': 0, 'medium': 0, 'low': 0}
          component_counts = {}
          stride_counts = {}
          
          for item in issues + prs:
              labels = [label['name'] for label in item.get('labels', [])]
              
              # Count risk levels
              for risk in risk_counts:
                  if f'security-{risk}' in labels:
                      risk_counts[risk] += 1
                      break
              
              # Count components
              for label in labels:
                  if label.startswith('component-'):
                      component = label.replace('component-', '')
                      component_counts[component] = component_counts.get(component, 0) + 1
                  elif label.startswith('stride-'):
                      threat = label.replace('stride-', '')
                      stride_counts[threat] = stride_counts.get(threat, 0) + 1
          
          # Generate report
          report = {
              'timestamp': datetime.utcnow().isoformat() + 'Z',
              'total_security_items': total_security_items,
              'risk_distribution': risk_counts,
              'component_distribution': component_counts,
              'stride_distribution': stride_counts,
              'open_issues': len([i for i in issues if i['state'] == 'open']),
              'open_prs': len([p for p in prs if p['state'] == 'open'])
          }
          
          with open('security-metrics-report.json', 'w') as f:
              json.dump(report, f, indent=2)
          
          print("üìä Security Metrics Summary:")
          print(f"  Total Security Items: {total_security_items}")
          print(f"  Open Issues: {report['open_issues']}")
          print(f"  Open PRs: {report['open_prs']}")
          print(f"  Risk Distribution: {risk_counts}")
          print(f"  Top Components: {dict(sorted(component_counts.items(), key=lambda x: x[1], reverse=True)[:5])}")
          EOF

      - name: Upload Security Reports
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: |
            security-analysis.json
            security-metrics.json
            security-metrics-report.json
          retention-days: 90