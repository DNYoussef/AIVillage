name: Pre-commit Performance Optimization

on:
  workflow_dispatch:
  schedule:
    # Run performance analysis daily
    - cron: '0 6 * * *'
  push:
    paths:
      - '.pre-commit-config.yaml'
      - 'scripts/ci/**'

jobs:
  performance-analysis:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pre-commit

      - name: Cache pre-commit hooks
        uses: actions/cache@v4
        with:
          path: ~/.cache/pre-commit
          key: pre-commit-${{ runner.os }}-${{ hashFiles('.pre-commit-config.yaml') }}
          restore-keys: |
            pre-commit-${{ runner.os }}-

      - name: Install pre-commit hooks
        run: pre-commit install

      - name: Benchmark pre-commit performance
        id: benchmark
        run: |
          echo "Starting pre-commit benchmark..."
          python scripts/ci/precommit_performance_monitor.py benchmark > benchmark_results.txt

          # Extract benchmark time
          BENCHMARK_TIME=$(grep -oE '[0-9]+\.[0-9]+s' benchmark_results.txt | head -1 | sed 's/s//')
          echo "benchmark_time=$BENCHMARK_TIME" >> $GITHUB_OUTPUT
          echo "Benchmark completed in ${BENCHMARK_TIME}s"

          # Check if benchmark exceeds target
          python -c "
          import sys
          time = float('$BENCHMARK_TIME' or '999')
          target = 120.0
          if time > target:
              print(f'âŒ Performance regression: {time:.1f}s > {target}s')
              sys.exit(1)
          else:
              print(f'âœ… Performance within target: {time:.1f}s <= {target}s')
          "

      - name: Generate performance report
        run: |
          python scripts/ci/precommit_performance_monitor.py > performance_report.txt
          cat performance_report.txt

      - name: Upload performance artifacts
        uses: actions/upload-artifact@v4
        with:
          name: performance-analysis
          path: |
            performance_report.txt
            benchmark_results.txt
            .pre-commit-metrics.json
          retention-days: 30

      - name: Comment on PR (if applicable)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('performance_report.txt', 'utf8');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## ðŸš€ Pre-commit Performance Analysis

              **Benchmark Time**: ${{ steps.benchmark.outputs.benchmark_time }}s
              **Target**: 120.0s

              <details>
              <summary>Detailed Performance Report</summary>

              \`\`\`
              ${report}
              \`\`\`
              </details>

              *This analysis helps maintain fast developer workflows by keeping pre-commit execution under 2 minutes.*`
            });

  file-scope-analysis:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Analyze file scope impact
        run: |
          echo "ðŸ“Š Pre-commit File Scope Analysis"
          echo "=================================="

          echo "Total Python files:"
          find . -name "*.py" -type f | wc -l

          echo "Files excluded by current config:"
          find . -path "*/deprecated/*" -name "*.py" -o \
                 -path "*/archive/*" -name "*.py" -o \
                 -path "*/backups/*" -name "*.py" -o \
                 -path "*/__pycache__/*" -name "*.py" -o \
                 -path "*/.git/*" -name "*.py" -o \
                 -path "*/.pytest_cache/*" -name "*.py" | wc -l

          echo "Effective files processed:"
          find . -name "*.py" -type f \
            ! -path "*/deprecated/*" \
            ! -path "*/archive/*" \
            ! -path "*/backups/*" \
            ! -path "*/__pycache__/*" \
            ! -path "*/.git/*" \
            ! -path "*/.pytest_cache/*" \
            ! -path "*/node_modules/*" \
            ! -path "*/.tox/*" \
            ! -path "*/.venv/*" \
            ! -path "*/venv/*" \
            ! -path "*/env/*" | wc -l

          echo "Largest files (potential bottlenecks):"
          find . -name "*.py" -type f \
            ! -path "*/deprecated/*" \
            ! -path "*/archive/*" \
            ! -path "*/backups/*" \
            -exec wc -l {} + | sort -nr | head -10

      - name: Validate exclusion patterns
        run: |
          echo "ðŸ” Validating exclusion patterns effectiveness"

          # Check for common performance bottlenecks
          echo "Checking for unexcluded cache directories..."
          find . -name "__pycache__" -type d | head -5

          echo "Checking for unexcluded temporary files..."
          find . -name "*.pyc" -o -name "*.pyo" -o -name "*.pyd" | head -5

          echo "Large directories that might need exclusion:"
          du -sh */ 2>/dev/null | sort -hr | head -10
