# Stage 3: Mathematical Reasoning Configuration
# Advanced math reasoning and multi-hop text understanding

stage:
  name: "math_reasoning"
  description: "Mathematical reasoning and multi-hop text understanding"
  stage_id: 3

# Training Parameters
training:
  max_steps: 16000               # Longer training for complex reasoning
  batch_size: 4                  # Smaller batch for longer sequences
  sequence_length: 1536          # Extended context for reasoning chains
  learning_rate: 5e-5            # Further reduced LR for stability

  eval_interval: 800
  save_interval: 4000
  log_interval: 200

# Model Behavior
model:
  max_refinement_steps: 8        # More steps for deep reasoning
  act_threshold: 0.99
  ponder_cost_initial: 0.02
  ponder_cost_final: 0.02        # Stable ponder cost

  # Increase memory utilization
  memory_settings:
    ltm_read_only: false
    ltm_write_alpha: 0.15         # Higher write rate for complex reasoning
    ltm_decay_rate: 5e-4          # Slower decay to preserve reasoning chains

# Data Configuration
data:
  # Mathematical and reasoning tasks
  task_types:
    - "gsm8k_problems"            # Grade school math word problems
    - "math_competition"          # Mathematical competition problems
    - "hotpot_qa"                 # Multi-hop question answering
    - "logical_reasoning"         # Formal logical reasoning
    - "proof_generation"          # Mathematical proof steps

  # Data sources
  datasets:
    - "gsm8k"
    - "math_dataset"
    - "hotpot_qa"
    - "logical_reasoning_corpus"

  # Reasoning-focused augmentation
  augmentation:
    enabled: true
    rate: 0.4                    # Lighter augmentation for reasoning
    types:
      - "problem_rephrasing"      # Rephrase problems
      - "step_reordering"         # Reorder reasoning steps
      - "context_variation"       # Vary problem context

    # Math-specific augmentation
    math_problems:
      number_variations: true     # Change specific numbers
      context_substitution: true  # Different story contexts
      difficulty_scaling: true    # Scale problem difficulty

    # Multi-hop QA augmentation
    multihop_qa:
      hop_count_variation: [2, 3, 4]  # Different numbers of reasoning hops
      distractor_addition: true       # Add irrelevant information
      entity_substitution: true       # Change entities while preserving logic

# Loss Configuration
loss:
  deep_supervision_weight: 1.0
  improvement_weight: 0.1
  consistency_weight: 0.1
  ponder_weight: 1.5             # Higher penalty to encourage efficient reasoning

# GrokFast Settings (reduced for stability in later stages)
grokfast:
  enabled: true
  global_multiplier: 0.6         # 40% reduction as per Agent 4
  focus_components: ["refinement_core"]

  components:
    refinement_core:
      alpha: 0.95                # Reduced smoothing
      lamb: 1.2                  # Reduced amplification
      window_size: 150           # Longer window for stability

    gated_ltm:
      alpha: 0.95
      lamb: 1.5                  # Keep memory dynamics
      window_size: 50

    act_halting:
      enabled: false

# Convergence Criteria
convergence:
  patience: 1000                 # Long patience for complex reasoning
  min_accuracy: 0.6              # Lower target due to complexity
  max_ponder_cost: 8.0          # Allow significant pondering
  min_improvement: 1e-4

  # Reasoning-specific indicators
  grokking_indicators:
    reasoning_chain_emergence: true   # Multi-step reasoning appears
    mathematical_insight_jumps: true  # Sudden math understanding
    generalization_to_unseen: true    # Generalizes to new problem types

# Memory Management
memory:
  consolidation_frequency: "low"     # Preserve complex reasoning chains
  memory_capacity_usage_target: 0.7  # Higher memory usage

  # Reasoning-specific memory
  reasoning_memory:
    mathematical_facts: true         # Store math facts and formulas
    reasoning_patterns: true         # Store common reasoning patterns
    proof_strategies: true           # Store proof techniques
    multihop_chains: true           # Store complex reasoning chains

# Validation Tasks
validation:
  tasks:
    - name: "gsm8k_evaluation"
      description: "Solve grade school math word problems"
      expected_accuracy: 0.65

    - name: "math_competition_problems"
      description: "Solve mathematical competition problems"
      expected_accuracy: 0.4

    - name: "hotpot_qa_evaluation"
      description: "Answer multi-hop questions"
      expected_accuracy: 0.6

    - name: "logical_reasoning_tests"
      description: "Solve formal logical reasoning problems"
      expected_accuracy: 0.7

# Reasoning Quality Analysis
reasoning_analysis:
  # Track quality of reasoning chains
  track_metrics:
    - "reasoning_chain_length"      # How many steps in reasoning?
    - "step_correctness"           # Are individual steps correct?
    - "logical_coherence"          # Is reasoning logically coherent?
    - "mathematical_accuracy"      # Are calculations correct?
    - "fact_retrieval_accuracy"    # Can model retrieve relevant facts?

  # Quality thresholds
  quality_thresholds:
    min_chain_coherence: 0.8
    min_step_accuracy: 0.85
    min_fact_accuracy: 0.9

  analysis_interval: 1000
  save_reasoning_examples: true

# Advanced Features
advanced_features:
  # Chain-of-thought analysis
  chain_of_thought:
    enable_cot_training: true
    cot_loss_weight: 0.2
    require_explicit_steps: true

  # Mathematical reasoning features
  math_features:
    symbolic_manipulation: true
    numerical_computation: true
    geometric_reasoning: false     # Not in this stage

  # Multi-hop reasoning features
  multihop_features:
    entity_tracking: true
    relation_reasoning: true
    temporal_reasoning: true

# Resource Management
resources:
  max_memory_gb: 16
  max_time_hours: 8

  # Optimization for complex reasoning
  gradient_checkpointing: true
  activation_checkpointing: true
  mixed_precision: true

# Stage Advancement Criteria
advancement:
  required_metrics:
    min_accuracy: 0.6
    max_ponder_cost: 8.0
    reasoning_quality_threshold: 0.75

  preferred_metrics:
    gsm8k_accuracy: 0.65
    hotpot_qa_accuracy: 0.6
    reasoning_chain_coherence: 0.8
    mathematical_fact_retrieval: 0.9
