"""
MCP Monitoring System - Comprehensive Health Checks and Performance Monitoring

This module provides comprehensive monitoring and health check infrastructure for MCP
server coordination in CI/CD pipelines. Designed for observability, alerting, and
performance optimization.

Key Features:
- Multi-dimensional health monitoring (availability, performance, functionality)
- Real-time metrics collection and aggregation
- Alerting with configurable thresholds and escalation
- Performance trending and anomaly detection
- Integration with CI/CD pipeline status reporting
- Comprehensive dashboard data export
"""

import asyncio
import json
import logging
import statistics
import time
from collections import defaultdict, deque
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Callable, Deque, Dict, List, Optional, Set, Union
from uuid import uuid4

logger = logging.getLogger(__name__)


class HealthStatus(Enum):
    """Health status levels"""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    CRITICAL = "critical"
    UNKNOWN = "unknown"


class MetricType(Enum):
    """Types of metrics collected"""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    TIMING = "timing"


class AlertSeverity(Enum):
    """Alert severity levels"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


@dataclass
class HealthCheck:
    """Definition of a health check"""
    check_id: str = field(default_factory=lambda: f"check_{uuid4().hex[:8]}")
    name: str = ""
    description: str = ""
    component: str = ""
    
    # Check configuration
    check_function: Optional[Callable] = None
    check_interval_seconds: float = 30.0
    timeout_seconds: float = 10.0
    
    # Thresholds
    warning_threshold: Optional[float] = None
    critical_threshold: Optional[float] = None
    
    # State
    enabled: bool = True
    last_check_time: Optional[datetime] = None
    last_status: HealthStatus = HealthStatus.UNKNOWN
    last_result: Dict[str, Any] = field(default_factory=dict)
    consecutive_failures: int = 0
    
    # History
    check_history: Deque[Dict[str, Any]] = field(default_factory=lambda: deque(maxlen=100))


@dataclass
class Metric:
    """A monitoring metric"""
    metric_id: str = field(default_factory=lambda: f"metric_{uuid4().hex[:8]}")
    name: str = ""
    description: str = ""
    metric_type: MetricType = MetricType.GAUGE
    component: str = ""
    
    # Current state
    value: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)
    labels: Dict[str, str] = field(default_factory=dict)
    
    # History for trending
    history: Deque[Dict[str, Any]] = field(default_factory=lambda: deque(maxlen=1000))
    
    def record_value(self, value: float, labels: Dict[str, str] = None):
        """Record a new metric value"""
        self.value = value
        self.timestamp = datetime.now()
        if labels:
            self.labels = labels
        
        self.history.append({
            "value": value,
            "timestamp": self.timestamp,
            "labels": labels or {}
        })


@dataclass
class Alert:
    """An alert generated by the monitoring system"""
    alert_id: str = field(default_factory=lambda: f"alert_{uuid4().hex[:8]}")
    severity: AlertSeverity = AlertSeverity.INFO
    component: str = ""
    title: str = ""
    description: str = ""
    
    # Context
    metric_name: Optional[str] = None
    metric_value: Optional[float] = None
    threshold_value: Optional[float] = None
    check_name: Optional[str] = None
    
    # Timing
    triggered_at: datetime = field(default_factory=datetime.now)
    resolved_at: Optional[datetime] = None
    acknowledgments: List[Dict[str, Any]] = field(default_factory=list)
    
    # State
    is_active: bool = True
    escalation_level: int = 0


class PerformanceAnalyzer:
    """Analyzes performance metrics and detects anomalies"""
    
    def __init__(self, window_minutes: int = 15):
        self.window_minutes = window_minutes
        self.baseline_cache: Dict[str, Dict[str, float]] = {}
        self.anomaly_threshold_multiplier = 2.0
    
    def analyze_metric_trend(self, metric: Metric) -> Dict[str, Any]:
        """Analyze trend and detect anomalies for a metric"""
        if len(metric.history) < 5:
            return {"status": "insufficient_data", "trend": "unknown"}
        
        # Get recent values
        cutoff_time = datetime.now() - timedelta(minutes=self.window_minutes)
        recent_values = [
            entry["value"] for entry in metric.history
            if entry["timestamp"] >= cutoff_time
        ]
        
        if len(recent_values) < 3:
            return {"status": "insufficient_recent_data", "trend": "unknown"}
        
        # Calculate statistics
        mean_value = statistics.mean(recent_values)
        median_value = statistics.median(recent_values)
        
        try:
            std_dev = statistics.stdev(recent_values) if len(recent_values) > 1 else 0
        except statistics.StatisticsError:
            std_dev = 0
        
        # Determine trend
        if len(recent_values) >= 5:
            first_half = recent_values[:len(recent_values)//2]
            second_half = recent_values[len(recent_values)//2:]
            
            first_avg = statistics.mean(first_half)
            second_avg = statistics.mean(second_half)
            
            if second_avg > first_avg * 1.1:
                trend = "increasing"
            elif second_avg < first_avg * 0.9:
                trend = "decreasing"
            else:
                trend = "stable"
        else:
            trend = "stable"
        
        # Check for anomalies
        baseline = self._get_baseline(metric.name)
        anomaly_detected = False
        
        if baseline and baseline.get("mean"):
            baseline_mean = baseline["mean"]
            baseline_std = baseline.get("std", 0)
            
            if abs(mean_value - baseline_mean) > baseline_std * self.anomaly_threshold_multiplier:
                anomaly_detected = True
        
        return {
            "status": "analyzed",
            "trend": trend,
            "mean": mean_value,
            "median": median_value,
            "std_dev": std_dev,
            "min": min(recent_values),
            "max": max(recent_values),
            "anomaly_detected": anomaly_detected,
            "data_points": len(recent_values)
        }
    
    def _get_baseline(self, metric_name: str) -> Optional[Dict[str, float]]:
        """Get baseline statistics for a metric"""
        return self.baseline_cache.get(metric_name)
    
    def update_baseline(self, metric_name: str, values: List[float]):
        """Update baseline statistics for a metric"""
        if not values:
            return
        
        self.baseline_cache[metric_name] = {
            "mean": statistics.mean(values),
            "median": statistics.median(values),
            "std": statistics.stdev(values) if len(values) > 1 else 0,
            "min": min(values),
            "max": max(values),
            "count": len(values),
            "updated_at": datetime.now().timestamp()
        }


class AlertManager:
    """Manages alerts and notifications"""
    
    def __init__(self):
        self.alerts: Dict[str, Alert] = {}
        self.alert_rules: Dict[str, Dict[str, Any]] = {}
        self.notification_handlers: List[Callable] = []
        self.suppression_rules: Dict[str, Dict[str, Any]] = {}
        
        # Statistics
        self.stats = {
            "alerts_triggered": 0,
            "alerts_resolved": 0,
            "alerts_escalated": 0,
            "notifications_sent": 0
        }
    
    def add_alert_rule(self, rule_name: str, component: str, metric_name: str, 
                      severity: AlertSeverity, threshold: float, comparison: str = "greater_than",
                      duration_minutes: int = 1):
        """Add an alert rule"""
        self.alert_rules[rule_name] = {
            "component": component,
            "metric_name": metric_name,
            "severity": severity,
            "threshold": threshold,
            "comparison": comparison,
            "duration_minutes": duration_minutes,
            "enabled": True
        }
    
    def evaluate_metric(self, metric: Metric) -> Optional[Alert]:
        """Evaluate a metric against alert rules"""
        for rule_name, rule in self.alert_rules.items():
            if not rule["enabled"]:
                continue
            
            if (rule["component"] == metric.component and 
                rule["metric_name"] == metric.name):
                
                # Check if threshold is breached
                threshold_breached = False
                comparison = rule["comparison"]
                threshold = rule["threshold"]
                
                if comparison == "greater_than" and metric.value > threshold:
                    threshold_breached = True
                elif comparison == "less_than" and metric.value < threshold:
                    threshold_breached = True
                elif comparison == "equals" and abs(metric.value - threshold) < 0.001:
                    threshold_breached = True
                
                if threshold_breached:
                    # Check if we should suppress this alert
                    if self._should_suppress_alert(rule_name, metric):
                        continue
                    
                    # Create alert
                    alert = Alert(
                        severity=rule["severity"],
                        component=metric.component,
                        title=f"{rule_name} threshold breached",
                        description=f"Metric {metric.name} value {metric.value} {comparison} threshold {threshold}",
                        metric_name=metric.name,
                        metric_value=metric.value,
                        threshold_value=threshold
                    )
                    
                    self.alerts[alert.alert_id] = alert
                    self.stats["alerts_triggered"] += 1
                    
                    return alert
        
        return None
    
    def evaluate_health_check(self, health_check: HealthCheck) -> Optional[Alert]:
        """Evaluate a health check result for alerts"""
        if health_check.last_status == HealthStatus.HEALTHY:
            return None
        
        severity_map = {
            HealthStatus.DEGRADED: AlertSeverity.WARNING,
            HealthStatus.UNHEALTHY: AlertSeverity.ERROR,
            HealthStatus.CRITICAL: AlertSeverity.CRITICAL
        }
        
        severity = severity_map.get(health_check.last_status, AlertSeverity.WARNING)
        
        alert = Alert(
            severity=severity,
            component=health_check.component,
            title=f"Health check failed: {health_check.name}",
            description=f"Health check {health_check.name} status: {health_check.last_status.value}",
            check_name=health_check.name
        )
        
        self.alerts[alert.alert_id] = alert
        self.stats["alerts_triggered"] += 1
        
        return alert
    
    def _should_suppress_alert(self, rule_name: str, metric: Metric) -> bool:
        """Check if alert should be suppressed"""
        suppression = self.suppression_rules.get(rule_name)
        if not suppression:
            return False
        
        # Check time-based suppression
        if suppression.get("suppress_duration_minutes"):
            last_alert_time = suppression.get("last_alert_time")
            if last_alert_time:
                time_since_last = datetime.now() - last_alert_time
                if time_since_last.total_seconds() < suppression["suppress_duration_minutes"] * 60:
                    return True
        
        return False
    
    def resolve_alert(self, alert_id: str, resolution_message: str = ""):
        """Resolve an active alert"""
        alert = self.alerts.get(alert_id)
        if alert and alert.is_active:
            alert.is_active = False
            alert.resolved_at = datetime.now()
            self.stats["alerts_resolved"] += 1
    
    async def send_notifications(self, alert: Alert):
        """Send notifications for an alert"""
        for handler in self.notification_handlers:
            try:
                await handler(alert)
                self.stats["notifications_sent"] += 1
            except Exception as e:
                logger.error(f"Failed to send notification: {e}")


class MCPMonitoringSystem:
    """
    Comprehensive MCP Monitoring System
    
    Provides:
    - Real-time health monitoring of MCP components
    - Performance metrics collection and analysis
    - Alerting with configurable rules and escalation
    - Trend analysis and anomaly detection
    - CI/CD pipeline integration for status reporting
    - Dashboard data export for visualization
    """
    
    def __init__(self, memory_client=None):
        self.memory_client = memory_client
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        
        # Core components
        self.health_checks: Dict[str, HealthCheck] = {}
        self.metrics: Dict[str, Metric] = {}
        self.performance_analyzer = PerformanceAnalyzer()
        self.alert_manager = AlertManager()
        
        # Background tasks
        self.monitoring_active = True
        self.health_check_task: Optional[asyncio.Task] = None
        self.metrics_collection_task: Optional[asyncio.Task] = None
        self.analysis_task: Optional[asyncio.Task] = None
        
        # Configuration
        self.default_check_interval = 30.0
        self.metrics_collection_interval = 10.0
        self.analysis_interval = 60.0
        
        # System metrics
        self.system_start_time = datetime.now()
        self.stats = {
            "health_checks_performed": 0,
            "metrics_collected": 0,
            "alerts_generated": 0,
            "anomalies_detected": 0,
            "uptime_seconds": 0.0
        }
        
        self.logger.info("MCP Monitoring System initialized")
    
    async def initialize(self) -> bool:
        """Initialize the monitoring system"""
        try:
            # Register default notification handlers
            self.alert_manager.notification_handlers.append(self._default_alert_handler)
            
            # Add default alert rules
            self._add_default_alert_rules()
            
            # Add default health checks
            await self._add_default_health_checks()
            
            # Start monitoring tasks
            self.health_check_task = asyncio.create_task(self._health_check_loop())
            self.metrics_collection_task = asyncio.create_task(self._metrics_collection_loop())
            self.analysis_task = asyncio.create_task(self._analysis_loop())
            
            self.logger.info("MCP Monitoring System initialized successfully")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to initialize monitoring system: {e}")
            return False
    
    def add_health_check(self, health_check: HealthCheck):
        """Add a health check to the monitoring system"""
        self.health_checks[health_check.check_id] = health_check
        self.logger.info(f"Added health check: {health_check.name}")
    
    def add_metric(self, metric: Metric):
        """Add a metric to the monitoring system"""
        self.metrics[metric.metric_id] = metric
        self.logger.info(f"Added metric: {metric.name}")
    
    def record_metric_value(self, metric_name: str, value: float, labels: Dict[str, str] = None):
        """Record a value for a metric"""
        for metric in self.metrics.values():
            if metric.name == metric_name:
                metric.record_value(value, labels)
                self.stats["metrics_collected"] += 1
                return
        
        # Metric not found, create it
        metric = Metric(
            name=metric_name,
            description=f"Auto-created metric for {metric_name}",
            component="system"
        )
        metric.record_value(value, labels)
        self.add_metric(metric)
    
    async def perform_health_check(self, check_id: str) -> Dict[str, Any]:
        """Perform a specific health check"""
        health_check = self.health_checks.get(check_id)
        if not health_check or not health_check.enabled:
            return {"status": "disabled", "check_id": check_id}
        
        start_time = time.perf_counter()
        
        try:
            # Execute health check function
            if health_check.check_function:
                check_result = await asyncio.wait_for(
                    health_check.check_function(),
                    timeout=health_check.timeout_seconds
                )
            else:
                # Default health check
                check_result = await self._default_health_check(health_check)
            
            execution_time = (time.perf_counter() - start_time) * 1000
            
            # Determine status
            status = self._determine_health_status(check_result, health_check)
            
            # Update health check state
            health_check.last_check_time = datetime.now()
            health_check.last_status = status
            health_check.last_result = check_result
            
            if status == HealthStatus.HEALTHY:
                health_check.consecutive_failures = 0
            else:
                health_check.consecutive_failures += 1
            
            # Store in history
            history_entry = {
                "timestamp": health_check.last_check_time,
                "status": status.value,
                "result": check_result,
                "execution_time_ms": execution_time
            }
            health_check.check_history.append(history_entry)
            
            # Check for alerts
            alert = self.alert_manager.evaluate_health_check(health_check)
            if alert:
                await self.alert_manager.send_notifications(alert)
                self.stats["alerts_generated"] += 1
            
            self.stats["health_checks_performed"] += 1
            
            return {
                "status": status.value,
                "check_id": check_id,
                "execution_time_ms": execution_time,
                "result": check_result
            }
            
        except asyncio.TimeoutError:
            health_check.consecutive_failures += 1
            health_check.last_status = HealthStatus.CRITICAL
            return {
                "status": "timeout",
                "check_id": check_id,
                "error": f"Health check timed out after {health_check.timeout_seconds}s"
            }
        except Exception as e:
            health_check.consecutive_failures += 1
            health_check.last_status = HealthStatus.CRITICAL
            return {
                "status": "error",
                "check_id": check_id,
                "error": str(e)
            }
    
    def _determine_health_status(self, result: Dict[str, Any], health_check: HealthCheck) -> HealthStatus:
        """Determine health status from check result"""
        if isinstance(result, dict):
            if result.get("healthy", True):
                return HealthStatus.HEALTHY
            elif result.get("degraded"):
                return HealthStatus.DEGRADED
            elif result.get("critical"):
                return HealthStatus.CRITICAL
            else:
                return HealthStatus.UNHEALTHY
        elif isinstance(result, bool):
            return HealthStatus.HEALTHY if result else HealthStatus.UNHEALTHY
        else:
            return HealthStatus.UNKNOWN
    
    async def _default_health_check(self, health_check: HealthCheck) -> Dict[str, Any]:
        """Default health check implementation"""
        # Basic connectivity and responsiveness check
        try:
            # Simulate health check based on component
            if "memory" in health_check.component.lower():
                # Memory server health check
                if self.memory_client:
                    # Try to store and retrieve a test value
                    test_key = f"health_check_{int(time.time())}"
                    if hasattr(self.memory_client, 'store'):
                        await self.memory_client.store(test_key, "health_check", "monitoring")
                        result = await self.memory_client.retrieve(test_key, "monitoring")
                        return {"healthy": result == "health_check", "response_time_ms": 10}
                    else:
                        return {"healthy": True, "response_time_ms": 1, "note": "no_memory_client"}
                else:
                    return {"healthy": False, "error": "no_memory_client"}
            
            elif "github" in health_check.component.lower():
                # GitHub server health check
                return {"healthy": True, "response_time_ms": 50, "note": "simulated"}
            
            elif "sequential" in health_check.component.lower():
                # Sequential thinking server health check
                return {"healthy": True, "response_time_ms": 20, "note": "simulated"}
            
            else:
                # Generic health check
                return {"healthy": True, "response_time_ms": 5}
                
        except Exception as e:
            return {"healthy": False, "error": str(e)}
    
    def _add_default_alert_rules(self):
        """Add default alert rules"""
        # Response time alerts
        self.alert_manager.add_alert_rule(
            "high_response_time",
            "system",
            "response_time_ms",
            AlertSeverity.WARNING,
            1000.0,  # 1 second
            "greater_than"
        )
        
        # Error rate alerts
        self.alert_manager.add_alert_rule(
            "high_error_rate",
            "system", 
            "error_rate",
            AlertSeverity.ERROR,
            0.1,  # 10%
            "greater_than"
        )
        
        # Memory usage alerts
        self.alert_manager.add_alert_rule(
            "high_memory_usage",
            "system",
            "memory_usage_percent",
            AlertSeverity.WARNING,
            80.0,  # 80%
            "greater_than"
        )
    
    async def _add_default_health_checks(self):
        """Add default health checks"""
        # Memory server health check
        memory_check = HealthCheck(
            name="Memory Server Health",
            description="Check MCP Memory server availability and responsiveness",
            component="memory_server",
            check_interval_seconds=30.0
        )
        self.add_health_check(memory_check)
        
        # Sequential thinking server health check
        st_check = HealthCheck(
            name="Sequential Thinking Health",
            description="Check Sequential Thinking MCP server status",
            component="sequential_thinking_server",
            check_interval_seconds=45.0
        )
        self.add_health_check(st_check)
        
        # GitHub server health check
        github_check = HealthCheck(
            name="GitHub Server Health", 
            description="Check GitHub MCP server connectivity",
            component="github_server",
            check_interval_seconds=60.0
        )
        self.add_health_check(github_check)
        
        # System health check
        system_check = HealthCheck(
            name="System Health",
            description="Overall system health and performance",
            component="monitoring_system",
            check_interval_seconds=20.0
        )
        self.add_health_check(system_check)
    
    async def _health_check_loop(self):
        """Main health check loop"""
        while self.monitoring_active:
            try:
                current_time = datetime.now()
                
                # Check which health checks need to be performed
                for health_check in self.health_checks.values():
                    if not health_check.enabled:
                        continue
                    
                    should_check = False
                    if health_check.last_check_time is None:
                        should_check = True
                    else:
                        time_since_last = current_time - health_check.last_check_time
                        if time_since_last.total_seconds() >= health_check.check_interval_seconds:
                            should_check = True
                    
                    if should_check:
                        asyncio.create_task(self.perform_health_check(health_check.check_id))
                
                await asyncio.sleep(5.0)  # Check every 5 seconds
                
            except asyncio.CancelledError:
                self.logger.info("Health check loop cancelled")
                break
            except Exception as e:
                self.logger.error(f"Error in health check loop: {e}")
                await asyncio.sleep(10.0)
    
    async def _metrics_collection_loop(self):
        """Collect system and component metrics"""
        while self.monitoring_active:
            try:
                # Collect system metrics
                await self._collect_system_metrics()
                
                # Collect component metrics
                await self._collect_component_metrics()
                
                # Evaluate metrics against alert rules
                for metric in self.metrics.values():
                    alert = self.alert_manager.evaluate_metric(metric)
                    if alert:
                        await self.alert_manager.send_notifications(alert)
                        self.stats["alerts_generated"] += 1
                
                await asyncio.sleep(self.metrics_collection_interval)
                
            except asyncio.CancelledError:
                self.logger.info("Metrics collection loop cancelled")
                break
            except Exception as e:
                self.logger.error(f"Error in metrics collection loop: {e}")
                await asyncio.sleep(30.0)
    
    async def _collect_system_metrics(self):
        """Collect system-level metrics"""
        current_time = datetime.now()
        uptime = (current_time - self.system_start_time).total_seconds()
        
        # Record uptime
        self.record_metric_value("uptime_seconds", uptime)
        
        # Record health check success rate
        total_checks = self.stats["health_checks_performed"]
        failed_checks = len([hc for hc in self.health_checks.values() if hc.last_status != HealthStatus.HEALTHY])
        success_rate = (total_checks - failed_checks) / max(total_checks, 1)
        self.record_metric_value("health_check_success_rate", success_rate)
        
        # Record alert statistics
        active_alerts = len([a for a in self.alert_manager.alerts.values() if a.is_active])
        self.record_metric_value("active_alerts", active_alerts)
        
        # Simulate resource usage metrics
        import random
        self.record_metric_value("cpu_usage_percent", random.uniform(10, 80))
        self.record_metric_value("memory_usage_percent", random.uniform(20, 90))
        self.record_metric_value("disk_usage_percent", random.uniform(30, 70))
    
    async def _collect_component_metrics(self):
        """Collect component-specific metrics"""
        # Collect health check timing metrics
        for health_check in self.health_checks.values():
            if health_check.check_history:
                latest = health_check.check_history[-1]
                self.record_metric_value(
                    f"{health_check.component}_response_time_ms",
                    latest.get("execution_time_ms", 0),
                    {"component": health_check.component}
                )
        
        # Collect alert manager metrics
        self.record_metric_value("alerts_triggered_total", self.alert_manager.stats["alerts_triggered"])
        self.record_metric_value("alerts_resolved_total", self.alert_manager.stats["alerts_resolved"])
    
    async def _analysis_loop(self):
        """Perform periodic analysis and trend detection"""
        while self.monitoring_active:
            try:
                # Analyze metric trends
                for metric in self.metrics.values():
                    analysis = self.performance_analyzer.analyze_metric_trend(metric)
                    
                    if analysis.get("anomaly_detected"):
                        self.stats["anomalies_detected"] += 1
                        self.logger.warning(f"Anomaly detected in metric {metric.name}: {analysis}")
                        
                        # Create anomaly alert
                        anomaly_alert = Alert(
                            severity=AlertSeverity.WARNING,
                            component=metric.component,
                            title=f"Anomaly detected: {metric.name}",
                            description=f"Anomaly detected in {metric.name}: {analysis['trend']} trend",
                            metric_name=metric.name,
                            metric_value=metric.value
                        )
                        
                        self.alert_manager.alerts[anomaly_alert.alert_id] = anomaly_alert
                        await self.alert_manager.send_notifications(anomaly_alert)
                
                # Update baselines
                await self._update_metric_baselines()
                
                await asyncio.sleep(self.analysis_interval)
                
            except asyncio.CancelledError:
                self.logger.info("Analysis loop cancelled")
                break
            except Exception as e:
                self.logger.error(f"Error in analysis loop: {e}")
                await asyncio.sleep(60.0)
    
    async def _update_metric_baselines(self):
        """Update baseline statistics for metrics"""
        cutoff_time = datetime.now() - timedelta(hours=24)  # 24-hour baseline
        
        for metric in self.metrics.values():
            baseline_values = [
                entry["value"] for entry in metric.history
                if entry["timestamp"] >= cutoff_time
            ]
            
            if len(baseline_values) > 10:  # Need sufficient data
                self.performance_analyzer.update_baseline(metric.name, baseline_values)
    
    async def _default_alert_handler(self, alert: Alert):
        """Default alert notification handler"""
        self.logger.warning(f"ALERT [{alert.severity.value.upper()}] {alert.title}: {alert.description}")
        
        # Store alert in memory if available
        if self.memory_client and hasattr(self.memory_client, 'store'):
            try:
                alert_data = {
                    "alert_id": alert.alert_id,
                    "severity": alert.severity.value,
                    "component": alert.component,
                    "title": alert.title,
                    "description": alert.description,
                    "triggered_at": alert.triggered_at.isoformat(),
                    "is_active": alert.is_active
                }
                
                await self.memory_client.store(
                    f"alert_{alert.alert_id}",
                    alert_data,
                    "monitoring_alerts"
                )
            except Exception as e:
                self.logger.warning(f"Failed to store alert in memory: {e}")
    
    def get_system_status(self) -> Dict[str, Any]:
        """Get comprehensive monitoring system status"""
        current_time = datetime.now()
        uptime = (current_time - self.system_start_time).total_seconds()
        
        # Health check summary
        health_summary = {
            "total_checks": len(self.health_checks),
            "healthy": len([hc for hc in self.health_checks.values() if hc.last_status == HealthStatus.HEALTHY]),
            "degraded": len([hc for hc in self.health_checks.values() if hc.last_status == HealthStatus.DEGRADED]),
            "unhealthy": len([hc for hc in self.health_checks.values() if hc.last_status == HealthStatus.UNHEALTHY]),
            "critical": len([hc for hc in self.health_checks.values() if hc.last_status == HealthStatus.CRITICAL]),
            "unknown": len([hc for hc in self.health_checks.values() if hc.last_status == HealthStatus.UNKNOWN])
        }
        
        # Metric summary
        metric_summary = {
            "total_metrics": len(self.metrics),
            "metrics_with_data": len([m for m in self.metrics.values() if len(m.history) > 0]),
            "recent_anomalies": self.stats["anomalies_detected"]
        }
        
        # Alert summary
        active_alerts = [a for a in self.alert_manager.alerts.values() if a.is_active]
        alert_summary = {
            "total_alerts": len(self.alert_manager.alerts),
            "active_alerts": len(active_alerts),
            "critical_alerts": len([a for a in active_alerts if a.severity == AlertSeverity.CRITICAL]),
            "warning_alerts": len([a for a in active_alerts if a.severity == AlertSeverity.WARNING])
        }
        
        return {
            "system_info": {
                "monitoring_active": self.monitoring_active,
                "uptime_seconds": uptime,
                "tasks_running": {
                    "health_checks": self.health_check_task and not self.health_check_task.done(),
                    "metrics_collection": self.metrics_collection_task and not self.metrics_collection_task.done(),
                    "analysis": self.analysis_task and not self.analysis_task.done()
                }
            },
            "health_checks": health_summary,
            "metrics": metric_summary,
            "alerts": alert_summary,
            "statistics": self.stats.copy()
        }
    
    def get_dashboard_data(self) -> Dict[str, Any]:
        """Get data formatted for dashboard display"""
        # Recent metrics for charts
        metric_data = {}
        for metric in self.metrics.values():
            if len(metric.history) > 0:
                recent_history = list(metric.history)[-50:]  # Last 50 data points
                metric_data[metric.name] = {
                    "current_value": metric.value,
                    "history": [
                        {"timestamp": entry["timestamp"].isoformat(), "value": entry["value"]}
                        for entry in recent_history
                    ],
                    "component": metric.component,
                    "type": metric.metric_type.value
                }
        
        # Health check status
        health_data = {}
        for health_check in self.health_checks.values():
            health_data[health_check.name] = {
                "status": health_check.last_status.value,
                "last_check": health_check.last_check_time.isoformat() if health_check.last_check_time else None,
                "consecutive_failures": health_check.consecutive_failures,
                "component": health_check.component
            }
        
        # Active alerts
        alert_data = []
        for alert in self.alert_manager.alerts.values():
            if alert.is_active:
                alert_data.append({
                    "id": alert.alert_id,
                    "severity": alert.severity.value,
                    "title": alert.title,
                    "component": alert.component,
                    "triggered_at": alert.triggered_at.isoformat(),
                    "description": alert.description
                })
        
        return {
            "metrics": metric_data,
            "health_checks": health_data,
            "alerts": alert_data,
            "generated_at": datetime.now().isoformat()
        }
    
    async def shutdown(self):
        """Shutdown the monitoring system"""
        self.logger.info("Shutting down MCP Monitoring System...")
        
        self.monitoring_active = False
        
        # Cancel all tasks
        tasks = [self.health_check_task, self.metrics_collection_task, self.analysis_task]
        for task in tasks:
            if task and not task.done():
                task.cancel()
                try:
                    await task
                except asyncio.CancelledError:
                    pass
        
        # Update stats
        uptime = (datetime.now() - self.system_start_time).total_seconds()
        self.stats["uptime_seconds"] = uptime
        
        self.logger.info("MCP Monitoring System shutdown complete")


# Example usage and testing
async def example_monitoring_usage():
    """Example of how to use the MCP Monitoring System"""
    
    # Create monitoring system
    monitoring = MCPMonitoringSystem()
    await monitoring.initialize()
    
    # Add custom health check
    async def custom_health_check():
        return {"healthy": True, "response_time_ms": 15, "custom_metric": 42}
    
    custom_check = HealthCheck(
        name="Custom Service Health",
        description="Check custom service availability",
        component="custom_service",
        check_function=custom_health_check,
        check_interval_seconds=10.0
    )
    monitoring.add_health_check(custom_check)
    
    # Add custom metric
    custom_metric = Metric(
        name="custom_requests_per_second",
        description="Requests processed per second",
        metric_type=MetricType.GAUGE,
        component="custom_service"
    )
    monitoring.add_metric(custom_metric)
    
    # Record some metric values
    for i in range(10):
        monitoring.record_metric_value("custom_requests_per_second", 10 + i * 2)
        await asyncio.sleep(1)
    
    # Let monitoring run
    await asyncio.sleep(15)
    
    # Get status
    status = monitoring.get_system_status()
    print(f"Monitoring Status: {json.dumps(status, indent=2, default=str)}")
    
    # Get dashboard data
    dashboard = monitoring.get_dashboard_data()
    print(f"Dashboard Data: {json.dumps(dashboard, indent=2, default=str)}")
    
    await monitoring.shutdown()


if __name__ == "__main__":
    asyncio.run(example_monitoring_usage())