# AIVillage Unified Compression System

A consolidated compression system that combines the best implementations from across the codebase into a single, production-ready interface.

## Overview

The unified compression system provides:
- **Simple Quantization** (4x) for models <100M parameters
- **Mobile Optimization** (8-16x) with automatic size targeting  
- **Advanced Pipeline** (100x+) for large models with 4-stage compression
- **Automatic Strategy Selection** based on model size and requirements
- **Comprehensive Benchmarking** with accuracy retention metrics
- **Graceful Fallback** when advanced methods fail

## Quick Start

```python
from src.production.compression import UnifiedCompressor, CompressionStrategy

# Automatic compression (recommended)
compressor = UnifiedCompressor()
result = await compressor.compress_model("path/to/model")

print(f"Compression ratio: {result.compression_ratio:.2f}x")
print(f"Mobile compatible: {result.mobile_compatible}")
```

## Compression Strategies

### AUTO (Recommended)
Automatically selects the best strategy based on model size:
- **<100M params**: Simple quantization
- **>100M params**: Mobile or advanced compression
- **Very large models**: Full advanced pipeline

### SIMPLE 
Fast 4x compression using ternary quantization:
- BitNet 1.58-bit quantization
- Suitable for models under 100M parameters
- ~2-5 seconds compression time
- Minimal accuracy loss (<2%)

### MOBILE
Mobile-optimized compression targeting specific file sizes:
- Stage 1: BitNet quantization (4x)
- Stage 2: SeedLM compression (additional 2-4x if needed)
- Target: <100MB by default (configurable)
- Good balance of size and quality

### ADVANCED
Full 4-stage pipeline for maximum compression:
- Stage 1: BitNet quantization (16x)
- Stage 2: SeedLM LFSR compression (8x)  
- Stage 3: VPTQ vector quantization (2x)
- Stage 4: HyperCompression ergodic encoding (2x)
- **Total: 100x+ compression ratio**
- Requires more compute and time

## Usage Examples

### Basic Compression
```python
from src.production.compression import compress_simple

# Simple compression
result = await compress_simple("path/to/model")
print(f"Compressed {result.original_size_mb:.1f}MB â†’ {result.compressed_size_mb:.1f}MB")
```

### Mobile Deployment
```python
from src.production.compression import compress_mobile

# Compress for mobile deployment (target 50MB)
result = await compress_mobile(
    model="path/to/model",
    mobile_target_mb=50
)

if result.mobile_compatible:
    print("Ready for mobile deployment!")
```

### Advanced Compression
```python
from src.production.compression import UnifiedCompressor, CompressionStrategy

compressor = UnifiedCompressor(
    strategy=CompressionStrategy.ADVANCED,
    accuracy_threshold=0.90  # Allow 10% accuracy loss
)

result = await compressor.compress_model(
    model="path/to/large/model",
    output_path="compressed_output/"
)
```

### Custom Configuration
```python
compressor = UnifiedCompressor(
    strategy=CompressionStrategy.MOBILE,
    mobile_target_mb=75,          # Target 75MB
    accuracy_threshold=0.95,       # Keep 95% accuracy
    enable_benchmarking=True       # Run quality tests
)

result = await compressor.compress_model(model)

# Check benchmarking results
if result.benchmark_metrics:
    print(f"Text similarity: {result.benchmark_metrics['text_similarity']:.2%}")
```

## CLI Usage

```bash
# Compress with automatic strategy selection
python -m src.production.compression.unified_compressor model_path/

# Specify strategy and target size
python -m src.production.compression.unified_compressor model_path/ \
    --strategy mobile \
    --target-mb 50 \
    --output compressed_model/

# Advanced compression without benchmarking
python -m src.production.compression.unified_compressor model_path/ \
    --strategy advanced \
    --no-benchmark
```

## Configuration

Compression behavior is configured via `configs/compression.yaml`:

```yaml
seedlm_config:
  global:
    compression_preset: "balanced"  # fast, balanced, quality
    target_compression_ratio: 15.0
    max_accuracy_drop: 0.05
  
  progressive_encoding:
    base_quality: 0.3
    enhancement_layers: 3
    enable_streaming: true
```

## Architecture

```
UnifiedCompressor
â”œâ”€â”€ Strategy Selection (auto/simple/mobile/advanced)
â”œâ”€â”€ Core Algorithms
â”‚   â”œâ”€â”€ BitNet (ternary quantization)
â”‚   â”œâ”€â”€ SeedLM (LFSR compression)
â”‚   â””â”€â”€ VPTQ (vector quantization)
â”œâ”€â”€ Production Pipeline (advanced compression)
â”œâ”€â”€ Benchmarking (accuracy validation)
â””â”€â”€ Fallback Handling (error recovery)
```

## Compression Algorithms

### BitNet Quantization
- **Source**: `src/agent_forge/compression/bitnet.py`
- **Method**: Ternary weights (-1, 0, +1) with efficient packing
- **Ratio**: ~4x compression
- **Quality**: Minimal accuracy loss for most models

### SeedLM Compression  
- **Source**: `src/agent_forge/compression/seedlm.py`
- **Method**: LFSR-based pseudo-random compression
- **Ratio**: 2-8x additional compression
- **Features**: Progressive encoding, streaming support

### VPTQ Vector Quantization
- **Source**: `src/agent_forge/compression/vptq.py`  
- **Method**: K-means clustering of weight vectors
- **Ratio**: ~2x additional compression
- **Quality**: Good preservation of model structure

### HyperCompression
- **Source**: `src/production/compression/hyper_compression.py`
- **Method**: Ergodic encoding with context modeling
- **Ratio**: ~2x final compression stage
- **Note**: Currently uses zlib, planned for enhancement

## Performance Benchmarks

| Strategy | Typical Ratio | Time (7B model) | Accuracy Retained | Mobile Ready |
|----------|---------------|-----------------|-------------------|--------------|
| Simple   | 4x           | 2-5 min         | >98%             | Depends      |
| Mobile   | 8-16x        | 5-15 min        | >95%             | âœ… Yes       |
| Advanced | 100x+        | 30-60 min       | >90%             | âœ… Yes       |

*Benchmarks on consumer hardware (RTX 4090, 32GB RAM)*

## Error Handling

The system includes comprehensive error handling:

1. **Graceful Fallback**: Advanced compression falls back to simple if it fails
2. **Dependency Management**: Missing libraries handled gracefully
3. **Memory Management**: Automatic cleanup and memory monitoring
4. **Validation**: Input validation and sanity checks

## Integration Points

### With Agent Forge
```python
from src.agent_forge.compression import bitnet_compress
from src.production.compression import UnifiedCompressor

# Direct algorithm access
compressed_model = bitnet_compress(model)

# Or via unified interface
compressor = UnifiedCompressor(strategy=CompressionStrategy.SIMPLE)
result = await compressor.compress_model(model)
```

### With Twin Runtime
```python
from src.twin_runtime.compressed_loader import CompressedLoader

# Load compressed model for inference
loader = CompressedLoader()
model = loader.load_compressed_model("compressed_model/")
```

### With Production Pipeline
```python
from src.production.compression import CompressionPipeline

# Use existing production pipeline for advanced compression
pipeline = CompressionPipeline(config)
result = await pipeline.compress_model()
```

## Testing

Run the unified test suite:

```bash
# Run all compression tests
pytest tests/compression/test_unified_compression.py -v

# Run performance tests (slow)
pytest tests/compression/test_unified_compression.py::TestPerformance -v -m slow

# Run specific test categories
pytest tests/compression/test_unified_compression.py::TestUnifiedCompressor -v
```

## Troubleshooting

### Common Issues

**ImportError for compression modules**
- Ensure all dependencies are installed: `pip install -r requirements.txt`
- Check that agent_forge modules are in Python path

**CUDA out of memory during compression**
- Reduce batch size in configuration
- Use CPU-only mode: set `CUDA_VISIBLE_DEVICES=""`
- Try simple compression strategy first

**Poor compression ratios**
- Check model architecture (some models compress better than others)
- Verify configuration settings in `configs/compression.yaml`
- Try different compression strategies

**Accuracy loss too high**
- Lower `accuracy_threshold` setting
- Use `CompressionStrategy.SIMPLE` for minimal loss
- Enable benchmarking to monitor quality metrics

### Debug Mode

Enable debug logging:
```python
import logging
logging.basicConfig(level=logging.DEBUG)

compressor = UnifiedCompressor()
result = await compressor.compress_model(model)
```

## Roadmap

### Current Status âœ…
- [x] Unified compression interface
- [x] Automatic strategy selection  
- [x] Comprehensive test suite
- [x] CLI interface
- [x] Error handling and fallback

### Planned Enhancements ðŸš§
- [ ] GPU kernel optimization for BitNet
- [ ] Real-time compression for streaming
- [ ] Model-specific compression profiles
- [ ] Distributed compression across multiple devices
- [ ] Integration with federated learning pipeline

### Future Research ðŸ”¬
- [ ] Learned compression dictionaries
- [ ] Neural architecture search for compression
- [ ] Quantum-inspired compression algorithms
- [ ] Hardware-specific optimization (Apple Silicon, TPU)

## Contributing

When contributing to the compression system:

1. **Maintain compatibility** with existing `UnifiedCompressor` interface
2. **Add comprehensive tests** for new features
3. **Update benchmarks** if performance characteristics change
4. **Document configuration options** in YAML schema
5. **Preserve fallback behavior** for robustness

## License

This compression system is part of the AIVillage project and follows the same licensing terms.