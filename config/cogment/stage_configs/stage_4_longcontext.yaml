# Stage 4: Long Context Configuration
# Long-context understanding and generation with extended sequences

stage:
  name: "long_context"
  description: "Long-context understanding and generation"
  stage_id: 4

# Training Parameters
training:
  max_steps: 32000               # Extended training for long context
  batch_size: 2                  # Small batch for memory constraints
  sequence_length: 2048          # Full context length
  learning_rate: 2e-5            # Very low LR for stability
  
  eval_interval: 1600
  save_interval: 8000
  log_interval: 400

# Model Behavior
model:
  max_refinement_steps: 8        # Maintain deep reasoning capability
  act_threshold: 0.99
  ponder_cost_initial: 0.02
  ponder_cost_final: 0.02
  
  # Maximum memory utilization
  memory_settings:
    ltm_read_only: false
    ltm_write_alpha: 0.2          # Maximum write rate
    ltm_decay_rate: 1e-4          # Minimal decay for long-term retention

# Data Configuration
data:
  # Long-context tasks
  task_types:
    - "longbench_tasks"           # Long document understanding
    - "scrolls_datasets"          # SCROLLS benchmark tasks
    - "book_summarization"        # Long document summarization
    - "multi_document_qa"         # Questions spanning multiple documents
    - "narrative_generation"      # Long narrative generation
    
  # Data sources
  datasets:
    - "longbench"
    - "scrolls"
    - "long_document_corpus"
    - "multi_document_qa_corpus"
    
  # Long-context specific augmentation
  augmentation:
    enabled: true
    rate: 0.3                    # Minimal augmentation for long contexts
    types:
      - "document_shuffling"      # Reorder document sections
      - "context_truncation"      # Train on partial contexts
      - "distractor_injection"    # Add irrelevant long content
      
    # Long-context specific settings
    long_context:
      max_context_length: 2048
      min_context_length: 1536
      document_chunking: true
      overlap_size: 128
      
    # Multi-document settings
    multi_document:
      max_documents: 4
      document_length_range: [400, 600]
      relevance_distribution: [0.7, 0.2, 0.1]  # Main, supporting, distractor

# Loss Configuration
loss:
  deep_supervision_weight: 1.0
  improvement_weight: 0.1
  consistency_weight: 0.1
  ponder_weight: 2.0             # Higher penalty for long sequences

# GrokFast Settings (further reduced for long-context stability)
grokfast:
  enabled: true
  global_multiplier: 0.5         # 50% reduction for long sequences
  focus_components: ["refinement_core"]
  
  components:
    refinement_core:
      alpha: 0.92                # Even more reduced
      lamb: 1.0                  # Minimal amplification
      window_size: 200           # Longer window for stability
      
    gated_ltm:
      alpha: 0.95
      lamb: 1.3                  # Gentle memory acceleration
      window_size: 75
      
    act_halting:
      enabled: false

# Convergence Criteria
convergence:
  patience: 1500                 # Very long patience for complex long-context tasks
  min_accuracy: 0.5              # Realistic target for long context
  max_ponder_cost: 8.0
  min_improvement: 5e-5          # Very small improvements acceptable
  
  # Long-context specific indicators
  grokking_indicators:
    context_integration_emergence: true    # Can integrate across long contexts
    hierarchical_understanding: true       # Multi-level understanding
    selective_attention_patterns: true     # Learns to focus on relevant parts

# Memory Management
memory:
  consolidation_frequency: "very_low"    # Preserve all long-context patterns
  memory_capacity_usage_target: 0.9      # Near-maximum memory usage
  
  # Long-context specific memory
  long_context_memory:
    hierarchical_representations: true    # Multi-level document structure
    cross_document_relations: true        # Relations between documents
    temporal_sequence_patterns: true      # Long temporal dependencies
    narrative_structure_patterns: true    # Story/document structure

# Validation Tasks
validation:
  tasks:
    - name: "longbench_evaluation"
      description: "Long document understanding tasks"
      expected_accuracy: 0.55
      
    - name: "scrolls_evaluation"
      description: "SCROLLS benchmark tasks"
      expected_accuracy: 0.5
      
    - name: "book_summarization"
      description: "Summarize long documents"
      expected_quality: 0.6
      
    - name: "multi_document_qa"
      description: "Answer questions requiring multiple documents"
      expected_accuracy: 0.45
      
    - name: "narrative_coherence"
      description: "Generate coherent long narratives"
      expected_coherence: 0.7

# Long-Context Analysis
long_context_analysis:
  # Track long-context specific capabilities
  track_metrics:
    - "attention_span"             # How far back can model attend?
    - "context_utilization"        # How much of context is actually used?
    - "hierarchical_processing"    # Multi-level processing capability
    - "selective_attention"        # Can model focus on relevant parts?
    - "cross_reference_ability"    # Can model connect distant references?
    
  # Analysis settings
  attention_analysis:
    save_attention_maps: true
    analyze_attention_patterns: true
    track_long_distance_dependencies: true
    
  analysis_interval: 2000
  save_long_context_examples: true

# Memory Optimization
memory_optimization:
  # Specific optimizations for long contexts
  gradient_checkpointing: true
  activation_checkpointing: true
  sequence_parallel: true         # Enable for long sequences
  attention_optimization: "flash_attention"
  
  # Memory-efficient attention
  attention_settings:
    chunk_size: 256
    overlap_size: 64
    sparse_attention: false       # Keep dense for reasoning quality
    
  # KV cache optimization
  kv_cache:
    compression_enabled: true
    compression_ratio: 0.8
    eviction_policy: "lru"

# Advanced Long-Context Features
advanced_features:
  # Hierarchical processing
  hierarchical_processing:
    enable_multi_scale: true
    scale_levels: [64, 256, 1024, 2048]
    cross_scale_attention: true
    
  # Document structure awareness
  document_structure:
    paragraph_boundaries: true
    section_boundaries: true
    topic_transitions: true
    
  # Retrieval augmentation
  retrieval_augmentation:
    enable_retrieval: false       # Focus on pure long-context for now
    retrieval_frequency: "adaptive"

# Resource Management
resources:
  max_memory_gb: 24               # Higher memory for long contexts
  max_time_hours: 16              # Extended training time
  
  # Specific optimizations
  cpu_offloading: true            # Offload to CPU when needed
  disk_offloading: false          # Keep in memory for performance
  mixed_precision: true
  tensor_parallel: false          # Keep simple for now

# Stage Completion Criteria
completion:
  required_metrics:
    min_accuracy: 0.5
    max_ponder_cost: 8.0
    long_context_capability: true
    
  preferred_metrics:
    longbench_score: 0.55
    scrolls_score: 0.5
    attention_span: 1800          # Can attend to 1800+ tokens back
    context_utilization: 0.7      # Uses 70%+ of available context
    hierarchical_processing: true
    
  # Final validation
  final_validation:
    comprehensive_evaluation: true
    cross_domain_generalization: true
    long_context_stress_tests: true