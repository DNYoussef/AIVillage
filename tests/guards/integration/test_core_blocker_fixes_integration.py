#!/usr/bin/env python3
"""
Core Blocker Fixes Integration Guard Tests
==========================================

Prevents regression in core blocker resolution system.
Tests comprehensive fixes for GrokFast, RAG, P2P, and import conflicts.

Generated by TDD London School Swarm Agent for Phase 5 guard protection.
"""

import pytest
import json
import tempfile
import shutil
from pathlib import Path

import sys

sys.path.insert(0, "src")

from src.core.blockers_fix import CoreBlockerResolver, BlockerStatus, BlockerResult


class TestCoreBlockerFixesIntegration:
    """Integration tests for core blocker fixes system."""

    @pytest.fixture
    def temp_project_root(self):
        """Create temporary project root for testing."""
        temp_dir = Path(tempfile.mkdtemp())

        # Create basic project structure
        (temp_dir / "src").mkdir(exist_ok=True)
        (temp_dir / "src" / "core").mkdir(exist_ok=True)
        (temp_dir / "config").mkdir(exist_ok=True)
        (temp_dir / "data").mkdir(exist_ok=True)
        (temp_dir / "tests").mkdir(exist_ok=True)

        # Create mock source files
        (temp_dir / "experiments").mkdir(exist_ok=True)
        (temp_dir / "experiments" / "training").mkdir(exist_ok=True)
        grokfast_content = '''
"""Mock GrokFast implementation for testing."""

class GrokFastOptimizer:
    def __init__(self, params, lr=0.001):
        self.param_groups = [{"params": params, "lr": lr}]
        self.defaults = {"lr": lr}
    
    def step(self):
        pass
    
    def zero_grad(self):
        pass

def create_grokfast_adamw(params, lr=0.001):
    return GrokFastOptimizer(params, lr)

class GrokFastTask:
    pass
'''
        (temp_dir / "experiments" / "training" / "grokfast.py").write_text(grokfast_content)

        yield temp_dir

        # Cleanup
        shutil.rmtree(temp_dir, ignore_errors=True)

    @pytest.fixture
    def resolver(self, temp_project_root):
        """Create resolver with temporary project root."""
        return CoreBlockerResolver(temp_project_root)

    def test_grokfast_dependency_resolution_integration(self, resolver, temp_project_root):
        """Test complete GrokFast dependency resolution."""
        # Run GrokFast resolution
        result = resolver._resolve_grokfast_dependency()

        assert result.status == BlockerStatus.RESOLVED, f"GrokFast resolution failed: {result.error}"

        # Check that unified module was created
        unified_path = temp_project_root / "src" / "core" / "grokfast.py"
        assert unified_path.exists(), "Unified GrokFast module not created"

        # Check that __init__.py was created
        init_path = temp_project_root / "src" / "core" / "__init__.py"
        assert init_path.exists(), "Core package __init__.py not created"

        # Check unified module content
        unified_content = unified_path.read_text()
        assert "GrokFastOptimizer" in unified_content, "GrokFastOptimizer not in unified module"
        assert "create_grokfast_adamw" in unified_content, "Factory function not in unified module"
        assert "__all__" in unified_content, "Public API not defined"

        # Test that module details were captured
        assert "module_path" in result.details, "Module path not in result details"
        assert "available_classes" in result.details, "Available classes not in result details"

    def test_rag_accuracy_resolution_integration(self, resolver, temp_project_root):
        """Test complete RAG accuracy resolution."""
        # Run RAG accuracy resolution
        result = resolver._resolve_rag_accuracy()

        # Should resolve with fixes applied
        assert result.status in [
            BlockerStatus.RESOLVED,
            BlockerStatus.FAILED,
        ], f"RAG resolution in unexpected state: {result.status}"

        if result.status == BlockerStatus.RESOLVED:
            # Check that fixes were applied
            assert "fixes_applied" in result.details, "Fixes not documented"

            # Check for created structures
            vector_dir = temp_project_root / "data" / "vector_memory"
            kb_dir = temp_project_root / "data" / "knowledge_base"
            config_dir = temp_project_root / "config"

            # At least one of these should exist
            created_structures = [vector_dir.exists(), kb_dir.exists(), (config_dir / "rag_config.json").exists()]
            assert any(created_structures), "No RAG structures created"

    def test_p2p_protocol_mismatch_resolution_integration(self, resolver, temp_project_root):
        """Test complete P2P protocol mismatch resolution."""
        # Create mock P2P structure
        p2p_root = temp_project_root / "infrastructure" / "p2p"
        p2p_root.mkdir(parents=True, exist_ok=True)
        (p2p_root / "bitchat").mkdir(exist_ok=True)
        (p2p_root / "betanet").mkdir(exist_ok=True)

        # Run P2P resolution
        result = resolver._resolve_p2p_protocol_mismatch()

        assert result.status == BlockerStatus.RESOLVED, f"P2P resolution failed: {result.error}"

        # Check that protocol adapter was created
        adapter_path = p2p_root / "unified_protocol_adapter.py"
        assert adapter_path.exists(), "Unified protocol adapter not created"

        # Check that negotiation system was created
        negotiation_path = p2p_root / "protocol_negotiation.py"
        assert negotiation_path.exists(), "Protocol negotiation not created"

        # Check adapter content
        adapter_content = adapter_path.read_text()
        assert "UnifiedProtocolAdapter" in adapter_content, "Main adapter class not found"
        assert "ProtocolType" in adapter_content, "Protocol type enum not found"
        assert "MessageEnvelope" in adapter_content, "Message envelope not found"

        # Check negotiation content
        negotiation_content = negotiation_path.read_text()
        assert "ProtocolNegotiator" in negotiation_content, "Negotiator class not found"
        assert "negotiate_protocol" in negotiation_content, "Negotiation method not found"

    def test_import_path_conflicts_resolution_integration(self, resolver, temp_project_root):
        """Test complete import path conflicts resolution."""
        # Create conflicting agent_forge directories
        (temp_project_root / "core" / "agent_forge").mkdir(parents=True, exist_ok=True)
        (temp_project_root / "packages" / "agent_forge").mkdir(parents=True, exist_ok=True)

        # Run import resolution
        result = resolver._resolve_import_path_conflicts()

        assert result.status == BlockerStatus.RESOLVED, f"Import resolution failed: {result.error}"

        # Check that import resolver was created
        resolver_path = temp_project_root / "src" / "core" / "import_resolver.py"
        assert resolver_path.exists(), "Import resolver not created"

        # Check that path mapping was created
        mapping_path = temp_project_root / "config" / "import_path_mapping.json"
        assert mapping_path.exists(), "Path mapping config not created"

        # Check resolver content
        resolver_content = resolver_path.read_text()
        assert "ImportPathResolver" in resolver_content, "Resolver class not found"
        assert "resolve_agent_forge_import" in resolver_content, "Resolution method not found"
        assert "get_agent_forge_class" in resolver_content, "Class getter not found"

        # Check mapping content
        mapping_content = json.loads(mapping_path.read_text())
        assert "agent_forge_paths" in mapping_content, "Path mappings not found"
        assert "resolution_priority" in mapping_content, "Resolution priority not defined"

    def test_complete_blocker_resolution_workflow(self, resolver):
        """Test complete workflow resolving all blockers."""
        # Run complete resolution
        results = resolver.resolve_all_blockers()

        # Should have results for all 4 blockers
        expected_blockers = {"grokfast_dependency", "rag_accuracy", "p2p_protocol_mismatch", "import_path_conflicts"}

        result_blockers = {r.blocker_name for r in results}
        assert result_blockers == expected_blockers, f"Missing blockers: {expected_blockers - result_blockers}"

        # Check that results are properly structured
        for result in results:
            assert isinstance(result, BlockerResult), "Result not proper type"
            assert result.blocker_name in expected_blockers, f"Unexpected blocker: {result.blocker_name}"
            assert isinstance(result.status, BlockerStatus), "Status not proper enum"
            assert isinstance(result.message, str), "Message not string"
            assert len(result.message) > 0, "Empty message"

            # If resolved, should have details
            if result.status == BlockerStatus.RESOLVED:
                assert isinstance(result.details, dict), "Details not dict for resolved blocker"
                assert len(result.details) > 0, "Empty details for resolved blocker"

    def test_summary_report_generation_integration(self, resolver):
        """Test comprehensive summary report generation."""
        # Run resolution to generate results
        resolver.resolve_all_blockers()

        # Generate summary report
        summary = resolver.generate_summary_report()

        # Check report structure
        required_fields = [
            "total_blockers",
            "resolved_count",
            "failed_count",
            "success_rate",
            "resolved_blockers",
            "failed_blockers",
            "detailed_results",
            "recommendations",
            "next_steps",
        ]

        for field in required_fields:
            assert field in summary, f"Missing required field: {field}"

        # Check field types and values
        assert isinstance(summary["total_blockers"], int), "Total blockers not int"
        assert summary["total_blockers"] == 4, "Should have 4 total blockers"

        assert isinstance(summary["resolved_count"], int), "Resolved count not int"
        assert isinstance(summary["failed_count"], int), "Failed count not int"
        assert summary["resolved_count"] + summary["failed_count"] == summary["total_blockers"], "Counts don't add up"

        assert isinstance(summary["success_rate"], float), "Success rate not float"
        assert 0 <= summary["success_rate"] <= 1, "Success rate out of range"

        assert isinstance(summary["recommendations"], list), "Recommendations not list"
        assert isinstance(summary["next_steps"], list), "Next steps not list"

    def test_error_handling_in_resolution_workflow(self, temp_project_root):
        """Test error handling during resolution workflow."""
        # Create resolver with invalid project root
        invalid_root = temp_project_root / "nonexistent"
        resolver = CoreBlockerResolver(invalid_root)

        # Should handle errors gracefully
        results = resolver.resolve_all_blockers()

        # Should still return results for all blockers
        assert len(results) == 4, "Should return results for all blockers even with errors"

        # Results should indicate failures or have fallback behavior
        for result in results:
            assert isinstance(result, BlockerResult), "Should return valid result objects"
            assert result.blocker_name in [
                "grokfast_dependency",
                "rag_accuracy",
                "p2p_protocol_mismatch",
                "import_path_conflicts",
            ]

            # If failed, should have error information
            if result.status == BlockerStatus.FAILED:
                assert result.error is not None, "Failed result should have error info"
                assert len(result.error) > 0, "Error message should not be empty"

    def test_idempotent_resolution_behavior(self, resolver):
        """Test that running resolution multiple times is safe."""
        # Run resolution twice
        results1 = resolver.resolve_all_blockers()
        results2 = resolver.resolve_all_blockers()

        # Should have same number of results
        assert len(results1) == len(results2), "Different number of results on re-run"

        # Results should be consistent (same blockers addressed)
        blockers1 = {r.blocker_name for r in results1}
        blockers2 = {r.blocker_name for r in results2}
        assert blockers1 == blockers2, "Different blockers addressed on re-run"

        # Resolution should be idempotent (same outcomes)
        for r1, r2 in zip(results1, results2):
            if r1.blocker_name == r2.blocker_name:
                # Status might change from FAILED to RESOLVED if files created
                # But shouldn't go from RESOLVED to FAILED
                if r1.status == BlockerStatus.RESOLVED:
                    assert r2.status == BlockerStatus.RESOLVED, f"Resolution regressed for {r1.blocker_name}"


class TestCoreBlockerBehavioralContracts:
    """Behavioral contract tests for core blocker system."""

    @pytest.fixture
    def resolver(self):
        return CoreBlockerResolver()

    def test_blocker_result_consistency_contract(self, resolver):
        """Contract: BlockerResult objects maintain consistent structure."""
        # Run single blocker resolution
        result = resolver._resolve_grokfast_dependency()

        # Check result structure consistency
        assert hasattr(result, "blocker_name"), "Missing blocker_name attribute"
        assert hasattr(result, "status"), "Missing status attribute"
        assert hasattr(result, "message"), "Missing message attribute"
        assert hasattr(result, "details"), "Missing details attribute"
        assert hasattr(result, "error"), "Missing error attribute"

        # Check data types
        assert isinstance(result.blocker_name, str), "Blocker name not string"
        assert isinstance(result.status, BlockerStatus), "Status not BlockerStatus enum"
        assert isinstance(result.message, str), "Message not string"
        assert isinstance(result.details, dict), "Details not dict"
        assert result.error is None or isinstance(result.error, str), "Error not string or None"

        # Test to_dict conversion
        result_dict = result.to_dict()
        required_keys = {"blocker", "status", "message", "details", "error"}
        assert set(result_dict.keys()) == required_keys, "to_dict missing required keys"

    def test_resolver_initialization_contract(self):
        """Contract: Resolver initializes with valid defaults."""
        resolver = CoreBlockerResolver()

        # Should have project root
        assert resolver.project_root is not None, "Project root not set"
        assert isinstance(resolver.project_root, Path), "Project root not Path object"

        # Should have empty results initially
        assert resolver.results == [], "Initial results not empty"

        # Should have expected blocker list
        expected_blockers = ["grokfast_dependency", "rag_accuracy", "p2p_protocol_mismatch", "import_path_conflicts"]
        assert resolver.BLOCKERS == expected_blockers, "Unexpected blocker list"

    def test_resolution_completeness_contract(self, resolver):
        """Contract: Resolution always addresses all known blockers."""
        results = resolver.resolve_all_blockers()

        # Should have exactly 4 results
        assert len(results) == 4, f"Expected 4 results, got {len(results)}"

        # Should cover all expected blockers
        resolved_blockers = {r.blocker_name for r in results}
        expected_blockers = {"grokfast_dependency", "rag_accuracy", "p2p_protocol_mismatch", "import_path_conflicts"}
        assert resolved_blockers == expected_blockers, f"Missing blockers: {expected_blockers - resolved_blockers}"

        # All results should be valid
        for result in results:
            assert result.status in [
                BlockerStatus.RESOLVED,
                BlockerStatus.FAILED,
            ], f"Invalid status for {result.blocker_name}: {result.status}"

    def test_error_propagation_contract(self):
        """Contract: Errors are properly captured and don't crash system."""
        # Create resolver with invalid configuration
        resolver = CoreBlockerResolver(Path("/nonexistent/path"))

        # Should not raise exceptions
        try:
            results = resolver.resolve_all_blockers()

            # Should still return results
            assert len(results) > 0, "No results returned despite errors"

            # Failed results should have error information
            failed_results = [r for r in results if r.status == BlockerStatus.FAILED]
            for result in failed_results:
                assert result.error is not None, f"Failed result missing error: {result.blocker_name}"
                assert len(result.error) > 0, f"Empty error for failed result: {result.blocker_name}"

        except Exception as e:
            pytest.fail(f"Resolution should not raise exceptions: {e}")

    def test_summary_report_contract(self, resolver):
        """Contract: Summary reports maintain consistent format."""
        # Generate some results first
        resolver.resolve_all_blockers()

        # Generate multiple summary reports
        summary1 = resolver.generate_summary_report()
        summary2 = resolver.generate_summary_report()

        # Should have same structure
        assert set(summary1.keys()) == set(summary2.keys()), "Summary structure changed"

        # Should have same basic metrics (if no changes made)
        assert summary1["total_blockers"] == summary2["total_blockers"], "Total blockers changed"
        assert summary1["resolved_count"] == summary2["resolved_count"], "Resolved count changed"
        assert summary1["failed_count"] == summary2["failed_count"], "Failed count changed"

        # Recommendations and next steps should be lists
        assert isinstance(summary1["recommendations"], list), "Recommendations not list"
        assert isinstance(summary1["next_steps"], list), "Next steps not list"

        # Success rate should be consistent
        expected_rate = summary1["resolved_count"] / summary1["total_blockers"]
        assert abs(summary1["success_rate"] - expected_rate) < 0.001, "Success rate calculation error"
